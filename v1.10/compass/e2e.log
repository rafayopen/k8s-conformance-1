May 21 10:03:02.734: INFO: Overriding default scale value of zero to 1
May 21 10:03:02.735: INFO: Overriding default milliseconds value of zero to 5000
I0521 10:03:02.946919      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-252039709
I0521 10:03:02.947180      15 e2e.go:333] Starting e2e run "26151954-5cde-11e8-8768-12f5d52dbf0b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1526896982 - Will randomize all specs
Will run 141 of 836 specs

May 21 10:03:03.069: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:03:03.073: INFO: Waiting up to 4h0m0s for all (but 0) nodes to be schedulable
May 21 10:03:03.103: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 10:03:03.234: INFO: 69 / 69 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 10:03:03.234: INFO: expected 31 pod replicas in namespace 'kube-system', 31 are Running and Ready.
May 21 10:03:03.248: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 10:03:03.248: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt
May 21 10:03:03.260: INFO: e2e test version: v1.10.0
May 21 10:03:03.261: INFO: kube-apiserver version: v1.10.1
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:03:03.261: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:03:03.319212      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
May 21 10:03:03.379: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 2 Minute to see if the garbage collector mistakenly deletes the rs
STEP: expected 0 Deploymentss, got 1 Deployments
STEP: Gathering metrics
W0521 10:03:08.957613      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:03:08.957: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:03:08.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sqk6s" for this suite.
May 21 10:03:14.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:03:15.125: INFO: namespace: e2e-tests-gc-sqk6s, resource: bindings, ignored listing per whitelist
May 21 10:03:15.150: INFO: namespace e2e-tests-gc-sqk6s deletion completed in 6.18662949s

• [SLOW TEST:11.889 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd)  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:03:15.150: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:03:15.206879      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd)  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test override arguments
May 21 10:03:15.266: INFO: Waiting up to 5m0s for pod "client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-containers-bqxg7" to be "success or failure"
May 21 10:03:15.271: INFO: Pod "client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.313577ms
May 21 10:03:17.275: INFO: Pod "client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008723769s
May 21 10:03:19.281: INFO: Pod "client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014423347s
STEP: Saw pod success
May 21 10:03:19.281: INFO: Pod "client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:03:19.283: INFO: Trying to get logs from node master-192.168.130.2 pod client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:03:19.309: INFO: Waiting for pod client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b to disappear
May 21 10:03:19.311: INFO: Pod client-containers-2d9da405-5cde-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:03:19.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bqxg7" for this suite.
May 21 10:03:25.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:03:25.393: INFO: namespace: e2e-tests-containers-bqxg7, resource: bindings, ignored listing per whitelist
May 21 10:03:25.524: INFO: namespace e2e-tests-containers-bqxg7 deletion completed in 6.20567187s

• [SLOW TEST:10.374 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be able to override the image's default arguments (docker cmd)  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:03:25.525: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:03:25.572227      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-33cb396a-5cde-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:03:25.639: INFO: Waiting up to 5m0s for pod "pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-fjqh8" to be "success or failure"
May 21 10:03:25.649: INFO: Pod "pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.238162ms
May 21 10:03:27.654: INFO: Pod "pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015090878s
STEP: Saw pod success
May 21 10:03:27.654: INFO: Pod "pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:03:27.658: INFO: Trying to get logs from node master-192.168.130.1 pod pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:03:27.686: INFO: Waiting for pod pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b to disappear
May 21 10:03:27.704: INFO: Pod pod-secrets-33cbe7cc-5cde-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:03:27.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fjqh8" for this suite.
May 21 10:03:33.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:03:33.826: INFO: namespace: e2e-tests-secrets-fjqh8, resource: bindings, ignored listing per whitelist
May 21 10:03:33.936: INFO: namespace e2e-tests-secrets-fjqh8 deletion completed in 6.219613121s

• [SLOW TEST:8.412 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:03:33.937: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:03:33.972781      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 10:03:34.021: INFO: Waiting up to 1m0s for all nodes to be ready
May 21 10:04:34.088: INFO: Waiting for terminating namespaces to be deleted...
May 21 10:04:34.095: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 10:04:34.130: INFO: 69 / 69 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 10:04:34.130: INFO: expected 31 pod replicas in namespace 'kube-system', 31 are Running and Ready.
May 21 10:04:34.144: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 10:04:34.144: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.1 before test
May 21 10:04:34.154: INFO: kube-apiserver-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.154: INFO: kube-dns-v22-864bd47fb9-fxkqk from kube-system started at 2018-05-21 05:22:09 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container dnsmasq ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container kubedns ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:04:34.154: INFO: storage-provisioner-nfs-provisioner-nfs-v1-0-bffdf9746-h8fs9 from kube-system started at 2018-05-21 05:31:18 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.154: INFO: kube-scheduler-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.154: INFO: sonobuoy from sonobuoy started at 2018-05-21 10:02:59 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 10:04:34.154: INFO: apiserver-provider-ipvsdr-preset-949858699-jz4x9 from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:04:34.154: INFO: logging-fluentd-fluentd-v1-0-z76bf from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.154: INFO: apiserver-proxy-nginx-preset-865784f6fb-dp8vr from kube-system started at 2018-05-21 05:21:38 +0000 UTC (2 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container proxy ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:04:34.154: INFO: kube-controller-manager-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.154: INFO: canal-bc599 from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:04:34.154: INFO: exporters-gpu-gpu-v1-0-jkdz2 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.154: INFO: exporters-node-node-v1-0-sxnm2 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.154: INFO: monitoring-prometheus-prometheus-v1-0-0 from kube-system started at 2018-05-21 05:31:22 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.154: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container c1 ready: true, restart count 0
May 21 10:04:34.154: INFO: 	Container c2 ready: true, restart count 0
May 21 10:04:34.154: INFO: kube-proxy-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.154: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.2 before test
May 21 10:04:34.187: INFO: notify-postgres-postgres-v1-0-57db6fb8d5-trcw7 from default started at 2018-05-21 05:31:59 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container postgres ready: true, restart count 0
May 21 10:04:34.187: INFO: kubernetes-admin-mongo-mongo-v1-0-78cb68d655-9ndmv from default started at 2018-05-21 05:32:41 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: kube-scheduler-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.187: INFO: kube-proxy-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.187: INFO: logging-fluentd-fluentd-v1-0-jqxwz from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.187: INFO: logging-elasticsearch-elasticsearch-v1-0-0 from kube-system started at 2018-05-21 05:31:10 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: storage-admin-admin-v1-0-786cdd76cf-p4jtp from default started at 2018-05-21 05:31:33 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: config-gc-gc-v1-0-747b8cc554-z8d5g from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 5
May 21 10:04:34.187: INFO: kube-apiserver-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.187: INFO: exporters-node-node-v1-0-5lnp5 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: storage-controller-controller-v1-0-55f4c7c5b4-qb5hh from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 4
May 21 10:04:34.187: INFO: dex-cauth-cauth-v1-0-8656d55578-jl6lf from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container cauth ready: true, restart count 6
May 21 10:04:34.187: INFO: config-sync-sync-v1-0-78c844cdcc-q6zns from default started at 2018-05-21 05:31:47 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: kube-controller-manager-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.187: INFO: canal-5z7qg from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:04:34.187: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:04:34.187: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:04:34.187: INFO: apiserver-proxy-nginx-preset-865784f6fb-j5p5k from kube-system started at 2018-05-21 05:21:39 +0000 UTC (2 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container proxy ready: true, restart count 0
May 21 10:04:34.187: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:04:34.187: INFO: apiserver-provider-ipvsdr-preset-949858699-glksh from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:04:34.187: INFO: kube-dns-autoscaler-v22-757d579667-dmf9r from kube-system started at 2018-05-21 05:21:46 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container autoscaler ready: true, restart count 0
May 21 10:04:34.187: INFO: kube-dns-v22-864bd47fb9-d4lms from kube-system started at 2018-05-21 05:21:47 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container dnsmasq ready: true, restart count 0
May 21 10:04:34.187: INFO: 	Container kubedns ready: true, restart count 0
May 21 10:04:34.187: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:04:34.187: INFO: default-http-backend-7558c79bdc-vrdsd from default started at 2018-05-21 05:21:38 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container default-http-backend ready: true, restart count 0
May 21 10:04:34.187: INFO: exporters-gpu-gpu-v1-0-pfgm6 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: clever-kubeflow-admin-kubeflow-admin-v1-0-6cd6f78557-dlz46 from default started at 2018-05-21 05:31:36 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.187: INFO: dex-caidex-caidex-v1-0-7fc9cddc49-t8mdt from default started at 2018-05-21 05:31:48 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.187: INFO: 	Container cauth ready: true, restart count 6
May 21 10:04:34.187: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.3 before test
May 21 10:04:34.260: INFO: heketi-69886b6db9-vd5gz from default started at 2018-05-21 05:22:10 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container heketi ready: true, restart count 0
May 21 10:04:34.260: INFO: cluster-mongo-mongo-v1-0-8665b5cbfd-w4lfn from default started at 2018-05-21 05:31:38 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: console-web-redis-redis-v1-0-f9d568d94-rvmh7 from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: kube-controller-manager-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.260: INFO: kube-scheduler-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.260: INFO: apiserver-provider-ipvsdr-preset-949858699-h46q4 from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:04:34.260: INFO: statistician-server-server-v1-0-6f4db6b9f6-r7ptq from default started at 2018-05-21 05:31:48 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: clever-mongo-mongo-v1-0-68dcbfcc8-bzhhb from default started at 2018-05-21 05:32:41 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: logging-elasticsearch-elasticsearch-v1-0-1 from kube-system started at 2018-05-21 05:32:58 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: exporters-node-node-v1-0-dsvzf from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: logging-eventer-eventer-v1-0-76954b748b-4kjj7 from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.260: INFO: app-admin-admin-v1-0-77b745f8f-vpxjb from default started at 2018-05-21 05:31:40 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: exporters-gpu-gpu-v1-0-j62dq from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: monitoring-kube-state-metrics-kube-state-metrics-v1-0-5db5lrxwt from kube-system started at 2018-05-21 05:31:19 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container kube-state-metrics ready: true, restart count 0
May 21 10:04:34.260: INFO: tenant-controller-controller-v1-0-7ffcd7969b-xq5dc from kube-system started at 2018-05-21 05:31:20 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 1
May 21 10:04:34.260: INFO: helm-registry-registry-v1-0-5bf6f7f68f-6bd98 from default started at 2018-05-21 05:33:48 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: canal-2lnvt from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:04:34.260: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:04:34.260: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:04:34.260: INFO: apiserver-proxy-nginx-preset-865784f6fb-w2flj from kube-system started at 2018-05-21 05:21:38 +0000 UTC (2 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container proxy ready: true, restart count 0
May 21 10:04:34.260: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:04:34.260: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-2dswv from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.260: INFO: cargo-admin-admin-v1-0-748bdbfdf5-cwx76 from default started at 2018-05-21 05:31:31 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.260: INFO: monitoring-operator-operator-v1-0-56484b7647-wg8xf from default started at 2018-05-21 05:31:47 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 5
May 21 10:04:34.260: INFO: kube-apiserver-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.260: INFO: kube-proxy-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.260: INFO: logging-fluentd-fluentd-v1-0-87742 from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.260: INFO: 	Container c0 ready: true, restart count 7
May 21 10:04:34.260: INFO: 
Logging pods the kubelet thinks is on node node-192.168.130.4 before test
May 21 10:04:34.276: INFO: hybrid-controller-manager-controller-manager-v1-0-7f864846p9dll from kube-system started at 2018-05-21 05:31:11 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.276: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.276: INFO: exporters-gpu-gpu-v1-0-jrw8h from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.276: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.276: INFO: exporters-elasticsearch-elasticsearch-v1-0-6d84c684f5-fqgv8 from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.276: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: open-api-server-server-v1-0-575fb8d756-v5bsp from default started at 2018-05-21 05:31:22 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: alerting-notifier-notifier-v1-0-5fd6f8f86b-2xg5r from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: config-mongo-mongo-v1-0-76f5dbc994-xpf7x from default started at 2018-05-21 05:33:41 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: release-controller-v0.2.2-67cd497946-lx95q from kube-system started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container controller ready: true, restart count 0
May 21 10:04:34.277: INFO: config-admission-admission-v1-0-5d997c56d9-2mh59 from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-9btgl from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: license-server-server-v1-0-54675fc555-tsf6q from default started at 2018-05-21 05:31:27 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container license ready: true, restart count 0
May 21 10:04:34.277: INFO: cluster-admin-admin-v1-0-796967fcff-gkffj from default started at 2018-05-21 05:31:35 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 4
May 21 10:04:34.277: INFO: kube-proxy-node-192.168.130.4 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.277: INFO: logging-fluentd-fluentd-v1-0-zh7xb from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.277: INFO: am-mysql-v2.0-c6db7f6b5-vk465 from default started at 2018-05-21 05:28:54 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container am-mysql ready: true, restart count 0
May 21 10:04:34.277: INFO: exporters-node-node-v1-0-4tt9v from kube-system started at 2018-05-21 05:31:15 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: logging-elasticsearch-elasticsearch-v1-0-2 from kube-system started at 2018-05-21 05:35:35 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: am-minion-v0.0.3-6c77b79c44-znc7x from default started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container am-minion ready: true, restart count 0
May 21 10:04:34.277: INFO: monitoring-admin-admin-v1-0-58bdfdf6c9-45tl9 from default started at 2018-05-21 05:31:44 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 2
May 21 10:04:34.277: INFO: clever-postgres-postgres-v1-0-574b75cd65-mkrp4 from default started at 2018-05-21 05:33:43 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: devops-admin-admin-v1-0-6db9f89cd6-8d7sr from default started at 2018-05-21 05:31:43 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 5
May 21 10:04:34.277: INFO: cyclone-server-server-v1-0-5d9d48f887-9dl77 from default started at 2018-05-21 05:32:37 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 2
May 21 10:04:34.277: INFO: cluster-addon-addon-v1-0-5c4b74889-mdwqc from kube-system started at 2018-05-21 05:31:15 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: storage-controller-k-controller-k-v1-0-5549d55d89-g5vmg from kube-system started at 2018-05-21 05:31:18 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: dex-postgres-postgres-v1-0-79d84d7fd8-ptr85 from default started at 2018-05-21 05:33:44 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: canal-dwmxv from kube-system started at 2018-05-21 05:22:10 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:04:34.277: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:04:34.277: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:04:34.277: INFO: cluster-machine-machine-v1-0-5675994fcd-56s7q from default started at 2018-05-21 05:31:36 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: clever-web-web-v1-0-8564f766cc-78dwb from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: cluster-controller-controller-v1-0-6574f8897b-f7mtl from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: logging-admin-admin-v1-0-668cc758bb-s6r89 from default started at 2018-05-21 05:31:40 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: hodor-server-server-v1-0-67c74dc768-c6jhn from default started at 2018-05-21 05:31:43 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.277: INFO: loadbalancer-admin-admin-v1-0-c774889df-78nl8 from default started at 2018-05-21 05:31:22 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.277: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.277: INFO: 
Logging pods the kubelet thinks is on node node-192.168.130.5 before test
May 21 10:04:34.291: INFO: canal-4rctf from kube-system started at 2018-05-21 05:22:10 +0000 UTC (3 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:04:34.292: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:04:34.292: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:04:34.292: INFO: exporters-node-node-v1-0-q5zcw from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: alerting-manager-manager-v1-0-85f76b45d7-7mnwh from default started at 2018-05-21 05:31:32 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: cargo-mongo-mongo-v1-0-7997dc6b94-czd8f from default started at 2018-05-21 05:33:42 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: cyclone-mongo-mongo-v1-0-7d4c8684b6-jsd47 from default started at 2018-05-21 05:34:21 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: config-reference-reference-v1-0-5b964f9ccc-66k9t from kube-system started at 2018-05-21 05:31:13 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: monitoring-grafana-grafana-v1-0-86c8b866d4-mbbnl from kube-system started at 2018-05-21 05:31:19 +0000 UTC (2 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: 	Container c1 ready: true, restart count 0
May 21 10:04:34.292: INFO: config-admin-admin-v1-0-5f674d5fb9-gfdk4 from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: monitoring-mongo-mongo-v1-0-7f6984c8fd-2z6ns from default started at 2018-05-21 05:32:30 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: notify-admin-admin-v1-0-7fd9bbf9c8-b7w4n from default started at 2018-05-21 05:31:29 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: logging-kibana-kibana-v1-0-68c977f968-sfmvf from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: logging-fluentd-fluentd-v1-0-rstpn from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 6
May 21 10:04:34.292: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-wwhnc from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: exporters-gpu-gpu-v1-0-s89lk from kube-system started at 2018-05-21 05:31:13 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: exporters-app-app-v1-0-8b7f56b56-49mdb from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: clever-tf-operator-tf-operator-v1-0-557cfb5974-dbn9p from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: am-master-v3.0-56f955cdc9-4r2nd from default started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container am-master ready: true, restart count 2
May 21 10:04:34.292: INFO: console-web-web-web-v1-0-559b9c4967-2st5h from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 5
May 21 10:04:34.292: INFO: gitbook-server-server-v1-0-756c7d7b64-cmk9q from default started at 2018-05-21 05:31:46 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: console-web-mongo-mongo-v1-0-7584454d5d-2w7f2 from default started at 2018-05-21 05:33:45 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: sonobuoy-e2e-job-961741dcd1894b0e from sonobuoy started at 2018-05-21 10:03:01 +0000 UTC (2 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container e2e ready: true, restart count 0
May 21 10:04:34.292: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 10:04:34.292: INFO: kube-proxy-node-192.168.130.5 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:04:34.292: INFO: canary-release-controller-controller-v1-0-6cf74f987c-gclpn from kube-system started at 2018-05-21 05:31:12 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: devops-mongo-mongo-v1-0-fdb9d968b-l85bz from default started at 2018-05-21 05:33:43 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: monitoring-heapster-heapster-v1-0-f6f95b846-nfl7k from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: kubernetes-admin-server-server-v1-0-5dbdc9f7f9-crqzr from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: dex-mongo-mongo-v1-0-5b65cbcdcd-kkswv from default started at 2018-05-21 05:33:59 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: am-minion-v0.0.3-67d4cf786d-8wwsd from kube-system started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container am-minion ready: true, restart count 0
May 21 10:04:34.292: INFO: loadbalancer-controller-controller-v1-0-6574dbc55b-npvdz from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: storage-admission-admission-v1-0-54cb855f9f-kng5q from kube-system started at 2018-05-21 05:31:16 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: clever-redis-redis-v1-0-76f69b9d69-ddhf4 from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: tenant-admin-admin-v1-0-68767d7bf8-gbm2r from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
May 21 10:04:34.292: INFO: clever-storage-manager-storage-manager-v1-0-847cc98444-fnkbx from default started at 2018-05-21 05:31:44 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 5
May 21 10:04:34.292: INFO: clever-mysql-mysql-v1-0-6bff585648-q4v45 from default started at 2018-05-21 05:34:02 +0000 UTC (1 container statuses recorded)
May 21 10:04:34.292: INFO: 	Container c0 ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1530a0cc9de32b25], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:04:35.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-79qf8" for this suite.
May 21 10:04:57.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:04:57.522: INFO: namespace: e2e-tests-sched-pred-79qf8, resource: bindings, ignored listing per whitelist
May 21 10:04:57.629: INFO: namespace e2e-tests-sched-pred-79qf8 deletion completed in 22.258336105s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:83.692 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update labels on modification [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:04:57.629: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:04:57.671209      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating the pod
May 21 10:05:00.284: INFO: Successfully updated pod "labelsupdate6ab25683-5cde-11e8-8768-12f5d52dbf0b"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:05:04.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p4tk9" for this suite.
May 21 10:05:26.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:05:26.391: INFO: namespace: e2e-tests-projected-p4tk9, resource: bindings, ignored listing per whitelist
May 21 10:05:26.527: INFO: namespace e2e-tests-projected-p4tk9 deletion completed in 22.196326978s

• [SLOW TEST:28.898 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:05:26.527: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:05:26.562707      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:05:26.634: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-m2l2s" to be "success or failure"
May 21 10:05:26.639: INFO: Pod "downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.003227ms
May 21 10:05:28.643: INFO: Pod "downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.009778245s
May 21 10:05:30.649: INFO: Pod "downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014872961s
STEP: Saw pod success
May 21 10:05:30.649: INFO: Pod "downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:05:30.652: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:05:30.703: INFO: Waiting for pod downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b to disappear
May 21 10:05:30.713: INFO: Pod downwardapi-volume-7bea66c2-5cde-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:05:30.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m2l2s" for this suite.
May 21 10:05:36.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:05:36.980: INFO: namespace: e2e-tests-downward-api-m2l2s, resource: bindings, ignored listing per whitelist
May 21 10:05:37.010: INFO: namespace e2e-tests-downward-api-m2l2s deletion completed in 6.292127388s

• [SLOW TEST:10.482 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:05:37.010: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:05:37.055309      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:05:37.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-r9k8d" to be "success or failure"
May 21 10:05:37.149: INFO: Pod "downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.563594ms
May 21 10:05:39.153: INFO: Pod "downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01612263s
STEP: Saw pod success
May 21 10:05:39.154: INFO: Pod "downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:05:39.156: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:05:39.181: INFO: Waiting for pod downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b to disappear
May 21 10:05:39.185: INFO: Pod downwardapi-volume-822d5373-5cde-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:05:39.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r9k8d" for this suite.
May 21 10:05:45.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:05:45.366: INFO: namespace: e2e-tests-downward-api-r9k8d, resource: bindings, ignored listing per whitelist
May 21 10:05:45.434: INFO: namespace e2e-tests-downward-api-r9k8d deletion completed in 6.240410964s

• [SLOW TEST:8.424 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:05:45.434: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:05:45.480455      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-v5rck
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a new StaefulSet
May 21 10:05:45.601: INFO: Found 0 stateful pods, waiting for 3
May 21 10:05:55.609: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:05:55.609: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:05:55.609: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
May 21 10:05:55.644: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 21 10:06:05.688: INFO: Updating stateful set ss2
May 21 10:06:05.700: INFO: Waiting for Pod e2e-tests-statefulset-v5rck/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
May 21 10:06:15.768: INFO: Found 1 stateful pods, waiting for 3
May 21 10:06:25.776: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:06:25.776: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:06:25.776: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 21 10:06:25.813: INFO: Updating stateful set ss2
May 21 10:06:25.819: INFO: Waiting for Pod e2e-tests-statefulset-v5rck/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 21 10:06:35.855: INFO: Updating stateful set ss2
May 21 10:06:35.861: INFO: Waiting for StatefulSet e2e-tests-statefulset-v5rck/ss2 to complete update
May 21 10:06:35.861: INFO: Waiting for Pod e2e-tests-statefulset-v5rck/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 21 10:06:45.878: INFO: Deleting all statefulset in ns e2e-tests-statefulset-v5rck
May 21 10:06:45.885: INFO: Scaling statefulset ss2 to 0
May 21 10:07:05.909: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:07:05.917: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:07:05.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-v5rck" for this suite.
May 21 10:07:11.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:07:12.074: INFO: namespace: e2e-tests-statefulset-v5rck, resource: bindings, ignored listing per whitelist
May 21 10:07:12.152: INFO: namespace e2e-tests-statefulset-v5rck deletion completed in 6.19593191s

• [SLOW TEST:86.718 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:07:12.153: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:07:12.194994      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-bmsdv
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bmsdv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bmsdv
May 21 10:07:12.264: INFO: Found 0 stateful pods, waiting for 1
May 21 10:07:22.277: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 21 10:07:22.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:07:22.688: INFO: stderr: ""
May 21 10:07:22.688: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:07:22.693: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 10:07:32.699: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:07:32.699: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:07:32.720: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
May 21 10:07:32.720: INFO: ss-0  node-192.168.130.4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  }]
May 21 10:07:32.720: INFO: 
May 21 10:07:32.720: INFO: StatefulSet ss has not reached scale 3, at 1
May 21 10:07:33.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99472256s
May 21 10:07:34.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985811242s
May 21 10:07:35.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97839129s
May 21 10:07:36.748: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972597161s
May 21 10:07:37.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.966849273s
May 21 10:07:38.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960144195s
May 21 10:07:39.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95398012s
May 21 10:07:40.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.948503592s
May 21 10:07:41.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 940.210526ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bmsdv
May 21 10:07:42.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:07:43.132: INFO: stderr: ""
May 21 10:07:43.132: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:07:43.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:07:43.463: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
May 21 10:07:43.463: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
May 21 10:07:43.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:07:43.822: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
May 21 10:07:43.822: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
May 21 10:07:43.827: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 21 10:07:53.836: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:07:53.836: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:07:53.836: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 21 10:07:53.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:07:54.164: INFO: stderr: ""
May 21 10:07:54.164: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:07:54.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:07:54.498: INFO: stderr: ""
May 21 10:07:54.498: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:07:54.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-bmsdv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:07:54.930: INFO: stderr: ""
May 21 10:07:54.930: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:07:54.930: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:07:54.944: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 21 10:08:04.956: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:08:04.956: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:08:04.956: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:08:04.972: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:04.972: INFO: ss-0  node-192.168.130.4    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  }]
May 21 10:08:04.972: INFO: ss-1  master-192.168.130.1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:04.972: INFO: ss-2  master-192.168.130.3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:04.972: INFO: 
May 21 10:08:04.972: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 10:08:05.977: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:05.977: INFO: ss-0  node-192.168.130.4    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  }]
May 21 10:08:05.977: INFO: ss-1  master-192.168.130.1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:05.977: INFO: ss-2  master-192.168.130.3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:05.977: INFO: 
May 21 10:08:05.977: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 10:08:06.983: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:06.983: INFO: ss-0  node-192.168.130.4    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:12 +0000 UTC  }]
May 21 10:08:06.983: INFO: ss-1  master-192.168.130.1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:06.983: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:06.983: INFO: 
May 21 10:08:06.983: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 10:08:07.987: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:07.987: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:07.988: INFO: 
May 21 10:08:07.988: INFO: StatefulSet ss has not reached scale 0, at 1
May 21 10:08:08.993: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:08.993: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:08.993: INFO: 
May 21 10:08:08.993: INFO: StatefulSet ss has not reached scale 0, at 1
May 21 10:08:09.998: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:09.998: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:09.998: INFO: 
May 21 10:08:09.998: INFO: StatefulSet ss has not reached scale 0, at 1
May 21 10:08:11.005: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:11.005: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:11.005: INFO: 
May 21 10:08:11.005: INFO: StatefulSet ss has not reached scale 0, at 1
May 21 10:08:12.016: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:12.016: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:12.016: INFO: 
May 21 10:08:12.016: INFO: StatefulSet ss has not reached scale 0, at 1
May 21 10:08:13.022: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:13.022: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:13.022: INFO: 
May 21 10:08:13.022: INFO: StatefulSet ss has not reached scale 0, at 1
May 21 10:08:14.028: INFO: POD   NODE                  PHASE    GRACE  CONDITIONS
May 21 10:08:14.028: INFO: ss-2  master-192.168.130.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:07:32 +0000 UTC  }]
May 21 10:08:14.028: INFO: 
May 21 10:08:14.028: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bmsdv
May 21 10:08:15.036: INFO: Scaling statefulset ss to 0
May 21 10:08:15.048: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 21 10:08:15.052: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bmsdv
May 21 10:08:15.060: INFO: Scaling statefulset ss to 0
May 21 10:08:15.070: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:08:15.074: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:08:15.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bmsdv" for this suite.
May 21 10:08:21.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:08:21.249: INFO: namespace: e2e-tests-statefulset-bmsdv, resource: bindings, ignored listing per whitelist
May 21 10:08:21.278: INFO: namespace e2e-tests-statefulset-bmsdv deletion completed in 6.178561404s

• [SLOW TEST:69.125 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:08:21.278: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:08:21.322126      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:08:45.402: INFO: Container started at 2018-05-21 10:08:22 +0000 UTC, pod became ready at 2018-05-21 10:08:44 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:08:45.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qmq57" for this suite.
May 21 10:09:07.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:09:07.578: INFO: namespace: e2e-tests-container-probe-qmq57, resource: bindings, ignored listing per whitelist
May 21 10:09:07.609: INFO: namespace e2e-tests-container-probe-qmq57 deletion completed in 22.198354428s

• [SLOW TEST:46.331 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  with readiness probe should not be ready before initial delay and never restart  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:09:07.609: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:09:07.656314      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-map-ffb2a605-5cde-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:09:07.732: INFO: Waiting up to 5m0s for pod "pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-bvpjc" to be "success or failure"
May 21 10:09:07.736: INFO: Pod "pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.384321ms
May 21 10:09:09.741: INFO: Pod "pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008040083s
STEP: Saw pod success
May 21 10:09:09.741: INFO: Pod "pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:09:09.743: INFO: Trying to get logs from node node-192.168.130.5 pod pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:09:09.770: INFO: Waiting for pod pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b to disappear
May 21 10:09:09.772: INFO: Pod pod-configmaps-ffb38af0-5cde-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:09:09.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bvpjc" for this suite.
May 21 10:09:15.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:09:16.000: INFO: namespace: e2e-tests-configmap-bvpjc, resource: bindings, ignored listing per whitelist
May 21 10:09:16.022: INFO: namespace e2e-tests-configmap-bvpjc deletion completed in 6.242800599s

• [SLOW TEST:8.413 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:09:16.022: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:09:16.060433      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:09:16.168: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 21 10:09:16.179: INFO: Number of nodes with available pods: 0
May 21 10:09:16.179: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 21 10:09:16.202: INFO: Number of nodes with available pods: 0
May 21 10:09:16.202: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:09:17.207: INFO: Number of nodes with available pods: 0
May 21 10:09:17.207: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:09:18.206: INFO: Number of nodes with available pods: 1
May 21 10:09:18.206: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 21 10:09:18.230: INFO: Number of nodes with available pods: 1
May 21 10:09:18.230: INFO: Number of running nodes: 0, number of available pods: 1
May 21 10:09:19.235: INFO: Number of nodes with available pods: 0
May 21 10:09:19.235: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 21 10:09:19.246: INFO: Number of nodes with available pods: 0
May 21 10:09:19.246: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:09:20.252: INFO: Number of nodes with available pods: 0
May 21 10:09:20.252: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:09:21.251: INFO: Number of nodes with available pods: 0
May 21 10:09:21.251: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:09:22.252: INFO: Number of nodes with available pods: 0
May 21 10:09:22.252: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:09:23.251: INFO: Number of nodes with available pods: 1
May 21 10:09:23.251: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:66
STEP: Deleting DaemonSet "daemon-set" with reaper
May 21 10:09:35.323: INFO: Number of nodes with available pods: 0
May 21 10:09:35.323: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:09:35.340: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8mh6q/daemonsets","resourceVersion":"59075"},"items":null}

May 21 10:09:35.344: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8mh6q/pods","resourceVersion":"59075"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:09:35.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8mh6q" for this suite.
May 21 10:09:43.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:09:43.490: INFO: namespace: e2e-tests-daemonsets-8mh6q, resource: bindings, ignored listing per whitelist
May 21 10:09:43.992: INFO: namespace e2e-tests-daemonsets-8mh6q deletion completed in 8.60264773s

• [SLOW TEST:27.970 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:09:43.992: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:09:44.040659      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:09:44.167: INFO: Waiting up to 5m0s for pod "downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-bdbzs" to be "success or failure"
May 21 10:09:44.196: INFO: Pod "downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.784832ms
May 21 10:09:46.202: INFO: Pod "downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034814207s
STEP: Saw pod success
May 21 10:09:46.202: INFO: Pod "downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:09:46.205: INFO: Trying to get logs from node node-192.168.130.4 pod downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:09:46.244: INFO: Waiting for pod downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:09:46.249: INFO: Pod downwardapi-volume-156703c9-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:09:46.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bdbzs" for this suite.
May 21 10:09:52.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:09:52.371: INFO: namespace: e2e-tests-projected-bdbzs, resource: bindings, ignored listing per whitelist
May 21 10:09:52.446: INFO: namespace e2e-tests-projected-bdbzs deletion completed in 6.190608059s

• [SLOW TEST:8.454 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:09:52.447: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:09:52.489514      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating the pod
May 21 10:09:57.091: INFO: Successfully updated pod "labelsupdate1a699ec0-5cdf-11e8-8768-12f5d52dbf0b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:09:59.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-97xzn" for this suite.
May 21 10:10:21.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:10:21.250: INFO: namespace: e2e-tests-downward-api-97xzn, resource: bindings, ignored listing per whitelist
May 21 10:10:21.327: INFO: namespace e2e-tests-downward-api-97xzn deletion completed in 22.203836776s

• [SLOW TEST:28.880 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:10:21.327: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:10:21.377990      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-map-2ba2baa0-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:10:21.449: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-922s6" to be "success or failure"
May 21 10:10:21.452: INFO: Pod "pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.156041ms
May 21 10:10:23.457: INFO: Pod "pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008166503s
STEP: Saw pod success
May 21 10:10:23.457: INFO: Pod "pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:10:23.460: INFO: Trying to get logs from node master-192.168.130.2 pod pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:10:23.482: INFO: Waiting for pod pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:10:23.487: INFO: Pod pod-projected-configmaps-2ba3c70f-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:10:23.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-922s6" for this suite.
May 21 10:10:29.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:10:29.671: INFO: namespace: e2e-tests-projected-922s6, resource: bindings, ignored listing per whitelist
May 21 10:10:29.684: INFO: namespace e2e-tests-projected-922s6 deletion completed in 6.175930666s

• [SLOW TEST:8.357 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:10:29.685: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:10:29.722171      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:10:29.787: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 21 10:10:29.799: INFO: Number of nodes with available pods: 0
May 21 10:10:29.799: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:10:30.817: INFO: Number of nodes with available pods: 0
May 21 10:10:30.817: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:10:31.830: INFO: Number of nodes with available pods: 2
May 21 10:10:31.830: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:10:32.813: INFO: Number of nodes with available pods: 5
May 21 10:10:32.813: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 21 10:10:32.855: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:32.855: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:32.855: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:32.855: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:32.855: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:33.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:33.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:33.869: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:33.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:33.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:34.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:34.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:34.869: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:34.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:34.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:35.867: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:35.867: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:35.867: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:35.867: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:35.867: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:35.867: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:36.874: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:36.874: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:36.874: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:36.874: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:36.874: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:36.874: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:37.874: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:37.874: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:37.874: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:37.874: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:37.874: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:37.874: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:38.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:38.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:38.868: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:38.868: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:38.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:38.868: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:39.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:39.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:39.869: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:39.869: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:39.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:39.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:40.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:40.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:40.868: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:40.868: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:40.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:40.868: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:41.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:41.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:41.868: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:41.868: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:41.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:41.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:42.870: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:42.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:42.870: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:42.870: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:42.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:42.870: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:43.870: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:43.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:43.870: INFO: Wrong image for pod: daemon-set-g5x4m. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:43.870: INFO: Pod daemon-set-g5x4m is not available
May 21 10:10:43.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:43.870: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:44.867: INFO: Pod daemon-set-6zxnj is not available
May 21 10:10:44.867: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:44.867: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:44.867: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:44.867: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:45.868: INFO: Pod daemon-set-6zxnj is not available
May 21 10:10:45.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:45.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:45.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:45.868: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:46.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:46.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:46.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:46.868: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:47.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:47.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:47.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:47.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:47.869: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:48.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:48.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:48.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:48.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:48.869: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:49.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:49.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:49.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:49.868: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:49.868: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:50.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:50.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:50.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:50.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:50.869: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:51.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:51.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:51.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:51.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:51.869: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:52.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:52.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:52.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:52.869: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:52.869: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:53.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:53.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:53.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:53.868: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:53.868: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:54.875: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:54.875: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:54.875: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:54.875: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:54.875: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:55.873: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:55.873: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:55.873: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:55.873: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:55.873: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:56.873: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:56.873: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:56.873: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:56.873: INFO: Wrong image for pod: daemon-set-m6c89. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:56.873: INFO: Pod daemon-set-m6c89 is not available
May 21 10:10:57.871: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:57.871: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:57.871: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:57.871: INFO: Pod daemon-set-qhnw6 is not available
May 21 10:10:58.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:58.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:58.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:59.870: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:59.870: INFO: Pod daemon-set-bklqm is not available
May 21 10:10:59.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:10:59.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:00.870: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:00.870: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:00.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:00.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:01.874: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:01.874: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:01.874: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:01.874: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:02.868: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:02.868: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:02.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:02.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:03.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:03.869: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:03.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:03.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:04.869: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:04.869: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:04.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:04.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:05.870: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:05.870: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:05.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:05.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:06.870: INFO: Wrong image for pod: daemon-set-bklqm. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:06.870: INFO: Pod daemon-set-bklqm is not available
May 21 10:11:06.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:06.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:07.876: INFO: Pod daemon-set-b6z5l is not available
May 21 10:11:07.876: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:07.876: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:08.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:08.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:09.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:09.868: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:09.868: INFO: Pod daemon-set-m5mnt is not available
May 21 10:11:10.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:10.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:10.869: INFO: Pod daemon-set-m5mnt is not available
May 21 10:11:11.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:11.870: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:11.870: INFO: Pod daemon-set-m5mnt is not available
May 21 10:11:12.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:12.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:12.869: INFO: Pod daemon-set-m5mnt is not available
May 21 10:11:13.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:13.869: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:13.869: INFO: Pod daemon-set-m5mnt is not available
May 21 10:11:14.873: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:14.873: INFO: Wrong image for pod: daemon-set-m5mnt. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:14.873: INFO: Pod daemon-set-m5mnt is not available
May 21 10:11:15.867: INFO: Pod daemon-set-f6z52 is not available
May 21 10:11:15.867: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:16.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:17.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:17.868: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:18.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:18.869: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:19.870: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:19.870: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:20.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:20.869: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:21.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:21.869: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:22.868: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:22.868: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:23.869: INFO: Wrong image for pod: daemon-set-fs52s. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 21 10:11:23.869: INFO: Pod daemon-set-fs52s is not available
May 21 10:11:25.868: INFO: Pod daemon-set-gshdj is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 21 10:11:25.888: INFO: Number of nodes with available pods: 4
May 21 10:11:25.888: INFO: Node master-192.168.130.3 is running more than one daemon pod
May 21 10:11:26.901: INFO: Number of nodes with available pods: 4
May 21 10:11:26.901: INFO: Node master-192.168.130.3 is running more than one daemon pod
May 21 10:11:27.900: INFO: Number of nodes with available pods: 5
May 21 10:11:27.900: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:66
STEP: Deleting DaemonSet "daemon-set" with reaper
May 21 10:11:37.954: INFO: Number of nodes with available pods: 0
May 21 10:11:37.954: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:11:37.958: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xtrvk/daemonsets","resourceVersion":"59601"},"items":null}

May 21 10:11:37.961: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xtrvk/pods","resourceVersion":"59601"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:11:37.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xtrvk" for this suite.
May 21 10:11:44.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:11:44.101: INFO: namespace: e2e-tests-daemonsets-xtrvk, resource: bindings, ignored listing per whitelist
May 21 10:11:44.243: INFO: namespace e2e-tests-daemonsets-xtrvk deletion completed in 6.256706057s

• [SLOW TEST:74.559 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:11:44.244: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:11:44.282674      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name s-test-opt-del-5d11859e-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating secret with name s-test-opt-upd-5d11864b-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5d11859e-5cdf-11e8-8768-12f5d52dbf0b
STEP: Updating secret s-test-opt-upd-5d11864b-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating secret with name s-test-opt-create-5d11866e-5cdf-11e8-8768-12f5d52dbf0b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:11:48.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lgkzm" for this suite.
May 21 10:12:10.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:12:10.647: INFO: namespace: e2e-tests-projected-lgkzm, resource: bindings, ignored listing per whitelist
May 21 10:12:10.700: INFO: namespace e2e-tests-projected-lgkzm deletion completed in 22.199673049s

• [SLOW TEST:26.457 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:12:10.701: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:12:10.746200      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 10:12:10.797: INFO: Waiting up to 1m0s for all nodes to be ready
May 21 10:13:10.872: INFO: Waiting for terminating namespaces to be deleted...
May 21 10:13:10.881: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 10:13:10.907: INFO: 69 / 69 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 10:13:10.907: INFO: expected 31 pod replicas in namespace 'kube-system', 31 are Running and Ready.
May 21 10:13:10.915: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 10:13:10.916: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.1 before test
May 21 10:13:10.927: INFO: apiserver-proxy-nginx-preset-865784f6fb-dp8vr from kube-system started at 2018-05-21 05:21:38 +0000 UTC (2 container statuses recorded)
May 21 10:13:10.927: INFO: 	Container proxy ready: true, restart count 0
May 21 10:13:10.927: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:13:10.927: INFO: logging-fluentd-fluentd-v1-0-z76bf from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.927: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.927: INFO: exporters-gpu-gpu-v1-0-jkdz2 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.927: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.927: INFO: exporters-node-node-v1-0-sxnm2 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.927: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.927: INFO: monitoring-prometheus-prometheus-v1-0-0 from kube-system started at 2018-05-21 05:31:22 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.928: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.928: INFO: 	Container c1 ready: true, restart count 0
May 21 10:13:10.928: INFO: 	Container c2 ready: true, restart count 0
May 21 10:13:10.928: INFO: kube-proxy-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.928: INFO: kube-controller-manager-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.928: INFO: canal-bc599 from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.928: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:13:10.928: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:13:10.928: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:13:10.928: INFO: storage-provisioner-nfs-provisioner-nfs-v1-0-bffdf9746-h8fs9 from kube-system started at 2018-05-21 05:31:18 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.928: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.928: INFO: kube-scheduler-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.928: INFO: kube-apiserver-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.928: INFO: kube-dns-v22-864bd47fb9-fxkqk from kube-system started at 2018-05-21 05:22:09 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.928: INFO: 	Container dnsmasq ready: true, restart count 0
May 21 10:13:10.928: INFO: 	Container kubedns ready: true, restart count 0
May 21 10:13:10.928: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:13:10.928: INFO: apiserver-provider-ipvsdr-preset-949858699-jz4x9 from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.928: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:13:10.928: INFO: sonobuoy from sonobuoy started at 2018-05-21 10:02:59 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.928: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 10:13:10.928: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.2 before test
May 21 10:13:10.951: INFO: config-sync-sync-v1-0-78c844cdcc-q6zns from default started at 2018-05-21 05:31:47 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: kube-controller-manager-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.951: INFO: canal-5z7qg from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:13:10.951: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:13:10.951: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:13:10.951: INFO: apiserver-proxy-nginx-preset-865784f6fb-j5p5k from kube-system started at 2018-05-21 05:21:39 +0000 UTC (2 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container proxy ready: true, restart count 0
May 21 10:13:10.951: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:13:10.951: INFO: apiserver-provider-ipvsdr-preset-949858699-glksh from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:13:10.951: INFO: kube-dns-autoscaler-v22-757d579667-dmf9r from kube-system started at 2018-05-21 05:21:46 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container autoscaler ready: true, restart count 0
May 21 10:13:10.951: INFO: kube-dns-v22-864bd47fb9-d4lms from kube-system started at 2018-05-21 05:21:47 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container dnsmasq ready: true, restart count 0
May 21 10:13:10.951: INFO: 	Container kubedns ready: true, restart count 0
May 21 10:13:10.951: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:13:10.951: INFO: dex-cauth-cauth-v1-0-8656d55578-jl6lf from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container cauth ready: true, restart count 6
May 21 10:13:10.951: INFO: default-http-backend-7558c79bdc-vrdsd from default started at 2018-05-21 05:21:38 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container default-http-backend ready: true, restart count 0
May 21 10:13:10.951: INFO: exporters-gpu-gpu-v1-0-pfgm6 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: clever-kubeflow-admin-kubeflow-admin-v1-0-6cd6f78557-dlz46 from default started at 2018-05-21 05:31:36 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: dex-caidex-caidex-v1-0-7fc9cddc49-t8mdt from default started at 2018-05-21 05:31:48 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container cauth ready: true, restart count 6
May 21 10:13:10.951: INFO: kubernetes-admin-mongo-mongo-v1-0-78cb68d655-9ndmv from default started at 2018-05-21 05:32:41 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: kube-scheduler-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.951: INFO: kube-proxy-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.951: INFO: logging-fluentd-fluentd-v1-0-jqxwz from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.951: INFO: logging-elasticsearch-elasticsearch-v1-0-0 from kube-system started at 2018-05-21 05:31:10 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: storage-admin-admin-v1-0-786cdd76cf-p4jtp from default started at 2018-05-21 05:31:33 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: config-gc-gc-v1-0-747b8cc554-z8d5g from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 5
May 21 10:13:10.951: INFO: notify-postgres-postgres-v1-0-57db6fb8d5-trcw7 from default started at 2018-05-21 05:31:59 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container postgres ready: true, restart count 0
May 21 10:13:10.951: INFO: kube-apiserver-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.951: INFO: exporters-node-node-v1-0-5lnp5 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.951: INFO: storage-controller-controller-v1-0-55f4c7c5b4-qb5hh from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.951: INFO: 	Container c0 ready: true, restart count 4
May 21 10:13:10.951: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.3 before test
May 21 10:13:10.968: INFO: monitoring-operator-operator-v1-0-56484b7647-wg8xf from default started at 2018-05-21 05:31:47 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 5
May 21 10:13:10.968: INFO: kube-apiserver-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.968: INFO: kube-proxy-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.968: INFO: logging-fluentd-fluentd-v1-0-87742 from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 7
May 21 10:13:10.968: INFO: cargo-admin-admin-v1-0-748bdbfdf5-cwx76 from default started at 2018-05-21 05:31:31 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.968: INFO: cluster-mongo-mongo-v1-0-8665b5cbfd-w4lfn from default started at 2018-05-21 05:31:38 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: console-web-redis-redis-v1-0-f9d568d94-rvmh7 from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: kube-controller-manager-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.968: INFO: kube-scheduler-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.968: INFO: apiserver-provider-ipvsdr-preset-949858699-h46q4 from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:13:10.968: INFO: heketi-69886b6db9-vd5gz from default started at 2018-05-21 05:22:10 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container heketi ready: true, restart count 0
May 21 10:13:10.968: INFO: clever-mongo-mongo-v1-0-68dcbfcc8-bzhhb from default started at 2018-05-21 05:32:41 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: logging-elasticsearch-elasticsearch-v1-0-1 from kube-system started at 2018-05-21 05:32:58 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: exporters-node-node-v1-0-dsvzf from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: logging-eventer-eventer-v1-0-76954b748b-4kjj7 from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.968: INFO: app-admin-admin-v1-0-77b745f8f-vpxjb from default started at 2018-05-21 05:31:40 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: statistician-server-server-v1-0-6f4db6b9f6-r7ptq from default started at 2018-05-21 05:31:48 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: monitoring-kube-state-metrics-kube-state-metrics-v1-0-5db5lrxwt from kube-system started at 2018-05-21 05:31:19 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container kube-state-metrics ready: true, restart count 0
May 21 10:13:10.968: INFO: tenant-controller-controller-v1-0-7ffcd7969b-xq5dc from kube-system started at 2018-05-21 05:31:20 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 1
May 21 10:13:10.968: INFO: helm-registry-registry-v1-0-5bf6f7f68f-6bd98 from default started at 2018-05-21 05:33:48 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: canal-2lnvt from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:13:10.968: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:13:10.968: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:13:10.968: INFO: apiserver-proxy-nginx-preset-865784f6fb-w2flj from kube-system started at 2018-05-21 05:21:38 +0000 UTC (2 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container proxy ready: true, restart count 0
May 21 10:13:10.968: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:13:10.968: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-2dswv from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: exporters-gpu-gpu-v1-0-j62dq from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.968: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.968: INFO: 
Logging pods the kubelet thinks is on node node-192.168.130.4 before test
May 21 10:13:10.984: INFO: clever-postgres-postgres-v1-0-574b75cd65-mkrp4 from default started at 2018-05-21 05:33:43 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: devops-admin-admin-v1-0-6db9f89cd6-8d7sr from default started at 2018-05-21 05:31:43 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 5
May 21 10:13:10.984: INFO: monitoring-admin-admin-v1-0-58bdfdf6c9-45tl9 from default started at 2018-05-21 05:31:44 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 2
May 21 10:13:10.984: INFO: cluster-addon-addon-v1-0-5c4b74889-mdwqc from kube-system started at 2018-05-21 05:31:15 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: cyclone-server-server-v1-0-5d9d48f887-9dl77 from default started at 2018-05-21 05:32:37 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 2
May 21 10:13:10.984: INFO: dex-postgres-postgres-v1-0-79d84d7fd8-ptr85 from default started at 2018-05-21 05:33:44 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: canal-dwmxv from kube-system started at 2018-05-21 05:22:10 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:13:10.984: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:13:10.984: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:13:10.984: INFO: storage-controller-k-controller-k-v1-0-5549d55d89-g5vmg from kube-system started at 2018-05-21 05:31:18 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: clever-web-web-v1-0-8564f766cc-78dwb from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: cluster-controller-controller-v1-0-6574f8897b-f7mtl from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: logging-admin-admin-v1-0-668cc758bb-s6r89 from default started at 2018-05-21 05:31:40 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: hodor-server-server-v1-0-67c74dc768-c6jhn from default started at 2018-05-21 05:31:43 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.984: INFO: loadbalancer-admin-admin-v1-0-c774889df-78nl8 from default started at 2018-05-21 05:31:22 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: cluster-machine-machine-v1-0-5675994fcd-56s7q from default started at 2018-05-21 05:31:36 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: exporters-gpu-gpu-v1-0-jrw8h from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: exporters-elasticsearch-elasticsearch-v1-0-6d84c684f5-fqgv8 from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: open-api-server-server-v1-0-575fb8d756-v5bsp from default started at 2018-05-21 05:31:22 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: alerting-notifier-notifier-v1-0-5fd6f8f86b-2xg5r from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: config-mongo-mongo-v1-0-76f5dbc994-xpf7x from default started at 2018-05-21 05:33:41 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: release-controller-v0.2.2-67cd497946-lx95q from kube-system started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container controller ready: true, restart count 0
May 21 10:13:10.984: INFO: hybrid-controller-manager-controller-manager-v1-0-7f864846p9dll from kube-system started at 2018-05-21 05:31:11 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-9btgl from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: license-server-server-v1-0-54675fc555-tsf6q from default started at 2018-05-21 05:31:27 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container license ready: true, restart count 0
May 21 10:13:10.984: INFO: cluster-admin-admin-v1-0-796967fcff-gkffj from default started at 2018-05-21 05:31:35 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 4
May 21 10:13:10.984: INFO: kube-proxy-node-192.168.130.4 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.984: INFO: config-admission-admission-v1-0-5d997c56d9-2mh59 from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: am-mysql-v2.0-c6db7f6b5-vk465 from default started at 2018-05-21 05:28:54 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container am-mysql ready: true, restart count 0
May 21 10:13:10.984: INFO: logging-fluentd-fluentd-v1-0-zh7xb from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.984: INFO: logging-elasticsearch-elasticsearch-v1-0-2 from kube-system started at 2018-05-21 05:35:35 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: am-minion-v0.0.3-6c77b79c44-znc7x from default started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container am-minion ready: true, restart count 0
May 21 10:13:10.984: INFO: exporters-node-node-v1-0-4tt9v from kube-system started at 2018-05-21 05:31:15 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.984: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.984: INFO: 
Logging pods the kubelet thinks is on node node-192.168.130.5 before test
May 21 10:13:10.999: INFO: cyclone-mongo-mongo-v1-0-7d4c8684b6-jsd47 from default started at 2018-05-21 05:34:21 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: canal-4rctf from kube-system started at 2018-05-21 05:22:10 +0000 UTC (3 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:13:10.999: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:13:10.999: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:13:10.999: INFO: exporters-node-node-v1-0-q5zcw from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: alerting-manager-manager-v1-0-85f76b45d7-7mnwh from default started at 2018-05-21 05:31:32 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: cargo-mongo-mongo-v1-0-7997dc6b94-czd8f from default started at 2018-05-21 05:33:42 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: config-reference-reference-v1-0-5b964f9ccc-66k9t from kube-system started at 2018-05-21 05:31:13 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: monitoring-grafana-grafana-v1-0-86c8b866d4-mbbnl from kube-system started at 2018-05-21 05:31:19 +0000 UTC (2 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: 	Container c1 ready: true, restart count 0
May 21 10:13:10.999: INFO: config-admin-admin-v1-0-5f674d5fb9-gfdk4 from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: monitoring-mongo-mongo-v1-0-7f6984c8fd-2z6ns from default started at 2018-05-21 05:32:30 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: exporters-app-app-v1-0-8b7f56b56-49mdb from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: clever-tf-operator-tf-operator-v1-0-557cfb5974-dbn9p from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: notify-admin-admin-v1-0-7fd9bbf9c8-b7w4n from default started at 2018-05-21 05:31:29 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: logging-kibana-kibana-v1-0-68c977f968-sfmvf from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: logging-fluentd-fluentd-v1-0-rstpn from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 6
May 21 10:13:10.999: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-wwhnc from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: exporters-gpu-gpu-v1-0-s89lk from kube-system started at 2018-05-21 05:31:13 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: sonobuoy-e2e-job-961741dcd1894b0e from sonobuoy started at 2018-05-21 10:03:01 +0000 UTC (2 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container e2e ready: true, restart count 0
May 21 10:13:10.999: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 10:13:10.999: INFO: am-master-v3.0-56f955cdc9-4r2nd from default started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container am-master ready: true, restart count 2
May 21 10:13:10.999: INFO: console-web-web-web-v1-0-559b9c4967-2st5h from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 5
May 21 10:13:10.999: INFO: gitbook-server-server-v1-0-756c7d7b64-cmk9q from default started at 2018-05-21 05:31:46 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: console-web-mongo-mongo-v1-0-7584454d5d-2w7f2 from default started at 2018-05-21 05:33:45 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: kube-proxy-node-192.168.130.5 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:13:10.999: INFO: canary-release-controller-controller-v1-0-6cf74f987c-gclpn from kube-system started at 2018-05-21 05:31:12 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: devops-mongo-mongo-v1-0-fdb9d968b-l85bz from default started at 2018-05-21 05:33:43 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: monitoring-heapster-heapster-v1-0-f6f95b846-nfl7k from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: tenant-admin-admin-v1-0-68767d7bf8-gbm2r from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: clever-storage-manager-storage-manager-v1-0-847cc98444-fnkbx from default started at 2018-05-21 05:31:44 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 5
May 21 10:13:10.999: INFO: kubernetes-admin-server-server-v1-0-5dbdc9f7f9-crqzr from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: dex-mongo-mongo-v1-0-5b65cbcdcd-kkswv from default started at 2018-05-21 05:33:59 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: am-minion-v0.0.3-67d4cf786d-8wwsd from kube-system started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container am-minion ready: true, restart count 0
May 21 10:13:10.999: INFO: loadbalancer-controller-controller-v1-0-6574dbc55b-npvdz from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: storage-admission-admission-v1-0-54cb855f9f-kng5q from kube-system started at 2018-05-21 05:31:16 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: clever-redis-redis-v1-0-76f69b9d69-ddhf4 from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
May 21 10:13:10.999: INFO: clever-mysql-mysql-v1-0-6bff585648-q4v45 from default started at 2018-05-21 05:34:02 +0000 UTC (1 container statuses recorded)
May 21 10:13:10.999: INFO: 	Container c0 ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-91ef1a78-5cdf-11e8-8768-12f5d52dbf0b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-91ef1a78-5cdf-11e8-8768-12f5d52dbf0b off the node node-192.168.130.5
STEP: verifying the node doesn't have the label kubernetes.io/e2e-91ef1a78-5cdf-11e8-8768-12f5d52dbf0b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:13:15.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-q7l4k" for this suite.
May 21 10:13:37.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:13:37.335: INFO: namespace: e2e-tests-sched-pred-q7l4k, resource: bindings, ignored listing per whitelist
May 21 10:13:37.362: INFO: namespace e2e-tests-sched-pred-q7l4k deletion completed in 22.188386186s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:86.662 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:13:37.363: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:13:37.399526      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-a07715e5-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:13:37.452: INFO: Waiting up to 5m0s for pod "pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-55rbt" to be "success or failure"
May 21 10:13:37.460: INFO: Pod "pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.789084ms
May 21 10:13:39.464: INFO: Pod "pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011485418s
May 21 10:13:41.475: INFO: Pod "pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022338039s
STEP: Saw pod success
May 21 10:13:41.475: INFO: Pod "pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:13:41.478: INFO: Trying to get logs from node node-192.168.130.4 pod pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:13:41.509: INFO: Waiting for pod pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:13:41.511: INFO: Pod pod-secrets-a077c634-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:13:41.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-55rbt" for this suite.
May 21 10:13:47.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:13:47.596: INFO: namespace: e2e-tests-secrets-55rbt, resource: bindings, ignored listing per whitelist
May 21 10:13:47.736: INFO: namespace e2e-tests-secrets-55rbt deletion completed in 6.22052136s

• [SLOW TEST:10.373 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:13:47.736: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:13:47.785635      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-g6nd4 in namespace e2e-tests-proxy-j5bfz
I0521 10:13:47.958625      15 runners.go:175] Created replication controller with name: proxy-service-g6nd4, namespace: e2e-tests-proxy-j5bfz, replica count: 1
I0521 10:13:48.959632      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 10:13:49.959871      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:50.960082      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:51.960446      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:52.960650      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:53.960960      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:54.961208      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:55.965319      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:56.965807      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 10:13:57.966086      15 runners.go:175] proxy-service-g6nd4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 10:13:57.974: INFO: setup took 10.043567883s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 21 10:13:58.011: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 35.700569ms)
May 21 10:13:58.012: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 37.54163ms)
May 21 10:13:58.012: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 36.525309ms)
May 21 10:13:58.013: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 38.558676ms)
May 21 10:13:58.013: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 38.174523ms)
May 21 10:13:58.022: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 47.0373ms)
May 21 10:13:58.022: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 46.971331ms)
May 21 10:13:58.028: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 53.318519ms)
May 21 10:13:58.028: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 53.500506ms)
May 21 10:13:58.035: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 59.593052ms)
May 21 10:13:58.035: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 59.71338ms)
May 21 10:13:58.035: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 60.637838ms)
May 21 10:13:58.037: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 60.979151ms)
May 21 10:13:58.037: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 61.643253ms)
May 21 10:13:58.037: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 62.743086ms)
May 21 10:13:58.039: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 63.86178ms)
May 21 10:13:58.045: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.097435ms)
May 21 10:13:58.045: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.996205ms)
May 21 10:13:58.045: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 5.32689ms)
May 21 10:13:58.049: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 9.319102ms)
May 21 10:13:58.050: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 9.298229ms)
May 21 10:13:58.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 10.469996ms)
May 21 10:13:58.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 10.63467ms)
May 21 10:13:58.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 11.023636ms)
May 21 10:13:58.051: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 11.470871ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 11.803962ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 11.756617ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 11.776579ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 12.079387ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 12.631572ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 12.57117ms)
May 21 10:13:58.052: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 12.18821ms)
May 21 10:13:58.060: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 6.618404ms)
May 21 10:13:58.061: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 7.902296ms)
May 21 10:13:58.061: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 8.191635ms)
May 21 10:13:58.061: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 7.669175ms)
May 21 10:13:58.062: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 9.124676ms)
May 21 10:13:58.062: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 8.541972ms)
May 21 10:13:58.063: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 9.487379ms)
May 21 10:13:58.063: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 9.889202ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 11.220053ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 10.12675ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 10.186415ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 11.150486ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 10.582417ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 10.711606ms)
May 21 10:13:58.064: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 10.797979ms)
May 21 10:13:58.065: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 10.728631ms)
May 21 10:13:58.069: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 4.126967ms)
May 21 10:13:58.069: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.965084ms)
May 21 10:13:58.069: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 4.465994ms)
May 21 10:13:58.070: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.891282ms)
May 21 10:13:58.070: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 5.242643ms)
May 21 10:13:58.070: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 5.21715ms)
May 21 10:13:58.071: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.364783ms)
May 21 10:13:58.071: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 5.419787ms)
May 21 10:13:58.071: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.801237ms)
May 21 10:13:58.072: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 6.638838ms)
May 21 10:13:58.073: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 7.445561ms)
May 21 10:13:58.073: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.571329ms)
May 21 10:13:58.074: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 7.791381ms)
May 21 10:13:58.074: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 8.775634ms)
May 21 10:13:58.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 8.851564ms)
May 21 10:13:58.075: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 8.936254ms)
May 21 10:13:58.081: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 5.912048ms)
May 21 10:13:58.081: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 5.672224ms)
May 21 10:13:58.081: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.951076ms)
May 21 10:13:58.081: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 6.03455ms)
May 21 10:13:58.081: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 6.422537ms)
May 21 10:13:58.082: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 6.79012ms)
May 21 10:13:58.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.984078ms)
May 21 10:13:58.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 7.743983ms)
May 21 10:13:58.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 8.284149ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 8.409876ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 8.854893ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 9.568696ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 9.318834ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 14.131886ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 8.899177ms)
May 21 10:13:58.089: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 8.775403ms)
May 21 10:13:58.093: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 3.728512ms)
May 21 10:13:58.095: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 4.656538ms)
May 21 10:13:58.095: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 5.570384ms)
May 21 10:13:58.095: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.850075ms)
May 21 10:13:58.095: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.793753ms)
May 21 10:13:58.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.882264ms)
May 21 10:13:58.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.82581ms)
May 21 10:13:58.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 5.021973ms)
May 21 10:13:58.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 5.611269ms)
May 21 10:13:58.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 5.785951ms)
May 21 10:13:58.096: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 5.405306ms)
May 21 10:13:58.097: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 6.261069ms)
May 21 10:13:58.098: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.149803ms)
May 21 10:13:58.098: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 7.743523ms)
May 21 10:13:58.098: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 7.149295ms)
May 21 10:13:58.098: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 7.865926ms)
May 21 10:13:58.102: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 4.336432ms)
May 21 10:13:58.102: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 4.028752ms)
May 21 10:13:58.102: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.863646ms)
May 21 10:13:58.102: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 4.221654ms)
May 21 10:13:58.102: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.097656ms)
May 21 10:13:58.102: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.487238ms)
May 21 10:13:58.103: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.719774ms)
May 21 10:13:58.104: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 5.013309ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.577669ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 6.17835ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 6.063949ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 5.879481ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.1199ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 6.346512ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 6.621622ms)
May 21 10:13:58.105: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 6.740775ms)
May 21 10:13:58.110: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 4.434531ms)
May 21 10:13:58.110: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.27425ms)
May 21 10:13:58.110: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.580661ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 14.09494ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 14.143777ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 14.221362ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 15.329563ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 14.680807ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 14.795245ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 14.870055ms)
May 21 10:13:58.121: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 14.976136ms)
May 21 10:13:58.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 15.02591ms)
May 21 10:13:58.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 15.715868ms)
May 21 10:13:58.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 15.634ms)
May 21 10:13:58.122: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 15.483154ms)
May 21 10:13:58.127: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 20.185737ms)
May 21 10:13:58.135: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 7.182072ms)
May 21 10:13:58.135: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 6.894119ms)
May 21 10:13:58.135: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 7.102319ms)
May 21 10:13:58.135: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 6.978722ms)
May 21 10:13:58.135: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 7.244735ms)
May 21 10:13:58.135: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 7.798923ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 8.10791ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 7.855931ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 8.327851ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 9.022297ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 8.462619ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 9.260134ms)
May 21 10:13:58.136: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 9.032255ms)
May 21 10:13:58.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 9.448757ms)
May 21 10:13:58.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 9.358728ms)
May 21 10:13:58.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 8.841361ms)
May 21 10:13:58.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 3.080393ms)
May 21 10:13:58.141: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.01952ms)
May 21 10:13:58.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 4.585428ms)
May 21 10:13:58.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.634517ms)
May 21 10:13:58.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.640755ms)
May 21 10:13:58.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 5.201287ms)
May 21 10:13:58.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 5.518346ms)
May 21 10:13:58.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 5.168049ms)
May 21 10:13:58.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 5.410288ms)
May 21 10:13:58.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.368145ms)
May 21 10:13:58.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 5.704056ms)
May 21 10:13:58.143: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 6.213038ms)
May 21 10:13:58.147: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 8.931561ms)
May 21 10:13:58.147: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 9.150701ms)
May 21 10:13:58.147: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 10.131132ms)
May 21 10:13:58.148: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 11.183345ms)
May 21 10:13:58.151: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 2.595653ms)
May 21 10:13:58.152: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 2.831609ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 4.587278ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.03893ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 4.165014ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 4.78912ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.261219ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.775693ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 3.977252ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.757481ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 3.913837ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 4.664815ms)
May 21 10:13:58.154: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 4.888025ms)
May 21 10:13:58.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 4.962751ms)
May 21 10:13:58.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.625765ms)
May 21 10:13:58.155: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.584546ms)
May 21 10:13:58.158: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 3.062867ms)
May 21 10:13:58.159: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.86478ms)
May 21 10:13:58.160: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 4.117492ms)
May 21 10:13:58.160: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.472014ms)
May 21 10:13:58.160: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 3.995134ms)
May 21 10:13:58.161: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 4.789731ms)
May 21 10:13:58.161: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 5.577834ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 6.425381ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 6.184288ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.777454ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 6.435373ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 6.22087ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 6.503859ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.115479ms)
May 21 10:13:58.162: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 6.164176ms)
May 21 10:13:58.163: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 7.527091ms)
May 21 10:13:58.166: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 2.814713ms)
May 21 10:13:58.166: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 2.8069ms)
May 21 10:13:58.166: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 3.141955ms)
May 21 10:13:58.166: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 3.153395ms)
May 21 10:13:58.166: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 3.071331ms)
May 21 10:13:58.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 3.670249ms)
May 21 10:13:58.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.486267ms)
May 21 10:13:58.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 4.744839ms)
May 21 10:13:58.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.298254ms)
May 21 10:13:58.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 4.646952ms)
May 21 10:13:58.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 4.559111ms)
May 21 10:13:58.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 4.871433ms)
May 21 10:13:58.169: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.046703ms)
May 21 10:13:58.169: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 5.145461ms)
May 21 10:13:58.169: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.854558ms)
May 21 10:13:58.170: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 5.964766ms)
May 21 10:13:58.173: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.170352ms)
May 21 10:13:58.173: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.178926ms)
May 21 10:13:58.173: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 3.452994ms)
May 21 10:13:58.175: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 4.37214ms)
May 21 10:13:58.175: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 5.207621ms)
May 21 10:13:58.176: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 5.425539ms)
May 21 10:13:58.176: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 4.972837ms)
May 21 10:13:58.176: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.695737ms)
May 21 10:13:58.176: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 5.558924ms)
May 21 10:13:58.176: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 5.695436ms)
May 21 10:13:58.177: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 6.20853ms)
May 21 10:13:58.177: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.945498ms)
May 21 10:13:58.178: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.566009ms)
May 21 10:13:58.178: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 7.001345ms)
May 21 10:13:58.178: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 7.588274ms)
May 21 10:13:58.178: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 7.463926ms)
May 21 10:13:58.182: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 3.877734ms)
May 21 10:13:58.183: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 4.06147ms)
May 21 10:13:58.184: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 5.164096ms)
May 21 10:13:58.184: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.115242ms)
May 21 10:13:58.184: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.445296ms)
May 21 10:13:58.184: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 5.216757ms)
May 21 10:13:58.185: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 5.43031ms)
May 21 10:13:58.185: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.516691ms)
May 21 10:13:58.185: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 6.413802ms)
May 21 10:13:58.186: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 6.815642ms)
May 21 10:13:58.187: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 7.648522ms)
May 21 10:13:58.187: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 7.044966ms)
May 21 10:13:58.187: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 8.153639ms)
May 21 10:13:58.187: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 8.416636ms)
May 21 10:13:58.187: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 8.362501ms)
May 21 10:13:58.188: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 8.695392ms)
May 21 10:13:58.190: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 2.630847ms)
May 21 10:13:58.191: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 3.217164ms)
May 21 10:13:58.191: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.063826ms)
May 21 10:13:58.191: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.102309ms)
May 21 10:13:58.191: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 3.095645ms)
May 21 10:13:58.191: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.383923ms)
May 21 10:13:58.192: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.263185ms)
May 21 10:13:58.192: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 3.661252ms)
May 21 10:13:58.192: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 4.224993ms)
May 21 10:13:58.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.104991ms)
May 21 10:13:58.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 4.623595ms)
May 21 10:13:58.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 5.083985ms)
May 21 10:13:58.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 4.801019ms)
May 21 10:13:58.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.189903ms)
May 21 10:13:58.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.127483ms)
May 21 10:13:58.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.263412ms)
May 21 10:13:58.197: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 3.240643ms)
May 21 10:13:58.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 3.467515ms)
May 21 10:13:58.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.69134ms)
May 21 10:13:58.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 3.396976ms)
May 21 10:13:58.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.691752ms)
May 21 10:13:58.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 4.141864ms)
May 21 10:13:58.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 4.507195ms)
May 21 10:13:58.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 4.822019ms)
May 21 10:13:58.199: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 4.484066ms)
May 21 10:13:58.200: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 4.461548ms)
May 21 10:13:58.200: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.941521ms)
May 21 10:13:58.200: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.996968ms)
May 21 10:13:58.200: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.224385ms)
May 21 10:13:58.200: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 5.181245ms)
May 21 10:13:58.200: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 6.026824ms)
May 21 10:13:58.201: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.217467ms)
May 21 10:13:58.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 5.412236ms)
May 21 10:13:58.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 5.574982ms)
May 21 10:13:58.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 5.652343ms)
May 21 10:13:58.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 5.856252ms)
May 21 10:13:58.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 5.871958ms)
May 21 10:13:58.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 6.710033ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 6.819169ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 6.457904ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 6.57727ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 7.041719ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 7.272902ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 7.234625ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 7.220183ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 7.482268ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 7.701984ms)
May 21 10:13:58.208: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 7.59431ms)
May 21 10:13:58.212: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.159349ms)
May 21 10:13:58.212: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 3.46929ms)
May 21 10:13:58.212: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 3.40182ms)
May 21 10:13:58.212: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 3.769248ms)
May 21 10:13:58.213: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 3.637296ms)
May 21 10:13:58.213: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 4.056199ms)
May 21 10:13:58.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 3.89431ms)
May 21 10:13:58.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 4.529594ms)
May 21 10:13:58.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 4.782707ms)
May 21 10:13:58.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 4.952661ms)
May 21 10:13:58.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 4.983747ms)
May 21 10:13:58.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 4.587455ms)
May 21 10:13:58.216: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 6.069018ms)
May 21 10:13:58.216: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 5.794852ms)
May 21 10:13:58.216: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 6.717145ms)
May 21 10:13:58.216: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 6.625908ms)
May 21 10:13:58.218: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:462/proxy/: tls qux (200; 2.786659ms)
May 21 10:13:58.219: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:443/proxy/... (200; 3.048525ms)
May 21 10:13:58.219: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:1080/proxy/rewri... (200; 3.285085ms)
May 21 10:13:58.220: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname1/proxy/: tls baz (200; 3.921048ms)
May 21 10:13:58.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname2/proxy/: bar (200; 4.926458ms)
May 21 10:13:58.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/proxy-service-g6nd4:portname1/proxy/: foo (200; 5.185964ms)
May 21 10:13:58.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:1080/proxy/... (200; 4.537841ms)
May 21 10:13:58.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.506135ms)
May 21 10:13:58.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22/proxy/rewriteme"... (200; 4.686239ms)
May 21 10:13:58.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/http:proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 4.579627ms)
May 21 10:13:58.222: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/https:proxy-service-g6nd4-ljd22:460/proxy/: tls baz (200; 4.502392ms)
May 21 10:13:58.222: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:162/proxy/: bar (200; 4.934145ms)
May 21 10:13:58.222: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/https:proxy-service-g6nd4:tlsportname2/proxy/: tls qux (200; 5.652283ms)
May 21 10:13:58.222: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/pods/proxy-service-g6nd4-ljd22:160/proxy/: foo (200; 4.84193ms)
May 21 10:13:58.222: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname1/proxy/: foo (200; 5.959262ms)
May 21 10:13:58.222: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5bfz/services/http:proxy-service-g6nd4:portname2/proxy/: bar (200; 5.452803ms)
STEP: deleting { ReplicationController} proxy-service-g6nd4 in namespace e2e-tests-proxy-j5bfz
May 21 10:13:59.360: INFO: Deleting { ReplicationController} proxy-service-g6nd4 took: 1.034533137s
May 21 10:13:59.360: INFO: Terminating { ReplicationController} proxy-service-g6nd4 pods took: 65.123µs
May 21 10:14:04.860: INFO: Garbage collecting { ReplicationController} proxy-service-g6nd4 pods took: 6.535027058s
[AfterEach] version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:14:04.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j5bfz" for this suite.
May 21 10:14:10.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:11.052: INFO: namespace: e2e-tests-proxy-j5bfz, resource: bindings, ignored listing per whitelist
May 21 10:14:11.057: INFO: namespace e2e-tests-proxy-j5bfz deletion completed in 6.19047191s

• [SLOW TEST:23.321 seconds]
[sig-network] Proxy
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:14:11.058: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:14:11.100781      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-map-b490c19c-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:14:11.178: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-kz4mf" to be "success or failure"
May 21 10:14:11.190: INFO: Pod "pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.936925ms
May 21 10:14:13.195: INFO: Pod "pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.016799257s
May 21 10:14:15.201: INFO: Pod "pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022784305s
STEP: Saw pod success
May 21 10:14:15.201: INFO: Pod "pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:14:15.205: INFO: Trying to get logs from node master-192.168.130.2 pod pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:14:15.244: INFO: Waiting for pod pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:14:15.246: INFO: Pod pod-projected-configmaps-b491713c-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:14:15.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kz4mf" for this suite.
May 21 10:14:21.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:21.463: INFO: namespace: e2e-tests-projected-kz4mf, resource: bindings, ignored listing per whitelist
May 21 10:14:21.496: INFO: namespace e2e-tests-projected-kz4mf deletion completed in 6.235585222s

• [SLOW TEST:10.439 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:14:21.497: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:14:21.543004      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating projection with secret that has name projected-secret-test-bac8ba29-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:14:21.619: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-qhdbd" to be "success or failure"
May 21 10:14:21.638: INFO: Pod "pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.05382ms
May 21 10:14:23.643: INFO: Pod "pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024297155s
STEP: Saw pod success
May 21 10:14:23.643: INFO: Pod "pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:14:23.646: INFO: Trying to get logs from node master-192.168.130.1 pod pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 10:14:23.667: INFO: Waiting for pod pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:14:23.672: INFO: Pod pod-projected-secrets-bacad480-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:14:23.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qhdbd" for this suite.
May 21 10:14:29.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:29.918: INFO: namespace: e2e-tests-projected-qhdbd, resource: bindings, ignored listing per whitelist
May 21 10:14:29.951: INFO: namespace e2e-tests-projected-qhdbd deletion completed in 6.268598676s

• [SLOW TEST:8.454 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:14:29.951: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:14:29.995313      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-map-bfd8e920-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:14:30.117: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-8hsdb" to be "success or failure"
May 21 10:14:30.126: INFO: Pod "pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.929105ms
May 21 10:14:32.130: INFO: Pod "pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01303306s
STEP: Saw pod success
May 21 10:14:32.130: INFO: Pod "pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:14:32.132: INFO: Trying to get logs from node node-192.168.130.5 pod pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:14:32.152: INFO: Waiting for pod pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:14:32.159: INFO: Pod pod-configmaps-bfda5f12-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:14:32.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8hsdb" for this suite.
May 21 10:14:38.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:38.251: INFO: namespace: e2e-tests-configmap-8hsdb, resource: bindings, ignored listing per whitelist
May 21 10:14:38.361: INFO: namespace e2e-tests-configmap-8hsdb deletion completed in 6.197618894s

• [SLOW TEST:8.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:14:38.362: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:14:38.415809      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-c4d79ec9-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:14:38.485: INFO: Waiting up to 5m0s for pod "pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-nsjnc" to be "success or failure"
May 21 10:14:38.490: INFO: Pod "pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.442151ms
May 21 10:14:40.494: INFO: Pod "pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009087897s
May 21 10:14:42.505: INFO: Pod "pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019792416s
STEP: Saw pod success
May 21 10:14:42.505: INFO: Pod "pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:14:42.507: INFO: Trying to get logs from node node-192.168.130.4 pod pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:14:42.540: INFO: Waiting for pod pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:14:42.543: INFO: Pod pod-configmaps-c4d8401a-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:14:42.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nsjnc" for this suite.
May 21 10:14:48.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:14:48.730: INFO: namespace: e2e-tests-configmap-nsjnc, resource: bindings, ignored listing per whitelist
May 21 10:14:48.736: INFO: namespace e2e-tests-configmap-nsjnc deletion completed in 6.187459344s

• [SLOW TEST:10.374 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:14:48.736: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:14:48.777241      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-cb04d826-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:14:48.845: INFO: Waiting up to 5m0s for pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-54lb2" to be "success or failure"
May 21 10:14:48.849: INFO: Pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.262498ms
May 21 10:14:50.854: INFO: Pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00915896s
May 21 10:14:52.859: INFO: Pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014142682s
May 21 10:14:54.867: INFO: Pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02253105s
May 21 10:14:56.873: INFO: Pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028012647s
STEP: Saw pod success
May 21 10:14:56.873: INFO: Pod "pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:14:56.876: INFO: Trying to get logs from node master-192.168.130.3 pod pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b container secret-env-test: <nil>
STEP: delete the pod
May 21 10:14:56.896: INFO: Waiting for pod pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b to disappear
May 21 10:14:56.898: INFO: Pod pod-secrets-cb0569fb-5cdf-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:14:56.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-54lb2" for this suite.
May 21 10:15:02.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:15:02.993: INFO: namespace: e2e-tests-secrets-54lb2, resource: bindings, ignored listing per whitelist
May 21 10:15:03.120: INFO: namespace e2e-tests-secrets-54lb2 deletion completed in 6.215735938s

• [SLOW TEST:14.384 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:15:03.121: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:15:03.189052      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name cm-test-opt-del-d39ac343-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating configMap with name cm-test-opt-upd-d39ac392-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d39ac343-5cdf-11e8-8768-12f5d52dbf0b
STEP: Updating configmap cm-test-opt-upd-d39ac392-5cdf-11e8-8768-12f5d52dbf0b
STEP: Creating configMap with name cm-test-opt-create-d39ac3ae-5cdf-11e8-8768-12f5d52dbf0b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:16:23.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wskjf" for this suite.
May 21 10:16:45.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:16:46.019: INFO: namespace: e2e-tests-configmap-wskjf, resource: bindings, ignored listing per whitelist
May 21 10:16:46.113: INFO: namespace e2e-tests-configmap-wskjf deletion completed in 22.173139909s

• [SLOW TEST:102.992 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:16:46.113: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:16:46.160102      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 10:16:46.226: INFO: Waiting up to 5m0s for pod "pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-lgkr7" to be "success or failure"
May 21 10:16:46.254: INFO: Pod "pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.881057ms
May 21 10:16:48.259: INFO: Pod "pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033115879s
STEP: Saw pod success
May 21 10:16:48.259: INFO: Pod "pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:16:48.264: INFO: Trying to get logs from node master-192.168.130.1 pod pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:16:48.289: INFO: Waiting for pod pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:16:48.295: INFO: Pod pod-10fc2c98-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:16:48.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lgkr7" for this suite.
May 21 10:16:54.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:16:54.391: INFO: namespace: e2e-tests-emptydir-lgkr7, resource: bindings, ignored listing per whitelist
May 21 10:16:54.505: INFO: namespace e2e-tests-emptydir-lgkr7 deletion completed in 6.19691698s

• [SLOW TEST:8.392 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count  [Slow] [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:16:54.505: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:16:54.551256      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count  [Slow] [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-g8kgm
May 21 10:16:56.623: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-g8kgm
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:16:56.627: INFO: Initial restart count of pod liveness-http is 0
May 21 10:17:10.666: INFO: Restart count of pod e2e-tests-container-probe-g8kgm/liveness-http is now 1 (14.038562277s elapsed)
May 21 10:17:30.723: INFO: Restart count of pod e2e-tests-container-probe-g8kgm/liveness-http is now 2 (34.095732578s elapsed)
May 21 10:17:50.781: INFO: Restart count of pod e2e-tests-container-probe-g8kgm/liveness-http is now 3 (54.154076567s elapsed)
May 21 10:18:36.903: INFO: Restart count of pod e2e-tests-container-probe-g8kgm/liveness-http is now 4 (1m40.275925067s elapsed)
May 21 10:18:50.963: INFO: Restart count of pod e2e-tests-container-probe-g8kgm/liveness-http is now 5 (1m54.335802777s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:18:50.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-g8kgm" for this suite.
May 21 10:18:57.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:18:57.260: INFO: namespace: e2e-tests-container-probe-g8kgm, resource: bindings, ignored listing per whitelist
May 21 10:18:57.276: INFO: namespace e2e-tests-container-probe-g8kgm deletion completed in 6.289353935s

• [SLOW TEST:122.771 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should have monotonically increasing restart count  [Slow] [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:18:57.277: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:18:57.330130      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-54p6v
May 21 10:19:03.408: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-54p6v
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:19:03.410: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:21:03.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-54p6v" for this suite.
May 21 10:21:09.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:21:09.997: INFO: namespace: e2e-tests-container-probe-54p6v, resource: bindings, ignored listing per whitelist
May 21 10:21:10.027: INFO: namespace e2e-tests-container-probe-54p6v deletion completed in 6.205657924s

• [SLOW TEST:132.750 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:21:10.027: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:21:10.068008      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 10:21:10.154: INFO: Waiting up to 5m0s for pod "pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-6vdkw" to be "success or failure"
May 21 10:21:10.158: INFO: Pod "pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.57317ms
May 21 10:21:12.163: INFO: Pod "pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008971066s
STEP: Saw pod success
May 21 10:21:12.163: INFO: Pod "pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:21:12.166: INFO: Trying to get logs from node master-192.168.130.3 pod pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:21:12.195: INFO: Waiting for pod pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:21:12.203: INFO: Pod pod-ae4b8950-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:21:12.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6vdkw" for this suite.
May 21 10:21:18.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:21:18.346: INFO: namespace: e2e-tests-emptydir-6vdkw, resource: bindings, ignored listing per whitelist
May 21 10:21:18.420: INFO: namespace e2e-tests-emptydir-6vdkw deletion completed in 6.211315911s

• [SLOW TEST:8.393 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:21:18.420: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:21:18.470006      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test env composition
May 21 10:21:18.532: INFO: Waiting up to 5m0s for pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-var-expansion-kc5zm" to be "success or failure"
May 21 10:21:18.540: INFO: Pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.250805ms
May 21 10:21:20.546: INFO: Pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014243122s
May 21 10:21:22.559: INFO: Pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027323532s
May 21 10:21:24.565: INFO: Pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032982262s
May 21 10:21:26.570: INFO: Pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.038112607s
STEP: Saw pod success
May 21 10:21:26.570: INFO: Pod "var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:21:26.573: INFO: Trying to get logs from node master-192.168.130.2 pod var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:21:26.598: INFO: Waiting for pod var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:21:26.603: INFO: Pod var-expansion-b34ab685-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:21:26.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kc5zm" for this suite.
May 21 10:21:32.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:21:32.719: INFO: namespace: e2e-tests-var-expansion-kc5zm, resource: bindings, ignored listing per whitelist
May 21 10:21:32.843: INFO: namespace e2e-tests-var-expansion-kc5zm deletion completed in 6.226320765s

• [SLOW TEST:14.423 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should allow composing env vars into new env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:21:32.843: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:21:32.892536      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5dr4k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:21:32.981: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:21:53.126: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.65.119:8080/dial?request=hostName&protocol=udp&host=192.168.65.118&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr4k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:21:53.126: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:21:53.260: INFO: Waiting for endpoints: map[]
May 21 10:21:53.266: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.65.119:8080/dial?request=hostName&protocol=udp&host=192.168.68.129&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr4k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:21:53.266: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:21:53.360: INFO: Waiting for endpoints: map[]
May 21 10:21:53.363: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.65.119:8080/dial?request=hostName&protocol=udp&host=192.168.66.109&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr4k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:21:53.363: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:21:53.472: INFO: Waiting for endpoints: map[]
May 21 10:21:53.475: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.65.119:8080/dial?request=hostName&protocol=udp&host=192.168.67.124&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr4k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:21:53.475: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:21:53.581: INFO: Waiting for endpoints: map[]
May 21 10:21:53.584: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.65.119:8080/dial?request=hostName&protocol=udp&host=192.168.64.151&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr4k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:21:53.584: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:21:53.676: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:21:53.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5dr4k" for this suite.
May 21 10:22:17.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:22:17.869: INFO: namespace: e2e-tests-pod-network-test-5dr4k, resource: bindings, ignored listing per whitelist
May 21 10:22:17.882: INFO: namespace e2e-tests-pod-network-test-5dr4k deletion completed in 24.200119729s

• [SLOW TEST:45.039 seconds]
[sig-network] Networking
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:22:17.882: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:22:17.927357      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 21 10:22:18.504: INFO: Waiting up to 5m0s for pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr" in namespace "e2e-tests-svcaccounts-mhxv4" to be "success or failure"
May 21 10:22:18.509: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.610927ms
May 21 10:22:20.516: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011442175s
May 21 10:22:22.520: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016122785s
STEP: Saw pod success
May 21 10:22:22.520: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr" satisfied condition "success or failure"
May 21 10:22:22.524: INFO: Trying to get logs from node node-192.168.130.4 pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr container token-test: <nil>
STEP: delete the pod
May 21 10:22:22.546: INFO: Waiting for pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr to disappear
May 21 10:22:22.551: INFO: Pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-25lsr no longer exists
STEP: Creating a pod to test consume service account root CA
May 21 10:22:22.560: INFO: Waiting up to 5m0s for pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk" in namespace "e2e-tests-svcaccounts-mhxv4" to be "success or failure"
May 21 10:22:22.564: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741914ms
May 21 10:22:24.570: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010246173s
May 21 10:22:26.577: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016908619s
STEP: Saw pod success
May 21 10:22:26.577: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk" satisfied condition "success or failure"
May 21 10:22:26.580: INFO: Trying to get logs from node master-192.168.130.3 pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk container root-ca-test: <nil>
STEP: delete the pod
May 21 10:22:26.605: INFO: Waiting for pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk to disappear
May 21 10:22:26.614: INFO: Pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-rw9lk no longer exists
STEP: Creating a pod to test consume service account namespace
May 21 10:22:26.620: INFO: Waiting up to 5m0s for pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk" in namespace "e2e-tests-svcaccounts-mhxv4" to be "success or failure"
May 21 10:22:26.626: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk": Phase="Pending", Reason="", readiness=false. Elapsed: 5.896818ms
May 21 10:22:28.632: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01147268s
STEP: Saw pod success
May 21 10:22:28.632: INFO: Pod "pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk" satisfied condition "success or failure"
May 21 10:22:28.635: INFO: Trying to get logs from node master-192.168.130.2 pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk container namespace-test: <nil>
STEP: delete the pod
May 21 10:22:28.661: INFO: Waiting for pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk to disappear
May 21 10:22:28.664: INFO: Pod pod-service-account-d709afc5-5ce0-11e8-8768-12f5d52dbf0b-wfbdk no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:22:28.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-mhxv4" for this suite.
May 21 10:22:34.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:22:34.772: INFO: namespace: e2e-tests-svcaccounts-mhxv4, resource: bindings, ignored listing per whitelist
May 21 10:22:34.965: INFO: namespace e2e-tests-svcaccounts-mhxv4 deletion completed in 6.293911271s

• [SLOW TEST:17.083 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:22:34.966: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:22:35.006134      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward api env vars
May 21 10:22:35.067: INFO: Waiting up to 5m0s for pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-gx5pm" to be "success or failure"
May 21 10:22:35.090: INFO: Pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 23.580655ms
May 21 10:22:37.095: INFO: Pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028127735s
May 21 10:22:39.101: INFO: Pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033980089s
May 21 10:22:41.107: INFO: Pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039929369s
May 21 10:22:43.111: INFO: Pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044716021s
STEP: Saw pod success
May 21 10:22:43.111: INFO: Pod "downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:22:43.114: INFO: Trying to get logs from node master-192.168.130.3 pod downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:22:43.136: INFO: Waiting for pod downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:22:43.143: INFO: Pod downward-api-e0e8d39f-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:22:43.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gx5pm" for this suite.
May 21 10:22:49.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:22:49.244: INFO: namespace: e2e-tests-downward-api-gx5pm, resource: bindings, ignored listing per whitelist
May 21 10:22:49.385: INFO: namespace e2e-tests-downward-api-gx5pm deletion completed in 6.238206576s

• [SLOW TEST:14.420 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:22:49.386: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:22:49.434209      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:22:49.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-zf885" to be "success or failure"
May 21 10:22:49.529: INFO: Pod "downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.176063ms
May 21 10:22:51.534: INFO: Pod "downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008272249s
STEP: Saw pod success
May 21 10:22:51.534: INFO: Pod "downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:22:51.537: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:22:51.562: INFO: Waiting for pod downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:22:51.574: INFO: Pod downwardapi-volume-e987470d-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:22:51.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zf885" for this suite.
May 21 10:22:57.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:22:57.669: INFO: namespace: e2e-tests-projected-zf885, resource: bindings, ignored listing per whitelist
May 21 10:22:57.758: INFO: namespace e2e-tests-projected-zf885 deletion completed in 6.178017554s

• [SLOW TEST:8.373 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:22:57.759: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:22:57.792486      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating projection with secret that has name projected-secret-test-map-ee7acb2a-5ce0-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:22:57.841: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-k6wj6" to be "success or failure"
May 21 10:22:57.844: INFO: Pod "pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.449276ms
May 21 10:22:59.849: INFO: Pod "pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008668323s
STEP: Saw pod success
May 21 10:22:59.849: INFO: Pod "pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:22:59.855: INFO: Trying to get logs from node node-192.168.130.4 pod pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 10:22:59.877: INFO: Waiting for pod pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:22:59.883: INFO: Pod pod-projected-secrets-ee7b4944-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:22:59.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k6wj6" for this suite.
May 21 10:23:05.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:23:05.980: INFO: namespace: e2e-tests-projected-k6wj6, resource: bindings, ignored listing per whitelist
May 21 10:23:06.087: INFO: namespace e2e-tests-projected-k6wj6 deletion completed in 6.196122287s

• [SLOW TEST:8.328 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:23:06.087: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:23:06.135032      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:23:06.222: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:66
May 21 10:23:06.228: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bt65x/daemonsets","resourceVersion":"61968"},"items":null}

May 21 10:23:06.231: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bt65x/pods","resourceVersion":"61968"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:23:06.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bt65x" for this suite.
May 21 10:23:12.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:23:12.390: INFO: namespace: e2e-tests-daemonsets-bt65x, resource: bindings, ignored listing per whitelist
May 21 10:23:12.462: INFO: namespace e2e-tests-daemonsets-bt65x deletion completed in 6.207449326s

S [SKIPPING] [6.375 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674

  May 21 10:23:06.222: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:296
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:23:12.462: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:23:12.511173      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 10:23:12.575: INFO: Waiting up to 5m0s for pod "pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-whpzk" to be "success or failure"
May 21 10:23:12.577: INFO: Pod "pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.360053ms
May 21 10:23:14.583: INFO: Pod "pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007696205s
May 21 10:23:16.588: INFO: Pod "pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012814218s
STEP: Saw pod success
May 21 10:23:16.588: INFO: Pod "pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:23:16.591: INFO: Trying to get logs from node master-192.168.130.3 pod pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:23:16.616: INFO: Waiting for pod pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b to disappear
May 21 10:23:16.620: INFO: Pod pod-f743e69b-5ce0-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:23:16.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-whpzk" for this suite.
May 21 10:23:22.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:23:22.800: INFO: namespace: e2e-tests-emptydir-whpzk, resource: bindings, ignored listing per whitelist
May 21 10:23:22.809: INFO: namespace e2e-tests-emptydir-whpzk deletion completed in 6.183064188s

• [SLOW TEST:10.347 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:23:22.809: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:23:22.844730      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating server pod server in namespace e2e-tests-prestop-7gbkf
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-7gbkf
STEP: Deleting pre-stop pod
May 21 10:23:37.978: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:23:37.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-7gbkf" for this suite.
May 21 10:24:18.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:24:18.194: INFO: namespace: e2e-tests-prestop-7gbkf, resource: bindings, ignored listing per whitelist
May 21 10:24:18.237: INFO: namespace e2e-tests-prestop-7gbkf deletion completed in 40.241275631s

• [SLOW TEST:55.429 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:24:18.238: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:24:18.287388      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-map-1e7b1721-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:24:18.373: INFO: Waiting up to 5m0s for pod "pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-d5qfw" to be "success or failure"
May 21 10:24:18.385: INFO: Pod "pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.890886ms
May 21 10:24:20.389: INFO: Pod "pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.016096507s
May 21 10:24:22.394: INFO: Pod "pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021184747s
STEP: Saw pod success
May 21 10:24:22.394: INFO: Pod "pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:24:22.398: INFO: Trying to get logs from node node-192.168.130.5 pod pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:24:22.421: INFO: Waiting for pod pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:24:22.423: INFO: Pod pod-configmaps-1e7bbf4c-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:24:22.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d5qfw" for this suite.
May 21 10:24:28.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:24:28.609: INFO: namespace: e2e-tests-configmap-d5qfw, resource: bindings, ignored listing per whitelist
May 21 10:24:28.642: INFO: namespace e2e-tests-configmap-d5qfw deletion completed in 6.214315374s

• [SLOW TEST:10.405 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:24:28.643: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:24:28.688586      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-24ac78b1-5ce1-11e8-8768-12f5d52dbf0b,GenerateName:,Namespace:e2e-tests-events-hmdvs,SelfLink:/api/v1/namespaces/e2e-tests-events-hmdvs/pods/send-events-24ac78b1-5ce1-11e8-8768-12f5d52dbf0b,UID:24acfe27-5ce1-11e8-ba59-5254000207f9,ResourceVersion:62298,Generation:0,CreationTimestamp:2018-05-21 10:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 748048956,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.67.127/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4jdjk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4jdjk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4jdjk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-192.168.130.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:24:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:24:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-05-21 10:24:28 +0000 UTC  }],Message:,Reason:,HostIP:192.168.130.4,PodIP:192.168.67.127,StartTime:2018-05-21 10:24:28 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-05-21 10:24:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker://sha256:7bb86f470b0f81f88b421acf654b851a66462cb9d3a8b35deae45c5feeecb5b7 docker://37a218d13f34eb77a9e740361ec53f4dc08f26e49172750a738dabd751112a47}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:24:34.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-hmdvs" for this suite.
May 21 10:24:56.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:24:57.010: INFO: namespace: e2e-tests-events-hmdvs, resource: bindings, ignored listing per whitelist
May 21 10:24:57.026: INFO: namespace e2e-tests-events-hmdvs deletion completed in 22.207534674s

• [SLOW TEST:28.383 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:24:57.026: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:24:57.068121      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:53
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating service endpoint-test2 in namespace e2e-tests-services-64fw2
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-64fw2 to expose endpoints map[]
May 21 10:24:57.159: INFO: Get endpoints failed (10.418752ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 21 10:24:58.163: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-64fw2 exposes endpoints map[] (1.015090081s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-64fw2
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-64fw2 to expose endpoints map[pod1:[80]]
May 21 10:25:00.200: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-64fw2 exposes endpoints map[pod1:[80]] (2.025584138s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-64fw2
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-64fw2 to expose endpoints map[pod1:[80] pod2:[80]]
May 21 10:25:02.255: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-64fw2 exposes endpoints map[pod1:[80] pod2:[80]] (2.04875592s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-64fw2
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-64fw2 to expose endpoints map[pod2:[80]]
May 21 10:25:03.277: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-64fw2 exposes endpoints map[pod2:[80]] (1.015676184s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-64fw2
STEP: waiting up to 1m0s for service endpoint-test2 in namespace e2e-tests-services-64fw2 to expose endpoints map[]
May 21 10:25:04.298: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-64fw2 exposes endpoints map[] (1.014560163s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:25:04.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-64fw2" for this suite.
May 21 10:25:26.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:25:26.457: INFO: namespace: e2e-tests-services-64fw2, resource: bindings, ignored listing per whitelist
May 21 10:25:26.538: INFO: namespace e2e-tests-services-64fw2 deletion completed in 22.207540936s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:58

• [SLOW TEST:29.512 seconds]
[sig-network] Services
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:25:26.539: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:25:26.586528      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 10:25:26.639: INFO: Waiting up to 1m0s for all nodes to be ready
May 21 10:26:26.712: INFO: Waiting for terminating namespaces to be deleted...
May 21 10:26:26.719: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 10:26:26.749: INFO: 69 / 69 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 10:26:26.749: INFO: expected 31 pod replicas in namespace 'kube-system', 31 are Running and Ready.
May 21 10:26:26.759: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 21 10:26:26.759: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.1 before test
May 21 10:26:26.772: INFO: exporters-gpu-gpu-v1-0-jkdz2 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.772: INFO: exporters-node-node-v1-0-sxnm2 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.772: INFO: monitoring-prometheus-prometheus-v1-0-0 from kube-system started at 2018-05-21 05:31:22 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container c1 ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container c2 ready: true, restart count 0
May 21 10:26:26.772: INFO: kube-proxy-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.772: INFO: kube-controller-manager-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.772: INFO: canal-bc599 from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:26:26.772: INFO: storage-provisioner-nfs-provisioner-nfs-v1-0-bffdf9746-h8fs9 from kube-system started at 2018-05-21 05:31:18 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.772: INFO: kube-scheduler-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.772: INFO: kube-apiserver-master-192.168.130.1 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.772: INFO: kube-dns-v22-864bd47fb9-fxkqk from kube-system started at 2018-05-21 05:22:09 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container dnsmasq ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container kubedns ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:26:26.772: INFO: apiserver-provider-ipvsdr-preset-949858699-jz4x9 from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:26:26.772: INFO: sonobuoy from sonobuoy started at 2018-05-21 10:02:59 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 10:26:26.772: INFO: apiserver-proxy-nginx-preset-865784f6fb-dp8vr from kube-system started at 2018-05-21 05:21:38 +0000 UTC (2 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container proxy ready: true, restart count 0
May 21 10:26:26.772: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:26:26.772: INFO: logging-fluentd-fluentd-v1-0-z76bf from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.772: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.772: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.2 before test
May 21 10:26:26.785: INFO: dex-caidex-caidex-v1-0-7fc9cddc49-t8mdt from default started at 2018-05-21 05:31:48 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.785: INFO: 	Container cauth ready: true, restart count 6
May 21 10:26:26.786: INFO: default-http-backend-7558c79bdc-vrdsd from default started at 2018-05-21 05:21:38 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container default-http-backend ready: true, restart count 0
May 21 10:26:26.786: INFO: exporters-gpu-gpu-v1-0-pfgm6 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: clever-kubeflow-admin-kubeflow-admin-v1-0-6cd6f78557-dlz46 from default started at 2018-05-21 05:31:36 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: logging-elasticsearch-elasticsearch-v1-0-0 from kube-system started at 2018-05-21 05:31:10 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: storage-admin-admin-v1-0-786cdd76cf-p4jtp from default started at 2018-05-21 05:31:33 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: config-gc-gc-v1-0-747b8cc554-z8d5g from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 5
May 21 10:26:26.786: INFO: notify-postgres-postgres-v1-0-57db6fb8d5-trcw7 from default started at 2018-05-21 05:31:59 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container postgres ready: true, restart count 0
May 21 10:26:26.786: INFO: kubernetes-admin-mongo-mongo-v1-0-78cb68d655-9ndmv from default started at 2018-05-21 05:32:41 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: kube-scheduler-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.786: INFO: kube-proxy-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.786: INFO: logging-fluentd-fluentd-v1-0-jqxwz from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.786: INFO: kube-apiserver-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.786: INFO: exporters-node-node-v1-0-5lnp5 from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: storage-controller-controller-v1-0-55f4c7c5b4-qb5hh from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 4
May 21 10:26:26.786: INFO: apiserver-provider-ipvsdr-preset-949858699-glksh from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:26:26.786: INFO: kube-dns-autoscaler-v22-757d579667-dmf9r from kube-system started at 2018-05-21 05:21:46 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container autoscaler ready: true, restart count 0
May 21 10:26:26.786: INFO: kube-dns-v22-864bd47fb9-d4lms from kube-system started at 2018-05-21 05:21:47 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container dnsmasq ready: true, restart count 0
May 21 10:26:26.786: INFO: 	Container kubedns ready: true, restart count 0
May 21 10:26:26.786: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:26:26.786: INFO: dex-cauth-cauth-v1-0-8656d55578-jl6lf from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container cauth ready: true, restart count 6
May 21 10:26:26.786: INFO: config-sync-sync-v1-0-78c844cdcc-q6zns from default started at 2018-05-21 05:31:47 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.786: INFO: kube-controller-manager-master-192.168.130.2 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.786: INFO: canal-5z7qg from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:26:26.786: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:26:26.786: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:26:26.786: INFO: apiserver-proxy-nginx-preset-865784f6fb-j5p5k from kube-system started at 2018-05-21 05:21:39 +0000 UTC (2 container statuses recorded)
May 21 10:26:26.786: INFO: 	Container proxy ready: true, restart count 0
May 21 10:26:26.786: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:26:26.786: INFO: 
Logging pods the kubelet thinks is on node master-192.168.130.3 before test
May 21 10:26:26.796: INFO: logging-fluentd-fluentd-v1-0-87742 from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 7
May 21 10:26:26.796: INFO: cargo-admin-admin-v1-0-748bdbfdf5-cwx76 from default started at 2018-05-21 05:31:31 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.796: INFO: monitoring-operator-operator-v1-0-56484b7647-wg8xf from default started at 2018-05-21 05:31:47 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 5
May 21 10:26:26.796: INFO: kube-apiserver-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.796: INFO: kube-proxy-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.796: INFO: apiserver-provider-ipvsdr-preset-949858699-h46q4 from kube-system started at 2018-05-21 05:21:39 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container ipvsdr ready: true, restart count 0
May 21 10:26:26.796: INFO: heketi-69886b6db9-vd5gz from default started at 2018-05-21 05:22:10 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container heketi ready: true, restart count 0
May 21 10:26:26.796: INFO: cluster-mongo-mongo-v1-0-8665b5cbfd-w4lfn from default started at 2018-05-21 05:31:38 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: console-web-redis-redis-v1-0-f9d568d94-rvmh7 from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: kube-controller-manager-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.796: INFO: kube-scheduler-master-192.168.130.3 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.796: INFO: app-admin-admin-v1-0-77b745f8f-vpxjb from default started at 2018-05-21 05:31:40 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: statistician-server-server-v1-0-6f4db6b9f6-r7ptq from default started at 2018-05-21 05:31:48 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: clever-mongo-mongo-v1-0-68dcbfcc8-bzhhb from default started at 2018-05-21 05:32:41 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: logging-elasticsearch-elasticsearch-v1-0-1 from kube-system started at 2018-05-21 05:32:58 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: exporters-node-node-v1-0-dsvzf from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: logging-eventer-eventer-v1-0-76954b748b-4kjj7 from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.796: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-2dswv from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: exporters-gpu-gpu-v1-0-j62dq from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: monitoring-kube-state-metrics-kube-state-metrics-v1-0-5db5lrxwt from kube-system started at 2018-05-21 05:31:19 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container kube-state-metrics ready: true, restart count 0
May 21 10:26:26.796: INFO: tenant-controller-controller-v1-0-7ffcd7969b-xq5dc from kube-system started at 2018-05-21 05:31:20 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 1
May 21 10:26:26.796: INFO: helm-registry-registry-v1-0-5bf6f7f68f-6bd98 from default started at 2018-05-21 05:33:48 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.796: INFO: canal-2lnvt from kube-system started at 2018-05-21 05:21:10 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:26:26.796: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:26:26.796: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:26:26.796: INFO: apiserver-proxy-nginx-preset-865784f6fb-w2flj from kube-system started at 2018-05-21 05:21:38 +0000 UTC (2 container statuses recorded)
May 21 10:26:26.796: INFO: 	Container proxy ready: true, restart count 0
May 21 10:26:26.796: INFO: 	Container sidecar ready: true, restart count 0
May 21 10:26:26.796: INFO: 
Logging pods the kubelet thinks is on node node-192.168.130.4 before test
May 21 10:26:26.811: INFO: exporters-node-node-v1-0-4tt9v from kube-system started at 2018-05-21 05:31:15 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: logging-elasticsearch-elasticsearch-v1-0-2 from kube-system started at 2018-05-21 05:35:35 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: am-minion-v0.0.3-6c77b79c44-znc7x from default started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container am-minion ready: true, restart count 0
May 21 10:26:26.811: INFO: monitoring-admin-admin-v1-0-58bdfdf6c9-45tl9 from default started at 2018-05-21 05:31:44 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 2
May 21 10:26:26.811: INFO: clever-postgres-postgres-v1-0-574b75cd65-mkrp4 from default started at 2018-05-21 05:33:43 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: devops-admin-admin-v1-0-6db9f89cd6-8d7sr from default started at 2018-05-21 05:31:43 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 5
May 21 10:26:26.811: INFO: cyclone-server-server-v1-0-5d9d48f887-9dl77 from default started at 2018-05-21 05:32:37 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 2
May 21 10:26:26.811: INFO: cluster-addon-addon-v1-0-5c4b74889-mdwqc from kube-system started at 2018-05-21 05:31:15 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: storage-controller-k-controller-k-v1-0-5549d55d89-g5vmg from kube-system started at 2018-05-21 05:31:18 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: dex-postgres-postgres-v1-0-79d84d7fd8-ptr85 from default started at 2018-05-21 05:33:44 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: canal-dwmxv from kube-system started at 2018-05-21 05:22:10 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:26:26.811: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:26:26.811: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:26:26.811: INFO: cluster-machine-machine-v1-0-5675994fcd-56s7q from default started at 2018-05-21 05:31:36 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: clever-web-web-v1-0-8564f766cc-78dwb from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: cluster-controller-controller-v1-0-6574f8897b-f7mtl from default started at 2018-05-21 05:31:37 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: logging-admin-admin-v1-0-668cc758bb-s6r89 from default started at 2018-05-21 05:31:40 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: hodor-server-server-v1-0-67c74dc768-c6jhn from default started at 2018-05-21 05:31:43 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.811: INFO: loadbalancer-admin-admin-v1-0-c774889df-78nl8 from default started at 2018-05-21 05:31:22 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: hybrid-controller-manager-controller-manager-v1-0-7f864846p9dll from kube-system started at 2018-05-21 05:31:11 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: exporters-gpu-gpu-v1-0-jrw8h from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: exporters-elasticsearch-elasticsearch-v1-0-6d84c684f5-fqgv8 from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: open-api-server-server-v1-0-575fb8d756-v5bsp from default started at 2018-05-21 05:31:22 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: alerting-notifier-notifier-v1-0-5fd6f8f86b-2xg5r from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: config-mongo-mongo-v1-0-76f5dbc994-xpf7x from default started at 2018-05-21 05:33:41 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: release-controller-v0.2.2-67cd497946-lx95q from kube-system started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container controller ready: true, restart count 0
May 21 10:26:26.811: INFO: config-admission-admission-v1-0-5d997c56d9-2mh59 from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-9btgl from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.811: INFO: license-server-server-v1-0-54675fc555-tsf6q from default started at 2018-05-21 05:31:27 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container license ready: true, restart count 0
May 21 10:26:26.811: INFO: cluster-admin-admin-v1-0-796967fcff-gkffj from default started at 2018-05-21 05:31:35 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 4
May 21 10:26:26.811: INFO: kube-proxy-node-192.168.130.4 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.811: INFO: logging-fluentd-fluentd-v1-0-zh7xb from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.811: INFO: am-mysql-v2.0-c6db7f6b5-vk465 from default started at 2018-05-21 05:28:54 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.811: INFO: 	Container am-mysql ready: true, restart count 0
May 21 10:26:26.811: INFO: 
Logging pods the kubelet thinks is on node node-192.168.130.5 before test
May 21 10:26:26.829: INFO: console-web-web-web-v1-0-559b9c4967-2st5h from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 5
May 21 10:26:26.829: INFO: gitbook-server-server-v1-0-756c7d7b64-cmk9q from default started at 2018-05-21 05:31:46 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: console-web-mongo-mongo-v1-0-7584454d5d-2w7f2 from default started at 2018-05-21 05:33:45 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: sonobuoy-e2e-job-961741dcd1894b0e from sonobuoy started at 2018-05-21 10:03:01 +0000 UTC (2 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container e2e ready: true, restart count 0
May 21 10:26:26.829: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 10:26:26.829: INFO: am-master-v3.0-56f955cdc9-4r2nd from default started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container am-master ready: true, restart count 2
May 21 10:26:26.829: INFO: canary-release-controller-controller-v1-0-6cf74f987c-gclpn from kube-system started at 2018-05-21 05:31:12 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: devops-mongo-mongo-v1-0-fdb9d968b-l85bz from default started at 2018-05-21 05:33:43 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: kube-proxy-node-192.168.130.5 from kube-system started at <nil> (0 container statuses recorded)
May 21 10:26:26.829: INFO: monitoring-heapster-heapster-v1-0-f6f95b846-nfl7k from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: loadbalancer-controller-controller-v1-0-6574dbc55b-npvdz from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: storage-admission-admission-v1-0-54cb855f9f-kng5q from kube-system started at 2018-05-21 05:31:16 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: clever-redis-redis-v1-0-76f69b9d69-ddhf4 from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: tenant-admin-admin-v1-0-68767d7bf8-gbm2r from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: clever-storage-manager-storage-manager-v1-0-847cc98444-fnkbx from default started at 2018-05-21 05:31:44 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 5
May 21 10:26:26.829: INFO: kubernetes-admin-server-server-v1-0-5dbdc9f7f9-crqzr from default started at 2018-05-21 05:31:45 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: dex-mongo-mongo-v1-0-5b65cbcdcd-kkswv from default started at 2018-05-21 05:33:59 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: am-minion-v0.0.3-67d4cf786d-8wwsd from kube-system started at 2018-05-21 05:28:47 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container am-minion ready: true, restart count 0
May 21 10:26:26.829: INFO: clever-mysql-mysql-v1-0-6bff585648-q4v45 from default started at 2018-05-21 05:34:02 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: exporters-node-node-v1-0-q5zcw from kube-system started at 2018-05-21 05:31:14 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: alerting-manager-manager-v1-0-85f76b45d7-7mnwh from default started at 2018-05-21 05:31:32 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: cargo-mongo-mongo-v1-0-7997dc6b94-czd8f from default started at 2018-05-21 05:33:42 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: cyclone-mongo-mongo-v1-0-7d4c8684b6-jsd47 from default started at 2018-05-21 05:34:21 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: canal-4rctf from kube-system started at 2018-05-21 05:22:10 +0000 UTC (3 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container calico-node ready: true, restart count 0
May 21 10:26:26.829: INFO: 	Container install-cni ready: true, restart count 0
May 21 10:26:26.829: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 10:26:26.829: INFO: monitoring-grafana-grafana-v1-0-86c8b866d4-mbbnl from kube-system started at 2018-05-21 05:31:19 +0000 UTC (2 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: 	Container c1 ready: true, restart count 0
May 21 10:26:26.829: INFO: config-admin-admin-v1-0-5f674d5fb9-gfdk4 from default started at 2018-05-21 05:31:39 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: monitoring-mongo-mongo-v1-0-7f6984c8fd-2z6ns from default started at 2018-05-21 05:32:30 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: config-reference-reference-v1-0-5b964f9ccc-66k9t from kube-system started at 2018-05-21 05:31:13 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: logging-fluentd-fluentd-v1-0-rstpn from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 6
May 21 10:26:26.829: INFO: monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-wwhnc from kube-system started at 2018-05-21 05:31:08 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: exporters-gpu-gpu-v1-0-s89lk from kube-system started at 2018-05-21 05:31:13 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: exporters-app-app-v1-0-8b7f56b56-49mdb from kube-system started at 2018-05-21 05:31:17 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: clever-tf-operator-tf-operator-v1-0-557cfb5974-dbn9p from default started at 2018-05-21 05:31:28 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: notify-admin-admin-v1-0-7fd9bbf9c8-b7w4n from default started at 2018-05-21 05:31:29 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
May 21 10:26:26.829: INFO: logging-kibana-kibana-v1-0-68c977f968-sfmvf from kube-system started at 2018-05-21 05:31:07 +0000 UTC (1 container statuses recorded)
May 21 10:26:26.829: INFO: 	Container c0 ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: verifying the node has the label node master-192.168.130.1
STEP: verifying the node has the label node master-192.168.130.2
STEP: verifying the node has the label node master-192.168.130.3
STEP: verifying the node has the label node node-192.168.130.4
STEP: verifying the node has the label node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod alerting-manager-manager-v1-0-85f76b45d7-7mnwh requesting resource cpu=20m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod alerting-notifier-notifier-v1-0-5fd6f8f86b-2xg5r requesting resource cpu=20m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod am-master-v3.0-56f955cdc9-4r2nd requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod am-minion-v0.0.3-6c77b79c44-znc7x requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod am-mysql-v2.0-c6db7f6b5-vk465 requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod app-admin-admin-v1-0-77b745f8f-vpxjb requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.010: INFO: Pod cargo-admin-admin-v1-0-748bdbfdf5-cwx76 requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.010: INFO: Pod cargo-mongo-mongo-v1-0-7997dc6b94-czd8f requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod clever-kubeflow-admin-kubeflow-admin-v1-0-6cd6f78557-dlz46 requesting resource cpu=0m on Node master-192.168.130.2
May 21 10:26:27.010: INFO: Pod clever-mongo-mongo-v1-0-68dcbfcc8-bzhhb requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.010: INFO: Pod clever-mysql-mysql-v1-0-6bff585648-q4v45 requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod clever-postgres-postgres-v1-0-574b75cd65-mkrp4 requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod clever-redis-redis-v1-0-76f69b9d69-ddhf4 requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod clever-storage-manager-storage-manager-v1-0-847cc98444-fnkbx requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod clever-tf-operator-tf-operator-v1-0-557cfb5974-dbn9p requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod clever-web-web-v1-0-8564f766cc-78dwb requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod cluster-admin-admin-v1-0-796967fcff-gkffj requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod cluster-controller-controller-v1-0-6574f8897b-f7mtl requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod cluster-machine-machine-v1-0-5675994fcd-56s7q requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.010: INFO: Pod cluster-mongo-mongo-v1-0-8665b5cbfd-w4lfn requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.010: INFO: Pod config-admin-admin-v1-0-5f674d5fb9-gfdk4 requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.010: INFO: Pod config-gc-gc-v1-0-747b8cc554-z8d5g requesting resource cpu=300m on Node master-192.168.130.2
May 21 10:26:27.010: INFO: Pod config-mongo-mongo-v1-0-76f5dbc994-xpf7x requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod config-sync-sync-v1-0-78c844cdcc-q6zns requesting resource cpu=300m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod console-web-mongo-mongo-v1-0-7584454d5d-2w7f2 requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod console-web-redis-redis-v1-0-f9d568d94-rvmh7 requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod console-web-web-web-v1-0-559b9c4967-2st5h requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod cyclone-mongo-mongo-v1-0-7d4c8684b6-jsd47 requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod cyclone-server-server-v1-0-5d9d48f887-9dl77 requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod default-http-backend-7558c79bdc-vrdsd requesting resource cpu=50m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod devops-admin-admin-v1-0-6db9f89cd6-8d7sr requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod devops-mongo-mongo-v1-0-fdb9d968b-l85bz requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod dex-caidex-caidex-v1-0-7fc9cddc49-t8mdt requesting resource cpu=500m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod dex-cauth-cauth-v1-0-8656d55578-jl6lf requesting resource cpu=200m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod dex-mongo-mongo-v1-0-5b65cbcdcd-kkswv requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod dex-postgres-postgres-v1-0-79d84d7fd8-ptr85 requesting resource cpu=500m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod gitbook-server-server-v1-0-756c7d7b64-cmk9q requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod heketi-69886b6db9-vd5gz requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod helm-registry-registry-v1-0-5bf6f7f68f-6bd98 requesting resource cpu=100m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod hodor-server-server-v1-0-67c74dc768-c6jhn requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod kubernetes-admin-mongo-mongo-v1-0-78cb68d655-9ndmv requesting resource cpu=0m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kubernetes-admin-server-server-v1-0-5dbdc9f7f9-crqzr requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod license-server-server-v1-0-54675fc555-tsf6q requesting resource cpu=50m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod loadbalancer-admin-admin-v1-0-c774889df-78nl8 requesting resource cpu=200m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod logging-admin-admin-v1-0-668cc758bb-s6r89 requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod monitoring-admin-admin-v1-0-58bdfdf6c9-45tl9 requesting resource cpu=100m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod monitoring-mongo-mongo-v1-0-7f6984c8fd-2z6ns requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod monitoring-operator-operator-v1-0-56484b7647-wg8xf requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod notify-admin-admin-v1-0-7fd9bbf9c8-b7w4n requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod notify-postgres-postgres-v1-0-57db6fb8d5-trcw7 requesting resource cpu=0m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod open-api-server-server-v1-0-575fb8d756-v5bsp requesting resource cpu=100m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod statistician-server-server-v1-0-6f4db6b9f6-r7ptq requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod storage-admin-admin-v1-0-786cdd76cf-p4jtp requesting resource cpu=0m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod storage-controller-controller-v1-0-55f4c7c5b4-qb5hh requesting resource cpu=0m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod tenant-admin-admin-v1-0-68767d7bf8-gbm2r requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod am-minion-v0.0.3-67d4cf786d-8wwsd requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod apiserver-provider-ipvsdr-preset-949858699-glksh requesting resource cpu=200m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod apiserver-provider-ipvsdr-preset-949858699-h46q4 requesting resource cpu=200m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod apiserver-provider-ipvsdr-preset-949858699-jz4x9 requesting resource cpu=200m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod apiserver-proxy-nginx-preset-865784f6fb-dp8vr requesting resource cpu=100m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod apiserver-proxy-nginx-preset-865784f6fb-j5p5k requesting resource cpu=100m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod apiserver-proxy-nginx-preset-865784f6fb-w2flj requesting resource cpu=100m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod canal-2lnvt requesting resource cpu=250m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod canal-4rctf requesting resource cpu=250m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod canal-5z7qg requesting resource cpu=250m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod canal-bc599 requesting resource cpu=250m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod canal-dwmxv requesting resource cpu=250m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod canary-release-controller-controller-v1-0-6cf74f987c-gclpn requesting resource cpu=200m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod cluster-addon-addon-v1-0-5c4b74889-mdwqc requesting resource cpu=25m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod config-admission-admission-v1-0-5d997c56d9-2mh59 requesting resource cpu=200m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod config-reference-reference-v1-0-5b964f9ccc-66k9t requesting resource cpu=200m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod exporters-app-app-v1-0-8b7f56b56-49mdb requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod exporters-elasticsearch-elasticsearch-v1-0-6d84c684f5-fqgv8 requesting resource cpu=25m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod exporters-gpu-gpu-v1-0-j62dq requesting resource cpu=50m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod exporters-gpu-gpu-v1-0-jkdz2 requesting resource cpu=50m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod exporters-gpu-gpu-v1-0-jrw8h requesting resource cpu=50m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod exporters-gpu-gpu-v1-0-pfgm6 requesting resource cpu=50m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod exporters-gpu-gpu-v1-0-s89lk requesting resource cpu=50m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod exporters-node-node-v1-0-4tt9v requesting resource cpu=10m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod exporters-node-node-v1-0-5lnp5 requesting resource cpu=10m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod exporters-node-node-v1-0-dsvzf requesting resource cpu=10m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod exporters-node-node-v1-0-q5zcw requesting resource cpu=10m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod exporters-node-node-v1-0-sxnm2 requesting resource cpu=10m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod hybrid-controller-manager-controller-manager-v1-0-7f864846p9dll requesting resource cpu=500m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod kube-apiserver-master-192.168.130.1 requesting resource cpu=250m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod kube-apiserver-master-192.168.130.2 requesting resource cpu=250m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kube-apiserver-master-192.168.130.3 requesting resource cpu=250m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod kube-controller-manager-master-192.168.130.1 requesting resource cpu=200m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod kube-controller-manager-master-192.168.130.2 requesting resource cpu=200m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kube-controller-manager-master-192.168.130.3 requesting resource cpu=200m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod kube-dns-autoscaler-v22-757d579667-dmf9r requesting resource cpu=20m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kube-dns-v22-864bd47fb9-d4lms requesting resource cpu=260m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kube-dns-v22-864bd47fb9-fxkqk requesting resource cpu=260m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod kube-proxy-master-192.168.130.1 requesting resource cpu=100m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod kube-proxy-master-192.168.130.2 requesting resource cpu=100m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kube-proxy-master-192.168.130.3 requesting resource cpu=100m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod kube-proxy-node-192.168.130.4 requesting resource cpu=100m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod kube-proxy-node-192.168.130.5 requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod kube-scheduler-master-192.168.130.1 requesting resource cpu=100m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod kube-scheduler-master-192.168.130.2 requesting resource cpu=100m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod kube-scheduler-master-192.168.130.3 requesting resource cpu=100m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod loadbalancer-controller-controller-v1-0-6574dbc55b-npvdz requesting resource cpu=200m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod logging-elasticsearch-elasticsearch-v1-0-0 requesting resource cpu=100m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod logging-elasticsearch-elasticsearch-v1-0-1 requesting resource cpu=100m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod logging-elasticsearch-elasticsearch-v1-0-2 requesting resource cpu=100m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod logging-eventer-eventer-v1-0-76954b748b-4kjj7 requesting resource cpu=25m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod logging-fluentd-fluentd-v1-0-87742 requesting resource cpu=200m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod logging-fluentd-fluentd-v1-0-jqxwz requesting resource cpu=200m on Node master-192.168.130.2
May 21 10:26:27.011: INFO: Pod logging-fluentd-fluentd-v1-0-rstpn requesting resource cpu=200m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod logging-fluentd-fluentd-v1-0-z76bf requesting resource cpu=200m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod logging-fluentd-fluentd-v1-0-zh7xb requesting resource cpu=200m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod logging-kibana-kibana-v1-0-68c977f968-sfmvf requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod monitoring-grafana-grafana-v1-0-86c8b866d4-mbbnl requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod monitoring-heapster-heapster-v1-0-f6f95b846-nfl7k requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod monitoring-kube-state-metrics-kube-state-metrics-v1-0-5db5lrxwt requesting resource cpu=100m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-2dswv requesting resource cpu=0m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-9btgl requesting resource cpu=0m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod monitoring-metrics-server-metrics-server-v1-0-c6d778b4b-wwhnc requesting resource cpu=0m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod monitoring-prometheus-prometheus-v1-0-0 requesting resource cpu=2000m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod release-controller-v0.2.2-67cd497946-lx95q requesting resource cpu=100m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod storage-admission-admission-v1-0-54cb855f9f-kng5q requesting resource cpu=100m on Node node-192.168.130.5
May 21 10:26:27.011: INFO: Pod storage-controller-k-controller-k-v1-0-5549d55d89-g5vmg requesting resource cpu=100m on Node node-192.168.130.4
May 21 10:26:27.011: INFO: Pod storage-provisioner-nfs-provisioner-nfs-v1-0-bffdf9746-h8fs9 requesting resource cpu=100m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod tenant-controller-controller-v1-0-7ffcd7969b-xq5dc requesting resource cpu=500m on Node master-192.168.130.3
May 21 10:26:27.011: INFO: Pod sonobuoy requesting resource cpu=0m on Node master-192.168.130.1
May 21 10:26:27.011: INFO: Pod sonobuoy-e2e-job-961741dcd1894b0e requesting resource cpu=0m on Node node-192.168.130.5
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2a1526-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe3f9dbe8e], Reason = [Scheduled], Message = [Successfully assigned filler-pod-6b2a1526-5ce1-11e8-8768-12f5d52dbf0b to master-192.168.130.2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2a1526-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe52981431], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-l4j5z" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2a1526-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe9440728e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause-amd64:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2a1526-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe966bf8ab], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2a1526-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe9effc107], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ba608-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe40812b8a], Reason = [Scheduled], Message = [Successfully assigned filler-pod-6b2ba608-5ce1-11e8-8768-12f5d52dbf0b to master-192.168.130.3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ba608-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe51c63355], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-l4j5z" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ba608-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe78fff8f6], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause-amd64:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ba608-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe816a238b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ba608-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe89e11377], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2cf162-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe4084a482], Reason = [Scheduled], Message = [Successfully assigned filler-pod-6b2cf162-5ce1-11e8-8768-12f5d52dbf0b to node-192.168.130.4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2cf162-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe544aafb1], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-l4j5z" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2cf162-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe91ccf0f7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause-amd64:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2cf162-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe949b8e46], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2cf162-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe9ae10ffe], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ebc4e-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe41d90905], Reason = [Scheduled], Message = [Successfully assigned filler-pod-6b2ebc4e-5ce1-11e8-8768-12f5d52dbf0b to node-192.168.130.5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ebc4e-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe512519d4], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-l4j5z" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ebc4e-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe77c6f53a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause-amd64:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ebc4e-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe7fbed576], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b2ebc4e-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe85f26a26], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b303ea4-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe422d977c], Reason = [Scheduled], Message = [Successfully assigned filler-pod-6b303ea4-5ce1-11e8-8768-12f5d52dbf0b to master-192.168.130.1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b303ea4-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe51eaad90], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-l4j5z" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b303ea4-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe8e33089b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause-amd64:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b303ea4-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe918af6db], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6b303ea4-5ce1-11e8-8768-12f5d52dbf0b.1530a1fe98973ecd], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1530a1ff32dc196c], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 Insufficient cpu.]
STEP: removing the label node off the node master-192.168.130.1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node master-192.168.130.2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node master-192.168.130.3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-192.168.130.4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-192.168.130.5
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:26:32.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9c8qc" for this suite.
May 21 10:26:56.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:26:56.417: INFO: namespace: e2e-tests-sched-pred-9c8qc, resource: bindings, ignored listing per whitelist
May 21 10:26:56.452: INFO: namespace e2e-tests-sched-pred-9c8qc deletion completed in 24.221033078s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:89.913 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a docker exec liveness probe with timeout  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:26:56.453: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:26:56.498350      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a docker exec liveness probe with timeout  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:26:56.609: INFO: The default exec handler, dockertools.NativeExecHandler, does not support timeouts due to a limitation in the Docker Remote API
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:26:56.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hwm9l" for this suite.
May 21 10:27:02.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:27:02.755: INFO: namespace: e2e-tests-container-probe-hwm9l, resource: bindings, ignored listing per whitelist
May 21 10:27:02.831: INFO: namespace e2e-tests-container-probe-hwm9l deletion completed in 6.215435406s

S [SKIPPING] [6.378 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be restarted with a docker exec liveness probe with timeout  [Conformance] [It]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674

  May 21 10:26:56.609: The default exec handler, dockertools.NativeExecHandler, does not support timeouts due to a limitation in the Docker Remote API

  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:296
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:27:02.832: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:27:02.885579      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test substitution in container's args
May 21 10:27:02.960: INFO: Waiting up to 5m0s for pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-var-expansion-98zqv" to be "success or failure"
May 21 10:27:02.967: INFO: Pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.010227ms
May 21 10:27:04.972: INFO: Pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012010756s
May 21 10:27:06.977: INFO: Pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017254084s
May 21 10:27:08.983: INFO: Pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023094773s
May 21 10:27:10.988: INFO: Pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027903788s
STEP: Saw pod success
May 21 10:27:10.988: INFO: Pod "var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:27:10.991: INFO: Trying to get logs from node master-192.168.130.1 pod var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:27:11.021: INFO: Waiting for pod var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:27:11.029: INFO: Pod var-expansion-8094c085-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:27:11.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-98zqv" for this suite.
May 21 10:27:17.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:27:17.263: INFO: namespace: e2e-tests-var-expansion-98zqv, resource: bindings, ignored listing per whitelist
May 21 10:27:17.289: INFO: namespace e2e-tests-var-expansion-98zqv deletion completed in 6.252596118s

• [SLOW TEST:14.457 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should allow substituting values in a container's args  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:27:17.289: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:27:17.343459      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-upd-8937a567-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-8937a567-5ce1-11e8-8768-12f5d52dbf0b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:27:21.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n9hgb" for this suite.
May 21 10:27:43.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:27:43.645: INFO: namespace: e2e-tests-configmap-n9hgb, resource: bindings, ignored listing per whitelist
May 21 10:27:43.696: INFO: namespace e2e-tests-configmap-n9hgb deletion completed in 22.19385778s

• [SLOW TEST:26.408 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:27:43.696: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:27:43.740020      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 10:27:43.835: INFO: Waiting up to 5m0s for pod "pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-spvrf" to be "success or failure"
May 21 10:27:43.845: INFO: Pod "pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.97209ms
May 21 10:27:45.850: INFO: Pod "pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015613814s
STEP: Saw pod success
May 21 10:27:45.850: INFO: Pod "pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:27:45.856: INFO: Trying to get logs from node node-192.168.130.4 pod pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:27:45.880: INFO: Waiting for pod pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:27:45.884: INFO: Pod pod-98f0ca08-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:27:45.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-spvrf" for this suite.
May 21 10:27:51.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:27:52.067: INFO: namespace: e2e-tests-emptydir-spvrf, resource: bindings, ignored listing per whitelist
May 21 10:27:52.091: INFO: namespace e2e-tests-emptydir-spvrf deletion completed in 6.200243633s

• [SLOW TEST:8.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:27:52.091: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:27:52.138457      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-9def9689-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:27:52.203: INFO: Waiting up to 5m0s for pod "pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-6pbkd" to be "success or failure"
May 21 10:27:52.207: INFO: Pod "pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.685829ms
May 21 10:27:54.213: INFO: Pod "pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009981127s
STEP: Saw pod success
May 21 10:27:54.214: INFO: Pod "pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:27:54.217: INFO: Trying to get logs from node master-192.168.130.3 pod pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:27:54.256: INFO: Waiting for pod pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:27:54.267: INFO: Pod pod-secrets-9df03c40-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:27:54.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6pbkd" for this suite.
May 21 10:28:00.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:28:00.497: INFO: namespace: e2e-tests-secrets-6pbkd, resource: bindings, ignored listing per whitelist
May 21 10:28:00.522: INFO: namespace e2e-tests-secrets-6pbkd deletion completed in 6.249913823s

• [SLOW TEST:8.431 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:28:00.522: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:28:00.562467      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 10:28:03.153: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a2f4e286-5ce1-11e8-8768-12f5d52dbf0b"
May 21 10:28:03.153: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a2f4e286-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-pods-sf46j" to be "terminated due to deadline exceeded"
May 21 10:28:03.157: INFO: Pod "pod-update-activedeadlineseconds-a2f4e286-5ce1-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 4.401119ms
May 21 10:28:05.163: INFO: Pod "pod-update-activedeadlineseconds-a2f4e286-5ce1-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.00964926s
May 21 10:28:07.167: INFO: Pod "pod-update-activedeadlineseconds-a2f4e286-5ce1-11e8-8768-12f5d52dbf0b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.013723386s
May 21 10:28:07.167: INFO: Pod "pod-update-activedeadlineseconds-a2f4e286-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:28:07.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sf46j" for this suite.
May 21 10:28:13.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:28:13.356: INFO: namespace: e2e-tests-pods-sf46j, resource: bindings, ignored listing per whitelist
May 21 10:28:13.364: INFO: namespace e2e-tests-pods-sf46j deletion completed in 6.190734281s

• [SLOW TEST:12.841 seconds]
[k8s.io] Pods
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should allow activeDeadlineSeconds to be updated  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:28:13.364: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:28:13.419616      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name cm-test-opt-del-aaa5c657-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating configMap with name cm-test-opt-upd-aaa5c816-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-aaa5c657-5ce1-11e8-8768-12f5d52dbf0b
STEP: Updating configmap cm-test-opt-upd-aaa5c816-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating configMap with name cm-test-opt-create-aaa5c847-5ce1-11e8-8768-12f5d52dbf0b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:28:17.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fkvqv" for this suite.
May 21 10:28:41.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:28:41.783: INFO: namespace: e2e-tests-projected-fkvqv, resource: bindings, ignored listing per whitelist
May 21 10:28:41.853: INFO: namespace e2e-tests-projected-fkvqv deletion completed in 24.201417698s

• [SLOW TEST:28.489 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:28:41.853: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:28:41.909141      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-map-bb9ab7ff-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:28:41.977: INFO: Waiting up to 5m0s for pod "pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-pxz7q" to be "success or failure"
May 21 10:28:41.981: INFO: Pod "pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.626998ms
May 21 10:28:43.985: INFO: Pod "pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.007367364s
May 21 10:28:46.002: INFO: Pod "pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024672254s
STEP: Saw pod success
May 21 10:28:46.002: INFO: Pod "pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:28:46.029: INFO: Trying to get logs from node node-192.168.130.5 pod pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:28:46.129: INFO: Waiting for pod pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:28:46.140: INFO: Pod pod-secrets-bb9b596d-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:28:46.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pxz7q" for this suite.
May 21 10:28:52.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:28:52.289: INFO: namespace: e2e-tests-secrets-pxz7q, resource: bindings, ignored listing per whitelist
May 21 10:28:52.373: INFO: namespace e2e-tests-secrets-pxz7q deletion completed in 6.226499634s

• [SLOW TEST:10.520 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:28:52.373: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:28:52.420594      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c1e1b3d4-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c1e1b3d4-5ce1-11e8-8768-12f5d52dbf0b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:28:56.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r6ttb" for this suite.
May 21 10:29:18.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:29:18.900: INFO: namespace: e2e-tests-projected-r6ttb, resource: bindings, ignored listing per whitelist
May 21 10:29:18.961: INFO: namespace e2e-tests-projected-r6ttb deletion completed in 22.224011823s

• [SLOW TEST:26.588 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:29:18.962: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:29:18.996079      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap e2e-tests-configmap-qll4q/configmap-test-d1b82d8d-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:29:19.092: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-qll4q" to be "success or failure"
May 21 10:29:19.095: INFO: Pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357577ms
May 21 10:29:21.100: INFO: Pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007684199s
May 21 10:29:23.105: INFO: Pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012540123s
May 21 10:29:25.108: INFO: Pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016361009s
May 21 10:29:27.112: INFO: Pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020435908s
STEP: Saw pod success
May 21 10:29:27.112: INFO: Pod "pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:29:27.115: INFO: Trying to get logs from node master-192.168.130.3 pod pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b container env-test: <nil>
STEP: delete the pod
May 21 10:29:27.141: INFO: Waiting for pod pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:29:27.146: INFO: Pod pod-configmaps-d1b95b5a-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:29:27.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qll4q" for this suite.
May 21 10:29:33.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:29:33.263: INFO: namespace: e2e-tests-configmap-qll4q, resource: bindings, ignored listing per whitelist
May 21 10:29:33.372: INFO: namespace e2e-tests-configmap-qll4q deletion completed in 6.220349985s

• [SLOW TEST:14.410 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:29:33.372: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:29:33.413181      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:29:33.523: INFO: (0) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.310566ms)
May 21 10:29:33.527: INFO: (1) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.508272ms)
May 21 10:29:33.531: INFO: (2) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.977756ms)
May 21 10:29:33.535: INFO: (3) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.963501ms)
May 21 10:29:33.540: INFO: (4) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.294008ms)
May 21 10:29:33.544: INFO: (5) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.978777ms)
May 21 10:29:33.548: INFO: (6) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.983143ms)
May 21 10:29:33.551: INFO: (7) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.842035ms)
May 21 10:29:33.555: INFO: (8) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.89179ms)
May 21 10:29:33.560: INFO: (9) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.155664ms)
May 21 10:29:33.564: INFO: (10) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.064564ms)
May 21 10:29:33.567: INFO: (11) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.57411ms)
May 21 10:29:33.571: INFO: (12) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.834235ms)
May 21 10:29:33.575: INFO: (13) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.413586ms)
May 21 10:29:33.578: INFO: (14) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.689874ms)
May 21 10:29:33.582: INFO: (15) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.790232ms)
May 21 10:29:33.586: INFO: (16) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.506062ms)
May 21 10:29:33.589: INFO: (17) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.733077ms)
May 21 10:29:33.593: INFO: (18) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.568465ms)
May 21 10:29:33.597: INFO: (19) /api/v1/nodes/master-192.168.130.1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.431808ms)
[AfterEach] version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:29:33.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-m94bf" for this suite.
May 21 10:29:39.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:29:39.688: INFO: namespace: e2e-tests-proxy-m94bf, resource: bindings, ignored listing per whitelist
May 21 10:29:39.807: INFO: namespace e2e-tests-proxy-m94bf deletion completed in 6.205025966s

• [SLOW TEST:6.435 seconds]
[sig-network] Proxy
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:29:39.807: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:29:39.851648      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: getting the auto-created API token
May 21 10:29:40.435: INFO: created pod pod-service-account-defaultsa
May 21 10:29:40.435: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 21 10:29:40.441: INFO: created pod pod-service-account-mountsa
May 21 10:29:40.441: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 21 10:29:40.446: INFO: created pod pod-service-account-nomountsa
May 21 10:29:40.446: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 21 10:29:40.457: INFO: created pod pod-service-account-defaultsa-mountspec
May 21 10:29:40.457: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 21 10:29:40.468: INFO: created pod pod-service-account-mountsa-mountspec
May 21 10:29:40.468: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 21 10:29:40.488: INFO: created pod pod-service-account-nomountsa-mountspec
May 21 10:29:40.488: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 21 10:29:40.504: INFO: created pod pod-service-account-defaultsa-nomountspec
May 21 10:29:40.504: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 21 10:29:40.514: INFO: created pod pod-service-account-mountsa-nomountspec
May 21 10:29:40.514: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 21 10:29:40.523: INFO: created pod pod-service-account-nomountsa-nomountspec
May 21 10:29:40.523: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:29:40.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-wcrzz" for this suite.
May 21 10:29:46.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:29:46.988: INFO: namespace: e2e-tests-svcaccounts-wcrzz, resource: bindings, ignored listing per whitelist
May 21 10:29:47.033: INFO: namespace e2e-tests-svcaccounts-wcrzz deletion completed in 6.491501436s

• [SLOW TEST:7.226 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:29:47.033: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:29:47.082386      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-map-e273b85c-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:29:47.154: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-4nstd" to be "success or failure"
May 21 10:29:47.157: INFO: Pod "pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.76159ms
May 21 10:29:49.162: INFO: Pod "pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008617158s
STEP: Saw pod success
May 21 10:29:49.162: INFO: Pod "pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:29:49.166: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:29:49.190: INFO: Waiting for pod pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:29:49.199: INFO: Pod pod-projected-configmaps-e274552a-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:29:49.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4nstd" for this suite.
May 21 10:29:55.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:29:55.367: INFO: namespace: e2e-tests-projected-4nstd, resource: bindings, ignored listing per whitelist
May 21 10:29:55.421: INFO: namespace e2e-tests-projected-4nstd deletion completed in 6.211671632s

• [SLOW TEST:8.388 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:29:55.421: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:29:55.474270      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:29:55.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-5gw6l" to be "success or failure"
May 21 10:29:55.525: INFO: Pod "downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.242642ms
May 21 10:29:57.530: INFO: Pod "downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010165419s
STEP: Saw pod success
May 21 10:29:57.530: INFO: Pod "downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:29:57.533: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:29:57.567: INFO: Waiting for pod downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:29:57.572: INFO: Pod downwardapi-volume-e770cddb-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:29:57.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5gw6l" for this suite.
May 21 10:30:03.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:30:03.758: INFO: namespace: e2e-tests-downward-api-5gw6l, resource: bindings, ignored listing per whitelist
May 21 10:30:03.764: INFO: namespace e2e-tests-downward-api-5gw6l deletion completed in 6.18667307s

• [SLOW TEST:8.343 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:30:03.764: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:30:03.808241      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating secret e2e-tests-secrets-4f2vg/secret-test-ec6b7cce-5ce1-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:30:03.878: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-4f2vg" to be "success or failure"
May 21 10:30:03.881: INFO: Pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.134003ms
May 21 10:30:05.886: INFO: Pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00768022s
May 21 10:30:07.893: INFO: Pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015189623s
May 21 10:30:09.898: INFO: Pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 6.019434659s
May 21 10:30:11.903: INFO: Pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.025336772s
STEP: Saw pod success
May 21 10:30:11.904: INFO: Pod "pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:30:11.912: INFO: Trying to get logs from node master-192.168.130.1 pod pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b container env-test: <nil>
STEP: delete the pod
May 21 10:30:11.936: INFO: Waiting for pod pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:30:11.942: INFO: Pod pod-configmaps-ec6c1f3d-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:30:11.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4f2vg" for this suite.
May 21 10:30:17.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:30:18.085: INFO: namespace: e2e-tests-secrets-4f2vg, resource: bindings, ignored listing per whitelist
May 21 10:30:18.219: INFO: namespace e2e-tests-secrets-4f2vg deletion completed in 6.269787472s

• [SLOW TEST:14.455 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:30:18.219: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:30:18.261643      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test use defaults
May 21 10:30:18.381: INFO: Waiting up to 5m0s for pod "client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-containers-4mrq6" to be "success or failure"
May 21 10:30:18.399: INFO: Pod "client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.453942ms
May 21 10:30:20.404: INFO: Pod "client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022258665s
May 21 10:30:22.408: INFO: Pod "client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026383018s
STEP: Saw pod success
May 21 10:30:22.408: INFO: Pod "client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:30:22.411: INFO: Trying to get logs from node node-192.168.130.5 pod client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:30:22.447: INFO: Waiting for pod client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b to disappear
May 21 10:30:22.449: INFO: Pod client-containers-f5104034-5ce1-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:30:22.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4mrq6" for this suite.
May 21 10:30:28.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:30:28.620: INFO: namespace: e2e-tests-containers-4mrq6, resource: bindings, ignored listing per whitelist
May 21 10:30:28.672: INFO: namespace e2e-tests-containers-4mrq6 deletion completed in 6.21853983s

• [SLOW TEST:10.453 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should use the image defaults if command and args are blank  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:30:28.672: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:30:28.725526      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0521 10:30:39.013355      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:30:39.013: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:30:39.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7srfj" for this suite.
May 21 10:30:47.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:30:47.176: INFO: namespace: e2e-tests-gc-7srfj, resource: bindings, ignored listing per whitelist
May 21 10:30:47.245: INFO: namespace e2e-tests-gc-7srfj deletion completed in 8.227159671s

• [SLOW TEST:18.573 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:30:47.245: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:30:47.288303      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:53
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-t9tkz
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-t9tkz to expose endpoints map[]
May 21 10:30:47.364: INFO: Get endpoints failed (11.815576ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 21 10:30:48.369: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t9tkz exposes endpoints map[] (1.016776874s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-t9tkz
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-t9tkz to expose endpoints map[pod1:[100]]
May 21 10:30:50.408: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t9tkz exposes endpoints map[pod1:[100]] (2.028410118s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-t9tkz
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-t9tkz to expose endpoints map[pod1:[100] pod2:[101]]
May 21 10:30:52.447: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t9tkz exposes endpoints map[pod1:[100] pod2:[101]] (2.03177302s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-t9tkz
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-t9tkz to expose endpoints map[pod2:[101]]
May 21 10:30:53.468: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t9tkz exposes endpoints map[pod2:[101]] (1.01418075s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-t9tkz
STEP: waiting up to 1m0s for service multi-endpoint-test in namespace e2e-tests-services-t9tkz to expose endpoints map[]
May 21 10:30:54.488: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t9tkz exposes endpoints map[] (1.009649964s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:30:54.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-t9tkz" for this suite.
May 21 10:31:16.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:31:16.665: INFO: namespace: e2e-tests-services-t9tkz, resource: bindings, ignored listing per whitelist
May 21 10:31:16.708: INFO: namespace e2e-tests-services-t9tkz deletion completed in 22.178805305s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:58

• [SLOW TEST:29.462 seconds]
[sig-network] Services
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:31:16.708: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:31:16.754262      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-846p4
May 21 10:31:18.827: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-846p4
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:31:18.831: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:33:19.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-846p4" for this suite.
May 21 10:33:25.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:33:25.449: INFO: namespace: e2e-tests-container-probe-846p4, resource: bindings, ignored listing per whitelist
May 21 10:33:25.463: INFO: namespace e2e-tests-container-probe-846p4 deletion completed in 6.24503346s

• [SLOW TEST:128.756 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should *not* be restarted with a /healthz http liveness probe  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:33:25.464: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:33:25.519223      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-25m9s
I0521 10:33:25.577883      15 runners.go:175] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-25m9s, replica count: 1
I0521 10:33:26.578764      15 runners.go:175] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 10:33:27.579009      15 runners.go:175] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 10:33:27.691: INFO: Created: latency-svc-dn2lw
May 21 10:33:27.707: INFO: Got endpoints: latency-svc-dn2lw [27.713481ms]
May 21 10:33:27.723: INFO: Created: latency-svc-nksb5
May 21 10:33:27.729: INFO: Got endpoints: latency-svc-nksb5 [21.894046ms]
May 21 10:33:27.739: INFO: Created: latency-svc-kkb98
May 21 10:33:27.745: INFO: Created: latency-svc-z4ltt
May 21 10:33:27.745: INFO: Got endpoints: latency-svc-kkb98 [38.153015ms]
May 21 10:33:27.751: INFO: Got endpoints: latency-svc-z4ltt [43.381627ms]
May 21 10:33:27.756: INFO: Created: latency-svc-6xcnq
May 21 10:33:27.767: INFO: Got endpoints: latency-svc-6xcnq [59.779158ms]
May 21 10:33:27.769: INFO: Created: latency-svc-9m74h
May 21 10:33:27.775: INFO: Got endpoints: latency-svc-9m74h [67.768297ms]
May 21 10:33:27.777: INFO: Created: latency-svc-2s84z
May 21 10:33:27.782: INFO: Got endpoints: latency-svc-2s84z [73.897842ms]
May 21 10:33:27.786: INFO: Created: latency-svc-9bthv
May 21 10:33:27.787: INFO: Created: latency-svc-grs6g
May 21 10:33:27.792: INFO: Got endpoints: latency-svc-grs6g [24.110524ms]
May 21 10:33:27.794: INFO: Got endpoints: latency-svc-9bthv [86.843064ms]
May 21 10:33:27.800: INFO: Created: latency-svc-bp4h6
May 21 10:33:27.808: INFO: Created: latency-svc-6tmnv
May 21 10:33:27.808: INFO: Created: latency-svc-mfqd4
May 21 10:33:27.809: INFO: Got endpoints: latency-svc-bp4h6 [101.328331ms]
May 21 10:33:27.815: INFO: Got endpoints: latency-svc-mfqd4 [106.959737ms]
May 21 10:33:27.820: INFO: Got endpoints: latency-svc-6tmnv [111.69417ms]
May 21 10:33:27.820: INFO: Created: latency-svc-zzmwv
May 21 10:33:27.825: INFO: Got endpoints: latency-svc-zzmwv [116.95866ms]
May 21 10:33:27.828: INFO: Created: latency-svc-ljshk
May 21 10:33:27.832: INFO: Got endpoints: latency-svc-ljshk [123.80573ms]
May 21 10:33:27.837: INFO: Created: latency-svc-kmkv6
May 21 10:33:27.844: INFO: Got endpoints: latency-svc-kmkv6 [135.484802ms]
May 21 10:33:27.847: INFO: Created: latency-svc-69xcr
May 21 10:33:27.853: INFO: Created: latency-svc-rj6pc
May 21 10:33:27.854: INFO: Got endpoints: latency-svc-69xcr [146.140465ms]
May 21 10:33:27.862: INFO: Got endpoints: latency-svc-rj6pc [155.073771ms]
May 21 10:33:27.865: INFO: Created: latency-svc-tw95j
May 21 10:33:27.871: INFO: Got endpoints: latency-svc-tw95j [141.524919ms]
May 21 10:33:27.880: INFO: Created: latency-svc-hhfjn
May 21 10:33:27.880: INFO: Created: latency-svc-gbks9
May 21 10:33:27.883: INFO: Created: latency-svc-z2lzj
May 21 10:33:27.889: INFO: Created: latency-svc-bp685
May 21 10:33:27.892: INFO: Got endpoints: latency-svc-hhfjn [146.034763ms]
May 21 10:33:27.892: INFO: Got endpoints: latency-svc-gbks9 [140.917122ms]
May 21 10:33:27.892: INFO: Got endpoints: latency-svc-z2lzj [117.222834ms]
May 21 10:33:27.896: INFO: Created: latency-svc-mcb2c
May 21 10:33:27.899: INFO: Got endpoints: latency-svc-bp685 [116.816131ms]
May 21 10:33:27.902: INFO: Got endpoints: latency-svc-mcb2c [109.858138ms]
May 21 10:33:27.906: INFO: Created: latency-svc-84bhg
May 21 10:33:27.911: INFO: Got endpoints: latency-svc-84bhg [116.968688ms]
May 21 10:33:27.912: INFO: Created: latency-svc-s4mtr
May 21 10:33:27.923: INFO: Got endpoints: latency-svc-s4mtr [113.563775ms]
May 21 10:33:27.924: INFO: Created: latency-svc-s72jh
May 21 10:33:27.928: INFO: Created: latency-svc-5gnbv
May 21 10:33:27.933: INFO: Got endpoints: latency-svc-5gnbv [113.659441ms]
May 21 10:33:27.933: INFO: Got endpoints: latency-svc-s72jh [118.611984ms]
May 21 10:33:27.940: INFO: Created: latency-svc-65xzb
May 21 10:33:27.944: INFO: Got endpoints: latency-svc-65xzb [119.500568ms]
May 21 10:33:27.946: INFO: Created: latency-svc-864fk
May 21 10:33:27.950: INFO: Got endpoints: latency-svc-864fk [118.426863ms]
May 21 10:33:27.955: INFO: Created: latency-svc-ljmft
May 21 10:33:27.961: INFO: Got endpoints: latency-svc-ljmft [117.881506ms]
May 21 10:33:27.962: INFO: Created: latency-svc-v9f6x
May 21 10:33:27.966: INFO: Got endpoints: latency-svc-v9f6x [112.20611ms]
May 21 10:33:27.971: INFO: Created: latency-svc-mxxzt
May 21 10:33:27.975: INFO: Created: latency-svc-8xv52
May 21 10:33:27.976: INFO: Got endpoints: latency-svc-mxxzt [114.310851ms]
May 21 10:33:27.981: INFO: Got endpoints: latency-svc-8xv52 [110.282875ms]
May 21 10:33:27.985: INFO: Created: latency-svc-blhs7
May 21 10:33:27.988: INFO: Got endpoints: latency-svc-blhs7 [96.298523ms]
May 21 10:33:27.994: INFO: Created: latency-svc-rq5v5
May 21 10:33:28.000: INFO: Got endpoints: latency-svc-rq5v5 [108.068152ms]
May 21 10:33:28.002: INFO: Created: latency-svc-l44rg
May 21 10:33:28.007: INFO: Created: latency-svc-6qj2h
May 21 10:33:28.012: INFO: Got endpoints: latency-svc-l44rg [120.128577ms]
May 21 10:33:28.019: INFO: Created: latency-svc-42cgx
May 21 10:33:28.028: INFO: Created: latency-svc-xrcml
May 21 10:33:28.048: INFO: Created: latency-svc-pkjlq
May 21 10:33:28.052: INFO: Got endpoints: latency-svc-6qj2h [153.824253ms]
May 21 10:33:28.060: INFO: Created: latency-svc-j78qq
May 21 10:33:28.064: INFO: Created: latency-svc-jm6wt
May 21 10:33:28.069: INFO: Created: latency-svc-kc75l
May 21 10:33:28.074: INFO: Created: latency-svc-5tltp
May 21 10:33:28.080: INFO: Created: latency-svc-5pcb5
May 21 10:33:28.088: INFO: Created: latency-svc-9cbwh
May 21 10:33:28.097: INFO: Created: latency-svc-6vrvt
May 21 10:33:28.097: INFO: Got endpoints: latency-svc-42cgx [195.931612ms]
May 21 10:33:28.102: INFO: Created: latency-svc-6m76w
May 21 10:33:28.106: INFO: Created: latency-svc-4nz7t
May 21 10:33:28.111: INFO: Created: latency-svc-rrqvl
May 21 10:33:28.117: INFO: Created: latency-svc-dqkkh
May 21 10:33:28.119: INFO: Created: latency-svc-n48kz
May 21 10:33:28.128: INFO: Created: latency-svc-2ntb9
May 21 10:33:28.149: INFO: Got endpoints: latency-svc-xrcml [237.16401ms]
May 21 10:33:28.164: INFO: Created: latency-svc-59jlc
May 21 10:33:28.215: INFO: Got endpoints: latency-svc-pkjlq [292.333671ms]
May 21 10:33:28.317: INFO: Got endpoints: latency-svc-j78qq [383.150646ms]
May 21 10:33:28.330: INFO: Got endpoints: latency-svc-jm6wt [396.081086ms]
May 21 10:33:28.342: INFO: Created: latency-svc-wm5md
May 21 10:33:28.362: INFO: Got endpoints: latency-svc-kc75l [417.032341ms]
May 21 10:33:28.418: INFO: Got endpoints: latency-svc-5tltp [467.814899ms]
May 21 10:33:28.424: INFO: Created: latency-svc-zpqvt
May 21 10:33:28.456: INFO: Created: latency-svc-chl57
May 21 10:33:28.457: INFO: Got endpoints: latency-svc-5pcb5 [495.579765ms]
May 21 10:33:28.467: INFO: Created: latency-svc-24vbw
May 21 10:33:28.496: INFO: Created: latency-svc-wfxdw
May 21 10:33:28.502: INFO: Got endpoints: latency-svc-9cbwh [535.879229ms]
May 21 10:33:28.536: INFO: Created: latency-svc-7xvth
May 21 10:33:28.562: INFO: Got endpoints: latency-svc-6vrvt [585.564383ms]
May 21 10:33:28.574: INFO: Created: latency-svc-h9zmr
May 21 10:33:28.619: INFO: Got endpoints: latency-svc-6m76w [637.855394ms]
May 21 10:33:28.619: INFO: Created: latency-svc-rpfzt
May 21 10:33:28.701: INFO: Got endpoints: latency-svc-4nz7t [712.735061ms]
May 21 10:33:28.720: INFO: Got endpoints: latency-svc-rrqvl [719.509671ms]
May 21 10:33:28.724: INFO: Created: latency-svc-fg4vz
May 21 10:33:28.767: INFO: Got endpoints: latency-svc-dqkkh [755.367175ms]
May 21 10:33:28.799: INFO: Created: latency-svc-v6s94
May 21 10:33:28.829: INFO: Got endpoints: latency-svc-n48kz [776.327129ms]
May 21 10:33:28.832: INFO: Created: latency-svc-5v4kb
May 21 10:33:28.864: INFO: Got endpoints: latency-svc-2ntb9 [766.74479ms]
May 21 10:33:28.873: INFO: Created: latency-svc-m9wz2
May 21 10:33:28.888: INFO: Created: latency-svc-6cf62
May 21 10:33:28.898: INFO: Created: latency-svc-xwrhg
May 21 10:33:28.903: INFO: Got endpoints: latency-svc-59jlc [754.121996ms]
May 21 10:33:28.919: INFO: Created: latency-svc-wfthr
May 21 10:33:28.953: INFO: Got endpoints: latency-svc-wm5md [737.410897ms]
May 21 10:33:28.963: INFO: Created: latency-svc-ljk8t
May 21 10:33:28.997: INFO: Got endpoints: latency-svc-zpqvt [680.342776ms]
May 21 10:33:29.008: INFO: Created: latency-svc-tddhz
May 21 10:33:29.054: INFO: Got endpoints: latency-svc-chl57 [724.277767ms]
May 21 10:33:29.071: INFO: Created: latency-svc-kgzdm
May 21 10:33:29.099: INFO: Got endpoints: latency-svc-24vbw [736.961296ms]
May 21 10:33:29.107: INFO: Created: latency-svc-mgn2b
May 21 10:33:29.148: INFO: Got endpoints: latency-svc-wfxdw [729.625281ms]
May 21 10:33:29.160: INFO: Created: latency-svc-lmp4s
May 21 10:33:29.199: INFO: Got endpoints: latency-svc-7xvth [741.644214ms]
May 21 10:33:29.211: INFO: Created: latency-svc-8wrh4
May 21 10:33:29.248: INFO: Got endpoints: latency-svc-h9zmr [745.462931ms]
May 21 10:33:29.260: INFO: Created: latency-svc-xx66c
May 21 10:33:29.301: INFO: Got endpoints: latency-svc-rpfzt [739.398264ms]
May 21 10:33:29.313: INFO: Created: latency-svc-hhmq2
May 21 10:33:29.353: INFO: Got endpoints: latency-svc-fg4vz [734.139164ms]
May 21 10:33:29.371: INFO: Created: latency-svc-wnps2
May 21 10:33:29.399: INFO: Got endpoints: latency-svc-v6s94 [697.711889ms]
May 21 10:33:29.426: INFO: Created: latency-svc-d8dzj
May 21 10:33:29.450: INFO: Got endpoints: latency-svc-5v4kb [730.137962ms]
May 21 10:33:29.467: INFO: Created: latency-svc-b7z6f
May 21 10:33:29.503: INFO: Got endpoints: latency-svc-m9wz2 [735.981146ms]
May 21 10:33:29.515: INFO: Created: latency-svc-8fhn7
May 21 10:33:29.549: INFO: Got endpoints: latency-svc-6cf62 [720.007506ms]
May 21 10:33:29.563: INFO: Created: latency-svc-7wszj
May 21 10:33:29.599: INFO: Got endpoints: latency-svc-xwrhg [734.44348ms]
May 21 10:33:29.611: INFO: Created: latency-svc-2zj5j
May 21 10:33:29.650: INFO: Got endpoints: latency-svc-wfthr [747.478603ms]
May 21 10:33:29.669: INFO: Created: latency-svc-d9ldp
May 21 10:33:29.698: INFO: Got endpoints: latency-svc-ljk8t [745.12911ms]
May 21 10:33:29.706: INFO: Created: latency-svc-mfk47
May 21 10:33:29.749: INFO: Got endpoints: latency-svc-tddhz [751.589402ms]
May 21 10:33:29.761: INFO: Created: latency-svc-gwfms
May 21 10:33:29.797: INFO: Got endpoints: latency-svc-kgzdm [742.961229ms]
May 21 10:33:29.807: INFO: Created: latency-svc-8rv25
May 21 10:33:29.849: INFO: Got endpoints: latency-svc-mgn2b [750.334986ms]
May 21 10:33:29.859: INFO: Created: latency-svc-t8fz7
May 21 10:33:29.898: INFO: Got endpoints: latency-svc-lmp4s [750.353037ms]
May 21 10:33:29.911: INFO: Created: latency-svc-h8d77
May 21 10:33:29.953: INFO: Got endpoints: latency-svc-8wrh4 [753.776807ms]
May 21 10:33:29.966: INFO: Created: latency-svc-tbphd
May 21 10:33:30.001: INFO: Got endpoints: latency-svc-xx66c [753.580542ms]
May 21 10:33:30.025: INFO: Created: latency-svc-xhlpt
May 21 10:33:30.064: INFO: Got endpoints: latency-svc-hhmq2 [762.461877ms]
May 21 10:33:30.078: INFO: Created: latency-svc-fxnvq
May 21 10:33:30.098: INFO: Got endpoints: latency-svc-wnps2 [744.852909ms]
May 21 10:33:30.111: INFO: Created: latency-svc-frvmn
May 21 10:33:30.147: INFO: Got endpoints: latency-svc-d8dzj [748.621608ms]
May 21 10:33:30.159: INFO: Created: latency-svc-x7w6q
May 21 10:33:30.198: INFO: Got endpoints: latency-svc-b7z6f [747.635965ms]
May 21 10:33:30.206: INFO: Created: latency-svc-qxrcg
May 21 10:33:30.248: INFO: Got endpoints: latency-svc-8fhn7 [745.030396ms]
May 21 10:33:30.261: INFO: Created: latency-svc-778l4
May 21 10:33:30.301: INFO: Got endpoints: latency-svc-7wszj [751.711777ms]
May 21 10:33:30.313: INFO: Created: latency-svc-mz84g
May 21 10:33:30.348: INFO: Got endpoints: latency-svc-2zj5j [749.096955ms]
May 21 10:33:30.356: INFO: Created: latency-svc-fjr9h
May 21 10:33:30.398: INFO: Got endpoints: latency-svc-d9ldp [747.556285ms]
May 21 10:33:30.411: INFO: Created: latency-svc-4dwqw
May 21 10:33:30.455: INFO: Got endpoints: latency-svc-mfk47 [757.48853ms]
May 21 10:33:30.471: INFO: Created: latency-svc-pclbc
May 21 10:33:30.499: INFO: Got endpoints: latency-svc-gwfms [750.7557ms]
May 21 10:33:30.509: INFO: Created: latency-svc-l4qqn
May 21 10:33:30.550: INFO: Got endpoints: latency-svc-8rv25 [752.632645ms]
May 21 10:33:30.560: INFO: Created: latency-svc-cfr4s
May 21 10:33:30.602: INFO: Got endpoints: latency-svc-t8fz7 [752.746514ms]
May 21 10:33:30.614: INFO: Created: latency-svc-9d77h
May 21 10:33:30.649: INFO: Got endpoints: latency-svc-h8d77 [750.928717ms]
May 21 10:33:30.662: INFO: Created: latency-svc-792pl
May 21 10:33:30.698: INFO: Got endpoints: latency-svc-tbphd [745.784298ms]
May 21 10:33:30.709: INFO: Created: latency-svc-ztxpk
May 21 10:33:30.749: INFO: Got endpoints: latency-svc-xhlpt [747.629067ms]
May 21 10:33:30.759: INFO: Created: latency-svc-dczwv
May 21 10:33:30.797: INFO: Got endpoints: latency-svc-fxnvq [733.450504ms]
May 21 10:33:30.808: INFO: Created: latency-svc-pjhzf
May 21 10:33:30.851: INFO: Got endpoints: latency-svc-frvmn [753.328157ms]
May 21 10:33:30.885: INFO: Created: latency-svc-gxznt
May 21 10:33:30.899: INFO: Got endpoints: latency-svc-x7w6q [751.872055ms]
May 21 10:33:30.921: INFO: Created: latency-svc-zkcpw
May 21 10:33:30.952: INFO: Got endpoints: latency-svc-qxrcg [754.354106ms]
May 21 10:33:30.982: INFO: Created: latency-svc-x7qsx
May 21 10:33:31.005: INFO: Got endpoints: latency-svc-778l4 [756.924948ms]
May 21 10:33:31.019: INFO: Created: latency-svc-wr6nl
May 21 10:33:31.065: INFO: Got endpoints: latency-svc-mz84g [763.848625ms]
May 21 10:33:31.149: INFO: Got endpoints: latency-svc-fjr9h [800.819172ms]
May 21 10:33:31.170: INFO: Got endpoints: latency-svc-4dwqw [771.902051ms]
May 21 10:33:31.170: INFO: Created: latency-svc-dxlr7
May 21 10:33:31.210: INFO: Got endpoints: latency-svc-pclbc [754.730783ms]
May 21 10:33:31.218: INFO: Created: latency-svc-2d25s
May 21 10:33:31.267: INFO: Created: latency-svc-slb44
May 21 10:33:31.304: INFO: Got endpoints: latency-svc-l4qqn [804.566908ms]
May 21 10:33:31.314: INFO: Got endpoints: latency-svc-cfr4s [764.503898ms]
May 21 10:33:31.347: INFO: Created: latency-svc-kmw5b
May 21 10:33:31.351: INFO: Got endpoints: latency-svc-9d77h [748.85966ms]
May 21 10:33:31.353: INFO: Created: latency-svc-56d45
May 21 10:33:31.373: INFO: Created: latency-svc-qsxjf
May 21 10:33:31.378: INFO: Created: latency-svc-6nwkh
May 21 10:33:31.398: INFO: Got endpoints: latency-svc-792pl [748.897164ms]
May 21 10:33:31.417: INFO: Created: latency-svc-x8l9c
May 21 10:33:31.475: INFO: Got endpoints: latency-svc-ztxpk [776.351164ms]
May 21 10:33:31.515: INFO: Got endpoints: latency-svc-dczwv [766.276303ms]
May 21 10:33:31.533: INFO: Created: latency-svc-fbsfb
May 21 10:33:31.556: INFO: Got endpoints: latency-svc-pjhzf [759.000234ms]
May 21 10:33:31.564: INFO: Created: latency-svc-7tchz
May 21 10:33:31.577: INFO: Created: latency-svc-jfzfm
May 21 10:33:31.598: INFO: Got endpoints: latency-svc-gxznt [747.212657ms]
May 21 10:33:31.630: INFO: Created: latency-svc-f9rxn
May 21 10:33:31.662: INFO: Got endpoints: latency-svc-zkcpw [762.850842ms]
May 21 10:33:31.709: INFO: Created: latency-svc-85srs
May 21 10:33:31.721: INFO: Got endpoints: latency-svc-x7qsx [769.352413ms]
May 21 10:33:31.767: INFO: Created: latency-svc-gx6sq
May 21 10:33:31.771: INFO: Got endpoints: latency-svc-wr6nl [766.023926ms]
May 21 10:33:31.809: INFO: Created: latency-svc-m2d8j
May 21 10:33:31.810: INFO: Got endpoints: latency-svc-dxlr7 [745.049505ms]
May 21 10:33:31.845: INFO: Created: latency-svc-lfxcb
May 21 10:33:31.849: INFO: Got endpoints: latency-svc-2d25s [699.869272ms]
May 21 10:33:31.860: INFO: Created: latency-svc-tc6d9
May 21 10:33:31.897: INFO: Got endpoints: latency-svc-slb44 [726.714371ms]
May 21 10:33:31.905: INFO: Created: latency-svc-kj97p
May 21 10:33:31.960: INFO: Got endpoints: latency-svc-kmw5b [749.327238ms]
May 21 10:33:31.975: INFO: Created: latency-svc-wbgfv
May 21 10:33:32.000: INFO: Got endpoints: latency-svc-56d45 [696.383736ms]
May 21 10:33:32.013: INFO: Created: latency-svc-pv54d
May 21 10:33:32.047: INFO: Got endpoints: latency-svc-qsxjf [732.577983ms]
May 21 10:33:32.058: INFO: Created: latency-svc-fw2mm
May 21 10:33:32.097: INFO: Got endpoints: latency-svc-6nwkh [746.716491ms]
May 21 10:33:32.110: INFO: Created: latency-svc-2sqbs
May 21 10:33:32.148: INFO: Got endpoints: latency-svc-x8l9c [749.45835ms]
May 21 10:33:32.158: INFO: Created: latency-svc-bx6dm
May 21 10:33:32.200: INFO: Got endpoints: latency-svc-fbsfb [724.874524ms]
May 21 10:33:32.228: INFO: Created: latency-svc-k8k8b
May 21 10:33:32.254: INFO: Got endpoints: latency-svc-7tchz [738.108653ms]
May 21 10:33:32.271: INFO: Created: latency-svc-p797h
May 21 10:33:32.298: INFO: Got endpoints: latency-svc-jfzfm [741.196971ms]
May 21 10:33:32.305: INFO: Created: latency-svc-jf9z4
May 21 10:33:32.348: INFO: Got endpoints: latency-svc-f9rxn [749.659014ms]
May 21 10:33:32.361: INFO: Created: latency-svc-x8shk
May 21 10:33:32.403: INFO: Got endpoints: latency-svc-85srs [740.296388ms]
May 21 10:33:32.415: INFO: Created: latency-svc-rjgsk
May 21 10:33:32.448: INFO: Got endpoints: latency-svc-gx6sq [726.111742ms]
May 21 10:33:32.464: INFO: Created: latency-svc-vmtz9
May 21 10:33:32.498: INFO: Got endpoints: latency-svc-m2d8j [726.405797ms]
May 21 10:33:32.510: INFO: Created: latency-svc-f6qcw
May 21 10:33:32.551: INFO: Got endpoints: latency-svc-lfxcb [741.457803ms]
May 21 10:33:32.560: INFO: Created: latency-svc-qsvg7
May 21 10:33:32.597: INFO: Got endpoints: latency-svc-tc6d9 [748.02373ms]
May 21 10:33:32.608: INFO: Created: latency-svc-2gbzg
May 21 10:33:32.647: INFO: Got endpoints: latency-svc-kj97p [749.968455ms]
May 21 10:33:32.659: INFO: Created: latency-svc-nkl4q
May 21 10:33:32.701: INFO: Got endpoints: latency-svc-wbgfv [740.967701ms]
May 21 10:33:32.710: INFO: Created: latency-svc-4hbl6
May 21 10:33:32.748: INFO: Got endpoints: latency-svc-pv54d [747.300737ms]
May 21 10:33:32.762: INFO: Created: latency-svc-h8l47
May 21 10:33:32.798: INFO: Got endpoints: latency-svc-fw2mm [750.720046ms]
May 21 10:33:32.817: INFO: Created: latency-svc-vz2jc
May 21 10:33:32.849: INFO: Got endpoints: latency-svc-2sqbs [751.766974ms]
May 21 10:33:32.864: INFO: Created: latency-svc-l99tv
May 21 10:33:32.897: INFO: Got endpoints: latency-svc-bx6dm [749.41204ms]
May 21 10:33:32.908: INFO: Created: latency-svc-xjpw7
May 21 10:33:32.948: INFO: Got endpoints: latency-svc-k8k8b [748.471409ms]
May 21 10:33:32.959: INFO: Created: latency-svc-bq2cb
May 21 10:33:32.997: INFO: Got endpoints: latency-svc-p797h [742.98662ms]
May 21 10:33:33.010: INFO: Created: latency-svc-rp7jk
May 21 10:33:33.051: INFO: Got endpoints: latency-svc-jf9z4 [753.627018ms]
May 21 10:33:33.069: INFO: Created: latency-svc-kxr77
May 21 10:33:33.098: INFO: Got endpoints: latency-svc-x8shk [749.42496ms]
May 21 10:33:33.110: INFO: Created: latency-svc-bk2mc
May 21 10:33:33.151: INFO: Got endpoints: latency-svc-rjgsk [748.47348ms]
May 21 10:33:33.162: INFO: Created: latency-svc-xsmb7
May 21 10:33:33.200: INFO: Got endpoints: latency-svc-vmtz9 [752.004229ms]
May 21 10:33:33.216: INFO: Created: latency-svc-kfrxm
May 21 10:33:33.251: INFO: Got endpoints: latency-svc-f6qcw [752.770042ms]
May 21 10:33:33.266: INFO: Created: latency-svc-vpqgr
May 21 10:33:33.303: INFO: Got endpoints: latency-svc-qsvg7 [751.453183ms]
May 21 10:33:33.313: INFO: Created: latency-svc-4c7sz
May 21 10:33:33.349: INFO: Got endpoints: latency-svc-2gbzg [751.712538ms]
May 21 10:33:33.359: INFO: Created: latency-svc-sthpn
May 21 10:33:33.423: INFO: Got endpoints: latency-svc-nkl4q [776.022264ms]
May 21 10:33:33.483: INFO: Got endpoints: latency-svc-4hbl6 [781.719263ms]
May 21 10:33:33.531: INFO: Got endpoints: latency-svc-h8l47 [783.116476ms]
May 21 10:33:33.535: INFO: Created: latency-svc-qzf2f
May 21 10:33:33.572: INFO: Got endpoints: latency-svc-vz2jc [774.273263ms]
May 21 10:33:33.693: INFO: Created: latency-svc-bdknb
May 21 10:33:33.727: INFO: Got endpoints: latency-svc-xjpw7 [829.550075ms]
May 21 10:33:33.727: INFO: Got endpoints: latency-svc-l99tv [877.508177ms]
May 21 10:33:33.729: INFO: Got endpoints: latency-svc-bq2cb [781.025364ms]
May 21 10:33:33.736: INFO: Created: latency-svc-fzsrq
May 21 10:33:33.745: INFO: Created: latency-svc-26bwc
May 21 10:33:33.757: INFO: Got endpoints: latency-svc-rp7jk [760.145173ms]
May 21 10:33:33.770: INFO: Created: latency-svc-qtl8c
May 21 10:33:33.792: INFO: Created: latency-svc-r8ddn
May 21 10:33:33.805: INFO: Created: latency-svc-h9gtd
May 21 10:33:33.807: INFO: Got endpoints: latency-svc-kxr77 [755.099718ms]
May 21 10:33:33.823: INFO: Created: latency-svc-x6tkx
May 21 10:33:33.835: INFO: Created: latency-svc-jfcrj
May 21 10:33:33.857: INFO: Got endpoints: latency-svc-bk2mc [759.515119ms]
May 21 10:33:33.889: INFO: Created: latency-svc-c4s7q
May 21 10:33:33.904: INFO: Got endpoints: latency-svc-xsmb7 [752.790128ms]
May 21 10:33:33.956: INFO: Got endpoints: latency-svc-kfrxm [756.439006ms]
May 21 10:33:33.957: INFO: Created: latency-svc-4fgnv
May 21 10:33:33.995: INFO: Created: latency-svc-g6h9s
May 21 10:33:34.007: INFO: Got endpoints: latency-svc-vpqgr [756.018364ms]
May 21 10:33:34.048: INFO: Created: latency-svc-pln4n
May 21 10:33:34.078: INFO: Got endpoints: latency-svc-4c7sz [775.034697ms]
May 21 10:33:34.116: INFO: Got endpoints: latency-svc-sthpn [766.98694ms]
May 21 10:33:34.134: INFO: Created: latency-svc-ml6px
May 21 10:33:34.157: INFO: Got endpoints: latency-svc-qzf2f [734.13681ms]
May 21 10:33:34.166: INFO: Created: latency-svc-llc79
May 21 10:33:34.171: INFO: Created: latency-svc-x7l54
May 21 10:33:34.202: INFO: Got endpoints: latency-svc-bdknb [719.647285ms]
May 21 10:33:34.218: INFO: Created: latency-svc-kvg4s
May 21 10:33:34.250: INFO: Got endpoints: latency-svc-fzsrq [719.215208ms]
May 21 10:33:34.264: INFO: Created: latency-svc-r6jkb
May 21 10:33:34.298: INFO: Got endpoints: latency-svc-26bwc [725.975366ms]
May 21 10:33:34.316: INFO: Created: latency-svc-jjvnh
May 21 10:33:34.349: INFO: Got endpoints: latency-svc-qtl8c [622.829194ms]
May 21 10:33:34.362: INFO: Created: latency-svc-zc2zw
May 21 10:33:34.400: INFO: Got endpoints: latency-svc-r8ddn [673.058117ms]
May 21 10:33:34.428: INFO: Created: latency-svc-spjjt
May 21 10:33:34.452: INFO: Got endpoints: latency-svc-h9gtd [722.732405ms]
May 21 10:33:34.462: INFO: Created: latency-svc-fph6j
May 21 10:33:34.496: INFO: Got endpoints: latency-svc-x6tkx [739.478209ms]
May 21 10:33:34.504: INFO: Created: latency-svc-pddrm
May 21 10:33:34.549: INFO: Got endpoints: latency-svc-jfcrj [741.960632ms]
May 21 10:33:34.567: INFO: Created: latency-svc-94djg
May 21 10:33:34.597: INFO: Got endpoints: latency-svc-c4s7q [739.223575ms]
May 21 10:33:34.606: INFO: Created: latency-svc-j7v4w
May 21 10:33:34.648: INFO: Got endpoints: latency-svc-4fgnv [744.259226ms]
May 21 10:33:34.659: INFO: Created: latency-svc-7gc8d
May 21 10:33:34.698: INFO: Got endpoints: latency-svc-g6h9s [741.792803ms]
May 21 10:33:34.705: INFO: Created: latency-svc-s72x7
May 21 10:33:34.751: INFO: Got endpoints: latency-svc-pln4n [744.032543ms]
May 21 10:33:34.765: INFO: Created: latency-svc-8hbtg
May 21 10:33:34.798: INFO: Got endpoints: latency-svc-ml6px [720.624407ms]
May 21 10:33:34.812: INFO: Created: latency-svc-wh7tt
May 21 10:33:34.851: INFO: Got endpoints: latency-svc-llc79 [735.270984ms]
May 21 10:33:34.867: INFO: Created: latency-svc-vnj8g
May 21 10:33:34.899: INFO: Got endpoints: latency-svc-x7l54 [741.587393ms]
May 21 10:33:34.925: INFO: Created: latency-svc-5qjz8
May 21 10:33:34.948: INFO: Got endpoints: latency-svc-kvg4s [745.47994ms]
May 21 10:33:34.955: INFO: Created: latency-svc-2pmwc
May 21 10:33:34.998: INFO: Got endpoints: latency-svc-r6jkb [747.244211ms]
May 21 10:33:35.005: INFO: Created: latency-svc-wnv7t
May 21 10:33:35.049: INFO: Got endpoints: latency-svc-jjvnh [751.312351ms]
May 21 10:33:35.058: INFO: Created: latency-svc-46mgk
May 21 10:33:35.097: INFO: Got endpoints: latency-svc-zc2zw [747.814819ms]
May 21 10:33:35.119: INFO: Created: latency-svc-bdz5r
May 21 10:33:35.150: INFO: Got endpoints: latency-svc-spjjt [749.857576ms]
May 21 10:33:35.165: INFO: Created: latency-svc-5fsvm
May 21 10:33:35.198: INFO: Got endpoints: latency-svc-fph6j [745.504829ms]
May 21 10:33:35.212: INFO: Created: latency-svc-5g7zw
May 21 10:33:35.254: INFO: Got endpoints: latency-svc-pddrm [757.05343ms]
May 21 10:33:35.264: INFO: Created: latency-svc-dzdwt
May 21 10:33:35.302: INFO: Got endpoints: latency-svc-94djg [753.176784ms]
May 21 10:33:35.311: INFO: Created: latency-svc-tzmwx
May 21 10:33:35.348: INFO: Got endpoints: latency-svc-j7v4w [750.85492ms]
May 21 10:33:35.358: INFO: Created: latency-svc-v8fxs
May 21 10:33:35.406: INFO: Got endpoints: latency-svc-7gc8d [757.869722ms]
May 21 10:33:35.416: INFO: Created: latency-svc-7t4q7
May 21 10:33:35.448: INFO: Got endpoints: latency-svc-s72x7 [749.535339ms]
May 21 10:33:35.457: INFO: Created: latency-svc-nzmxm
May 21 10:33:35.502: INFO: Got endpoints: latency-svc-8hbtg [750.883425ms]
May 21 10:33:35.516: INFO: Created: latency-svc-q4gmr
May 21 10:33:35.548: INFO: Got endpoints: latency-svc-wh7tt [749.795251ms]
May 21 10:33:35.598: INFO: Got endpoints: latency-svc-vnj8g [747.402394ms]
May 21 10:33:35.652: INFO: Got endpoints: latency-svc-5qjz8 [753.644059ms]
May 21 10:33:35.698: INFO: Got endpoints: latency-svc-2pmwc [750.120569ms]
May 21 10:33:35.748: INFO: Got endpoints: latency-svc-wnv7t [750.523568ms]
May 21 10:33:35.798: INFO: Got endpoints: latency-svc-46mgk [748.452432ms]
May 21 10:33:35.851: INFO: Got endpoints: latency-svc-bdz5r [753.441591ms]
May 21 10:33:35.897: INFO: Got endpoints: latency-svc-5fsvm [746.575066ms]
May 21 10:33:35.951: INFO: Got endpoints: latency-svc-5g7zw [753.625904ms]
May 21 10:33:36.008: INFO: Got endpoints: latency-svc-dzdwt [754.893817ms]
May 21 10:33:36.062: INFO: Got endpoints: latency-svc-tzmwx [759.809282ms]
May 21 10:33:36.104: INFO: Got endpoints: latency-svc-v8fxs [756.205296ms]
May 21 10:33:36.148: INFO: Got endpoints: latency-svc-7t4q7 [742.108013ms]
May 21 10:33:36.209: INFO: Got endpoints: latency-svc-nzmxm [760.915852ms]
May 21 10:33:36.256: INFO: Got endpoints: latency-svc-q4gmr [754.022949ms]
May 21 10:33:36.256: INFO: Latencies: [21.894046ms 24.110524ms 38.153015ms 43.381627ms 59.779158ms 67.768297ms 73.897842ms 86.843064ms 96.298523ms 101.328331ms 106.959737ms 108.068152ms 109.858138ms 110.282875ms 111.69417ms 112.20611ms 113.563775ms 113.659441ms 114.310851ms 116.816131ms 116.95866ms 116.968688ms 117.222834ms 117.881506ms 118.426863ms 118.611984ms 119.500568ms 120.128577ms 123.80573ms 135.484802ms 140.917122ms 141.524919ms 146.034763ms 146.140465ms 153.824253ms 155.073771ms 195.931612ms 237.16401ms 292.333671ms 383.150646ms 396.081086ms 417.032341ms 467.814899ms 495.579765ms 535.879229ms 585.564383ms 622.829194ms 637.855394ms 673.058117ms 680.342776ms 696.383736ms 697.711889ms 699.869272ms 712.735061ms 719.215208ms 719.509671ms 719.647285ms 720.007506ms 720.624407ms 722.732405ms 724.277767ms 724.874524ms 725.975366ms 726.111742ms 726.405797ms 726.714371ms 729.625281ms 730.137962ms 732.577983ms 733.450504ms 734.13681ms 734.139164ms 734.44348ms 735.270984ms 735.981146ms 736.961296ms 737.410897ms 738.108653ms 739.223575ms 739.398264ms 739.478209ms 740.296388ms 740.967701ms 741.196971ms 741.457803ms 741.587393ms 741.644214ms 741.792803ms 741.960632ms 742.108013ms 742.961229ms 742.98662ms 744.032543ms 744.259226ms 744.852909ms 745.030396ms 745.049505ms 745.12911ms 745.462931ms 745.47994ms 745.504829ms 745.784298ms 746.575066ms 746.716491ms 747.212657ms 747.244211ms 747.300737ms 747.402394ms 747.478603ms 747.556285ms 747.629067ms 747.635965ms 747.814819ms 748.02373ms 748.452432ms 748.471409ms 748.47348ms 748.621608ms 748.85966ms 748.897164ms 749.096955ms 749.327238ms 749.41204ms 749.42496ms 749.45835ms 749.535339ms 749.659014ms 749.795251ms 749.857576ms 749.968455ms 750.120569ms 750.334986ms 750.353037ms 750.523568ms 750.720046ms 750.7557ms 750.85492ms 750.883425ms 750.928717ms 751.312351ms 751.453183ms 751.589402ms 751.711777ms 751.712538ms 751.766974ms 751.872055ms 752.004229ms 752.632645ms 752.746514ms 752.770042ms 752.790128ms 753.176784ms 753.328157ms 753.441591ms 753.580542ms 753.625904ms 753.627018ms 753.644059ms 753.776807ms 754.022949ms 754.121996ms 754.354106ms 754.730783ms 754.893817ms 755.099718ms 755.367175ms 756.018364ms 756.205296ms 756.439006ms 756.924948ms 757.05343ms 757.48853ms 757.869722ms 759.000234ms 759.515119ms 759.809282ms 760.145173ms 760.915852ms 762.461877ms 762.850842ms 763.848625ms 764.503898ms 766.023926ms 766.276303ms 766.74479ms 766.98694ms 769.352413ms 771.902051ms 774.273263ms 775.034697ms 776.022264ms 776.327129ms 776.351164ms 781.025364ms 781.719263ms 783.116476ms 800.819172ms 804.566908ms 829.550075ms 877.508177ms]
May 21 10:33:36.256: INFO: 50 %ile: 745.504829ms
May 21 10:33:36.256: INFO: 90 %ile: 763.848625ms
May 21 10:33:36.256: INFO: 99 %ile: 829.550075ms
May 21 10:33:36.256: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:33:36.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-25m9s" for this suite.
May 21 10:33:48.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:33:48.422: INFO: namespace: e2e-tests-svc-latency-25m9s, resource: bindings, ignored listing per whitelist
May 21 10:33:49.092: INFO: namespace e2e-tests-svc-latency-25m9s deletion completed in 12.808476405s

• [SLOW TEST:23.628 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:33:49.092: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:33:49.135728      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward api env vars
May 21 10:33:49.194: INFO: Waiting up to 5m0s for pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-jcqkx" to be "success or failure"
May 21 10:33:49.197: INFO: Pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123255ms
May 21 10:33:51.202: INFO: Pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007785501s
May 21 10:33:53.206: INFO: Pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011838634s
May 21 10:33:55.213: INFO: Pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018217737s
May 21 10:33:57.216: INFO: Pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021964053s
STEP: Saw pod success
May 21 10:33:57.216: INFO: Pod "downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:33:57.219: INFO: Trying to get logs from node master-192.168.130.3 pod downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:33:57.241: INFO: Waiting for pod downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:33:57.244: INFO: Pod downward-api-72b8e943-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:33:57.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jcqkx" for this suite.
May 21 10:34:03.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:34:03.392: INFO: namespace: e2e-tests-downward-api-jcqkx, resource: bindings, ignored listing per whitelist
May 21 10:34:03.434: INFO: namespace e2e-tests-downward-api-jcqkx deletion completed in 6.181996131s

• [SLOW TEST:14.342 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:34:03.434: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:34:03.487393      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name s-test-opt-del-7b4d2e7f-5ce2-11e8-8768-12f5d52dbf0b
STEP: Creating secret with name s-test-opt-upd-7b4d2eef-5ce2-11e8-8768-12f5d52dbf0b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7b4d2e7f-5ce2-11e8-8768-12f5d52dbf0b
STEP: Updating secret s-test-opt-upd-7b4d2eef-5ce2-11e8-8768-12f5d52dbf0b
STEP: Creating secret with name s-test-opt-create-7b4d2f10-5ce2-11e8-8768-12f5d52dbf0b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:35:35.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hfcsr" for this suite.
May 21 10:35:57.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:35:57.608: INFO: namespace: e2e-tests-secrets-hfcsr, resource: bindings, ignored listing per whitelist
May 21 10:35:57.690: INFO: namespace e2e-tests-secrets-hfcsr deletion completed in 22.203525404s

• [SLOW TEST:114.255 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:35:57.690: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:35:57.734113      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-bf600126-5ce2-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:35:57.806: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-b6hfl" to be "success or failure"
May 21 10:35:57.810: INFO: Pod "pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.273756ms
May 21 10:35:59.814: INFO: Pod "pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008563858s
STEP: Saw pod success
May 21 10:35:59.814: INFO: Pod "pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:35:59.817: INFO: Trying to get logs from node node-192.168.130.5 pod pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:35:59.841: INFO: Waiting for pod pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:35:59.848: INFO: Pod pod-configmaps-bf6130cd-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:35:59.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b6hfl" for this suite.
May 21 10:36:05.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:06.021: INFO: namespace: e2e-tests-configmap-b6hfl, resource: bindings, ignored listing per whitelist
May 21 10:36:06.050: INFO: namespace e2e-tests-configmap-b6hfl deletion completed in 6.195578188s

• [SLOW TEST:8.360 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:36:06.050: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:36:06.108642      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-c463b015-5ce2-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:36:06.218: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-fpwth" to be "success or failure"
May 21 10:36:06.222: INFO: Pod "pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.910348ms
May 21 10:36:08.235: INFO: Pod "pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016790111s
STEP: Saw pod success
May 21 10:36:08.235: INFO: Pod "pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:36:08.240: INFO: Trying to get logs from node node-192.168.130.4 pod pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:36:08.269: INFO: Waiting for pod pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:36:08.278: INFO: Pod pod-projected-configmaps-c464bcde-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:36:08.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fpwth" for this suite.
May 21 10:36:14.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:14.385: INFO: namespace: e2e-tests-projected-fpwth, resource: bindings, ignored listing per whitelist
May 21 10:36:14.471: INFO: namespace e2e-tests-projected-fpwth deletion completed in 6.187777594s

• [SLOW TEST:8.421 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:36:14.471: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:36:14.517225      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0521 10:36:20.617637      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:36:20.617: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:36:20.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-65kpb" for this suite.
May 21 10:36:26.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:26.732: INFO: namespace: e2e-tests-gc-65kpb, resource: bindings, ignored listing per whitelist
May 21 10:36:26.791: INFO: namespace e2e-tests-gc-65kpb deletion completed in 6.167333752s

• [SLOW TEST:12.319 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:36:26.791: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:36:26.845103      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 10:36:26.919: INFO: Waiting up to 5m0s for pod "pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-45cz9" to be "success or failure"
May 21 10:36:26.925: INFO: Pod "pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.26434ms
May 21 10:36:28.931: INFO: Pod "pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012271077s
STEP: Saw pod success
May 21 10:36:28.932: INFO: Pod "pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:36:28.935: INFO: Trying to get logs from node master-192.168.130.3 pod pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:36:28.966: INFO: Waiting for pod pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:36:28.976: INFO: Pod pod-d0ba6883-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:36:28.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-45cz9" for this suite.
May 21 10:36:35.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:35.196: INFO: namespace: e2e-tests-emptydir-45cz9, resource: bindings, ignored listing per whitelist
May 21 10:36:35.212: INFO: namespace e2e-tests-emptydir-45cz9 deletion completed in 6.227052486s

• [SLOW TEST:8.421 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:36:35.212: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:36:35.257525      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 21 10:36:37.339: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-d5bb8ad1-5ce2-11e8-8768-12f5d52dbf0b", GenerateName:"", Namespace:"e2e-tests-pods-hf7p5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-hf7p5/pods/pod-submit-remove-d5bb8ad1-5ce2-11e8-8768-12f5d52dbf0b", UID:"d5bc9b5c-5ce2-11e8-ba59-5254000207f9", ResourceVersion:"66504", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63662495795, loc:(*time.Location)(0x65972e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"300225986"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.66.121/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-smxqp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420c69480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-smxqp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4220554d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"master-192.168.130.2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420c69780), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63662495795, loc:(*time.Location)(0x65972e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63662495797, loc:(*time.Location)(0x65972e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63662495795, loc:(*time.Location)(0x65972e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.130.2", PodIP:"192.168.66.121", StartTime:(*v1.Time)(0xc4221ac980), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4221ac9a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker://sha256:69854bafc1214f1a7f88c32f193dd0112e4d89d5bd9da9a85d95d5735acbc397", ContainerID:"docker://6cb716755b90ed0211b8715a23070474d8ef5f5e0700327670b70c932400851e"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:36:44.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hf7p5" for this suite.
May 21 10:36:50.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:36:51.100: INFO: namespace: e2e-tests-pods-hf7p5, resource: bindings, ignored listing per whitelist
May 21 10:36:51.156: INFO: namespace e2e-tests-pods-hf7p5 deletion completed in 6.204109241s

• [SLOW TEST:15.944 seconds]
[k8s.io] Pods
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:36:51.156: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:36:51.226161      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test substitution in container's command
May 21 10:36:51.276: INFO: Waiting up to 5m0s for pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-var-expansion-gm6js" to be "success or failure"
May 21 10:36:51.281: INFO: Pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.596118ms
May 21 10:36:53.295: INFO: Pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018859753s
May 21 10:36:55.299: INFO: Pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022950001s
May 21 10:36:57.303: INFO: Pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027413188s
May 21 10:36:59.308: INFO: Pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.032013554s
STEP: Saw pod success
May 21 10:36:59.308: INFO: Pod "var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:36:59.311: INFO: Trying to get logs from node master-192.168.130.1 pod var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:36:59.342: INFO: Waiting for pod var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:36:59.350: INFO: Pod var-expansion-df3fc698-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:36:59.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gm6js" for this suite.
May 21 10:37:05.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:05.454: INFO: namespace: e2e-tests-var-expansion-gm6js, resource: bindings, ignored listing per whitelist
May 21 10:37:05.564: INFO: namespace e2e-tests-var-expansion-gm6js deletion completed in 6.208628465s

• [SLOW TEST:14.408 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should allow substituting values in a container's command  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:37:05.564: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:37:05.603608      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:37:05.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-65lhl" to be "success or failure"
May 21 10:37:05.674: INFO: Pod "downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.501058ms
May 21 10:37:07.680: INFO: Pod "downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016449689s
STEP: Saw pod success
May 21 10:37:07.680: INFO: Pod "downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:37:07.684: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:37:07.723: INFO: Waiting for pod downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:37:07.731: INFO: Pod downwardapi-volume-e7d300df-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:37:07.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-65lhl" for this suite.
May 21 10:37:13.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:13.886: INFO: namespace: e2e-tests-projected-65lhl, resource: bindings, ignored listing per whitelist
May 21 10:37:13.955: INFO: namespace e2e-tests-projected-65lhl deletion completed in 6.218920012s

• [SLOW TEST:8.390 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:37:13.955: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:37:14.001611      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 10:37:14.065: INFO: Waiting up to 5m0s for pod "pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-r5gwd" to be "success or failure"
May 21 10:37:14.073: INFO: Pod "pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.26476ms
May 21 10:37:16.079: INFO: Pod "pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b": Phase="Running", Reason="", readiness=true. Elapsed: 2.013585761s
May 21 10:37:18.084: INFO: Pod "pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019148191s
STEP: Saw pod success
May 21 10:37:18.084: INFO: Pod "pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:37:18.088: INFO: Trying to get logs from node node-192.168.130.4 pod pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:37:18.129: INFO: Waiting for pod pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:37:18.136: INFO: Pod pod-ecd34fb0-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:37:18.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r5gwd" for this suite.
May 21 10:37:24.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:24.291: INFO: namespace: e2e-tests-emptydir-r5gwd, resource: bindings, ignored listing per whitelist
May 21 10:37:24.374: INFO: namespace e2e-tests-emptydir-r5gwd deletion completed in 6.232201821s

• [SLOW TEST:10.419 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:37:24.375: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:37:24.425579      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:37:24.506: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-4czdn" to be "success or failure"
May 21 10:37:24.510: INFO: Pod "downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.191078ms
May 21 10:37:26.513: INFO: Pod "downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007921008s
STEP: Saw pod success
May 21 10:37:26.514: INFO: Pod "downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:37:26.517: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:37:26.553: INFO: Waiting for pod downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b to disappear
May 21 10:37:26.559: INFO: Pod downwardapi-volume-f30e0a71-5ce2-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:37:26.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4czdn" for this suite.
May 21 10:37:32.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:37:32.731: INFO: namespace: e2e-tests-downward-api-4czdn, resource: bindings, ignored listing per whitelist
May 21 10:37:32.783: INFO: namespace e2e-tests-downward-api-4czdn deletion completed in 6.216843398s

• [SLOW TEST:8.408 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:37:32.783: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:37:32.827989      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 10:37:32.907: INFO: Number of nodes with available pods: 0
May 21 10:37:32.907: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:37:33.924: INFO: Number of nodes with available pods: 0
May 21 10:37:33.924: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:37:34.930: INFO: Number of nodes with available pods: 4
May 21 10:37:34.930: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:37:35.918: INFO: Number of nodes with available pods: 5
May 21 10:37:35.918: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 21 10:37:35.959: INFO: Number of nodes with available pods: 4
May 21 10:37:35.959: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:36.967: INFO: Number of nodes with available pods: 4
May 21 10:37:36.967: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:37.971: INFO: Number of nodes with available pods: 4
May 21 10:37:37.971: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:38.974: INFO: Number of nodes with available pods: 4
May 21 10:37:38.974: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:39.971: INFO: Number of nodes with available pods: 4
May 21 10:37:39.971: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:40.971: INFO: Number of nodes with available pods: 4
May 21 10:37:40.971: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:41.970: INFO: Number of nodes with available pods: 4
May 21 10:37:41.970: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:42.974: INFO: Number of nodes with available pods: 4
May 21 10:37:42.974: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:43.971: INFO: Number of nodes with available pods: 4
May 21 10:37:43.971: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:44.977: INFO: Number of nodes with available pods: 4
May 21 10:37:44.977: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:45.971: INFO: Number of nodes with available pods: 4
May 21 10:37:45.971: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:46.971: INFO: Number of nodes with available pods: 4
May 21 10:37:46.971: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:47.970: INFO: Number of nodes with available pods: 4
May 21 10:37:47.970: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:48.969: INFO: Number of nodes with available pods: 4
May 21 10:37:48.969: INFO: Node node-192.168.130.5 is running more than one daemon pod
May 21 10:37:49.971: INFO: Number of nodes with available pods: 5
May 21 10:37:49.971: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:66
STEP: Deleting DaemonSet "daemon-set" with reaper
May 21 10:37:58.011: INFO: Number of nodes with available pods: 0
May 21 10:37:58.011: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:37:58.025: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kqgw6/daemonsets","resourceVersion":"66908"},"items":null}

May 21 10:37:58.030: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kqgw6/pods","resourceVersion":"66909"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:37:58.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kqgw6" for this suite.
May 21 10:38:04.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:04.139: INFO: namespace: e2e-tests-daemonsets-kqgw6, resource: bindings, ignored listing per whitelist
May 21 10:38:04.260: INFO: namespace e2e-tests-daemonsets-kqgw6 deletion completed in 6.203000804s

• [SLOW TEST:31.477 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:38:04.260: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:38:04.310202      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:38:04.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-s269r" to be "success or failure"
May 21 10:38:04.375: INFO: Pod "downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.131884ms
May 21 10:38:06.379: INFO: Pod "downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013803403s
STEP: Saw pod success
May 21 10:38:06.380: INFO: Pod "downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:38:06.384: INFO: Trying to get logs from node master-192.168.130.2 pod downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:38:06.419: INFO: Waiting for pod downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:38:06.429: INFO: Pod downwardapi-volume-0ad0f983-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:38:06.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s269r" for this suite.
May 21 10:38:12.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:12.594: INFO: namespace: e2e-tests-downward-api-s269r, resource: bindings, ignored listing per whitelist
May 21 10:38:12.642: INFO: namespace e2e-tests-downward-api-s269r deletion completed in 6.208279598s

• [SLOW TEST:8.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:38:12.643: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:38:12.683079      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 10:38:12.774: INFO: Number of nodes with available pods: 0
May 21 10:38:12.774: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:38:13.810: INFO: Number of nodes with available pods: 0
May 21 10:38:13.810: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:38:14.799: INFO: Number of nodes with available pods: 4
May 21 10:38:14.800: INFO: Node node-192.168.130.4 is running more than one daemon pod
May 21 10:38:15.784: INFO: Number of nodes with available pods: 5
May 21 10:38:15.784: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 21 10:38:15.820: INFO: Number of nodes with available pods: 4
May 21 10:38:15.820: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:38:16.835: INFO: Number of nodes with available pods: 4
May 21 10:38:16.835: INFO: Node master-192.168.130.1 is running more than one daemon pod
May 21 10:38:17.831: INFO: Number of nodes with available pods: 5
May 21 10:38:17.831: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:66
STEP: Deleting DaemonSet "daemon-set" with reaper
May 21 10:38:25.881: INFO: Number of nodes with available pods: 0
May 21 10:38:25.881: INFO: Number of running nodes: 0, number of available pods: 0
May 21 10:38:25.889: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4zq2h/daemonsets","resourceVersion":"67095"},"items":null}

May 21 10:38:25.895: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4zq2h/pods","resourceVersion":"67095"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:38:25.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4zq2h" for this suite.
May 21 10:38:31.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:32.363: INFO: namespace: e2e-tests-daemonsets-4zq2h, resource: bindings, ignored listing per whitelist
May 21 10:38:32.388: INFO: namespace e2e-tests-daemonsets-4zq2h deletion completed in 6.457323912s

• [SLOW TEST:19.745 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:38:32.388: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:38:32.442873      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test override all
May 21 10:38:32.513: INFO: Waiting up to 5m0s for pod "client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-containers-w8p7v" to be "success or failure"
May 21 10:38:32.514: INFO: Pod "client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.705719ms
May 21 10:38:34.520: INFO: Pod "client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006928022s
STEP: Saw pod success
May 21 10:38:34.520: INFO: Pod "client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:38:34.523: INFO: Trying to get logs from node master-192.168.130.1 pod client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:38:34.550: INFO: Waiting for pod client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:38:34.556: INFO: Pod client-containers-1b97f088-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:38:34.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-w8p7v" for this suite.
May 21 10:38:40.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:38:40.827: INFO: namespace: e2e-tests-containers-w8p7v, resource: bindings, ignored listing per whitelist
May 21 10:38:40.968: INFO: namespace e2e-tests-containers-w8p7v deletion completed in 6.406120641s

• [SLOW TEST:8.580 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be able to override the image's default command and arguments  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:38:40.968: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:38:41.016522      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p7fhq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:38:41.064: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:39:07.208: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.66.125 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7fhq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:39:07.208: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:39:08.334: INFO: Found all expected endpoints: [netserver-0]
May 21 10:39:08.338: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.67.143 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7fhq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:39:08.338: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:39:09.476: INFO: Found all expected endpoints: [netserver-1]
May 21 10:39:09.481: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.64.174 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7fhq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:39:09.481: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:39:10.629: INFO: Found all expected endpoints: [netserver-2]
May 21 10:39:10.636: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.65.138 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7fhq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:39:10.636: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:39:11.747: INFO: Found all expected endpoints: [netserver-3]
May 21 10:39:11.751: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.68.145 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7fhq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:39:11.751: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:39:12.868: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:39:12.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p7fhq" for this suite.
May 21 10:39:36.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:39:37.109: INFO: namespace: e2e-tests-pod-network-test-p7fhq, resource: bindings, ignored listing per whitelist
May 21 10:39:37.133: INFO: namespace e2e-tests-pod-network-test-p7fhq deletion completed in 24.237874334s

• [SLOW TEST:56.165 seconds]
[sig-network] Networking
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:39:37.133: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:39:37.181862      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 10:39:39.788: INFO: Successfully updated pod "pod-update-422efa1b-5ce3-11e8-8768-12f5d52dbf0b"
STEP: verifying the updated pod is in kubernetes
May 21 10:39:39.796: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:39:39.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hft8s" for this suite.
May 21 10:40:03.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:03.933: INFO: namespace: e2e-tests-pods-hft8s, resource: bindings, ignored listing per whitelist
May 21 10:40:04.038: INFO: namespace e2e-tests-pods-hft8s deletion completed in 24.236392609s

• [SLOW TEST:26.904 seconds]
[k8s.io] Pods
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be updated  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's memory request [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:04.038: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:04.083012      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:40:04.159: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-sp7n7" to be "success or failure"
May 21 10:40:04.171: INFO: Pod "downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.705559ms
May 21 10:40:06.175: INFO: Pod "downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015638704s
STEP: Saw pod success
May 21 10:40:06.175: INFO: Pod "downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:40:06.178: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:40:06.209: INFO: Waiting for pod downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:40:06.218: INFO: Pod downwardapi-volume-52374359-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:06.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sp7n7" for this suite.
May 21 10:40:12.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:12.382: INFO: namespace: e2e-tests-projected-sp7n7, resource: bindings, ignored listing per whitelist
May 21 10:40:12.420: INFO: namespace e2e-tests-projected-sp7n7 deletion completed in 6.195999136s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:12.420: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:12.456303      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-57306a82-5ce3-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:40:12.517: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-mwlw5" to be "success or failure"
May 21 10:40:12.520: INFO: Pod "pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.869155ms
May 21 10:40:14.526: INFO: Pod "pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009117648s
STEP: Saw pod success
May 21 10:40:14.526: INFO: Pod "pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:40:14.528: INFO: Trying to get logs from node master-192.168.130.1 pod pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:40:14.546: INFO: Waiting for pod pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:40:14.555: INFO: Pod pod-projected-configmaps-5731f7b9-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:14.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mwlw5" for this suite.
May 21 10:40:20.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:20.723: INFO: namespace: e2e-tests-projected-mwlw5, resource: bindings, ignored listing per whitelist
May 21 10:40:20.745: INFO: namespace e2e-tests-projected-mwlw5 deletion completed in 6.181137772s

• [SLOW TEST:8.324 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:20.745: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:20.792694      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir volume type on node default medium
May 21 10:40:20.861: INFO: Waiting up to 5m0s for pod "pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-wsgr5" to be "success or failure"
May 21 10:40:20.870: INFO: Pod "pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.909461ms
May 21 10:40:22.875: INFO: Pod "pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014360748s
STEP: Saw pod success
May 21 10:40:22.875: INFO: Pod "pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:40:22.884: INFO: Trying to get logs from node node-192.168.130.5 pod pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:40:22.909: INFO: Waiting for pod pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:40:22.914: INFO: Pod pod-5c2c3939-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:22.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wsgr5" for this suite.
May 21 10:40:28.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:29.063: INFO: namespace: e2e-tests-emptydir-wsgr5, resource: bindings, ignored listing per whitelist
May 21 10:40:29.129: INFO: namespace e2e-tests-emptydir-wsgr5 deletion completed in 6.202267167s

• [SLOW TEST:8.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:29.129: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:29.171943      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 Pods, got 2 Pods
STEP: Gathering metrics
W0521 10:40:30.276313      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:40:30.276: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:30.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hl7mr" for this suite.
May 21 10:40:36.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:36.451: INFO: namespace: e2e-tests-gc-hl7mr, resource: bindings, ignored listing per whitelist
May 21 10:40:36.516: INFO: namespace e2e-tests-gc-hl7mr deletion completed in 6.231553017s

• [SLOW TEST:7.387 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint)  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:36.516: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:36.559739      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint)  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test override command
May 21 10:40:36.617: INFO: Waiting up to 5m0s for pod "client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-containers-872hf" to be "success or failure"
May 21 10:40:36.623: INFO: Pod "client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092721ms
May 21 10:40:38.634: INFO: Pod "client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016745798s
STEP: Saw pod success
May 21 10:40:38.634: INFO: Pod "client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:40:38.638: INFO: Trying to get logs from node master-192.168.130.3 pod client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:40:38.673: INFO: Waiting for pod client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:40:38.678: INFO: Pod client-containers-65906c61-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:38.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-872hf" for this suite.
May 21 10:40:44.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:44.804: INFO: namespace: e2e-tests-containers-872hf, resource: bindings, ignored listing per whitelist
May 21 10:40:44.972: INFO: namespace e2e-tests-containers-872hf deletion completed in 6.284585854s

• [SLOW TEST:8.456 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be able to override the image's default command (docker entrypoint)  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:44.972: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:45.017289      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:40:45.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-wrp6w" to be "success or failure"
May 21 10:40:45.141: INFO: Pod "downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.374608ms
May 21 10:40:47.147: INFO: Pod "downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017208064s
STEP: Saw pod success
May 21 10:40:47.147: INFO: Pod "downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:40:47.150: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:40:47.178: INFO: Waiting for pod downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:40:47.182: INFO: Pod downwardapi-volume-6a9deaa1-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:47.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wrp6w" for this suite.
May 21 10:40:53.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:53.367: INFO: namespace: e2e-tests-projected-wrp6w, resource: bindings, ignored listing per whitelist
May 21 10:40:53.381: INFO: namespace e2e-tests-projected-wrp6w deletion completed in 6.193767903s

• [SLOW TEST:8.409 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:53.381: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:53.420712      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:53
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[AfterEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:40:53.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jgcd5" for this suite.
May 21 10:40:59.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:40:59.526: INFO: namespace: e2e-tests-services-jgcd5, resource: bindings, ignored listing per whitelist
May 21 10:40:59.644: INFO: namespace e2e-tests-services-jgcd5 deletion completed in 6.172372407s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:58

• [SLOW TEST:6.262 seconds]
[sig-network] Services
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:40:59.644: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:40:59.685898      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward api env vars
May 21 10:40:59.752: INFO: Waiting up to 5m0s for pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-9fcb5" to be "success or failure"
May 21 10:40:59.761: INFO: Pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.645556ms
May 21 10:41:01.765: INFO: Pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013082875s
May 21 10:41:03.769: INFO: Pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017121307s
May 21 10:41:05.773: INFO: Pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021461582s
May 21 10:41:07.778: INFO: Pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.026035976s
STEP: Saw pod success
May 21 10:41:07.778: INFO: Pod "downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:41:07.781: INFO: Trying to get logs from node master-192.168.130.3 pod downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:41:07.804: INFO: Waiting for pod downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:41:07.812: INFO: Pod downward-api-73594188-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:41:07.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9fcb5" for this suite.
May 21 10:41:13.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:13.921: INFO: namespace: e2e-tests-downward-api-9fcb5, resource: bindings, ignored listing per whitelist
May 21 10:41:13.994: INFO: namespace e2e-tests-downward-api-9fcb5 deletion completed in 6.175822011s

• [SLOW TEST:14.351 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:41:13.994: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:41:14.036395      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:41:14.104: INFO: (0) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.471328ms)
May 21 10:41:14.109: INFO: (1) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.949489ms)
May 21 10:41:14.113: INFO: (2) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.864684ms)
May 21 10:41:14.118: INFO: (3) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.465148ms)
May 21 10:41:14.121: INFO: (4) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.418564ms)
May 21 10:41:14.127: INFO: (5) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.320545ms)
May 21 10:41:14.130: INFO: (6) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.344443ms)
May 21 10:41:14.133: INFO: (7) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.214267ms)
May 21 10:41:14.137: INFO: (8) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.693596ms)
May 21 10:41:14.140: INFO: (9) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.384411ms)
May 21 10:41:14.144: INFO: (10) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.288919ms)
May 21 10:41:14.147: INFO: (11) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.782968ms)
May 21 10:41:14.151: INFO: (12) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.581955ms)
May 21 10:41:14.154: INFO: (13) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.399309ms)
May 21 10:41:14.158: INFO: (14) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.270429ms)
May 21 10:41:14.161: INFO: (15) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.60513ms)
May 21 10:41:14.165: INFO: (16) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.625916ms)
May 21 10:41:14.168: INFO: (17) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.334421ms)
May 21 10:41:14.172: INFO: (18) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.54759ms)
May 21 10:41:14.175: INFO: (19) /api/v1/nodes/master-192.168.130.1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.27301ms)
[AfterEach] version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:41:14.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-rv5ck" for this suite.
May 21 10:41:20.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:20.379: INFO: namespace: e2e-tests-proxy-rv5ck, resource: bindings, ignored listing per whitelist
May 21 10:41:20.384: INFO: namespace e2e-tests-proxy-rv5ck deletion completed in 6.204613899s

• [SLOW TEST:6.390 seconds]
[sig-network] Proxy
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:41:20.384: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:41:20.423404      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:41:20.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lxs9b" for this suite.
May 21 10:41:42.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:42.579: INFO: namespace: e2e-tests-pods-lxs9b, resource: bindings, ignored listing per whitelist
May 21 10:41:42.726: INFO: namespace e2e-tests-pods-lxs9b deletion completed in 22.219272047s

• [SLOW TEST:22.341 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:41:42.726: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:41:42.800058      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward api env vars
May 21 10:41:42.867: INFO: Waiting up to 5m0s for pod "downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-nc4pb" to be "success or failure"
May 21 10:41:42.873: INFO: Pod "downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555751ms
May 21 10:41:44.877: INFO: Pod "downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010109327s
May 21 10:41:46.881: INFO: Pod "downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014526023s
May 21 10:41:48.887: INFO: Pod "downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019796298s
STEP: Saw pod success
May 21 10:41:48.887: INFO: Pod "downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:41:48.893: INFO: Trying to get logs from node master-192.168.130.3 pod downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:41:48.947: INFO: Waiting for pod downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:41:48.950: INFO: Pod downward-api-8d0d1efd-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:41:48.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nc4pb" for this suite.
May 21 10:41:54.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:41:55.069: INFO: namespace: e2e-tests-downward-api-nc4pb, resource: bindings, ignored listing per whitelist
May 21 10:41:55.151: INFO: namespace e2e-tests-downward-api-nc4pb deletion completed in 6.193539449s

• [SLOW TEST:12.425 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:41:55.151: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:41:55.193067      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0521 10:42:35.298304      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 10:42:35.298: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:42:35.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-697pj" for this suite.
May 21 10:42:43.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:43.542: INFO: namespace: e2e-tests-gc-697pj, resource: bindings, ignored listing per whitelist
May 21 10:42:43.555: INFO: namespace e2e-tests-gc-697pj deletion completed in 8.251859355s

• [SLOW TEST:48.404 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:42:43.556: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:42:43.600756      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:42:43.669: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:42:44.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-bfb58" for this suite.
May 21 10:42:50.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:42:50.448: INFO: namespace: e2e-tests-custom-resource-definition-bfb58, resource: bindings, ignored listing per whitelist
May 21 10:42:50.539: INFO: namespace e2e-tests-custom-resource-definition-bfb58 deletion completed in 6.256608988s

• [SLOW TEST:6.983 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:42:50.540: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:42:50.590204      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-g8snl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-g8snl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-g8snl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-g8snl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-g8snl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-g8snl.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 10:43:02.775: INFO: DNS probes using dns-test-b5760206-5ce3-11e8-8768-12f5d52dbf0b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:43:02.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-g8snl" for this suite.
May 21 10:43:08.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:43:08.915: INFO: namespace: e2e-tests-dns-g8snl, resource: bindings, ignored listing per whitelist
May 21 10:43:09.018: INFO: namespace e2e-tests-dns-g8snl deletion completed in 6.209753006s

• [SLOW TEST:18.478 seconds]
[sig-network] DNS
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:43:09.018: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:43:09.072378      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:43:11.161: INFO: Waiting up to 5m0s for pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-pods-5gpdt" to be "success or failure"
May 21 10:43:11.164: INFO: Pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204519ms
May 21 10:43:13.169: INFO: Pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007818354s
May 21 10:43:15.174: INFO: Pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012738245s
May 21 10:43:17.178: INFO: Pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017125024s
May 21 10:43:19.183: INFO: Pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021729575s
STEP: Saw pod success
May 21 10:43:19.183: INFO: Pod "client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:43:19.185: INFO: Trying to get logs from node node-192.168.130.5 pod client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b container env3cont: <nil>
STEP: delete the pod
May 21 10:43:19.217: INFO: Waiting for pod client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:43:19.220: INFO: Pod client-envvars-c1ad0ca6-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:43:19.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5gpdt" for this suite.
May 21 10:43:41.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:43:41.374: INFO: namespace: e2e-tests-pods-5gpdt, resource: bindings, ignored listing per whitelist
May 21 10:43:41.433: INFO: namespace e2e-tests-pods-5gpdt deletion completed in 22.207734089s

• [SLOW TEST:32.415 seconds]
[k8s.io] Pods
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should contain environment variables for services  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:43:41.433: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:43:41.472016      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pvxpg
May 21 10:43:43.545: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pvxpg
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:43:43.548: INFO: Initial restart count of pod liveness-http is 0
May 21 10:44:01.604: INFO: Restart count of pod e2e-tests-container-probe-pvxpg/liveness-http is now 1 (18.05595296s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:44:01.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pvxpg" for this suite.
May 21 10:44:07.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:07.776: INFO: namespace: e2e-tests-container-probe-pvxpg, resource: bindings, ignored listing per whitelist
May 21 10:44:07.889: INFO: namespace e2e-tests-container-probe-pvxpg deletion completed in 6.253663658s

• [SLOW TEST:26.455 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be restarted with a /healthz http liveness probe  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:44:07.889: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:44:07.929886      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 10:44:07.988: INFO: Waiting up to 5m0s for pod "pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-ssfl5" to be "success or failure"
May 21 10:44:07.994: INFO: Pod "pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.317862ms
May 21 10:44:10.003: INFO: Pod "pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015293963s
STEP: Saw pod success
May 21 10:44:10.003: INFO: Pod "pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:44:10.006: INFO: Trying to get logs from node master-192.168.130.3 pod pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:44:10.035: INFO: Waiting for pod pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:44:10.039: INFO: Pod pod-e38d374e-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:44:10.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ssfl5" for this suite.
May 21 10:44:16.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:16.229: INFO: namespace: e2e-tests-emptydir-ssfl5, resource: bindings, ignored listing per whitelist
May 21 10:44:16.268: INFO: namespace e2e-tests-emptydir-ssfl5 deletion completed in 6.224346526s

• [SLOW TEST:8.379 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:44:16.269: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:44:16.321435      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-e88ebb6e-5ce3-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:44:16.396: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-mz486" to be "success or failure"
May 21 10:44:16.401: INFO: Pod "pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.548253ms
May 21 10:44:18.405: INFO: Pod "pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009196384s
STEP: Saw pod success
May 21 10:44:18.405: INFO: Pod "pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:44:18.409: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:44:18.433: INFO: Waiting for pod pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b to disappear
May 21 10:44:18.441: INFO: Pod pod-projected-configmaps-e88f7937-5ce3-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:44:18.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mz486" for this suite.
May 21 10:44:24.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:44:24.598: INFO: namespace: e2e-tests-projected-mz486, resource: bindings, ignored listing per whitelist
May 21 10:44:24.676: INFO: namespace e2e-tests-projected-mz486 deletion completed in 6.221390362s

• [SLOW TEST:8.407 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:44:24.676: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:44:24.722975      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-l6bfd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:44:24.788: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:44:48.947: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.64.188:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l6bfd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:44:48.947: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:44:49.070: INFO: Found all expected endpoints: [netserver-0]
May 21 10:44:49.074: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.66.129:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l6bfd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:44:49.074: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:44:49.181: INFO: Found all expected endpoints: [netserver-1]
May 21 10:44:49.184: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.68.151:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l6bfd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:44:49.184: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:44:49.300: INFO: Found all expected endpoints: [netserver-2]
May 21 10:44:49.305: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.67.146:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l6bfd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:44:49.305: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:44:49.416: INFO: Found all expected endpoints: [netserver-3]
May 21 10:44:49.420: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.65.142:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-l6bfd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:44:49.420: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:44:49.525: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:44:49.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-l6bfd" for this suite.
May 21 10:45:13.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:45:13.662: INFO: namespace: e2e-tests-pod-network-test-l6bfd, resource: bindings, ignored listing per whitelist
May 21 10:45:13.713: INFO: namespace e2e-tests-pod-network-test-l6bfd deletion completed in 24.180766764s

• [SLOW TEST:49.037 seconds]
[sig-network] Networking
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:45:13.713: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:45:13.759200      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-69tvh;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-69tvh;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-69tvh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-69tvh.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-69tvh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 192.79.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.79.192_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 192.79.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.79.192_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-69tvh;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-69tvh;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-69tvh.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-69tvh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-69tvh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-69tvh.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-69tvh.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-69tvh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 192.79.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.79.192_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 192.79.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.79.192_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 10:45:27.972: INFO: DNS probes using dns-test-0acd6cff-5ce4-11e8-8768-12f5d52dbf0b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:45:28.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-69tvh" for this suite.
May 21 10:45:34.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:45:34.194: INFO: namespace: e2e-tests-dns-69tvh, resource: bindings, ignored listing per whitelist
May 21 10:45:34.282: INFO: namespace e2e-tests-dns-69tvh deletion completed in 6.211859107s

• [SLOW TEST:20.569 seconds]
[sig-network] DNS
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:45:34.283: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:45:34.329558      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward api env vars
May 21 10:45:34.393: INFO: Waiting up to 5m0s for pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-wnmjm" to be "success or failure"
May 21 10:45:34.401: INFO: Pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.888093ms
May 21 10:45:36.405: INFO: Pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012898707s
May 21 10:45:38.411: INFO: Pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018759793s
May 21 10:45:40.418: INFO: Pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025201363s
May 21 10:45:42.423: INFO: Pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030163091s
STEP: Saw pod success
May 21 10:45:42.423: INFO: Pod "downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:45:42.425: INFO: Trying to get logs from node master-192.168.130.3 pod downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b container dapi-container: <nil>
STEP: delete the pod
May 21 10:45:42.450: INFO: Waiting for pod downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b to disappear
May 21 10:45:42.461: INFO: Pod downward-api-170ccf54-5ce4-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:45:42.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wnmjm" for this suite.
May 21 10:45:48.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:45:48.679: INFO: namespace: e2e-tests-downward-api-wnmjm, resource: bindings, ignored listing per whitelist
May 21 10:45:48.690: INFO: namespace e2e-tests-downward-api-wnmjm deletion completed in 6.222868968s

• [SLOW TEST:14.407 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection] [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:45:48.690: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:45:48.731884      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection] [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-projected-all-test-volume-1fa1a8a7-5ce4-11e8-8768-12f5d52dbf0b
STEP: Creating secret with name secret-projected-all-test-volume-1fa1a84b-5ce4-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test Check all projections for projected volume plugin
May 21 10:45:48.798: INFO: Waiting up to 5m0s for pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-54l7x" to be "success or failure"
May 21 10:45:48.801: INFO: Pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.36034ms
May 21 10:45:50.806: INFO: Pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008395226s
May 21 10:45:52.812: INFO: Pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013830391s
May 21 10:45:54.817: INFO: Pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018924484s
May 21 10:45:56.821: INFO: Pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022737175s
STEP: Saw pod success
May 21 10:45:56.821: INFO: Pod "projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:45:56.823: INFO: Trying to get logs from node master-192.168.130.3 pod projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b container projected-all-volume-test: <nil>
STEP: delete the pod
May 21 10:45:56.852: INFO: Waiting for pod projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b to disappear
May 21 10:45:56.855: INFO: Pod projected-volume-1fa1a7f0-5ce4-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:45:56.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-54l7x" for this suite.
May 21 10:46:02.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:46:02.979: INFO: namespace: e2e-tests-projected-54l7x, resource: bindings, ignored listing per whitelist
May 21 10:46:03.052: INFO: namespace e2e-tests-projected-54l7x deletion completed in 6.190032819s

• [SLOW TEST:14.362 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection] [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:46:03.052: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:46:03.096547      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-b5scp
May 21 10:46:13.160: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-b5scp
STEP: checking the pod's current state and verifying that restartCount is present
May 21 10:46:13.163: INFO: Initial restart count of pod liveness-exec is 0
May 21 10:47:09.314: INFO: Restart count of pod e2e-tests-container-probe-b5scp/liveness-exec is now 1 (56.151314847s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:47:09.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b5scp" for this suite.
May 21 10:47:15.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:15.540: INFO: namespace: e2e-tests-container-probe-b5scp, resource: bindings, ignored listing per whitelist
May 21 10:47:15.558: INFO: namespace e2e-tests-container-probe-b5scp deletion completed in 6.213115472s

• [SLOW TEST:72.506 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should be restarted with a exec "cat /tmp/health" liveness probe [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:47:15.558: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:47:15.601548      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name projected-configmap-test-volume-536afa35-5ce4-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:47:15.672: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-k5fsm" to be "success or failure"
May 21 10:47:15.675: INFO: Pod "pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.049215ms
May 21 10:47:17.681: INFO: Pod "pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008317773s
STEP: Saw pod success
May 21 10:47:17.681: INFO: Pod "pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:47:17.684: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:47:17.714: INFO: Waiting for pod pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b to disappear
May 21 10:47:17.718: INFO: Pod pod-projected-configmaps-536b95ce-5ce4-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:47:17.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k5fsm" for this suite.
May 21 10:47:23.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:23.894: INFO: namespace: e2e-tests-projected-k5fsm, resource: bindings, ignored listing per whitelist
May 21 10:47:23.897: INFO: namespace e2e-tests-projected-k5fsm deletion completed in 6.174365347s

• [SLOW TEST:8.339 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:47:23.898: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:47:23.943210      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:47:24.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-5jqhk" to be "success or failure"
May 21 10:47:24.022: INFO: Pod "downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.421371ms
May 21 10:47:26.027: INFO: Pod "downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010219545s
STEP: Saw pod success
May 21 10:47:26.027: INFO: Pod "downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:47:26.030: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:47:26.056: INFO: Waiting for pod downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b to disappear
May 21 10:47:26.063: INFO: Pod downwardapi-volume-5863f7a0-5ce4-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:47:26.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5jqhk" for this suite.
May 21 10:47:32.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:32.293: INFO: namespace: e2e-tests-downward-api-5jqhk, resource: bindings, ignored listing per whitelist
May 21 10:47:32.303: INFO: namespace e2e-tests-downward-api-5jqhk deletion completed in 6.235078559s

• [SLOW TEST:8.405 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:47:32.304: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:47:32.354177      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating the pod
May 21 10:47:34.960: INFO: Successfully updated pod "annotationupdate5d658ea8-5ce4-11e8-8768-12f5d52dbf0b"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:47:36.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zqbf" for this suite.
May 21 10:47:59.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:47:59.173: INFO: namespace: e2e-tests-projected-9zqbf, resource: bindings, ignored listing per whitelist
May 21 10:47:59.179: INFO: namespace e2e-tests-projected-9zqbf deletion completed in 22.187162259s

• [SLOW TEST:26.875 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:47:59.179: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:47:59.223343      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 10:47:59.273: INFO: Creating ReplicaSet my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b
May 21 10:47:59.284: INFO: Pod name my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b: Found 0 pods out of 1
May 21 10:48:04.289: INFO: Pod name my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b: Found 1 pods out of 1
May 21 10:48:04.289: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b" is running
May 21 10:48:04.293: INFO: Pod "my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b-prhlp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-05-21 10:47:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-05-21 10:48:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-05-21 10:47:59 +0000 UTC Reason: Message:}])
May 21 10:48:04.293: INFO: Trying to dial the pod
May 21 10:48:09.310: INFO: Controller my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b: Got expected result from replica 1 [my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b-prhlp]: "my-hostname-basic-6d698496-5ce4-11e8-8768-12f5d52dbf0b-prhlp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:48:09.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-gj69q" for this suite.
May 21 10:48:15.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:15.405: INFO: namespace: e2e-tests-replicaset-gj69q, resource: bindings, ignored listing per whitelist
May 21 10:48:15.526: INFO: namespace e2e-tests-replicaset-gj69q deletion completed in 6.209384203s

• [SLOW TEST:16.347 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:48:15.526: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:48:15.572770      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating replication controller my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b
May 21 10:48:15.633: INFO: Pod name my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b: Found 0 pods out of 1
May 21 10:48:20.639: INFO: Pod name my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b: Found 1 pods out of 1
May 21 10:48:20.639: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b" are running
May 21 10:48:20.642: INFO: Pod "my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b-cz5kl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-05-21 10:48:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-05-21 10:48:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-05-21 10:48:15 +0000 UTC Reason: Message:}])
May 21 10:48:20.642: INFO: Trying to dial the pod
May 21 10:48:25.691: INFO: Controller my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b: Got expected result from replica 1 [my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b-cz5kl]: "my-hostname-basic-7728a588-5ce4-11e8-8768-12f5d52dbf0b-cz5kl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:48:25.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-d5htj" for this suite.
May 21 10:48:31.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:31.848: INFO: namespace: e2e-tests-replication-controller-d5htj, resource: bindings, ignored listing per whitelist
May 21 10:48:31.905: INFO: namespace e2e-tests-replication-controller-d5htj deletion completed in 6.205309362s

• [SLOW TEST:16.379 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:48:31.905: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:48:31.948707      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:48:32.002: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-6c6rs" to be "success or failure"
May 21 10:48:32.006: INFO: Pod "downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.690035ms
May 21 10:48:34.011: INFO: Pod "downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008960759s
STEP: Saw pod success
May 21 10:48:34.011: INFO: Pod "downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:48:34.014: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:48:34.037: INFO: Waiting for pod downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b to disappear
May 21 10:48:34.040: INFO: Pod downwardapi-volume-80ea60cc-5ce4-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:48:34.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6c6rs" for this suite.
May 21 10:48:40.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:40.138: INFO: namespace: e2e-tests-downward-api-6c6rs, resource: bindings, ignored listing per whitelist
May 21 10:48:40.246: INFO: namespace e2e-tests-downward-api-6c6rs deletion completed in 6.20039959s

• [SLOW TEST:8.341 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:48:40.246: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:48:40.284267      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test hostPath mode
May 21 10:48:40.343: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-np6zq" to be "success or failure"
May 21 10:48:40.348: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.642677ms
May 21 10:48:42.352: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008423536s
STEP: Saw pod success
May 21 10:48:42.352: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 21 10:48:42.355: INFO: Trying to get logs from node node-192.168.130.4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 21 10:48:42.377: INFO: Waiting for pod pod-host-path-test to disappear
May 21 10:48:42.382: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:48:42.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-np6zq" for this suite.
May 21 10:48:48.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:48.568: INFO: namespace: e2e-tests-hostpath-np6zq, resource: bindings, ignored listing per whitelist
May 21 10:48:48.583: INFO: namespace e2e-tests-hostpath-np6zq deletion completed in 6.190011574s

• [SLOW TEST:8.337 seconds]
[sig-storage] HostPath
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:48:48.584: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:48:48.626557      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:48:48.690: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-thxvq" to be "success or failure"
May 21 10:48:48.698: INFO: Pod "downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.314155ms
May 21 10:48:50.704: INFO: Pod "downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014482151s
STEP: Saw pod success
May 21 10:48:50.704: INFO: Pod "downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:48:50.713: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:48:50.749: INFO: Waiting for pod downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b to disappear
May 21 10:48:50.751: INFO: Pod downwardapi-volume-8adb7d36-5ce4-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:48:50.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-thxvq" for this suite.
May 21 10:48:56.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:48:56.894: INFO: namespace: e2e-tests-projected-thxvq, resource: bindings, ignored listing per whitelist
May 21 10:48:56.970: INFO: namespace e2e-tests-projected-thxvq deletion completed in 6.214542298s

• [SLOW TEST:8.387 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:48:56.970: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:48:57.012513      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-f62jh
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-f62jh
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-f62jh
May 21 10:48:57.104: INFO: Found 0 stateful pods, waiting for 1
May 21 10:49:07.109: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 21 10:49:07.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:49:07.502: INFO: stderr: ""
May 21 10:49:07.502: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:49:07.507: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 10:49:17.512: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:49:17.512: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:49:17.532: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999165s
May 21 10:49:18.538: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99527376s
May 21 10:49:19.543: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989377291s
May 21 10:49:20.547: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984794969s
May 21 10:49:21.553: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.98042168s
May 21 10:49:22.557: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975091189s
May 21 10:49:23.562: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970062482s
May 21 10:49:24.567: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.965186609s
May 21 10:49:25.573: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.960191161s
May 21 10:49:26.579: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.685894ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-f62jh
May 21 10:49:27.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:49:27.966: INFO: stderr: ""
May 21 10:49:27.966: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:49:27.971: INFO: Found 1 stateful pods, waiting for 3
May 21 10:49:37.976: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:49:37.976: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:49:37.976: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 21 10:49:37.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:49:38.340: INFO: stderr: ""
May 21 10:49:38.340: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:49:38.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:49:38.712: INFO: stderr: ""
May 21 10:49:38.712: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:49:38.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:49:39.049: INFO: stderr: ""
May 21 10:49:39.050: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 10:49:39.050: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:49:39.055: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 21 10:49:49.066: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:49:49.066: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:49:49.066: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 10:49:49.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999583s
May 21 10:49:50.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996420897s
May 21 10:49:51.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99121513s
May 21 10:49:52.103: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98225969s
May 21 10:49:53.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97750099s
May 21 10:49:54.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972837417s
May 21 10:49:55.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967248673s
May 21 10:49:56.123: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96199012s
May 21 10:49:57.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957606955s
May 21 10:49:58.168: INFO: Verifying statefulset ss doesn't scale past 3 for another 918.2269ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-f62jh
May 21 10:49:59.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:49:59.515: INFO: stderr: ""
May 21 10:49:59.515: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:49:59.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:49:59.858: INFO: stderr: ""
May 21 10:49:59.858: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 10:49:59.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:50:00.229: INFO: rc: 126
May 21 10:50:00.229: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil> rpc error: code = 2 desc = oci runtime error: exec failed: cannot exec a container that has run and stopped

 command terminated with exit code 126
 [] <nil> 0xc420df0b10 exit status 126 <nil> <nil> true [0xc42087f728 0xc42087f7a0 0xc42087f7e0] [0xc42087f728 0xc42087f7a0 0xc42087f7e0] [0xc42087f748 0xc42087f7d8] [0x94d8e0 0x94d8e0] 0xc421bad920 <nil>}:
Command stdout:
rpc error: code = 2 desc = oci runtime error: exec failed: cannot exec a container that has run and stopped


stderr:
command terminated with exit code 126

error:
exit status 126

May 21 10:50:10.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:50:10.367: INFO: rc: 1
May 21 10:50:10.367: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420df0ff0 exit status 1 <nil> <nil> true [0xc42087f7e8 0xc42087f820 0xc42087f848] [0xc42087f7e8 0xc42087f820 0xc42087f848] [0xc42087f808 0xc42087f840] [0x94d8e0 0x94d8e0] 0xc421badaa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:50:20.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:50:20.532: INFO: rc: 1
May 21 10:50:20.532: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f09170 exit status 1 <nil> <nil> true [0xc420085f00 0xc420085f18 0xc420085f30] [0xc420085f00 0xc420085f18 0xc420085f30] [0xc420085f10 0xc420085f28] [0x94d8e0 0x94d8e0] 0xc421c744e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:50:30.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:50:30.698: INFO: rc: 1
May 21 10:50:30.698: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f095c0 exit status 1 <nil> <nil> true [0xc420085f38 0xc420085f50 0xc420085f68] [0xc420085f38 0xc420085f50 0xc420085f68] [0xc420085f48 0xc420085f60] [0x94d8e0 0x94d8e0] 0xc421c74f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:50:40.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:50:40.855: INFO: rc: 1
May 21 10:50:40.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f099b0 exit status 1 <nil> <nil> true [0xc420085f70 0xc420085f88 0xc420085fa0] [0xc420085f70 0xc420085f88 0xc420085fa0] [0xc420085f80 0xc420085f98] [0x94d8e0 0x94d8e0] 0xc421c750e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:50:50.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:50:51.021: INFO: rc: 1
May 21 10:50:51.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420df13e0 exit status 1 <nil> <nil> true [0xc42087f850 0xc42087f8b0 0xc42087f8d8] [0xc42087f850 0xc42087f8b0 0xc42087f8d8] [0xc42087f880 0xc42087f8d0] [0x94d8e0 0x94d8e0] 0xc421badbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:51:01.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:51:01.201: INFO: rc: 1
May 21 10:51:01.201: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f8c3c0 exit status 1 <nil> <nil> true [0xc42000e0d0 0xc42000e130 0xc42000e498] [0xc42000e0d0 0xc42000e130 0xc42000e498] [0xc42000e108 0xc42000e488] [0x94d8e0 0x94d8e0] 0xc421f15800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:51:11.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:51:11.352: INFO: rc: 1
May 21 10:51:11.352: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e2510 exit status 1 <nil> <nil> true [0xc420e32000 0xc420e32018 0xc420e32030] [0xc420e32000 0xc420e32018 0xc420e32030] [0xc420e32010 0xc420e32028] [0x94d8e0 0x94d8e0] 0xc421308060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:51:21.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:51:21.505: INFO: rc: 1
May 21 10:51:21.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ffa570 exit status 1 <nil> <nil> true [0xc42087e228 0xc42087e298 0xc42087e2e8] [0xc42087e228 0xc42087e298 0xc42087e2e8] [0xc42087e278 0xc42087e2d8] [0x94d8e0 0x94d8e0] 0xc42130a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:51:31.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:51:31.684: INFO: rc: 1
May 21 10:51:31.684: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e2960 exit status 1 <nil> <nil> true [0xc420e32038 0xc420e32050 0xc420e32068] [0xc420e32038 0xc420e32050 0xc420e32068] [0xc420e32048 0xc420e32060] [0x94d8e0 0x94d8e0] 0xc421308180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:51:41.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:51:41.871: INFO: rc: 1
May 21 10:51:41.872: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ffab40 exit status 1 <nil> <nil> true [0xc42087e308 0xc42087e3c8 0xc42087e410] [0xc42087e308 0xc42087e3c8 0xc42087e410] [0xc42087e3a0 0xc42087e3f0] [0x94d8e0 0x94d8e0] 0xc42130a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:51:51.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:51:52.023: INFO: rc: 1
May 21 10:51:52.023: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c2540 exit status 1 <nil> <nil> true [0xc420084130 0xc4200842b0 0xc420084300] [0xc420084130 0xc4200842b0 0xc420084300] [0xc420084260 0xc4200842f0] [0x94d8e0 0x94d8e0] 0xc421a1e300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:52:02.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:52:02.177: INFO: rc: 1
May 21 10:52:02.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ffaf30 exit status 1 <nil> <nil> true [0xc42087e420 0xc42087e470 0xc42087e578] [0xc42087e420 0xc42087e470 0xc42087e578] [0xc42087e450 0xc42087e530] [0x94d8e0 0x94d8e0] 0xc42130a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:52:12.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:52:12.328: INFO: rc: 1
May 21 10:52:12.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ffb380 exit status 1 <nil> <nil> true [0xc42087e5d8 0xc42087e658 0xc42087e770] [0xc42087e5d8 0xc42087e658 0xc42087e770] [0xc42087e638 0xc42087e6d0] [0x94d8e0 0x94d8e0] 0xc42130ab40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:52:22.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:52:22.477: INFO: rc: 1
May 21 10:52:22.477: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f8c8a0 exit status 1 <nil> <nil> true [0xc42000e4a0 0xc42000e4c0 0xc42000e4e0] [0xc42000e4a0 0xc42000e4c0 0xc42000e4e0] [0xc42000e4b8 0xc42000e4d8] [0x94d8e0 0x94d8e0] 0xc421f15980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:52:32.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:52:32.635: INFO: rc: 1
May 21 10:52:32.635: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c2c30 exit status 1 <nil> <nil> true [0xc420084310 0xc420084340 0xc4200857e8] [0xc420084310 0xc420084340 0xc4200857e8] [0xc420084330 0xc4200857e0] [0x94d8e0 0x94d8e0] 0xc421a1e420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:52:42.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:52:42.804: INFO: rc: 1
May 21 10:52:42.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f8ccf0 exit status 1 <nil> <nil> true [0xc42000e4e8 0xc42000e508 0xc42000e520] [0xc42000e4e8 0xc42000e508 0xc42000e520] [0xc42000e500 0xc42000e518] [0x94d8e0 0x94d8e0] 0xc421f15aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:52:52.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:52:52.991: INFO: rc: 1
May 21 10:52:52.991: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f8d0b0 exit status 1 <nil> <nil> true [0xc42000e530 0xc42000e558 0xc42000e578] [0xc42000e530 0xc42000e558 0xc42000e578] [0xc42000e548 0xc42000e570] [0x94d8e0 0x94d8e0] 0xc421f15bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:53:02.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:53:03.148: INFO: rc: 1
May 21 10:53:03.148: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c2570 exit status 1 <nil> <nil> true [0xc420084240 0xc4200842d0 0xc420084310] [0xc420084240 0xc4200842d0 0xc420084310] [0xc4200842b0 0xc420084300] [0x94d8e0 0x94d8e0] 0xc421a1e300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:53:13.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:53:13.295: INFO: rc: 1
May 21 10:53:13.295: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c2cf0 exit status 1 <nil> <nil> true [0xc420084320 0xc4200857d8 0xc420085810] [0xc420084320 0xc4200857d8 0xc420085810] [0xc420084340 0xc4200857e8] [0x94d8e0 0x94d8e0] 0xc421a1e420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:53:23.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:53:23.419: INFO: rc: 1
May 21 10:53:23.420: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c3140 exit status 1 <nil> <nil> true [0xc420085820 0xc420085838 0xc420085850] [0xc420085820 0xc420085838 0xc420085850] [0xc420085830 0xc420085848] [0x94d8e0 0x94d8e0] 0xc421a1e540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:53:33.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:53:33.558: INFO: rc: 1
May 21 10:53:33.558: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f8c3f0 exit status 1 <nil> <nil> true [0xc42087e228 0xc42087e298 0xc42087e2e8] [0xc42087e228 0xc42087e298 0xc42087e2e8] [0xc42087e278 0xc42087e2d8] [0x94d8e0 0x94d8e0] 0xc42130a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:53:43.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:53:43.729: INFO: rc: 1
May 21 10:53:43.730: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c3530 exit status 1 <nil> <nil> true [0xc420085858 0xc420085870 0xc420085888] [0xc420085858 0xc420085870 0xc420085888] [0xc420085868 0xc420085880] [0x94d8e0 0x94d8e0] 0xc421a1e6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:53:53.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:53:53.887: INFO: rc: 1
May 21 10:53:53.887: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e2540 exit status 1 <nil> <nil> true [0xc42000e010 0xc42000e108 0xc42000e488] [0xc42000e010 0xc42000e108 0xc42000e488] [0xc42000e0e8 0xc42000e478] [0x94d8e0 0x94d8e0] 0xc421f15800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:54:03.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:54:04.043: INFO: rc: 1
May 21 10:54:04.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e2a20 exit status 1 <nil> <nil> true [0xc42000e498 0xc42000e4b8 0xc42000e4d8] [0xc42000e498 0xc42000e4b8 0xc42000e4d8] [0xc42000e4a8 0xc42000e4d0] [0x94d8e0 0x94d8e0] 0xc421f15980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:54:14.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:54:14.264: INFO: rc: 1
May 21 10:54:14.264: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e2e70 exit status 1 <nil> <nil> true [0xc42000e4e0 0xc42000e500 0xc42000e518] [0xc42000e4e0 0xc42000e500 0xc42000e518] [0xc42000e4f0 0xc42000e510] [0x94d8e0 0x94d8e0] 0xc421f15aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:54:24.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:54:24.410: INFO: rc: 1
May 21 10:54:24.410: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e32f0 exit status 1 <nil> <nil> true [0xc42000e520 0xc42000e548 0xc42000e570] [0xc42000e520 0xc42000e548 0xc42000e570] [0xc42000e538 0xc42000e568] [0x94d8e0 0x94d8e0] 0xc421f15bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:54:34.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:54:34.557: INFO: rc: 1
May 21 10:54:34.557: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e3770 exit status 1 <nil> <nil> true [0xc42000e578 0xc42000e5e8 0xc42000e618] [0xc42000e578 0xc42000e5e8 0xc42000e618] [0xc42000e5e0 0xc42000e610] [0x94d8e0 0x94d8e0] 0xc421f15ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:54:44.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:54:44.710: INFO: rc: 1
May 21 10:54:44.710: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213e3b90 exit status 1 <nil> <nil> true [0xc42000e620 0xc42000efd0 0xc42000efe8] [0xc42000e620 0xc42000efd0 0xc42000efe8] [0xc42000e650 0xc42000efe0] [0x94d8e0 0x94d8e0] 0xc421f15e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:54:54.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:54:54.894: INFO: rc: 1
May 21 10:54:54.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220c39b0 exit status 1 <nil> <nil> true [0xc420085890 0xc4200858a8 0xc4200858c0] [0xc420085890 0xc4200858a8 0xc4200858c0] [0xc4200858a0 0xc4200858b8] [0x94d8e0 0x94d8e0] 0xc421a1e900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 21 10:55:04.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-f62jh ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 10:55:05.074: INFO: rc: 1
May 21 10:55:05.074: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
May 21 10:55:05.074: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 21 10:55:05.100: INFO: Deleting all statefulset in ns e2e-tests-statefulset-f62jh
May 21 10:55:05.104: INFO: Scaling statefulset ss to 0
May 21 10:55:05.121: INFO: Waiting for statefulset status.replicas updated to 0
May 21 10:55:05.125: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:55:05.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-f62jh" for this suite.
May 21 10:55:11.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:55:11.236: INFO: namespace: e2e-tests-statefulset-f62jh, resource: bindings, ignored listing per whitelist
May 21 10:55:11.348: INFO: namespace e2e-tests-statefulset-f62jh deletion completed in 6.195915472s

• [SLOW TEST:374.377 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:55:11.348: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:55:11.390251      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:55:11.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-mqqgr" to be "success or failure"
May 21 10:55:11.460: INFO: Pod "downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.993365ms
May 21 10:55:13.466: INFO: Pod "downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012644862s
STEP: Saw pod success
May 21 10:55:13.466: INFO: Pod "downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:55:13.471: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:55:13.508: INFO: Waiting for pod downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:55:13.521: INFO: Pod downwardapi-volume-6f020d6c-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:55:13.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mqqgr" for this suite.
May 21 10:55:19.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:55:19.765: INFO: namespace: e2e-tests-projected-mqqgr, resource: bindings, ignored listing per whitelist
May 21 10:55:19.835: INFO: namespace e2e-tests-projected-mqqgr deletion completed in 6.305442464s

• [SLOW TEST:8.487 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:55:19.835: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:55:19.875094      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir volume type on tmpfs
May 21 10:55:19.970: INFO: Waiting up to 5m0s for pod "pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-6x4kc" to be "success or failure"
May 21 10:55:19.981: INFO: Pod "pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.008579ms
May 21 10:55:21.988: INFO: Pod "pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018496869s
May 21 10:55:23.994: INFO: Pod "pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024295551s
STEP: Saw pod success
May 21 10:55:23.994: INFO: Pod "pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:55:23.997: INFO: Trying to get logs from node master-192.168.130.3 pod pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:55:24.025: INFO: Waiting for pod pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:55:24.029: INFO: Pod pod-74133b1d-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:55:24.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6x4kc" for this suite.
May 21 10:55:30.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:55:30.222: INFO: namespace: e2e-tests-emptydir-6x4kc, resource: bindings, ignored listing per whitelist
May 21 10:55:30.225: INFO: namespace e2e-tests-emptydir-6x4kc deletion completed in 6.191039722s

• [SLOW TEST:10.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:55:30.227: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:55:30.272514      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap e2e-tests-configmap-n6xxj/configmap-test-7a407c4b-5ce5-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:55:30.323: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-n6xxj" to be "success or failure"
May 21 10:55:30.328: INFO: Pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.364551ms
May 21 10:55:32.332: INFO: Pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00912787s
May 21 10:55:34.337: INFO: Pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014043881s
May 21 10:55:36.346: INFO: Pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022620455s
May 21 10:55:38.355: INFO: Pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.031897013s
STEP: Saw pod success
May 21 10:55:38.355: INFO: Pod "pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:55:38.358: INFO: Trying to get logs from node master-192.168.130.3 pod pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b container env-test: <nil>
STEP: delete the pod
May 21 10:55:38.394: INFO: Waiting for pod pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:55:38.399: INFO: Pod pod-configmaps-7a413629-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:55:38.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n6xxj" for this suite.
May 21 10:55:44.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:55:44.558: INFO: namespace: e2e-tests-configmap-n6xxj, resource: bindings, ignored listing per whitelist
May 21 10:55:44.624: INFO: namespace e2e-tests-configmap-n6xxj deletion completed in 6.215982426s

• [SLOW TEST:14.397 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:55:44.624: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:55:44.675016      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:55:44.773: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-nxmg2" to be "success or failure"
May 21 10:55:44.778: INFO: Pod "downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.908932ms
May 21 10:55:46.783: INFO: Pod "downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010395312s
STEP: Saw pod success
May 21 10:55:46.783: INFO: Pod "downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:55:46.790: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:55:46.843: INFO: Waiting for pod downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:55:46.848: INFO: Pod downwardapi-volume-82ddb571-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:55:46.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nxmg2" for this suite.
May 21 10:55:52.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:55:52.976: INFO: namespace: e2e-tests-downward-api-nxmg2, resource: bindings, ignored listing per whitelist
May 21 10:55:53.045: INFO: namespace e2e-tests-downward-api-nxmg2 deletion completed in 6.192174337s

• [SLOW TEST:8.421 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:55:53.046: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:55:53.085000      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 10:55:53.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-downward-api-hkvm2" to be "success or failure"
May 21 10:55:53.179: INFO: Pod "downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.568406ms
May 21 10:55:55.183: INFO: Pod "downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006649551s
STEP: Saw pod success
May 21 10:55:55.183: INFO: Pod "downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:55:55.186: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 10:55:55.213: INFO: Waiting for pod downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:55:55.217: INFO: Pod downwardapi-volume-87dfeb18-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:55:55.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hkvm2" for this suite.
May 21 10:56:01.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:56:01.397: INFO: namespace: e2e-tests-downward-api-hkvm2, resource: bindings, ignored listing per whitelist
May 21 10:56:01.430: INFO: namespace e2e-tests-downward-api-hkvm2 deletion completed in 6.205005083s

• [SLOW TEST:8.385 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:56:01.430: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:56:01.472456      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-8cd997a5-5ce5-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 10:56:01.527: INFO: Waiting up to 5m0s for pod "pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-5nnrb" to be "success or failure"
May 21 10:56:01.535: INFO: Pod "pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.180467ms
May 21 10:56:03.545: INFO: Pod "pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018006132s
STEP: Saw pod success
May 21 10:56:03.545: INFO: Pod "pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:56:03.549: INFO: Trying to get logs from node master-192.168.130.3 pod pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 10:56:03.574: INFO: Waiting for pod pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:56:03.580: INFO: Pod pod-configmaps-8cda781f-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:56:03.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5nnrb" for this suite.
May 21 10:56:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:56:09.680: INFO: namespace: e2e-tests-configmap-5nnrb, resource: bindings, ignored listing per whitelist
May 21 10:56:09.777: INFO: namespace e2e-tests-configmap-5nnrb deletion completed in 6.190427224s

• [SLOW TEST:8.346 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:56:09.777: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:56:09.820777      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-d4sbq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 10:56:09.869: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 10:56:34.020: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.64.207:8080/dial?request=hostName&protocol=http&host=192.168.66.130&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-d4sbq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:56:34.020: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:56:34.190: INFO: Waiting for endpoints: map[]
May 21 10:56:34.193: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.64.207:8080/dial?request=hostName&protocol=http&host=192.168.67.149&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-d4sbq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:56:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:56:34.299: INFO: Waiting for endpoints: map[]
May 21 10:56:34.302: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.64.207:8080/dial?request=hostName&protocol=http&host=192.168.68.153&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-d4sbq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:56:34.302: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:56:34.423: INFO: Waiting for endpoints: map[]
May 21 10:56:34.435: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.64.207:8080/dial?request=hostName&protocol=http&host=192.168.65.145&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-d4sbq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:56:34.435: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:56:34.543: INFO: Waiting for endpoints: map[]
May 21 10:56:34.546: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.64.207:8080/dial?request=hostName&protocol=http&host=192.168.64.206&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-d4sbq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:56:34.546: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:56:34.645: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:56:34.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-d4sbq" for this suite.
May 21 10:56:58.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:56:58.843: INFO: namespace: e2e-tests-pod-network-test-d4sbq, resource: bindings, ignored listing per whitelist
May 21 10:56:58.885: INFO: namespace e2e-tests-pod-network-test-d4sbq deletion completed in 24.233926672s

• [SLOW TEST:49.108 seconds]
[sig-network] Networking
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http  [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:56:58.885: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:56:58.942179      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:57:59.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gk8jv" for this suite.
May 21 10:58:21.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:58:21.141: INFO: namespace: e2e-tests-container-probe-gk8jv, resource: bindings, ignored listing per whitelist
May 21 10:58:21.209: INFO: namespace e2e-tests-container-probe-gk8jv deletion completed in 22.196407549s

• [SLOW TEST:82.324 seconds]
[k8s.io] Probing container
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  with readiness probe that fails should never be ready and never restart  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:58:21.210: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:58:21.258315      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 10:58:21.313: INFO: Waiting up to 5m0s for pod "pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-l7w77" to be "success or failure"
May 21 10:58:21.316: INFO: Pod "pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.695911ms
May 21 10:58:23.320: INFO: Pod "pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007046942s
May 21 10:58:25.324: INFO: Pod "pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0114547s
STEP: Saw pod success
May 21 10:58:25.325: INFO: Pod "pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:58:25.327: INFO: Trying to get logs from node master-192.168.130.3 pod pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 10:58:25.347: INFO: Waiting for pod pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:58:25.353: INFO: Pod pod-e02c5e12-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:58:25.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l7w77" for this suite.
May 21 10:58:31.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:58:31.545: INFO: namespace: e2e-tests-emptydir-l7w77, resource: bindings, ignored listing per whitelist
May 21 10:58:31.587: INFO: namespace e2e-tests-emptydir-l7w77 deletion completed in 6.223760239s

• [SLOW TEST:10.377 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:58:31.587: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:58:31.631121      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name projected-secret-test-e65b44a1-5ce5-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 10:58:31.708: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-67gmq" to be "success or failure"
May 21 10:58:31.711: INFO: Pod "pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.66633ms
May 21 10:58:33.716: INFO: Pod "pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007168455s
May 21 10:58:35.728: INFO: Pod "pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019244212s
STEP: Saw pod success
May 21 10:58:35.728: INFO: Pod "pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 10:58:35.732: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 10:58:35.766: INFO: Waiting for pod pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b to disappear
May 21 10:58:35.773: INFO: Pod pod-projected-secrets-e65cb534-5ce5-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:58:35.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-67gmq" for this suite.
May 21 10:58:41.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:58:41.920: INFO: namespace: e2e-tests-projected-67gmq, resource: bindings, ignored listing per whitelist
May 21 10:58:41.977: INFO: namespace e2e-tests-projected-67gmq deletion completed in 6.198487588s

• [SLOW TEST:10.390 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:58:41.977: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:58:42.014153      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 21 10:58:46.173: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5l7v PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:58:46.174: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:58:46.270: INFO: Exec stderr: ""
May 21 10:58:46.270: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5l7v PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:58:46.270: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:58:46.359: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 21 10:58:46.359: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5l7v PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:58:46.359: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:58:46.445: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 21 10:58:46.445: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5l7v PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:58:46.445: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:58:46.552: INFO: Exec stderr: ""
May 21 10:58:46.552: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5l7v PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 10:58:46.552: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
May 21 10:58:46.649: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 10:58:46.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-q5l7v" for this suite.
May 21 10:59:40.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 10:59:40.826: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-q5l7v, resource: bindings, ignored listing per whitelist
May 21 10:59:40.856: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-q5l7v deletion completed in 54.200666816s

• [SLOW TEST:58.879 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should test kubelet managed /etc/hosts file  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 10:59:40.857: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 10:59:40.916082      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-h9hqh
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a new StatefulSet
May 21 10:59:40.981: INFO: Found 0 stateful pods, waiting for 3
May 21 10:59:50.987: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:59:50.987: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:59:50.987: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 21 10:59:51.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-h9hqh ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 10:59:51.358: INFO: stderr: ""
May 21 10:59:51.358: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
May 21 11:00:01.480: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 21 11:00:11.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-h9hqh ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 11:00:11.984: INFO: stderr: ""
May 21 11:00:11.984: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 11:00:32.010: INFO: Waiting for StatefulSet e2e-tests-statefulset-h9hqh/ss2 to complete update
May 21 11:00:32.010: INFO: Waiting for Pod e2e-tests-statefulset-h9hqh/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Rolling back to a previous revision
May 21 11:00:42.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-h9hqh ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 11:00:42.402: INFO: stderr: ""
May 21 11:00:42.402: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 11:00:52.460: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 21 11:01:02.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-252039709 exec --namespace=e2e-tests-statefulset-h9hqh ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 11:01:02.878: INFO: stderr: ""
May 21 11:01:02.878: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 11:01:12.908: INFO: Waiting for StatefulSet e2e-tests-statefulset-h9hqh/ss2 to complete update
May 21 11:01:12.908: INFO: Waiting for Pod e2e-tests-statefulset-h9hqh/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
May 21 11:01:12.908: INFO: Waiting for Pod e2e-tests-statefulset-h9hqh/ss2-1 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
May 21 11:01:12.908: INFO: Waiting for Pod e2e-tests-statefulset-h9hqh/ss2-2 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
May 21 11:01:22.917: INFO: Waiting for StatefulSet e2e-tests-statefulset-h9hqh/ss2 to complete update
May 21 11:01:22.917: INFO: Waiting for Pod e2e-tests-statefulset-h9hqh/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
May 21 11:01:22.917: INFO: Waiting for Pod e2e-tests-statefulset-h9hqh/ss2-1 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 21 11:01:32.925: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h9hqh
May 21 11:01:32.932: INFO: Scaling statefulset ss2 to 0
May 21 11:01:52.975: INFO: Waiting for statefulset status.replicas updated to 0
May 21 11:01:52.980: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:01:53.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h9hqh" for this suite.
May 21 11:01:59.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:01:59.204: INFO: namespace: e2e-tests-statefulset-h9hqh, resource: bindings, ignored listing per whitelist
May 21 11:01:59.204: INFO: namespace e2e-tests-statefulset-h9hqh deletion completed in 6.188223856s

• [SLOW TEST:138.347 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:01:59.205: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:01:59.250439      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-map-621a9f5c-5ce6-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 11:01:59.306: INFO: Waiting up to 5m0s for pod "pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-x9jlw" to be "success or failure"
May 21 11:01:59.312: INFO: Pod "pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.713957ms
May 21 11:02:01.317: INFO: Pod "pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011383989s
STEP: Saw pod success
May 21 11:02:01.317: INFO: Pod "pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:02:01.321: INFO: Trying to get logs from node master-192.168.130.3 pod pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 11:02:01.351: INFO: Waiting for pod pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:02:01.356: INFO: Pod pod-secrets-621b3583-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:01.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x9jlw" for this suite.
May 21 11:02:07.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:02:07.525: INFO: namespace: e2e-tests-secrets-x9jlw, resource: bindings, ignored listing per whitelist
May 21 11:02:07.554: INFO: namespace e2e-tests-secrets-x9jlw deletion completed in 6.191021229s

• [SLOW TEST:8.350 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:02:07.555: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:02:07.600000      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating projection with secret that has name projected-secret-test-67146115-5ce6-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 11:02:07.656: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-d59d5" to be "success or failure"
May 21 11:02:07.659: INFO: Pod "pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.974103ms
May 21 11:02:09.663: INFO: Pod "pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006973975s
STEP: Saw pod success
May 21 11:02:09.663: INFO: Pod "pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:02:09.667: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 11:02:09.712: INFO: Waiting for pod pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:02:09.716: INFO: Pod pod-projected-secrets-67151e1a-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d59d5" for this suite.
May 21 11:02:15.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:02:15.861: INFO: namespace: e2e-tests-projected-d59d5, resource: bindings, ignored listing per whitelist
May 21 11:02:15.922: INFO: namespace e2e-tests-projected-d59d5 deletion completed in 6.199497826s

• [SLOW TEST:8.367 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:02:15.922: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:02:15.965746      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating secret with name secret-test-6c1377ea-5ce6-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 11:02:16.037: INFO: Waiting up to 5m0s for pod "pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-secrets-w68r4" to be "success or failure"
May 21 11:02:16.041: INFO: Pod "pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.528364ms
May 21 11:02:18.046: INFO: Pod "pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008880954s
STEP: Saw pod success
May 21 11:02:18.046: INFO: Pod "pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:02:18.049: INFO: Trying to get logs from node master-192.168.130.3 pod pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b container secret-volume-test: <nil>
STEP: delete the pod
May 21 11:02:18.075: INFO: Waiting for pod pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:02:18.079: INFO: Pod pod-secrets-6c142f94-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:18.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w68r4" for this suite.
May 21 11:02:24.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:02:24.285: INFO: namespace: e2e-tests-secrets-w68r4, resource: bindings, ignored listing per whitelist
May 21 11:02:24.296: INFO: namespace e2e-tests-secrets-w68r4 deletion completed in 6.211849431s

• [SLOW TEST:8.374 seconds]
[sig-storage] Secrets
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:02:24.296: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:02:24.343992      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 11:02:24.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-qqwds" to be "success or failure"
May 21 11:02:24.399: INFO: Pod "downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.196123ms
May 21 11:02:26.406: INFO: Pod "downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009973014s
STEP: Saw pod success
May 21 11:02:26.406: INFO: Pod "downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:02:26.410: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 11:02:26.437: INFO: Waiting for pod downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:02:26.449: INFO: Pod downwardapi-volume-710f9665-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:26.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qqwds" for this suite.
May 21 11:02:32.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:02:32.521: INFO: namespace: e2e-tests-projected-qqwds, resource: bindings, ignored listing per whitelist
May 21 11:02:32.645: INFO: namespace e2e-tests-projected-qqwds deletion completed in 6.190870358s

• [SLOW TEST:8.349 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:02:32.645: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:02:32.698638      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating projection with secret that has name projected-secret-test-map-760ad295-5ce6-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 11:02:32.760: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-rmfl8" to be "success or failure"
May 21 11:02:32.764: INFO: Pod "pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.148241ms
May 21 11:02:34.769: INFO: Pod "pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008593662s
STEP: Saw pod success
May 21 11:02:34.769: INFO: Pod "pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:02:34.774: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 11:02:34.797: INFO: Waiting for pod pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:02:34.802: INFO: Pod pod-projected-secrets-760b7541-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:34.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rmfl8" for this suite.
May 21 11:02:40.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:02:40.869: INFO: namespace: e2e-tests-projected-rmfl8, resource: bindings, ignored listing per whitelist
May 21 11:02:41.014: INFO: namespace e2e-tests-projected-rmfl8 deletion completed in 6.205686297s

• [SLOW TEST:8.369 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
[sig-storage] Projected 
  should set mode on item file [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:02:41.014: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:02:41.075910      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test downward API volume plugin
May 21 11:02:41.141: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-kzmcm" to be "success or failure"
May 21 11:02:41.146: INFO: Pod "downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.706435ms
May 21 11:02:43.152: INFO: Pod "downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011036407s
STEP: Saw pod success
May 21 11:02:43.152: INFO: Pod "downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:02:43.155: INFO: Trying to get logs from node master-192.168.130.3 pod downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b container client-container: <nil>
STEP: delete the pod
May 21 11:02:43.186: INFO: Waiting for pod downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:02:43.190: INFO: Pod downwardapi-volume-7b09a998-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:43.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kzmcm" for this suite.
May 21 11:02:49.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:02:49.384: INFO: namespace: e2e-tests-projected-kzmcm, resource: bindings, ignored listing per whitelist
May 21 11:02:49.426: INFO: namespace e2e-tests-projected-kzmcm deletion completed in 6.229288039s

• [SLOW TEST:8.411 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:02:49.426: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:02:49.473197      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
May 21 11:02:49.562: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"800db687-5ce6-11e8-ba59-5254000207f9", Controller:(*bool)(0xc421b86dc6), BlockOwnerDeletion:(*bool)(0xc421b86dc7)}}
May 21 11:02:49.571: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"800b924d-5ce6-11e8-ba59-5254000207f9", Controller:(*bool)(0xc421b29a22), BlockOwnerDeletion:(*bool)(0xc421b29a23)}}
May 21 11:02:49.579: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"800c633a-5ce6-11e8-ba59-5254000207f9", Controller:(*bool)(0xc421fe5f0e), BlockOwnerDeletion:(*bool)(0xc421fe5f0f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:02:54.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ggrpj" for this suite.
May 21 11:03:00.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:03:00.809: INFO: namespace: e2e-tests-gc-ggrpj, resource: bindings, ignored listing per whitelist
May 21 11:03:00.826: INFO: namespace e2e-tests-gc-ggrpj deletion completed in 6.228031072s

• [SLOW TEST:11.400 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:03:00.826: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:03:00.880313      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: creating pod
May 21 11:03:02.989: INFO: Pod pod-hostip-86dc0d96-5ce6-11e8-8768-12f5d52dbf0b has hostIP: 192.168.130.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:03:02.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4c7wz" for this suite.
May 21 11:03:25.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:03:25.118: INFO: namespace: e2e-tests-pods-4c7wz, resource: bindings, ignored listing per whitelist
May 21 11:03:25.176: INFO: namespace e2e-tests-pods-4c7wz deletion completed in 22.180008966s

• [SLOW TEST:24.350 seconds]
[k8s.io] Pods
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
  should get a host IP  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:03:25.176: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:03:25.230207      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating projection with secret that has name projected-secret-test-955b919a-5ce6-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume secrets
May 21 11:03:25.296: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-projected-8mgb8" to be "success or failure"
May 21 11:03:25.304: INFO: Pod "pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.426956ms
May 21 11:03:27.309: INFO: Pod "pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012961821s
STEP: Saw pod success
May 21 11:03:27.309: INFO: Pod "pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:03:27.311: INFO: Trying to get logs from node master-192.168.130.3 pod pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 11:03:27.341: INFO: Waiting for pod pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:03:27.346: INFO: Pod pod-projected-secrets-955c563c-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:03:27.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8mgb8" for this suite.
May 21 11:03:33.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:03:33.407: INFO: namespace: e2e-tests-projected-8mgb8, resource: bindings, ignored listing per whitelist
May 21 11:03:33.541: INFO: namespace e2e-tests-projected-8mgb8 deletion completed in 6.188271663s

• [SLOW TEST:8.365 seconds]
[sig-storage] Projected
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:03:33.541: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:03:33.587989      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 11:03:33.665: INFO: Waiting up to 5m0s for pod "pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-8km9m" to be "success or failure"
May 21 11:03:33.669: INFO: Pod "pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127052ms
May 21 11:03:35.674: INFO: Pod "pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008643648s
STEP: Saw pod success
May 21 11:03:35.674: INFO: Pod "pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:03:35.677: INFO: Trying to get logs from node master-192.168.130.3 pod pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 11:03:35.702: INFO: Waiting for pod pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:03:35.707: INFO: Pod pod-9a5800d5-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:03:35.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8km9m" for this suite.
May 21 11:03:41.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:03:41.778: INFO: namespace: e2e-tests-emptydir-8km9m, resource: bindings, ignored listing per whitelist
May 21 11:03:41.893: INFO: namespace e2e-tests-emptydir-8km9m deletion completed in 6.179393387s

• [SLOW TEST:8.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:03:41.893: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:03:41.932498      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 11:03:41.992: INFO: Waiting up to 5m0s for pod "pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-qr9d7" to be "success or failure"
May 21 11:03:41.996: INFO: Pod "pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.134788ms
May 21 11:03:44.006: INFO: Pod "pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011730325s
May 21 11:03:46.016: INFO: Pod "pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021488577s
STEP: Saw pod success
May 21 11:03:46.016: INFO: Pod "pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:03:46.019: INFO: Trying to get logs from node master-192.168.130.3 pod pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 11:03:46.045: INFO: Waiting for pod pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:03:46.050: INFO: Pod pod-9f5016b6-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:03:46.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qr9d7" for this suite.
May 21 11:03:52.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:03:52.158: INFO: namespace: e2e-tests-emptydir-qr9d7, resource: bindings, ignored listing per whitelist
May 21 11:03:52.261: INFO: namespace e2e-tests-emptydir-qr9d7 deletion completed in 6.204696855s

• [SLOW TEST:10.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:03:52.261: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:03:52.308714      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0521 11:04:02.418076      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 11:04:02.418: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:04:02.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zxz65" for this suite.
May 21 11:04:08.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:04:08.523: INFO: namespace: e2e-tests-gc-zxz65, resource: bindings, ignored listing per whitelist
May 21 11:04:08.680: INFO: namespace e2e-tests-gc-zxz65 deletion completed in 6.247883999s

• [SLOW TEST:16.419 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:04:08.681: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:04:08.731236      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating configMap with name configmap-test-volume-af4b1ee9-5ce6-11e8-8768-12f5d52dbf0b
STEP: Creating a pod to test consume configMaps
May 21 11:04:08.808: INFO: Waiting up to 5m0s for pod "pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-configmap-p899k" to be "success or failure"
May 21 11:04:08.812: INFO: Pod "pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.354735ms
May 21 11:04:10.817: INFO: Pod "pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008716537s
STEP: Saw pod success
May 21 11:04:10.817: INFO: Pod "pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:04:10.821: INFO: Trying to get logs from node master-192.168.130.3 pod pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b container configmap-volume-test: <nil>
STEP: delete the pod
May 21 11:04:10.846: INFO: Waiting for pod pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:04:10.852: INFO: Pod pod-configmaps-af4bdaa9-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:04:10.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p899k" for this suite.
May 21 11:04:16.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:04:16.992: INFO: namespace: e2e-tests-configmap-p899k, resource: bindings, ignored listing per whitelist
May 21 11:04:17.059: INFO: namespace e2e-tests-configmap-p899k deletion completed in 6.201440743s

• [SLOW TEST:8.378 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:04:17.059: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:04:17.100096      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating the pod
May 21 11:04:19.698: INFO: Successfully updated pod "annotationupdateb4457174-5ce6-11e8-8768-12f5d52dbf0b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:04:21.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9dzsl" for this suite.
May 21 11:04:43.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:04:43.946: INFO: namespace: e2e-tests-downward-api-9dzsl, resource: bindings, ignored listing per whitelist
May 21 11:04:43.995: INFO: namespace e2e-tests-downward-api-9dzsl deletion completed in 22.267070462s

• [SLOW TEST:26.936 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification  [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:04:43.995: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:04:44.057812      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 11:04:44.132: INFO: Waiting up to 5m0s for pod "pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-s586f" to be "success or failure"
May 21 11:04:44.139: INFO: Pod "pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.348171ms
May 21 11:04:46.149: INFO: Pod "pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016583422s
STEP: Saw pod success
May 21 11:04:46.149: INFO: Pod "pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:04:46.152: INFO: Trying to get logs from node master-192.168.130.3 pod pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 11:04:46.175: INFO: Waiting for pod pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:04:46.181: INFO: Pod pod-c4592ed0-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:04:46.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s586f" for this suite.
May 21 11:04:52.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:04:52.386: INFO: namespace: e2e-tests-emptydir-s586f, resource: bindings, ignored listing per whitelist
May 21 11:04:52.397: INFO: namespace e2e-tests-emptydir-s586f deletion completed in 6.210079272s

• [SLOW TEST:8.401 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:04:52.397: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:04:52.488769      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-4cdv9
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-4cdv9
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-4cdv9
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-4cdv9
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-4cdv9
May 21 11:04:56.693: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4cdv9, name: ss-0, uid: cb03ba7c-5ce6-11e8-ba59-5254000207f9, status phase: Pending. Waiting for statefulset controller to delete.
May 21 11:04:56.885: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4cdv9, name: ss-0, uid: cb03ba7c-5ce6-11e8-ba59-5254000207f9, status phase: Failed. Waiting for statefulset controller to delete.
May 21 11:04:56.893: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4cdv9, name: ss-0, uid: cb03ba7c-5ce6-11e8-ba59-5254000207f9, status phase: Failed. Waiting for statefulset controller to delete.
May 21 11:04:56.897: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-4cdv9
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-4cdv9
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-4cdv9 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 21 11:05:00.951: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4cdv9
May 21 11:05:00.954: INFO: Scaling statefulset ss to 0
May 21 11:05:20.973: INFO: Waiting for statefulset status.replicas updated to 0
May 21 11:05:20.977: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:05:20.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4cdv9" for this suite.
May 21 11:05:27.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:05:27.133: INFO: namespace: e2e-tests-statefulset-4cdv9, resource: bindings, ignored listing per whitelist
May 21 11:05:27.209: INFO: namespace e2e-tests-statefulset-4cdv9 deletion completed in 6.204923112s

• [SLOW TEST:34.813 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:669
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 21 11:05:27.210: INFO: >>> kubeConfig: /tmp/kubeconfig-252039709
E0521 11:05:27.247062      15 memcache.go:153] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 11:05:27.307: INFO: Waiting up to 5m0s for pod "pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b" in namespace "e2e-tests-emptydir-689wk" to be "success or failure"
May 21 11:05:27.311: INFO: Pod "pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.882895ms
May 21 11:05:29.315: INFO: Pod "pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008132992s
STEP: Saw pod success
May 21 11:05:29.315: INFO: Pod "pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b" satisfied condition "success or failure"
May 21 11:05:29.319: INFO: Trying to get logs from node master-192.168.130.3 pod pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b container test-container: <nil>
STEP: delete the pod
May 21 11:05:29.346: INFO: Waiting for pod pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b to disappear
May 21 11:05:29.351: INFO: Pod pod-de159f01-5ce6-11e8-8768-12f5d52dbf0b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 21 11:05:29.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-689wk" for this suite.
May 21 11:05:35.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 11:05:35.484: INFO: namespace: e2e-tests-emptydir-689wk, resource: bindings, ignored listing per whitelist
May 21 11:05:35.586: INFO: namespace e2e-tests-emptydir-689wk deletion completed in 6.226772388s

• [SLOW TEST:8.376 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [Conformance]
  /workspace/anago-v1.10.0-rc.1.9+fc32d2f3698e36/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:674
------------------------------
SSMay 21 11:05:35.586: INFO: Running AfterSuite actions on all node
May 21 11:05:35.586: INFO: Running AfterSuite actions on node 1
May 21 11:05:35.586: INFO: Skipping dumping logs from cluster

Ran 139 of 836 Specs in 3752.517 seconds
SUCCESS! -- 139 Passed | 0 Failed | 0 Pending | 697 Skipped PASS

Ginkgo ran 1 suite in 1h2m33.20559231s
Test Suite Passed
