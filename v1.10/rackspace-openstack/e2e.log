Jun 29 15:20:51.192: INFO: Overriding default scale value of zero to 1
Jun 29 15:20:51.192: INFO: Overriding default milliseconds value of zero to 5000
I0629 15:20:51.453259      17 test_context.go:382] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-092945569
I0629 15:20:51.453683      17 e2e.go:333] Starting e2e run "01e2cc05-7bb0-11e8-8ddd-da371e372fc2" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1530285650 - Will randomize all specs
Will run 144 of 998 specs

Jun 29 15:20:51.687: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:20:51.691: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun 29 15:20:51.731: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 29 15:20:51.832: INFO: 44 / 44 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 29 15:20:51.832: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Jun 29 15:20:51.846: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jun 29 15:20:51.846: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt
Jun 29 15:20:51.862: INFO: e2e test version: v1.11.0
Jun 29 15:20:51.865: INFO: kube-apiserver version: v1.10.5+rackspace.0
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:20:51.865: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
Jun 29 15:20:52.017: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jun 29 15:20:52.034: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-98vms
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-98vms.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-98vms.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-98vms.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-98vms.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-98vms.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-98vms.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 29 15:21:08.380: INFO: DNS probes using dns-test-02855a4c-7bb0-11e8-8ddd-da371e372fc2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:21:08.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-98vms" for this suite.
Jun 29 15:21:14.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:21:14.567: INFO: namespace: e2e-tests-dns-98vms, resource: bindings, ignored listing per whitelist
Jun 29 15:21:14.701: INFO: namespace e2e-tests-dns-98vms deletion completed in 6.273558801s

â€¢ [SLOW TEST:22.836 seconds]
[sig-network] DNS
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:21:14.702: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-9hbfx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 29 15:21:15.005: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:15.005: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:15.005: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:15.011: INFO: Number of nodes with available pods: 0
Jun 29 15:21:15.011: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:21:16.020: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:16.020: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:16.020: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:16.027: INFO: Number of nodes with available pods: 0
Jun 29 15:21:16.027: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:21:17.022: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:17.022: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:17.023: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:17.030: INFO: Number of nodes with available pods: 0
Jun 29 15:21:17.030: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:21:18.029: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:18.029: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:18.029: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:18.037: INFO: Number of nodes with available pods: 3
Jun 29 15:21:18.037: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun 29 15:21:18.069: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:18.069: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:18.069: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:18.077: INFO: Number of nodes with available pods: 2
Jun 29 15:21:18.078: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:21:19.097: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:19.097: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:19.098: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:19.104: INFO: Number of nodes with available pods: 2
Jun 29 15:21:19.104: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:21:20.092: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:20.092: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:20.092: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:20.100: INFO: Number of nodes with available pods: 2
Jun 29 15:21:20.100: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:21:21.091: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:21.091: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:21.091: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:21.098: INFO: Number of nodes with available pods: 2
Jun 29 15:21:21.098: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:21:22.089: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:22.090: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:22.090: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:22.098: INFO: Number of nodes with available pods: 2
Jun 29 15:21:22.098: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:21:23.093: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:23.093: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:23.093: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:23.100: INFO: Number of nodes with available pods: 2
Jun 29 15:21:23.100: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:21:24.089: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:24.090: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:24.090: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:21:24.136: INFO: Number of nodes with available pods: 3
Jun 29 15:21:24.136: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9hbfx, will wait for the garbage collector to delete the pods
Jun 29 15:21:24.225: INFO: Deleting {extensions DaemonSet} daemon-set took: 19.948881ms
Jun 29 15:21:24.325: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.213845ms
Jun 29 15:21:38.772: INFO: Number of nodes with available pods: 0
Jun 29 15:21:38.772: INFO: Number of running nodes: 0, number of available pods: 0
Jun 29 15:21:38.790: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9hbfx/daemonsets","resourceVersion":"160273"},"items":null}

Jun 29 15:21:38.797: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9hbfx/pods","resourceVersion":"160273"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:21:38.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9hbfx" for this suite.
Jun 29 15:21:44.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:21:45.004: INFO: namespace: e2e-tests-daemonsets-9hbfx, resource: bindings, ignored listing per whitelist
Jun 29 15:21:45.093: INFO: namespace e2e-tests-daemonsets-9hbfx deletion completed in 6.256279299s

â€¢ [SLOW TEST:30.392 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:21:45.096: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-j6lqp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-223c31a6-7bb0-11e8-8ddd-da371e372fc2,GenerateName:,Namespace:e2e-tests-events-j6lqp,SelfLink:/api/v1/namespaces/e2e-tests-events-j6lqp/pods/send-events-223c31a6-7bb0-11e8-8ddd-da371e372fc2,UID:22469e6b-7bb0-11e8-b9b2-fa163ec8ddce,ResourceVersion:160333,Generation:0,CreationTimestamp:2018-06-29 15:21:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 363095056,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v26hm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v26hm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-v26hm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kubernetes-lblackstone-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215fefc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215fefe0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 15:21:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 15:21:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 15:21:48 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.8,PodIP:10.2.5.57,StartTime:2018-06-29 15:21:45 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-06-29 15:21:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 docker://8e5e2ccf5a39473aecc3fc53d292db8ddefdb0a96bc950328b26cdaf2e3d4043}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:21:51.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-j6lqp" for this suite.
Jun 29 15:21:57.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:21:57.555: INFO: namespace: e2e-tests-events-j6lqp, resource: bindings, ignored listing per whitelist
Jun 29 15:21:57.687: INFO: namespace e2e-tests-events-j6lqp deletion completed in 6.24077703s

â€¢ [SLOW TEST:12.591 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:21:57.687: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-pdnpt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-pdnpt;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-pdnpt;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-pdnpt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 159.62.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.62.159_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 159.62.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.62.159_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-pdnpt;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-pdnpt;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-pdnpt.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-pdnpt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-pdnpt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 159.62.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.62.159_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 159.62.3.10.in-addr.arpa. PTR)" && echo OK > /results/10.3.62.159_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 29 15:22:10.288: INFO: DNS probes using dns-test-29c3b7a1-7bb0-11e8-8ddd-da371e372fc2 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:22:10.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-pdnpt" for this suite.
Jun 29 15:22:16.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:22:16.570: INFO: namespace: e2e-tests-dns-pdnpt, resource: bindings, ignored listing per whitelist
Jun 29 15:22:16.699: INFO: namespace e2e-tests-dns-pdnpt deletion completed in 6.285792061s

â€¢ [SLOW TEST:19.012 seconds]
[sig-network] DNS
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:22:16.699: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t7r47
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun 29 15:22:17.016: INFO: Waiting up to 5m0s for pod "pod-35144727-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-t7r47" to be "success or failure"
Jun 29 15:22:17.041: INFO: Pod "pod-35144727-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.512322ms
Jun 29 15:22:19.050: INFO: Pod "pod-35144727-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033814255s
Jun 29 15:22:21.066: INFO: Pod "pod-35144727-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050135215s
STEP: Saw pod success
Jun 29 15:22:21.066: INFO: Pod "pod-35144727-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:22:21.071: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-35144727-7bb0-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:22:21.104: INFO: Waiting for pod pod-35144727-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:22:21.110: INFO: Pod pod-35144727-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:22:21.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t7r47" for this suite.
Jun 29 15:22:27.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:22:27.178: INFO: namespace: e2e-tests-emptydir-t7r47, resource: bindings, ignored listing per whitelist
Jun 29 15:22:27.395: INFO: namespace e2e-tests-emptydir-t7r47 deletion completed in 6.273143973s

â€¢ [SLOW TEST:10.696 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:22:27.400: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x7h97
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 29 15:22:27.706: INFO: Waiting up to 5m0s for pod "pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-x7h97" to be "success or failure"
Jun 29 15:22:27.731: INFO: Pod "pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.406609ms
Jun 29 15:22:29.740: INFO: Pod "pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034012782s
Jun 29 15:22:31.772: INFO: Pod "pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065725541s
STEP: Saw pod success
Jun 29 15:22:31.772: INFO: Pod "pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:22:31.778: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:22:31.809: INFO: Waiting for pod pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:22:31.840: INFO: Pod pod-3b76f4d3-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:22:31.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x7h97" for this suite.
Jun 29 15:22:37.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:22:38.011: INFO: namespace: e2e-tests-emptydir-x7h97, resource: bindings, ignored listing per whitelist
Jun 29 15:22:38.073: INFO: namespace e2e-tests-emptydir-x7h97 deletion completed in 6.223028062s

â€¢ [SLOW TEST:10.673 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:22:38.075: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-cgv4j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
Jun 29 15:22:38.321: INFO: Waiting up to 5m0s for pod "client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-containers-cgv4j" to be "success or failure"
Jun 29 15:22:38.327: INFO: Pod "client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.103281ms
Jun 29 15:22:40.337: INFO: Pod "client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016492611s
STEP: Saw pod success
Jun 29 15:22:40.338: INFO: Pod "client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:22:40.344: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:22:40.417: INFO: Waiting for pod client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:22:40.425: INFO: Pod client-containers-41cad9e7-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:22:40.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cgv4j" for this suite.
Jun 29 15:22:46.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:22:46.646: INFO: namespace: e2e-tests-containers-cgv4j, resource: bindings, ignored listing per whitelist
Jun 29 15:22:46.709: INFO: namespace e2e-tests-containers-cgv4j deletion completed in 6.271568562s

â€¢ [SLOW TEST:8.634 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:22:46.710: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-7sxxn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 15:22:46.977: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
Jun 29 15:22:46.989: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7sxxn/daemonsets","resourceVersion":"160626"},"items":null}

Jun 29 15:22:46.996: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7sxxn/pods","resourceVersion":"160626"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:22:47.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7sxxn" for this suite.
Jun 29 15:22:53.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:22:53.156: INFO: namespace: e2e-tests-daemonsets-7sxxn, resource: bindings, ignored listing per whitelist
Jun 29 15:22:53.361: INFO: namespace e2e-tests-daemonsets-7sxxn deletion completed in 6.295786503s

S [SKIPPING] [6.652 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

  Jun 29 15:22:46.977: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:22:53.361: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-g5mm8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 29 15:22:53.623: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 29 15:23:53.716: INFO: Waiting for terminating namespaces to be deleted...
Jun 29 15:23:53.729: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 29 15:23:53.760: INFO: 44 / 44 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 29 15:23:53.760: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Jun 29 15:23:53.774: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jun 29 15:23:53.774: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-0 before test
Jun 29 15:23:53.791: INFO: registry-job-6ff94bb84c-wpc5v from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container registry-job ready: true, restart count 0
Jun 29 15:23:53.791: INFO: alertmanager-main-2 from rackspace-system started at 2018-06-28 20:54:44 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:23:53.791: INFO: kube-proxy-8qt66 from kube-system started at 2018-06-28 20:27:44 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:23:53.791: INFO: npd-v0.4.1-fq8q4 from kube-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:23:53.791: INFO: fluentd-es-9thgd from rackspace-system started at 2018-06-28 20:36:33 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:23:53.791: INFO: container-linux-update-agent-g2b29 from rackspace-system started at 2018-06-28 20:38:23 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container update-agent ready: true, restart count 2
Jun 29 15:23:53.791: INFO: alertmanager-main-1 from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:23:53.791: INFO: influxdb-545869c56c-ndhzm from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container influxdb ready: true, restart count 0
Jun 29 15:23:53.791: INFO: es-data-1 from rackspace-system started at 2018-06-28 20:53:43 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container es-data ready: false, restart count 133
Jun 29 15:23:53.791: INFO: prometheus-customer-1 from monitoring started at 2018-06-28 20:54:23 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:23:53.791: INFO: kube-calico-dhfwc from kube-system started at 2018-06-28 20:27:47 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:23:53.791: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:23:53.791: INFO: container-linux-update-operator-6df89667cb-4gwlh from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container update-operator ready: true, restart count 0
Jun 29 15:23:53.791: INFO: nginx-ingress-controller-7c7b8f746d-85lzp from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jun 29 15:23:53.791: INFO: prometheus-k8s-0 from rackspace-system started at 2018-06-28 20:54:20 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:23:53.791: INFO: prometheus-customer-0 from monitoring started at 2018-06-28 20:54:23 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:23:53.791: INFO: registry-nginx-5fcb7bcccf-ktgcl from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container registry-nginx ready: true, restart count 0
Jun 29 15:23:53.791: INFO: kube-flannel-6tj5j from kube-system started at 2018-06-28 20:27:44 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container kube-flannel ready: true, restart count 2
Jun 29 15:23:53.791: INFO: configure-oom-kn8s9 from rackspace-system started at 2018-06-28 20:32:19 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:23:53.791: INFO: node-exporter-z7p55 from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:23:53.791: INFO: default-http-backend-658c6856c5-vtlcw from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container default-http-backend ready: true, restart count 0
Jun 29 15:23:53.791: INFO: kube-state-metrics-8747876f4-2rt6h from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container addon-resizer ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jun 29 15:23:53.791: INFO: prometheus-operator-95bb8bdf9-wshj6 from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.791: INFO: 	Container prometheus-operator ready: true, restart count 0
Jun 29 15:23:53.791: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-1 before test
Jun 29 15:23:53.810: INFO: configure-oom-mbr5n from rackspace-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.810: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:23:53.811: INFO: grafana-0 from rackspace-system started at 2018-06-28 20:58:57 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.811: INFO: 	Container grafana ready: true, restart count 0
Jun 29 15:23:53.811: INFO: 	Container grafana-watcher ready: true, restart count 0
Jun 29 15:23:53.811: INFO: kube-proxy-js89r from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.811: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:23:53.811: INFO: nginx-ingress-controller-7c7b8f746d-vjnl6 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.811: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jun 29 15:23:53.811: INFO: registry-admin-645ff5ff77-svlgr from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.812: INFO: 	Container registry-admin ready: true, restart count 0
Jun 29 15:23:53.812: INFO: es-data-0 from rackspace-system started at 2018-06-28 20:59:09 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.812: INFO: 	Container es-data ready: false, restart count 139
Jun 29 15:23:53.812: INFO: kube-calico-w8x5n from kube-system started at 2018-06-28 20:27:48 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.812: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:23:53.812: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:23:53.812: INFO: registry-image-scan-postgres-0 from rackspace-system started at 2018-06-28 20:58:32 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.812: INFO: 	Container registry-image-scan-postgres ready: true, restart count 0
Jun 29 15:23:53.812: INFO: prometheus-k8s-1 from rackspace-system started at 2018-06-28 20:58:31 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.813: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:23:53.813: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:23:53.813: INFO: alertmanager-main-0 from rackspace-system started at 2018-06-28 20:58:53 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.813: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:23:53.813: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:23:53.813: INFO: kube-flannel-2rvmq from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.813: INFO: 	Container kube-flannel ready: true, restart count 3
Jun 29 15:23:53.813: INFO: npd-v0.4.1-59zdt from kube-system started at 2018-06-28 20:32:21 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.813: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:23:53.814: INFO: fluentd-es-b4p8v from rackspace-system started at 2018-06-28 20:36:34 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.814: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:23:53.814: INFO: node-exporter-6ktxl from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.814: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:23:53.814: INFO: elasticsearch-exporter-7449557bc-rtkgp from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.814: INFO: 	Container elasticsearch-exporter ready: true, restart count 0
Jun 29 15:23:53.814: INFO: kibana-54898499fb-mqdg8 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.814: INFO: 	Container kibana ready: false, restart count 0
Jun 29 15:23:53.814: INFO: heapster-55f9c7bcb7-p62lz from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.815: INFO: 	Container heapster ready: true, restart count 0
Jun 29 15:23:53.815: INFO: container-linux-update-agent-qfmnq from rackspace-system started at 2018-06-28 20:38:24 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.815: INFO: 	Container update-agent ready: true, restart count 3
Jun 29 15:23:53.815: INFO: kubernetes-dashboard-8f54b8b54-fs95w from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.815: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 29 15:23:53.815: INFO: registry-7758dd67d6-hn8bb from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.815: INFO: 	Container registry ready: true, restart count 0
Jun 29 15:23:53.815: INFO: 	Container registry-exporter ready: true, restart count 0
Jun 29 15:23:53.815: INFO: registry-ui-844884c845-bblj9 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.816: INFO: 	Container registry-ui ready: true, restart count 3
Jun 29 15:23:53.816: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-2 before test
Jun 29 15:23:53.833: INFO: es-data-2 from rackspace-system started at 2018-06-28 21:03:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container es-data ready: false, restart count 130
Jun 29 15:23:53.833: INFO: etcdsnapshot-1530230820-cgxrr from rackspace-system started at 2018-06-29 00:07:01 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container snapshot ready: false, restart count 0
Jun 29 15:23:53.833: INFO: kube-flannel-m5kl7 from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container kube-flannel ready: true, restart count 2
Jun 29 15:23:53.833: INFO: registry-image-scan-8576ff96b4-ccbw2 from rackspace-system started at 2018-06-28 21:03:08 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container registry-image-scan ready: true, restart count 0
Jun 29 15:23:53.833: INFO: registry-mysql-0 from rackspace-system started at 2018-06-28 21:03:08 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container registry-mysql ready: true, restart count 0
Jun 29 15:23:53.833: INFO: sonobuoy from sonobuoy started at 2018-06-29 15:20:46 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 29 15:23:53.833: INFO: kube-proxy-tg7sf from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:23:53.833: INFO: configure-oom-ppn66 from rackspace-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:23:53.833: INFO: fluentd-es-dn97d from rackspace-system started at 2018-06-28 20:36:34 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:23:53.833: INFO: node-exporter-5szrw from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.833: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:23:53.833: INFO: sonobuoy-e2e-job-51bfab993f0f4b31 from sonobuoy started at 2018-06-29 15:20:49 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.834: INFO: 	Container e2e ready: true, restart count 0
Jun 29 15:23:53.834: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 29 15:23:53.834: INFO: etcdsnapshot-1530259620-852cf from rackspace-system started at 2018-06-29 08:07:07 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.834: INFO: 	Container snapshot ready: false, restart count 0
Jun 29 15:23:53.834: INFO: kube-calico-vtdww from kube-system started at 2018-06-28 20:27:48 +0000 UTC (2 container statuses recorded)
Jun 29 15:23:53.834: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:23:53.834: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:23:53.834: INFO: npd-v0.4.1-57n7d from kube-system started at 2018-06-28 20:32:21 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.834: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:23:53.834: INFO: container-linux-update-agent-mhr9w from rackspace-system started at 2018-06-28 20:38:24 +0000 UTC (1 container statuses recorded)
Jun 29 15:23:53.834: INFO: 	Container update-agent ready: true, restart count 2
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.153caadc568b2974], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:23:54.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-g5mm8" for this suite.
Jun 29 15:24:18.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:24:19.147: INFO: namespace: e2e-tests-sched-pred-g5mm8, resource: bindings, ignored listing per whitelist
Jun 29 15:24:19.192: INFO: namespace e2e-tests-sched-pred-g5mm8 deletion completed in 24.280495722s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:85.832 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:24:19.193: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-mjpz4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 15:24:19.464: INFO: Creating ReplicaSet my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2
Jun 29 15:24:19.479: INFO: Pod name my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2: Found 0 pods out of 1
Jun 29 15:24:24.500: INFO: Pod name my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2: Found 1 pods out of 1
Jun 29 15:24:24.500: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2" is running
Jun 29 15:24:24.508: INFO: Pod "my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2-mcwx7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-06-29 15:24:19 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-06-29 15:24:21 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-06-29 15:24:22 +0000 UTC Reason: Message:}])
Jun 29 15:24:24.508: INFO: Trying to dial the pod
Jun 29 15:24:29.561: INFO: Controller my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2: Got expected result from replica 1 [my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2-mcwx7]: "my-hostname-basic-7e1632fa-7bb0-11e8-8ddd-da371e372fc2-mcwx7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:24:29.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mjpz4" for this suite.
Jun 29 15:24:35.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:24:35.816: INFO: namespace: e2e-tests-replicaset-mjpz4, resource: bindings, ignored listing per whitelist
Jun 29 15:24:35.872: INFO: namespace e2e-tests-replicaset-mjpz4 deletion completed in 6.299248077s

â€¢ [SLOW TEST:16.679 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:24:35.874: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c9f86
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jun 29 15:24:36.161: INFO: Waiting up to 5m0s for pod "downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-c9f86" to be "success or failure"
Jun 29 15:24:36.167: INFO: Pod "downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.09479ms
Jun 29 15:24:38.176: INFO: Pod "downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01489808s
STEP: Saw pod success
Jun 29 15:24:38.176: INFO: Pod "downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:24:38.183: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 15:24:38.222: INFO: Waiting for pod downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:24:38.228: INFO: Pod downward-api-88078cff-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:24:38.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c9f86" for this suite.
Jun 29 15:24:44.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:24:44.297: INFO: namespace: e2e-tests-downward-api-c9f86, resource: bindings, ignored listing per whitelist
Jun 29 15:24:44.502: INFO: namespace e2e-tests-downward-api-c9f86 deletion completed in 6.262773782s

â€¢ [SLOW TEST:8.628 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:24:44.502: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-phwgf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-phwgf
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-phwgf
STEP: Deleting pre-stop pod
Jun 29 15:24:57.891: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:24:57.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-phwgf" for this suite.
Jun 29 15:25:37.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:25:38.057: INFO: namespace: e2e-tests-prestop-phwgf, resource: bindings, ignored listing per whitelist
Jun 29 15:25:38.233: INFO: namespace e2e-tests-prestop-phwgf deletion completed in 40.317529442s

â€¢ [SLOW TEST:53.731 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:25:38.235: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5m5x2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-ad2eff07-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:25:38.506: INFO: Waiting up to 5m0s for pod "pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-5m5x2" to be "success or failure"
Jun 29 15:25:38.511: INFO: Pod "pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.434979ms
Jun 29 15:25:40.530: INFO: Pod "pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024488802s
Jun 29 15:25:42.539: INFO: Pod "pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033179711s
STEP: Saw pod success
Jun 29 15:25:42.539: INFO: Pod "pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:25:42.560: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:25:42.604: INFO: Waiting for pod pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:25:42.614: INFO: Pod pod-secrets-ad30281f-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:25:42.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5m5x2" for this suite.
Jun 29 15:25:48.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:25:48.910: INFO: namespace: e2e-tests-secrets-5m5x2, resource: bindings, ignored listing per whitelist
Jun 29 15:25:48.972: INFO: namespace e2e-tests-secrets-5m5x2 deletion completed in 6.347135445s

â€¢ [SLOW TEST:10.737 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:25:48.975: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pvq5d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-b398ae91-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:25:49.259: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-pvq5d" to be "success or failure"
Jun 29 15:25:49.264: INFO: Pod "pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.855049ms
Jun 29 15:25:51.288: INFO: Pod "pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029374451s
STEP: Saw pod success
Jun 29 15:25:51.288: INFO: Pod "pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:25:51.294: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:25:51.327: INFO: Waiting for pod pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:25:51.332: INFO: Pod pod-projected-configmaps-b399b3f3-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:25:51.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pvq5d" for this suite.
Jun 29 15:25:57.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:25:57.606: INFO: namespace: e2e-tests-projected-pvq5d, resource: bindings, ignored listing per whitelist
Jun 29 15:25:57.613: INFO: namespace e2e-tests-projected-pvq5d deletion completed in 6.270230613s

â€¢ [SLOW TEST:8.637 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:25:57.614: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6jn8q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-b8bf4b5b-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:25:57.909: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-6jn8q" to be "success or failure"
Jun 29 15:25:57.921: INFO: Pod "pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.396136ms
Jun 29 15:25:59.939: INFO: Pod "pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029774873s
Jun 29 15:26:01.963: INFO: Pod "pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053487259s
STEP: Saw pod success
Jun 29 15:26:01.963: INFO: Pod "pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:26:01.978: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:26:02.039: INFO: Waiting for pod pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:26:02.044: INFO: Pod pod-projected-configmaps-b8c055d5-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:26:02.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jn8q" for this suite.
Jun 29 15:26:08.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:26:08.218: INFO: namespace: e2e-tests-projected-6jn8q, resource: bindings, ignored listing per whitelist
Jun 29 15:26:08.304: INFO: namespace e2e-tests-projected-6jn8q deletion completed in 6.249007153s

â€¢ [SLOW TEST:10.691 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:26:08.305: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gr5wr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-bf28dbc0-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:26:08.665: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-gr5wr" to be "success or failure"
Jun 29 15:26:08.686: INFO: Pod "pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.832011ms
Jun 29 15:26:10.695: INFO: Pod "pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029385527s
STEP: Saw pod success
Jun 29 15:26:10.695: INFO: Pod "pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:26:10.701: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:26:10.787: INFO: Waiting for pod pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:26:10.813: INFO: Pod pod-projected-secrets-bf2a4f54-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:26:10.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gr5wr" for this suite.
Jun 29 15:26:16.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:26:17.126: INFO: namespace: e2e-tests-projected-gr5wr, resource: bindings, ignored listing per whitelist
Jun 29 15:26:17.156: INFO: namespace e2e-tests-projected-gr5wr deletion completed in 6.302242667s

â€¢ [SLOW TEST:8.851 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:26:17.157: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ct4zx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:26:17.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-ct4zx" to be "success or failure"
Jun 29 15:26:17.473: INFO: Pod "downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.229132ms
Jun 29 15:26:19.480: INFO: Pod "downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012814407s
STEP: Saw pod success
Jun 29 15:26:19.480: INFO: Pod "downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:26:19.486: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:26:19.525: INFO: Waiting for pod downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:26:19.539: INFO: Pod downwardapi-volume-c469285d-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:26:19.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ct4zx" for this suite.
Jun 29 15:26:25.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:26:25.727: INFO: namespace: e2e-tests-downward-api-ct4zx, resource: bindings, ignored listing per whitelist
Jun 29 15:26:25.819: INFO: namespace e2e-tests-downward-api-ct4zx deletion completed in 6.268813783s

â€¢ [SLOW TEST:8.662 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:26:25.820: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xvbvv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-c98dc637-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:26:26.097: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-xvbvv" to be "success or failure"
Jun 29 15:26:26.105: INFO: Pod "pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.645236ms
Jun 29 15:26:28.114: INFO: Pod "pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017015965s
STEP: Saw pod success
Jun 29 15:26:28.118: INFO: Pod "pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:26:28.125: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:26:28.158: INFO: Waiting for pod pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:26:28.166: INFO: Pod pod-projected-configmaps-c98ec2d4-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:26:28.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xvbvv" for this suite.
Jun 29 15:26:34.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:26:34.334: INFO: namespace: e2e-tests-projected-xvbvv, resource: bindings, ignored listing per whitelist
Jun 29 15:26:34.478: INFO: namespace e2e-tests-projected-xvbvv deletion completed in 6.302150431s

â€¢ [SLOW TEST:8.658 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:26:34.479: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-b6p7n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 15:26:34.747: INFO: (0) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 9.224154ms)
Jun 29 15:26:34.755: INFO: (1) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.061532ms)
Jun 29 15:26:34.764: INFO: (2) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.212751ms)
Jun 29 15:26:34.772: INFO: (3) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.221091ms)
Jun 29 15:26:34.780: INFO: (4) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.266866ms)
Jun 29 15:26:34.788: INFO: (5) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.263325ms)
Jun 29 15:26:34.796: INFO: (6) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.609423ms)
Jun 29 15:26:34.804: INFO: (7) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.749806ms)
Jun 29 15:26:34.811: INFO: (8) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.250377ms)
Jun 29 15:26:34.818: INFO: (9) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.144488ms)
Jun 29 15:26:34.826: INFO: (10) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.297829ms)
Jun 29 15:26:34.833: INFO: (11) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.321931ms)
Jun 29 15:26:34.840: INFO: (12) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.040384ms)
Jun 29 15:26:34.847: INFO: (13) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 6.880455ms)
Jun 29 15:26:34.856: INFO: (14) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.106312ms)
Jun 29 15:26:34.865: INFO: (15) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 9.126518ms)
Jun 29 15:26:34.873: INFO: (16) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.813588ms)
Jun 29 15:26:34.879: INFO: (17) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 6.582108ms)
Jun 29 15:26:34.888: INFO: (18) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.764359ms)
Jun 29 15:26:34.896: INFO: (19) /api/v1/nodes/kubernetes-lblackstone-worker-0/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.252309ms)
[AfterEach] version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:26:34.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-b6p7n" for this suite.
Jun 29 15:26:40.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:26:41.109: INFO: namespace: e2e-tests-proxy-b6p7n, resource: bindings, ignored listing per whitelist
Jun 29 15:26:41.260: INFO: namespace e2e-tests-proxy-b6p7n deletion completed in 6.354228096s

â€¢ [SLOW TEST:6.781 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:26:41.261: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-28vvl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-d2c05a46-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:26:41.529: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-28vvl" to be "success or failure"
Jun 29 15:26:41.537: INFO: Pod "pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.708291ms
Jun 29 15:26:43.545: INFO: Pod "pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015799425s
Jun 29 15:26:45.571: INFO: Pod "pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041566844s
STEP: Saw pod success
Jun 29 15:26:45.571: INFO: Pod "pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:26:45.577: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:26:45.634: INFO: Waiting for pod pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:26:45.659: INFO: Pod pod-projected-secrets-d2c1621c-7bb0-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:26:45.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28vvl" for this suite.
Jun 29 15:26:51.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:26:51.771: INFO: namespace: e2e-tests-projected-28vvl, resource: bindings, ignored listing per whitelist
Jun 29 15:26:51.955: INFO: namespace e2e-tests-projected-28vvl deletion completed in 6.266197438s

â€¢ [SLOW TEST:10.693 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:26:51.955: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rgkhb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-d921e619-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating secret with name s-test-opt-upd-d921e672-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d921e619-7bb0-11e8-8ddd-da371e372fc2
STEP: Updating secret s-test-opt-upd-d921e672-7bb0-11e8-8ddd-da371e372fc2
STEP: Creating secret with name s-test-opt-create-d921e69b-7bb0-11e8-8ddd-da371e372fc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:28:01.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rgkhb" for this suite.
Jun 29 15:28:25.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:28:25.492: INFO: namespace: e2e-tests-projected-rgkhb, resource: bindings, ignored listing per whitelist
Jun 29 15:28:25.623: INFO: namespace e2e-tests-projected-rgkhb deletion completed in 24.294402507s

â€¢ [SLOW TEST:93.669 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:28:25.625: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-z4gbf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun 29 15:28:25.921: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-z4gbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-z4gbf/configmaps/e2e-watch-test-resource-version,UID:10ff3a98-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161733,Generation:0,CreationTimestamp:2018-06-29 15:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 29 15:28:25.922: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-z4gbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-z4gbf/configmaps/e2e-watch-test-resource-version,UID:10ff3a98-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161734,Generation:0,CreationTimestamp:2018-06-29 15:28:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:28:25.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-z4gbf" for this suite.
Jun 29 15:28:31.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:28:32.001: INFO: namespace: e2e-tests-watch-z4gbf, resource: bindings, ignored listing per whitelist
Jun 29 15:28:32.164: INFO: namespace e2e-tests-watch-z4gbf deletion completed in 6.231016311s

â€¢ [SLOW TEST:6.540 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:28:32.166: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-pdjl5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-14d85ef4-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:28:32.420: INFO: Waiting up to 5m0s for pod "pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-pdjl5" to be "success or failure"
Jun 29 15:28:32.426: INFO: Pod "pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.614988ms
Jun 29 15:28:34.433: INFO: Pod "pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012140284s
Jun 29 15:28:36.441: INFO: Pod "pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020526761s
STEP: Saw pod success
Jun 29 15:28:36.441: INFO: Pod "pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:28:36.447: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:28:36.480: INFO: Waiting for pod pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:28:36.485: INFO: Pod pod-secrets-14d9aa7c-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:28:36.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pdjl5" for this suite.
Jun 29 15:28:42.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:28:42.651: INFO: namespace: e2e-tests-secrets-pdjl5, resource: bindings, ignored listing per whitelist
Jun 29 15:28:42.770: INFO: namespace e2e-tests-secrets-pdjl5 deletion completed in 6.27501826s

â€¢ [SLOW TEST:10.605 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:28:42.776: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-plptv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun 29 15:28:43.038: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161812,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 29 15:28:43.038: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161812,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun 29 15:28:53.068: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161832,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 29 15:28:53.068: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161832,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun 29 15:29:03.097: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161851,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 29 15:29:03.097: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161851,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun 29 15:29:13.121: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161870,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 29 15:29:13.121: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-a,UID:1b3941cf-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161870,Generation:0,CreationTimestamp:2018-06-29 15:28:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun 29 15:29:23.149: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-b,UID:33208f37-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161892,Generation:0,CreationTimestamp:2018-06-29 15:29:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 29 15:29:23.151: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-b,UID:33208f37-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161892,Generation:0,CreationTimestamp:2018-06-29 15:29:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun 29 15:29:33.176: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-b,UID:33208f37-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161909,Generation:0,CreationTimestamp:2018-06-29 15:29:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 29 15:29:33.176: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-plptv,SelfLink:/api/v1/namespaces/e2e-tests-watch-plptv/configmaps/e2e-watch-test-configmap-b,UID:33208f37-7bb1-11e8-b9b2-fa163ec8ddce,ResourceVersion:161909,Generation:0,CreationTimestamp:2018-06-29 15:29:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:29:43.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-plptv" for this suite.
Jun 29 15:29:49.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:29:49.315: INFO: namespace: e2e-tests-watch-plptv, resource: bindings, ignored listing per whitelist
Jun 29 15:29:49.472: INFO: namespace e2e-tests-watch-plptv deletion completed in 6.272420066s

â€¢ [SLOW TEST:66.696 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:29:49.474: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bxrsq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-42f028f8-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:29:49.747: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-bxrsq" to be "success or failure"
Jun 29 15:29:49.752: INFO: Pod "pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.518163ms
Jun 29 15:29:51.763: INFO: Pod "pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015566953s
Jun 29 15:29:53.798: INFO: Pod "pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050949859s
STEP: Saw pod success
Jun 29 15:29:53.798: INFO: Pod "pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:29:53.805: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:29:53.850: INFO: Waiting for pod pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:29:53.863: INFO: Pod pod-projected-configmaps-42f1359f-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:29:53.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bxrsq" for this suite.
Jun 29 15:29:59.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:30:00.104: INFO: namespace: e2e-tests-projected-bxrsq, resource: bindings, ignored listing per whitelist
Jun 29 15:30:00.129: INFO: namespace e2e-tests-projected-bxrsq deletion completed in 6.248403897s

â€¢ [SLOW TEST:10.656 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:30:00.131: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-whmhq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 29 15:30:00.387: INFO: Waiting up to 5m0s for pod "pod-49488b09-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-whmhq" to be "success or failure"
Jun 29 15:30:00.393: INFO: Pod "pod-49488b09-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.725349ms
Jun 29 15:30:02.399: INFO: Pod "pod-49488b09-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011661113s
Jun 29 15:30:04.420: INFO: Pod "pod-49488b09-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032901364s
STEP: Saw pod success
Jun 29 15:30:04.420: INFO: Pod "pod-49488b09-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:30:04.427: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-49488b09-7bb1-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:30:04.462: INFO: Waiting for pod pod-49488b09-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:30:04.468: INFO: Pod pod-49488b09-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:30:04.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-whmhq" for this suite.
Jun 29 15:30:10.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:30:10.670: INFO: namespace: e2e-tests-emptydir-whmhq, resource: bindings, ignored listing per whitelist
Jun 29 15:30:10.739: INFO: namespace e2e-tests-emptydir-whmhq deletion completed in 6.262065541s

â€¢ [SLOW TEST:10.608 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:30:10.739: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-spdtz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jun 29 15:30:13.548: INFO: Successfully updated pod "annotationupdate4f9ab2ee-7bb1-11e8-8ddd-da371e372fc2"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:30:15.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-spdtz" for this suite.
Jun 29 15:30:39.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:30:39.682: INFO: namespace: e2e-tests-projected-spdtz, resource: bindings, ignored listing per whitelist
Jun 29 15:30:39.844: INFO: namespace e2e-tests-projected-spdtz deletion completed in 24.246151945s

â€¢ [SLOW TEST:29.105 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:30:39.850: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-xrb5k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun 29 15:30:46.234: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:46.234: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:46.447: INFO: Exec stderr: ""
Jun 29 15:30:46.447: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:46.447: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:46.671: INFO: Exec stderr: ""
Jun 29 15:30:46.671: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:46.671: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:46.829: INFO: Exec stderr: ""
Jun 29 15:30:46.829: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:46.829: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:46.971: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun 29 15:30:46.971: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:46.971: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:47.117: INFO: Exec stderr: ""
Jun 29 15:30:47.117: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:47.117: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:47.302: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun 29 15:30:47.302: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:47.302: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:47.477: INFO: Exec stderr: ""
Jun 29 15:30:47.477: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:47.478: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:47.634: INFO: Exec stderr: ""
Jun 29 15:30:47.634: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:47.634: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:47.800: INFO: Exec stderr: ""
Jun 29 15:30:47.801: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-xrb5k PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:30:47.801: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:30:47.970: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:30:47.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-xrb5k" for this suite.
Jun 29 15:31:34.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:31:34.050: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-xrb5k, resource: bindings, ignored listing per whitelist
Jun 29 15:31:34.243: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-xrb5k deletion completed in 46.263475344s

â€¢ [SLOW TEST:54.393 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:31:34.245: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2grqg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-81627b37-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:31:34.521: INFO: Waiting up to 5m0s for pod "pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-2grqg" to be "success or failure"
Jun 29 15:31:34.526: INFO: Pod "pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.658955ms
Jun 29 15:31:36.534: INFO: Pod "pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012087309s
STEP: Saw pod success
Jun 29 15:31:36.534: INFO: Pod "pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:31:36.539: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2 container secret-env-test: <nil>
STEP: delete the pod
Jun 29 15:31:36.571: INFO: Waiting for pod pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:31:36.576: INFO: Pod pod-secrets-81639929-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:31:36.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2grqg" for this suite.
Jun 29 15:31:42.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:31:42.732: INFO: namespace: e2e-tests-secrets-2grqg, resource: bindings, ignored listing per whitelist
Jun 29 15:31:42.868: INFO: namespace e2e-tests-secrets-2grqg deletion completed in 6.281738136s

â€¢ [SLOW TEST:8.624 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:31:42.869: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-djfv4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 29 15:31:43.169: INFO: Waiting up to 5m0s for pod "pod-868beff2-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-djfv4" to be "success or failure"
Jun 29 15:31:43.175: INFO: Pod "pod-868beff2-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.127811ms
Jun 29 15:31:45.192: INFO: Pod "pod-868beff2-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022170644s
Jun 29 15:31:47.198: INFO: Pod "pod-868beff2-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028604738s
STEP: Saw pod success
Jun 29 15:31:47.198: INFO: Pod "pod-868beff2-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:31:47.204: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-868beff2-7bb1-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:31:47.245: INFO: Waiting for pod pod-868beff2-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:31:47.250: INFO: Pod pod-868beff2-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:31:47.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-djfv4" for this suite.
Jun 29 15:31:53.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:31:53.418: INFO: namespace: e2e-tests-emptydir-djfv4, resource: bindings, ignored listing per whitelist
Jun 29 15:31:53.527: INFO: namespace e2e-tests-emptydir-djfv4 deletion completed in 6.26722096s

â€¢ [SLOW TEST:10.658 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:31:53.529: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-7t826
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7t826
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 29 15:31:53.791: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 29 15:32:16.008: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.2.3.177 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7t826 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:32:16.009: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:32:17.238: INFO: Found all expected endpoints: [netserver-0]
Jun 29 15:32:17.246: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.2.1.225 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7t826 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:32:17.246: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:32:18.472: INFO: Found all expected endpoints: [netserver-1]
Jun 29 15:32:18.479: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.2.5.68 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7t826 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 15:32:18.479: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 15:32:19.672: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:32:19.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7t826" for this suite.
Jun 29 15:32:43.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:32:43.862: INFO: namespace: e2e-tests-pod-network-test-7t826, resource: bindings, ignored listing per whitelist
Jun 29 15:32:43.966: INFO: namespace e2e-tests-pod-network-test-7t826 deletion completed in 24.281388761s

â€¢ [SLOW TEST:50.438 seconds]
[sig-network] Networking
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:32:43.968: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-n8spt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0629 15:33:24.336179      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 29 15:33:24.336: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:33:24.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-n8spt" for this suite.
Jun 29 15:33:32.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:33:32.571: INFO: namespace: e2e-tests-gc-n8spt, resource: bindings, ignored listing per whitelist
Jun 29 15:33:32.632: INFO: namespace e2e-tests-gc-n8spt deletion completed in 8.286571275s

â€¢ [SLOW TEST:48.665 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:33:32.634: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nm5qh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-c80b1ce5-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:33:33.061: INFO: Waiting up to 5m0s for pod "pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-nm5qh" to be "success or failure"
Jun 29 15:33:33.068: INFO: Pod "pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.59227ms
Jun 29 15:33:35.086: INFO: Pod "pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023986264s
Jun 29 15:33:37.094: INFO: Pod "pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032827683s
Jun 29 15:33:39.103: INFO: Pod "pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041233007s
STEP: Saw pod success
Jun 29 15:33:39.103: INFO: Pod "pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:33:39.122: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:33:39.159: INFO: Waiting for pod pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:33:39.165: INFO: Pod pod-secrets-c80c187b-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:33:39.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nm5qh" for this suite.
Jun 29 15:33:45.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:33:45.415: INFO: namespace: e2e-tests-secrets-nm5qh, resource: bindings, ignored listing per whitelist
Jun 29 15:33:45.486: INFO: namespace e2e-tests-secrets-nm5qh deletion completed in 6.309735758s

â€¢ [SLOW TEST:12.852 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:33:45.488: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wkqzt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-cf9e0e75-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:33:45.768: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-wkqzt" to be "success or failure"
Jun 29 15:33:45.795: INFO: Pod "pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.323682ms
Jun 29 15:33:47.803: INFO: Pod "pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034580743s
STEP: Saw pod success
Jun 29 15:33:47.804: INFO: Pod "pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:33:47.809: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:33:47.842: INFO: Waiting for pod pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:33:47.850: INFO: Pod pod-configmaps-cf9f5981-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:33:47.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wkqzt" for this suite.
Jun 29 15:33:53.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:33:53.897: INFO: namespace: e2e-tests-configmap-wkqzt, resource: bindings, ignored listing per whitelist
Jun 29 15:33:54.083: INFO: namespace e2e-tests-configmap-wkqzt deletion completed in 6.222660785s

â€¢ [SLOW TEST:8.595 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:33:54.083: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zcz5r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-d4bd1026-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:33:54.359: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-zcz5r" to be "success or failure"
Jun 29 15:33:54.364: INFO: Pod "pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.447417ms
Jun 29 15:33:56.384: INFO: Pod "pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024851911s
Jun 29 15:33:58.393: INFO: Pod "pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033651233s
STEP: Saw pod success
Jun 29 15:33:58.393: INFO: Pod "pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:33:58.399: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:33:58.459: INFO: Waiting for pod pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:33:58.465: INFO: Pod pod-configmaps-d4be3734-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:33:58.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zcz5r" for this suite.
Jun 29 15:34:04.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:34:04.596: INFO: namespace: e2e-tests-configmap-zcz5r, resource: bindings, ignored listing per whitelist
Jun 29 15:34:04.738: INFO: namespace e2e-tests-configmap-zcz5r deletion completed in 6.262694151s

â€¢ [SLOW TEST:10.654 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:34:04.739: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-r6l9s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-r6l9s
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-r6l9s
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-r6l9s
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-r6l9s
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-r6l9s
Jun 29 15:34:11.126: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-r6l9s, name: ss-0, uid: e00aabc8-7bb1-11e8-826d-fa163e9eef45, status phase: Pending. Waiting for statefulset controller to delete.
Jun 29 15:34:11.247: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-r6l9s, name: ss-0, uid: e00aabc8-7bb1-11e8-826d-fa163e9eef45, status phase: Failed. Waiting for statefulset controller to delete.
Jun 29 15:34:11.267: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-r6l9s, name: ss-0, uid: e00aabc8-7bb1-11e8-826d-fa163e9eef45, status phase: Failed. Waiting for statefulset controller to delete.
Jun 29 15:34:11.274: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-r6l9s
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-r6l9s
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-r6l9s and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jun 29 15:34:17.331: INFO: Deleting all statefulset in ns e2e-tests-statefulset-r6l9s
Jun 29 15:34:17.339: INFO: Scaling statefulset ss to 0
Jun 29 15:34:37.371: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 15:34:37.378: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:34:37.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-r6l9s" for this suite.
Jun 29 15:34:43.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:34:43.697: INFO: namespace: e2e-tests-statefulset-r6l9s, resource: bindings, ignored listing per whitelist
Jun 29 15:34:43.763: INFO: namespace e2e-tests-statefulset-r6l9s deletion completed in 6.320891699s

â€¢ [SLOW TEST:39.025 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:34:43.765: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ttjdc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-f25c8138-7bb1-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:34:44.060: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-ttjdc" to be "success or failure"
Jun 29 15:34:44.065: INFO: Pod "pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.546967ms
Jun 29 15:34:46.078: INFO: Pod "pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017714529s
STEP: Saw pod success
Jun 29 15:34:46.078: INFO: Pod "pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:34:46.085: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:34:46.144: INFO: Waiting for pod pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:34:46.149: INFO: Pod pod-projected-secrets-f25dc869-7bb1-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:34:46.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ttjdc" for this suite.
Jun 29 15:34:52.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:34:52.442: INFO: namespace: e2e-tests-projected-ttjdc, resource: bindings, ignored listing per whitelist
Jun 29 15:34:52.452: INFO: namespace e2e-tests-projected-ttjdc deletion completed in 6.293935279s

â€¢ [SLOW TEST:8.688 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:34:52.453: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-n9v6q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-n9v6q
Jun 29 15:34:54.737: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-n9v6q
STEP: checking the pod's current state and verifying that restartCount is present
Jun 29 15:34:54.742: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:38:56.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n9v6q" for this suite.
Jun 29 15:39:02.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:39:02.185: INFO: namespace: e2e-tests-container-probe-n9v6q, resource: bindings, ignored listing per whitelist
Jun 29 15:39:02.383: INFO: namespace e2e-tests-container-probe-n9v6q deletion completed in 6.247302182s

â€¢ [SLOW TEST:249.930 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:39:02.383: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-h8d4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 Pods, got 2 Pods
STEP: Gathering metrics
W0629 15:39:03.747587      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 29 15:39:03.747: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:39:03.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h8d4s" for this suite.
Jun 29 15:39:09.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:39:09.951: INFO: namespace: e2e-tests-gc-h8d4s, resource: bindings, ignored listing per whitelist
Jun 29 15:39:10.028: INFO: namespace e2e-tests-gc-h8d4s deletion completed in 6.270859099s

â€¢ [SLOW TEST:7.645 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:39:10.031: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-bzpnh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 29 15:39:10.325: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 29 15:40:10.411: INFO: Waiting for terminating namespaces to be deleted...
Jun 29 15:40:10.424: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 29 15:40:10.455: INFO: 44 / 44 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 29 15:40:10.455: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Jun 29 15:40:10.468: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jun 29 15:40:10.468: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-0 before test
Jun 29 15:40:10.487: INFO: container-linux-update-agent-g2b29 from rackspace-system started at 2018-06-28 20:38:23 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.488: INFO: 	Container update-agent ready: true, restart count 2
Jun 29 15:40:10.488: INFO: alertmanager-main-1 from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.488: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:40:10.488: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:40:10.488: INFO: influxdb-545869c56c-ndhzm from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.488: INFO: 	Container influxdb ready: true, restart count 0
Jun 29 15:40:10.488: INFO: registry-job-6ff94bb84c-wpc5v from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.488: INFO: 	Container registry-job ready: true, restart count 0
Jun 29 15:40:10.488: INFO: alertmanager-main-2 from rackspace-system started at 2018-06-28 20:54:44 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.489: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:40:10.489: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:40:10.489: INFO: kube-proxy-8qt66 from kube-system started at 2018-06-28 20:27:44 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.489: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:40:10.489: INFO: npd-v0.4.1-fq8q4 from kube-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.489: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:40:10.489: INFO: fluentd-es-9thgd from rackspace-system started at 2018-06-28 20:36:33 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.489: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:40:10.489: INFO: es-data-1 from rackspace-system started at 2018-06-28 20:53:43 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.489: INFO: 	Container es-data ready: true, restart count 136
Jun 29 15:40:10.489: INFO: prometheus-customer-1 from monitoring started at 2018-06-28 20:54:23 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.490: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:40:10.490: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:40:10.490: INFO: prometheus-k8s-0 from rackspace-system started at 2018-06-28 20:54:20 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.490: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:40:10.490: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:40:10.490: INFO: prometheus-customer-0 from monitoring started at 2018-06-28 20:54:23 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.490: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:40:10.490: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:40:10.490: INFO: kube-calico-dhfwc from kube-system started at 2018-06-28 20:27:47 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.490: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:40:10.491: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:40:10.491: INFO: container-linux-update-operator-6df89667cb-4gwlh from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.491: INFO: 	Container update-operator ready: true, restart count 0
Jun 29 15:40:10.491: INFO: nginx-ingress-controller-7c7b8f746d-85lzp from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.491: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jun 29 15:40:10.491: INFO: default-http-backend-658c6856c5-vtlcw from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.491: INFO: 	Container default-http-backend ready: true, restart count 0
Jun 29 15:40:10.491: INFO: kube-state-metrics-8747876f4-2rt6h from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.491: INFO: 	Container addon-resizer ready: true, restart count 0
Jun 29 15:40:10.491: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jun 29 15:40:10.491: INFO: prometheus-operator-95bb8bdf9-wshj6 from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.492: INFO: 	Container prometheus-operator ready: true, restart count 0
Jun 29 15:40:10.492: INFO: registry-nginx-5fcb7bcccf-ktgcl from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.492: INFO: 	Container registry-nginx ready: true, restart count 0
Jun 29 15:40:10.492: INFO: kube-flannel-6tj5j from kube-system started at 2018-06-28 20:27:44 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.492: INFO: 	Container kube-flannel ready: true, restart count 2
Jun 29 15:40:10.492: INFO: configure-oom-kn8s9 from rackspace-system started at 2018-06-28 20:32:19 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.492: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:40:10.492: INFO: node-exporter-z7p55 from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.492: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:40:10.492: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-1 before test
Jun 29 15:40:10.516: INFO: kube-flannel-2rvmq from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.516: INFO: 	Container kube-flannel ready: true, restart count 3
Jun 29 15:40:10.517: INFO: npd-v0.4.1-59zdt from kube-system started at 2018-06-28 20:32:21 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.517: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:40:10.517: INFO: fluentd-es-b4p8v from rackspace-system started at 2018-06-28 20:36:34 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.517: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:40:10.517: INFO: node-exporter-6ktxl from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.517: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:40:10.517: INFO: elasticsearch-exporter-7449557bc-rtkgp from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.517: INFO: 	Container elasticsearch-exporter ready: true, restart count 0
Jun 29 15:40:10.517: INFO: kibana-54898499fb-mqdg8 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.518: INFO: 	Container kibana ready: true, restart count 0
Jun 29 15:40:10.518: INFO: heapster-55f9c7bcb7-p62lz from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.518: INFO: 	Container heapster ready: true, restart count 0
Jun 29 15:40:10.518: INFO: container-linux-update-agent-qfmnq from rackspace-system started at 2018-06-28 20:38:24 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.518: INFO: 	Container update-agent ready: true, restart count 3
Jun 29 15:40:10.518: INFO: kubernetes-dashboard-8f54b8b54-fs95w from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.518: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 29 15:40:10.518: INFO: registry-7758dd67d6-hn8bb from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.519: INFO: 	Container registry ready: true, restart count 0
Jun 29 15:40:10.519: INFO: 	Container registry-exporter ready: true, restart count 0
Jun 29 15:40:10.519: INFO: registry-ui-844884c845-bblj9 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.519: INFO: 	Container registry-ui ready: true, restart count 3
Jun 29 15:40:10.519: INFO: configure-oom-mbr5n from rackspace-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.519: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:40:10.519: INFO: grafana-0 from rackspace-system started at 2018-06-28 20:58:57 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.519: INFO: 	Container grafana ready: true, restart count 0
Jun 29 15:40:10.519: INFO: 	Container grafana-watcher ready: true, restart count 0
Jun 29 15:40:10.519: INFO: kube-proxy-js89r from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.520: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:40:10.520: INFO: nginx-ingress-controller-7c7b8f746d-vjnl6 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.520: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jun 29 15:40:10.520: INFO: registry-admin-645ff5ff77-svlgr from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.520: INFO: 	Container registry-admin ready: true, restart count 0
Jun 29 15:40:10.520: INFO: kube-calico-w8x5n from kube-system started at 2018-06-28 20:27:48 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.520: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:40:10.520: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:40:10.520: INFO: registry-image-scan-postgres-0 from rackspace-system started at 2018-06-28 20:58:32 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.520: INFO: 	Container registry-image-scan-postgres ready: true, restart count 0
Jun 29 15:40:10.521: INFO: prometheus-k8s-1 from rackspace-system started at 2018-06-28 20:58:31 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.521: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:40:10.521: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:40:10.521: INFO: alertmanager-main-0 from rackspace-system started at 2018-06-28 20:58:53 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.521: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:40:10.521: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:40:10.521: INFO: es-data-0 from rackspace-system started at 2018-06-28 20:59:09 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.521: INFO: 	Container es-data ready: true, restart count 144
Jun 29 15:40:10.521: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-2 before test
Jun 29 15:40:10.537: INFO: node-exporter-5szrw from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.538: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:40:10.538: INFO: sonobuoy-e2e-job-51bfab993f0f4b31 from sonobuoy started at 2018-06-29 15:20:49 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.538: INFO: 	Container e2e ready: true, restart count 0
Jun 29 15:40:10.538: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 29 15:40:10.538: INFO: kube-calico-vtdww from kube-system started at 2018-06-28 20:27:48 +0000 UTC (2 container statuses recorded)
Jun 29 15:40:10.538: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:40:10.538: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:40:10.539: INFO: npd-v0.4.1-57n7d from kube-system started at 2018-06-28 20:32:21 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.539: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:40:10.539: INFO: container-linux-update-agent-mhr9w from rackspace-system started at 2018-06-28 20:38:24 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.539: INFO: 	Container update-agent ready: true, restart count 2
Jun 29 15:40:10.539: INFO: etcdsnapshot-1530259620-852cf from rackspace-system started at 2018-06-29 08:07:07 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.539: INFO: 	Container snapshot ready: false, restart count 0
Jun 29 15:40:10.539: INFO: kube-flannel-m5kl7 from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.539: INFO: 	Container kube-flannel ready: true, restart count 2
Jun 29 15:40:10.539: INFO: registry-image-scan-8576ff96b4-ccbw2 from rackspace-system started at 2018-06-28 21:03:08 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.540: INFO: 	Container registry-image-scan ready: true, restart count 0
Jun 29 15:40:10.540: INFO: registry-mysql-0 from rackspace-system started at 2018-06-28 21:03:08 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.540: INFO: 	Container registry-mysql ready: true, restart count 0
Jun 29 15:40:10.540: INFO: es-data-2 from rackspace-system started at 2018-06-28 21:03:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.540: INFO: 	Container es-data ready: false, restart count 133
Jun 29 15:40:10.540: INFO: etcdsnapshot-1530230820-cgxrr from rackspace-system started at 2018-06-29 00:07:01 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.540: INFO: 	Container snapshot ready: false, restart count 0
Jun 29 15:40:10.540: INFO: kube-proxy-tg7sf from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.540: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:40:10.541: INFO: configure-oom-ppn66 from rackspace-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.541: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:40:10.541: INFO: fluentd-es-dn97d from rackspace-system started at 2018-06-28 20:36:34 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.541: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:40:10.541: INFO: sonobuoy from sonobuoy started at 2018-06-29 15:20:46 +0000 UTC (1 container statuses recorded)
Jun 29 15:40:10.541: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b7678bc8-7bb2-11e8-8ddd-da371e372fc2 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b7678bc8-7bb2-11e8-8ddd-da371e372fc2 off the node kubernetes-lblackstone-worker-0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b7678bc8-7bb2-11e8-8ddd-da371e372fc2
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:40:18.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bzpnh" for this suite.
Jun 29 15:40:42.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:40:42.971: INFO: namespace: e2e-tests-sched-pred-bzpnh, resource: bindings, ignored listing per whitelist
Jun 29 15:40:43.110: INFO: namespace e2e-tests-sched-pred-bzpnh deletion completed in 24.294861712s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:93.080 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:40:43.111: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-s8qkc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
Jun 29 15:40:43.391: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-s8qkc" to be "success or failure"
Jun 29 15:40:43.402: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.282991ms
Jun 29 15:40:45.419: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027118339s
STEP: Saw pod success
Jun 29 15:40:45.419: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jun 29 15:40:45.427: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun 29 15:40:45.468: INFO: Waiting for pod pod-host-path-test to disappear
Jun 29 15:40:45.473: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:40:45.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-s8qkc" for this suite.
Jun 29 15:40:51.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:40:51.646: INFO: namespace: e2e-tests-hostpath-s8qkc, resource: bindings, ignored listing per whitelist
Jun 29 15:40:51.728: INFO: namespace e2e-tests-hostpath-s8qkc deletion completed in 6.243295378s

â€¢ [SLOW TEST:8.617 seconds]
[sig-storage] HostPath
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:40:51.729: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wvf5j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 29 15:40:52.011: INFO: Waiting up to 5m0s for pod "pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-wvf5j" to be "success or failure"
Jun 29 15:40:52.017: INFO: Pod "pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.311059ms
Jun 29 15:40:54.023: INFO: Pod "pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011812611s
Jun 29 15:40:56.031: INFO: Pod "pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020243831s
STEP: Saw pod success
Jun 29 15:40:56.032: INFO: Pod "pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:40:56.037: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:40:56.071: INFO: Waiting for pod pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:40:56.077: INFO: Pod pod-cdae9dd1-7bb2-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:40:56.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wvf5j" for this suite.
Jun 29 15:41:02.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:41:02.313: INFO: namespace: e2e-tests-emptydir-wvf5j, resource: bindings, ignored listing per whitelist
Jun 29 15:41:02.366: INFO: namespace e2e-tests-emptydir-wvf5j deletion completed in 6.280741774s

â€¢ [SLOW TEST:10.637 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:41:02.367: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-sf4kn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jun 29 15:41:05.257: INFO: Successfully updated pod "annotationupdated4044361-7bb2-11e8-8ddd-da371e372fc2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:41:07.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sf4kn" for this suite.
Jun 29 15:41:31.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:41:31.368: INFO: namespace: e2e-tests-downward-api-sf4kn, resource: bindings, ignored listing per whitelist
Jun 29 15:41:31.549: INFO: namespace e2e-tests-downward-api-sf4kn deletion completed in 24.245150766s

â€¢ [SLOW TEST:29.182 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:41:31.550: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zmzm4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:41:31.826: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-zmzm4" to be "success or failure"
Jun 29 15:41:31.833: INFO: Pod "downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.097052ms
Jun 29 15:41:33.840: INFO: Pod "downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014076569s
STEP: Saw pod success
Jun 29 15:41:33.840: INFO: Pod "downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:41:33.857: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:41:33.893: INFO: Waiting for pod downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:41:33.899: INFO: Pod downwardapi-volume-e569819c-7bb2-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:41:33.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zmzm4" for this suite.
Jun 29 15:41:39.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:41:40.088: INFO: namespace: e2e-tests-downward-api-zmzm4, resource: bindings, ignored listing per whitelist
Jun 29 15:41:40.155: INFO: namespace e2e-tests-downward-api-zmzm4 deletion completed in 6.247095298s

â€¢ [SLOW TEST:8.605 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:41:40.157: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9pmp5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-9pmp5/secret-test-ea8e5568-7bb2-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:41:40.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-9pmp5" to be "success or failure"
Jun 29 15:41:40.473: INFO: Pod "pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.118799ms
Jun 29 15:41:42.490: INFO: Pod "pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023589497s
STEP: Saw pod success
Jun 29 15:41:42.490: INFO: Pod "pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:41:42.495: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2 container env-test: <nil>
STEP: delete the pod
Jun 29 15:41:42.527: INFO: Waiting for pod pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:41:42.533: INFO: Pod pod-configmaps-ea8f6cac-7bb2-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:41:42.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9pmp5" for this suite.
Jun 29 15:41:48.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:41:48.769: INFO: namespace: e2e-tests-secrets-9pmp5, resource: bindings, ignored listing per whitelist
Jun 29 15:41:48.824: INFO: namespace e2e-tests-secrets-9pmp5 deletion completed in 6.280342547s

â€¢ [SLOW TEST:8.667 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:41:48.824: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4zjrl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4zjrl
Jun 29 15:41:53.102: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4zjrl
STEP: checking the pod's current state and verifying that restartCount is present
Jun 29 15:41:53.108: INFO: Initial restart count of pod liveness-http is 0
Jun 29 15:42:09.189: INFO: Restart count of pod e2e-tests-container-probe-4zjrl/liveness-http is now 1 (16.081004817s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:42:09.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4zjrl" for this suite.
Jun 29 15:42:15.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:42:15.323: INFO: namespace: e2e-tests-container-probe-4zjrl, resource: bindings, ignored listing per whitelist
Jun 29 15:42:15.555: INFO: namespace e2e-tests-container-probe-4zjrl deletion completed in 6.33671597s

â€¢ [SLOW TEST:26.731 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:42:15.558: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jzm9b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 29 15:42:15.821: INFO: Waiting up to 5m0s for pod "pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-jzm9b" to be "success or failure"
Jun 29 15:42:15.827: INFO: Pod "pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.494726ms
Jun 29 15:42:17.844: INFO: Pod "pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02326346s
STEP: Saw pod success
Jun 29 15:42:17.844: INFO: Pod "pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:42:17.858: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:42:17.900: INFO: Waiting for pod pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:42:17.907: INFO: Pod pod-ffa2b5eb-7bb2-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:42:17.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jzm9b" for this suite.
Jun 29 15:42:23.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:42:24.108: INFO: namespace: e2e-tests-emptydir-jzm9b, resource: bindings, ignored listing per whitelist
Jun 29 15:42:24.175: INFO: namespace e2e-tests-emptydir-jzm9b deletion completed in 6.244780747s

â€¢ [SLOW TEST:8.618 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:42:24.177: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8w54j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jun 29 15:42:24.459: INFO: Waiting up to 5m0s for pod "downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-8w54j" to be "success or failure"
Jun 29 15:42:24.464: INFO: Pod "downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.684722ms
Jun 29 15:42:26.473: INFO: Pod "downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014075343s
STEP: Saw pod success
Jun 29 15:42:26.473: INFO: Pod "downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:42:26.478: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 15:42:26.527: INFO: Waiting for pod downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:42:26.533: INFO: Pod downward-api-04c86131-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:42:26.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8w54j" for this suite.
Jun 29 15:42:32.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:42:32.858: INFO: namespace: e2e-tests-downward-api-8w54j, resource: bindings, ignored listing per whitelist
Jun 29 15:42:32.970: INFO: namespace e2e-tests-downward-api-8w54j deletion completed in 6.421076638s

â€¢ [SLOW TEST:8.793 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:42:32.971: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qszzr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-0a09f84f-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:42:33.284: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-qszzr" to be "success or failure"
Jun 29 15:42:33.289: INFO: Pod "pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.916737ms
Jun 29 15:42:35.331: INFO: Pod "pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046531084s
STEP: Saw pod success
Jun 29 15:42:35.331: INFO: Pod "pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:42:35.338: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:42:35.375: INFO: Waiting for pod pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:42:35.380: INFO: Pod pod-projected-secrets-0a0b4cde-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:42:35.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qszzr" for this suite.
Jun 29 15:42:41.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:42:41.747: INFO: namespace: e2e-tests-projected-qszzr, resource: bindings, ignored listing per whitelist
Jun 29 15:42:41.763: INFO: namespace e2e-tests-projected-qszzr deletion completed in 6.371480265s

â€¢ [SLOW TEST:8.792 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:42:41.764: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5fhmd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-0f48a13a-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:42:42.079: INFO: Waiting up to 5m0s for pod "pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-5fhmd" to be "success or failure"
Jun 29 15:42:42.086: INFO: Pod "pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.975386ms
Jun 29 15:42:44.094: INFO: Pod "pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015019745s
Jun 29 15:42:46.119: INFO: Pod "pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040051287s
STEP: Saw pod success
Jun 29 15:42:46.132: INFO: Pod "pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:42:46.140: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:42:46.177: INFO: Waiting for pod pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:42:46.181: INFO: Pod pod-configmaps-0f49ba62-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:42:46.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5fhmd" for this suite.
Jun 29 15:42:52.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:42:52.326: INFO: namespace: e2e-tests-configmap-5fhmd, resource: bindings, ignored listing per whitelist
Jun 29 15:42:52.681: INFO: namespace e2e-tests-configmap-5fhmd deletion completed in 6.488017042s

â€¢ [SLOW TEST:10.917 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:42:52.682: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-zsz9b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
Jun 29 15:42:54.987: INFO: Pod pod-hostip-15c5b17e-7bb3-11e8-8ddd-da371e372fc2 has hostIP: 10.0.0.7
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:42:54.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zsz9b" for this suite.
Jun 29 15:43:19.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:43:19.191: INFO: namespace: e2e-tests-pods-zsz9b, resource: bindings, ignored listing per whitelist
Jun 29 15:43:19.430: INFO: namespace e2e-tests-pods-zsz9b deletion completed in 24.434153977s

â€¢ [SLOW TEST:26.749 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:43:19.431: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-czl6m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:43:19.770: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-czl6m" to be "success or failure"
Jun 29 15:43:19.778: INFO: Pod "downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.73419ms
Jun 29 15:43:21.786: INFO: Pod "downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015918597s
Jun 29 15:43:23.793: INFO: Pod "downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022774677s
STEP: Saw pod success
Jun 29 15:43:23.793: INFO: Pod "downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:43:23.833: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:43:23.867: INFO: Waiting for pod downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:43:23.900: INFO: Pod downwardapi-volume-25c0736f-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:43:23.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-czl6m" for this suite.
Jun 29 15:43:29.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:43:30.093: INFO: namespace: e2e-tests-projected-czl6m, resource: bindings, ignored listing per whitelist
Jun 29 15:43:30.316: INFO: namespace e2e-tests-projected-czl6m deletion completed in 6.374636899s

â€¢ [SLOW TEST:10.885 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:43:30.316: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2mzrc
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
Jun 29 15:43:30.601: INFO: Waiting up to 5m0s for pod "pod-2c355817-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-2mzrc" to be "success or failure"
Jun 29 15:43:30.618: INFO: Pod "pod-2c355817-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.787279ms
Jun 29 15:43:32.681: INFO: Pod "pod-2c355817-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.069452668s
STEP: Saw pod success
Jun 29 15:43:32.681: INFO: Pod "pod-2c355817-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:43:32.687: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-2c355817-7bb3-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:43:32.780: INFO: Waiting for pod pod-2c355817-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:43:32.786: INFO: Pod pod-2c355817-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:43:32.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2mzrc" for this suite.
Jun 29 15:43:38.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:43:39.152: INFO: namespace: e2e-tests-emptydir-2mzrc, resource: bindings, ignored listing per whitelist
Jun 29 15:43:39.162: INFO: namespace e2e-tests-emptydir-2mzrc deletion completed in 6.329159984s

â€¢ [SLOW TEST:8.846 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:43:39.164: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-q68sm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
Jun 29 15:43:39.474: INFO: Waiting up to 5m0s for pod "client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-containers-q68sm" to be "success or failure"
Jun 29 15:43:39.480: INFO: Pod "client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.64316ms
Jun 29 15:43:41.498: INFO: Pod "client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023214539s
Jun 29 15:43:43.509: INFO: Pod "client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034209659s
STEP: Saw pod success
Jun 29 15:43:43.509: INFO: Pod "client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:43:43.516: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:43:43.549: INFO: Waiting for pod client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:43:43.554: INFO: Pod client-containers-317f8af2-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:43:43.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-q68sm" for this suite.
Jun 29 15:43:49.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:43:49.833: INFO: namespace: e2e-tests-containers-q68sm, resource: bindings, ignored listing per whitelist
Jun 29 15:43:49.889: INFO: namespace e2e-tests-containers-q68sm deletion completed in 6.324746629s

â€¢ [SLOW TEST:10.726 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:43:49.891: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-gldz6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 29 15:43:50.278: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:50.278: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:50.278: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:50.283: INFO: Number of nodes with available pods: 0
Jun 29 15:43:50.283: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:43:51.295: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:51.295: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:51.295: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:51.318: INFO: Number of nodes with available pods: 0
Jun 29 15:43:51.318: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:43:52.345: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:52.345: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:52.345: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:52.352: INFO: Number of nodes with available pods: 2
Jun 29 15:43:52.352: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:43:53.293: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:53.294: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:53.294: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:53.302: INFO: Number of nodes with available pods: 3
Jun 29 15:43:53.302: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun 29 15:43:53.385: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:53.385: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:53.385: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:53.475: INFO: Number of nodes with available pods: 2
Jun 29 15:43:53.476: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:43:54.489: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:54.489: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:54.489: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:54.497: INFO: Number of nodes with available pods: 2
Jun 29 15:43:54.497: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:43:55.490: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:55.490: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:55.490: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:55.501: INFO: Number of nodes with available pods: 2
Jun 29 15:43:55.501: INFO: Node kubernetes-lblackstone-worker-2 is running more than one daemon pod
Jun 29 15:43:56.491: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:56.491: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:56.491: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 15:43:56.502: INFO: Number of nodes with available pods: 3
Jun 29 15:43:56.502: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-gldz6, will wait for the garbage collector to delete the pods
Jun 29 15:43:56.643: INFO: Deleting {extensions DaemonSet} daemon-set took: 19.426757ms
Jun 29 15:43:56.762: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 119.07488ms
Jun 29 15:44:08.785: INFO: Number of nodes with available pods: 0
Jun 29 15:44:08.785: INFO: Number of running nodes: 0, number of available pods: 0
Jun 29 15:44:08.793: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gldz6/daemonsets","resourceVersion":"165115"},"items":null}

Jun 29 15:44:08.798: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gldz6/pods","resourceVersion":"165115"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:44:08.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gldz6" for this suite.
Jun 29 15:44:14.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:44:15.061: INFO: namespace: e2e-tests-daemonsets-gldz6, resource: bindings, ignored listing per whitelist
Jun 29 15:44:15.281: INFO: namespace e2e-tests-daemonsets-gldz6 deletion completed in 6.40421076s

â€¢ [SLOW TEST:25.390 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:44:15.281: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-lxzxh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
Jun 29 15:44:16.109: INFO: created pod pod-service-account-defaultsa
Jun 29 15:44:16.110: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun 29 15:44:16.125: INFO: created pod pod-service-account-mountsa
Jun 29 15:44:16.125: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun 29 15:44:16.133: INFO: created pod pod-service-account-nomountsa
Jun 29 15:44:16.133: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun 29 15:44:16.141: INFO: created pod pod-service-account-defaultsa-mountspec
Jun 29 15:44:16.141: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun 29 15:44:16.202: INFO: created pod pod-service-account-mountsa-mountspec
Jun 29 15:44:16.202: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun 29 15:44:16.218: INFO: created pod pod-service-account-nomountsa-mountspec
Jun 29 15:44:16.218: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun 29 15:44:16.269: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun 29 15:44:16.269: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun 29 15:44:16.280: INFO: created pod pod-service-account-mountsa-nomountspec
Jun 29 15:44:16.280: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun 29 15:44:16.289: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun 29 15:44:16.289: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:44:16.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-lxzxh" for this suite.
Jun 29 15:44:22.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:44:22.549: INFO: namespace: e2e-tests-svcaccounts-lxzxh, resource: bindings, ignored listing per whitelist
Jun 29 15:44:22.606: INFO: namespace e2e-tests-svcaccounts-lxzxh deletion completed in 6.254587489s

â€¢ [SLOW TEST:7.324 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:44:22.607: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s8pfx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 29 15:44:23.056: INFO: Waiting up to 5m0s for pod "pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-s8pfx" to be "success or failure"
Jun 29 15:44:23.064: INFO: Pod "pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.144287ms
Jun 29 15:44:25.073: INFO: Pod "pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01692002s
Jun 29 15:44:27.081: INFO: Pod "pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025259131s
STEP: Saw pod success
Jun 29 15:44:27.081: INFO: Pod "pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:44:27.086: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:44:27.142: INFO: Waiting for pod pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:44:27.146: INFO: Pod pod-4b79df73-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:44:27.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s8pfx" for this suite.
Jun 29 15:44:33.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:44:33.274: INFO: namespace: e2e-tests-emptydir-s8pfx, resource: bindings, ignored listing per whitelist
Jun 29 15:44:33.442: INFO: namespace e2e-tests-emptydir-s8pfx deletion completed in 6.285863806s

â€¢ [SLOW TEST:10.836 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:44:33.443: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-xs977
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 15:44:33.745: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:44:34.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-xs977" for this suite.
Jun 29 15:44:40.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:44:40.775: INFO: namespace: e2e-tests-custom-resource-definition-xs977, resource: bindings, ignored listing per whitelist
Jun 29 15:44:40.889: INFO: namespace e2e-tests-custom-resource-definition-xs977 deletion completed in 6.405030157s

â€¢ [SLOW TEST:7.445 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:44:40.892: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t7lv9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 29 15:44:41.161: INFO: Waiting up to 5m0s for pod "pod-5644283c-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-t7lv9" to be "success or failure"
Jun 29 15:44:41.166: INFO: Pod "pod-5644283c-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.029148ms
Jun 29 15:44:43.212: INFO: Pod "pod-5644283c-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05116492s
Jun 29 15:44:45.221: INFO: Pod "pod-5644283c-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06040649s
STEP: Saw pod success
Jun 29 15:44:45.222: INFO: Pod "pod-5644283c-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:44:45.229: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-5644283c-7bb3-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:44:45.288: INFO: Waiting for pod pod-5644283c-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:44:45.295: INFO: Pod pod-5644283c-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:44:45.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t7lv9" for this suite.
Jun 29 15:44:51.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:44:51.360: INFO: namespace: e2e-tests-emptydir-t7lv9, resource: bindings, ignored listing per whitelist
Jun 29 15:44:51.559: INFO: namespace e2e-tests-emptydir-t7lv9 deletion completed in 6.252257998s

â€¢ [SLOW TEST:10.667 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:44:51.559: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kj7pz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-5c9f7e84-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:44:51.830: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-kj7pz" to be "success or failure"
Jun 29 15:44:51.835: INFO: Pod "pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.620384ms
Jun 29 15:44:53.860: INFO: Pod "pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029378431s
STEP: Saw pod success
Jun 29 15:44:53.860: INFO: Pod "pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:44:53.867: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:44:53.909: INFO: Waiting for pod pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:44:53.915: INFO: Pod pod-projected-configmaps-5ca0a074-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:44:53.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kj7pz" for this suite.
Jun 29 15:44:59.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:45:00.101: INFO: namespace: e2e-tests-projected-kj7pz, resource: bindings, ignored listing per whitelist
Jun 29 15:45:00.151: INFO: namespace e2e-tests-projected-kj7pz deletion completed in 6.218111456s

â€¢ [SLOW TEST:8.592 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:45:00.152: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-tcdtd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-tcdtd
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
Jun 29 15:45:00.425: INFO: Found 0 stateful pods, waiting for 3
Jun 29 15:45:10.447: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 15:45:10.447: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 15:45:10.447: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Jun 29 15:45:10.495: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun 29 15:45:20.561: INFO: Updating stateful set ss2
Jun 29 15:45:20.573: INFO: Waiting for Pod e2e-tests-statefulset-tcdtd/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
Jun 29 15:45:30.729: INFO: Found 1 stateful pods, waiting for 3
Jun 29 15:45:40.751: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 15:45:40.752: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 15:45:40.752: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun 29 15:45:40.791: INFO: Updating stateful set ss2
Jun 29 15:45:40.802: INFO: Waiting for Pod e2e-tests-statefulset-tcdtd/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Jun 29 15:45:50.825: INFO: Waiting for Pod e2e-tests-statefulset-tcdtd/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Jun 29 15:46:00.853: INFO: Updating stateful set ss2
Jun 29 15:46:00.864: INFO: Waiting for StatefulSet e2e-tests-statefulset-tcdtd/ss2 to complete update
Jun 29 15:46:00.864: INFO: Waiting for Pod e2e-tests-statefulset-tcdtd/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jun 29 15:46:10.907: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tcdtd
Jun 29 15:46:10.914: INFO: Scaling statefulset ss2 to 0
Jun 29 15:46:30.957: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 15:46:30.974: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:46:31.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tcdtd" for this suite.
Jun 29 15:46:37.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:46:37.151: INFO: namespace: e2e-tests-statefulset-tcdtd, resource: bindings, ignored listing per whitelist
Jun 29 15:46:37.258: INFO: namespace e2e-tests-statefulset-tcdtd deletion completed in 6.244481083s

â€¢ [SLOW TEST:97.107 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:46:37.261: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dkfqn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jun 29 15:46:42.175: INFO: Successfully updated pod "labelsupdate9baaa5ce-7bb3-11e8-8ddd-da371e372fc2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:46:44.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dkfqn" for this suite.
Jun 29 15:47:08.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:47:08.395: INFO: namespace: e2e-tests-downward-api-dkfqn, resource: bindings, ignored listing per whitelist
Jun 29 15:47:08.463: INFO: namespace e2e-tests-downward-api-dkfqn deletion completed in 24.249875965s

â€¢ [SLOW TEST:31.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:47:08.465: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ptwzw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-ae393f4f-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:47:08.743: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-ptwzw" to be "success or failure"
Jun 29 15:47:08.748: INFO: Pod "pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507751ms
Jun 29 15:47:10.756: INFO: Pod "pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012949884s
Jun 29 15:47:12.763: INFO: Pod "pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020638991s
STEP: Saw pod success
Jun 29 15:47:12.763: INFO: Pod "pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:47:12.769: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:47:12.813: INFO: Waiting for pod pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:47:12.817: INFO: Pod pod-projected-secrets-ae3ac619-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:47:12.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ptwzw" for this suite.
Jun 29 15:47:18.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:47:19.029: INFO: namespace: e2e-tests-projected-ptwzw, resource: bindings, ignored listing per whitelist
Jun 29 15:47:19.061: INFO: namespace e2e-tests-projected-ptwzw deletion completed in 6.234033557s

â€¢ [SLOW TEST:10.597 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:47:19.062: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-g77bm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:47:19.395: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-g77bm" to be "success or failure"
Jun 29 15:47:19.400: INFO: Pod "downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.070472ms
Jun 29 15:47:21.408: INFO: Pod "downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013030814s
Jun 29 15:47:23.417: INFO: Pod "downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022521231s
STEP: Saw pod success
Jun 29 15:47:23.417: INFO: Pod "downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:47:23.430: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:47:23.462: INFO: Waiting for pod downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:47:23.467: INFO: Pod downwardapi-volume-b4943e6f-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:47:23.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g77bm" for this suite.
Jun 29 15:47:29.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:47:29.555: INFO: namespace: e2e-tests-downward-api-g77bm, resource: bindings, ignored listing per whitelist
Jun 29 15:47:29.713: INFO: namespace e2e-tests-downward-api-g77bm deletion completed in 6.236678697s

â€¢ [SLOW TEST:10.652 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:47:29.715: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-spfd5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:47:29.983: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-spfd5" to be "success or failure"
Jun 29 15:47:29.989: INFO: Pod "downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.293524ms
Jun 29 15:47:31.998: INFO: Pod "downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014294502s
Jun 29 15:47:34.005: INFO: Pod "downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021786537s
STEP: Saw pod success
Jun 29 15:47:34.005: INFO: Pod "downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:47:34.014: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:47:34.051: INFO: Waiting for pod downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:47:34.057: INFO: Pod downwardapi-volume-bae435bd-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:47:34.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-spfd5" for this suite.
Jun 29 15:47:40.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:47:40.280: INFO: namespace: e2e-tests-downward-api-spfd5, resource: bindings, ignored listing per whitelist
Jun 29 15:47:40.336: INFO: namespace e2e-tests-downward-api-spfd5 deletion completed in 6.269398747s

â€¢ [SLOW TEST:10.621 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:47:40.337: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-tf7zq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 15:47:40.614: INFO: (0) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 11.257124ms)
Jun 29 15:47:40.622: INFO: (1) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.364434ms)
Jun 29 15:47:40.631: INFO: (2) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.38468ms)
Jun 29 15:47:40.640: INFO: (3) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.829399ms)
Jun 29 15:47:40.649: INFO: (4) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.885884ms)
Jun 29 15:47:40.673: INFO: (5) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 24.069778ms)
Jun 29 15:47:40.683: INFO: (6) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 10.504249ms)
Jun 29 15:47:40.691: INFO: (7) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.14152ms)
Jun 29 15:47:40.698: INFO: (8) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.118597ms)
Jun 29 15:47:40.704: INFO: (9) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 6.744195ms)
Jun 29 15:47:40.717: INFO: (10) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 12.186417ms)
Jun 29 15:47:40.725: INFO: (11) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.286184ms)
Jun 29 15:47:40.733: INFO: (12) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.539451ms)
Jun 29 15:47:40.741: INFO: (13) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.901153ms)
Jun 29 15:47:40.748: INFO: (14) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.449636ms)
Jun 29 15:47:40.756: INFO: (15) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.617536ms)
Jun 29 15:47:40.764: INFO: (16) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 8.550226ms)
Jun 29 15:47:40.781: INFO: (17) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 16.489319ms)
Jun 29 15:47:40.793: INFO: (18) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 11.920093ms)
Jun 29 15:47:40.801: INFO: (19) /api/v1/nodes/kubernetes-lblackstone-worker-0:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="es-cluster-autoscale... (200; 7.792782ms)
[AfterEach] version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:47:40.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-tf7zq" for this suite.
Jun 29 15:47:46.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:47:46.944: INFO: namespace: e2e-tests-proxy-tf7zq, resource: bindings, ignored listing per whitelist
Jun 29 15:47:47.071: INFO: namespace e2e-tests-proxy-tf7zq deletion completed in 6.259614056s

â€¢ [SLOW TEST:6.734 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:47:47.074: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-78kkg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 29 15:47:47.320: INFO: Waiting up to 5m0s for pod "pod-c5398838-7bb3-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-78kkg" to be "success or failure"
Jun 29 15:47:47.327: INFO: Pod "pod-c5398838-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.517145ms
Jun 29 15:47:49.342: INFO: Pod "pod-c5398838-7bb3-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021909346s
Jun 29 15:47:51.350: INFO: Pod "pod-c5398838-7bb3-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030152771s
STEP: Saw pod success
Jun 29 15:47:51.350: INFO: Pod "pod-c5398838-7bb3-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:47:51.358: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-c5398838-7bb3-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:47:51.411: INFO: Waiting for pod pod-c5398838-7bb3-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:47:51.417: INFO: Pod pod-c5398838-7bb3-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:47:51.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-78kkg" for this suite.
Jun 29 15:47:57.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:47:57.635: INFO: namespace: e2e-tests-emptydir-78kkg, resource: bindings, ignored listing per whitelist
Jun 29 15:47:57.731: INFO: namespace e2e-tests-emptydir-78kkg deletion completed in 6.3041899s

â€¢ [SLOW TEST:10.657 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:47:57.731: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-pcf77
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-cb9812e3-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating configMap with name cm-test-opt-upd-cb98132f-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-cb9812e3-7bb3-11e8-8ddd-da371e372fc2
STEP: Updating configmap cm-test-opt-upd-cb98132f-7bb3-11e8-8ddd-da371e372fc2
STEP: Creating configMap with name cm-test-opt-create-cb981347-7bb3-11e8-8ddd-da371e372fc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:49:33.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pcf77" for this suite.
Jun 29 15:49:57.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:49:57.396: INFO: namespace: e2e-tests-configmap-pcf77, resource: bindings, ignored listing per whitelist
Jun 29 15:49:57.479: INFO: namespace e2e-tests-configmap-pcf77 deletion completed in 24.269324931s

â€¢ [SLOW TEST:119.748 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:49:57.480: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-gccfn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-4x8vc in namespace e2e-tests-proxy-gccfn
I0629 15:49:57.764616      17 runners.go:177] Created replication controller with name: proxy-service-4x8vc, namespace: e2e-tests-proxy-gccfn, replica count: 1
I0629 15:49:58.816711      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0629 15:49:59.817031      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0629 15:50:00.822594      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0629 15:50:01.822915      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0629 15:50:02.823267      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0629 15:50:03.823973      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0629 15:50:04.824477      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0629 15:50:05.824767      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0629 15:50:06.828903      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0629 15:50:07.829930      17 runners.go:177] proxy-service-4x8vc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 29 15:50:07.848: INFO: setup took 10.112910225s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun 29 15:50:07.869: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 20.456881ms)
Jun 29 15:50:07.875: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 25.521395ms)
Jun 29 15:50:07.876: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 26.518662ms)
Jun 29 15:50:07.876: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 26.296602ms)
Jun 29 15:50:07.876: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 26.632001ms)
Jun 29 15:50:07.876: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 26.99828ms)
Jun 29 15:50:07.877: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 28.40085ms)
Jun 29 15:50:07.877: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 27.531347ms)
Jun 29 15:50:07.877: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 27.858684ms)
Jun 29 15:50:07.881: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 32.700542ms)
Jun 29 15:50:07.883: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 34.490251ms)
Jun 29 15:50:07.891: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 41.750628ms)
Jun 29 15:50:07.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 42.942972ms)
Jun 29 15:50:07.893: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 44.735522ms)
Jun 29 15:50:07.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 46.168413ms)
Jun 29 15:50:07.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 45.784559ms)
Jun 29 15:50:07.907: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 11.443646ms)
Jun 29 15:50:07.909: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 13.244022ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 33.779426ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 34.336264ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 34.610835ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 34.232132ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 34.347884ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 34.17753ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 34.560014ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 34.405259ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 34.577698ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 34.676139ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 34.781088ms)
Jun 29 15:50:07.930: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 34.490456ms)
Jun 29 15:50:07.931: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 35.02014ms)
Jun 29 15:50:07.931: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 34.818859ms)
Jun 29 15:50:07.946: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 14.686753ms)
Jun 29 15:50:07.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 18.397612ms)
Jun 29 15:50:07.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 17.825408ms)
Jun 29 15:50:07.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 17.746743ms)
Jun 29 15:50:07.953: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 20.818687ms)
Jun 29 15:50:07.953: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 21.987196ms)
Jun 29 15:50:07.954: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 21.679742ms)
Jun 29 15:50:07.955: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 22.882633ms)
Jun 29 15:50:07.955: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 22.992415ms)
Jun 29 15:50:07.956: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 23.361327ms)
Jun 29 15:50:07.956: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 23.341653ms)
Jun 29 15:50:07.956: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 23.762754ms)
Jun 29 15:50:07.956: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 24.399074ms)
Jun 29 15:50:07.956: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 23.720206ms)
Jun 29 15:50:07.957: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 24.7945ms)
Jun 29 15:50:07.957: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 24.53172ms)
Jun 29 15:50:07.970: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 13.203207ms)
Jun 29 15:50:07.971: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 13.971891ms)
Jun 29 15:50:07.971: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 13.856322ms)
Jun 29 15:50:07.973: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 15.280853ms)
Jun 29 15:50:07.973: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 15.921895ms)
Jun 29 15:50:07.975: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 18.057937ms)
Jun 29 15:50:07.976: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 18.228404ms)
Jun 29 15:50:07.976: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 18.193627ms)
Jun 29 15:50:07.976: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 18.322632ms)
Jun 29 15:50:07.976: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 18.7179ms)
Jun 29 15:50:07.976: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 19.197178ms)
Jun 29 15:50:07.976: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 19.051945ms)
Jun 29 15:50:07.978: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 20.706127ms)
Jun 29 15:50:07.978: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 20.991802ms)
Jun 29 15:50:07.978: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 20.926501ms)
Jun 29 15:50:07.978: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 21.296795ms)
Jun 29 15:50:07.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 11.023179ms)
Jun 29 15:50:07.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 10.57302ms)
Jun 29 15:50:07.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 10.34099ms)
Jun 29 15:50:07.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 11.182815ms)
Jun 29 15:50:07.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 11.447222ms)
Jun 29 15:50:07.993: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 13.662867ms)
Jun 29 15:50:07.993: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 13.572343ms)
Jun 29 15:50:07.993: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 14.202985ms)
Jun 29 15:50:07.993: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 14.883326ms)
Jun 29 15:50:07.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 15.932621ms)
Jun 29 15:50:07.995: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 16.768253ms)
Jun 29 15:50:07.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 16.793858ms)
Jun 29 15:50:07.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 17.345402ms)
Jun 29 15:50:07.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 17.146838ms)
Jun 29 15:50:07.996: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 17.296606ms)
Jun 29 15:50:07.997: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 18.100088ms)
Jun 29 15:50:08.005: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 7.345585ms)
Jun 29 15:50:08.012: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 15.223785ms)
Jun 29 15:50:08.015: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 16.848902ms)
Jun 29 15:50:08.015: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 17.940224ms)
Jun 29 15:50:08.015: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 18.032322ms)
Jun 29 15:50:08.015: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 17.261479ms)
Jun 29 15:50:08.017: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 18.999079ms)
Jun 29 15:50:08.017: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 19.117692ms)
Jun 29 15:50:08.018: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 19.45108ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 23.624137ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 23.947973ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 24.584945ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 24.484709ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 24.170979ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 24.734397ms)
Jun 29 15:50:08.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 24.849469ms)
Jun 29 15:50:08.044: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 21.009311ms)
Jun 29 15:50:08.045: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 22.007368ms)
Jun 29 15:50:08.045: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 21.637764ms)
Jun 29 15:50:08.045: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 22.400486ms)
Jun 29 15:50:08.045: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 23.060158ms)
Jun 29 15:50:08.091: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 66.630643ms)
Jun 29 15:50:08.092: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 66.826178ms)
Jun 29 15:50:08.092: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 68.243456ms)
Jun 29 15:50:08.092: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 67.677658ms)
Jun 29 15:50:08.092: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 69.790409ms)
Jun 29 15:50:08.094: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 69.658758ms)
Jun 29 15:50:08.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 72.62469ms)
Jun 29 15:50:08.095: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 71.022906ms)
Jun 29 15:50:08.096: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 70.485041ms)
Jun 29 15:50:08.096: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 71.41918ms)
Jun 29 15:50:08.096: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 72.192643ms)
Jun 29 15:50:08.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 9.648144ms)
Jun 29 15:50:08.106: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 10.274642ms)
Jun 29 15:50:08.110: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 13.043198ms)
Jun 29 15:50:08.110: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 13.262891ms)
Jun 29 15:50:08.111: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 13.802064ms)
Jun 29 15:50:08.111: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.412926ms)
Jun 29 15:50:08.113: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 16.0188ms)
Jun 29 15:50:08.113: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 16.413653ms)
Jun 29 15:50:08.113: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 16.845544ms)
Jun 29 15:50:08.113: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 16.652083ms)
Jun 29 15:50:08.114: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 17.25382ms)
Jun 29 15:50:08.114: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 17.131712ms)
Jun 29 15:50:08.115: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 17.433401ms)
Jun 29 15:50:08.116: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 19.060974ms)
Jun 29 15:50:08.116: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 19.645368ms)
Jun 29 15:50:08.118: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 20.74376ms)
Jun 29 15:50:08.129: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 11.094533ms)
Jun 29 15:50:08.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 10.453427ms)
Jun 29 15:50:08.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 12.052998ms)
Jun 29 15:50:08.130: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 12.146847ms)
Jun 29 15:50:08.133: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 14.35655ms)
Jun 29 15:50:08.133: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 14.943746ms)
Jun 29 15:50:08.133: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 15.399809ms)
Jun 29 15:50:08.134: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 15.648772ms)
Jun 29 15:50:08.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 17.992182ms)
Jun 29 15:50:08.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 18.384082ms)
Jun 29 15:50:08.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 18.072037ms)
Jun 29 15:50:08.137: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 18.444879ms)
Jun 29 15:50:08.138: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 19.51354ms)
Jun 29 15:50:08.138: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 19.820651ms)
Jun 29 15:50:08.139: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 20.362612ms)
Jun 29 15:50:08.146: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 27.611571ms)
Jun 29 15:50:08.155: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 9.072002ms)
Jun 29 15:50:08.157: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 10.637571ms)
Jun 29 15:50:08.157: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 10.327458ms)
Jun 29 15:50:08.157: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 10.817401ms)
Jun 29 15:50:08.157: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 10.435234ms)
Jun 29 15:50:08.159: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 12.671594ms)
Jun 29 15:50:08.159: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 12.293966ms)
Jun 29 15:50:08.160: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 14.121991ms)
Jun 29 15:50:08.160: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 14.088346ms)
Jun 29 15:50:08.161: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 14.66278ms)
Jun 29 15:50:08.162: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 14.470934ms)
Jun 29 15:50:08.162: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 15.328509ms)
Jun 29 15:50:08.162: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 15.224752ms)
Jun 29 15:50:08.163: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 16.504267ms)
Jun 29 15:50:08.164: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 17.16789ms)
Jun 29 15:50:08.165: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 18.224959ms)
Jun 29 15:50:08.173: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 7.673833ms)
Jun 29 15:50:08.175: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 9.75803ms)
Jun 29 15:50:08.177: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 11.669986ms)
Jun 29 15:50:08.177: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 11.642683ms)
Jun 29 15:50:08.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 12.735196ms)
Jun 29 15:50:08.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 12.901329ms)
Jun 29 15:50:08.180: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 14.889112ms)
Jun 29 15:50:08.182: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 16.18865ms)
Jun 29 15:50:08.182: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 16.360861ms)
Jun 29 15:50:08.182: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 16.667914ms)
Jun 29 15:50:08.183: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 17.441868ms)
Jun 29 15:50:08.183: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 17.756854ms)
Jun 29 15:50:08.183: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 17.727943ms)
Jun 29 15:50:08.184: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 18.65473ms)
Jun 29 15:50:08.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 20.05705ms)
Jun 29 15:50:08.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 19.955758ms)
Jun 29 15:50:08.200: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.461422ms)
Jun 29 15:50:08.201: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 14.666497ms)
Jun 29 15:50:08.201: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 14.603661ms)
Jun 29 15:50:08.201: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 14.05548ms)
Jun 29 15:50:08.204: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 18.289055ms)
Jun 29 15:50:08.205: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 18.253877ms)
Jun 29 15:50:08.205: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 18.09242ms)
Jun 29 15:50:08.206: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 18.931064ms)
Jun 29 15:50:08.206: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 18.86031ms)
Jun 29 15:50:08.206: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 18.855089ms)
Jun 29 15:50:08.206: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 19.552892ms)
Jun 29 15:50:08.211: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 24.648342ms)
Jun 29 15:50:08.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 29.628208ms)
Jun 29 15:50:08.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 29.762664ms)
Jun 29 15:50:08.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 29.124006ms)
Jun 29 15:50:08.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 29.536499ms)
Jun 29 15:50:08.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 13.526543ms)
Jun 29 15:50:08.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.332405ms)
Jun 29 15:50:08.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 13.734778ms)
Jun 29 15:50:08.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 13.611946ms)
Jun 29 15:50:08.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 14.195724ms)
Jun 29 15:50:08.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.372259ms)
Jun 29 15:50:08.232: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 14.783688ms)
Jun 29 15:50:08.232: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 15.153797ms)
Jun 29 15:50:08.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 16.041963ms)
Jun 29 15:50:08.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 15.440705ms)
Jun 29 15:50:08.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 15.700916ms)
Jun 29 15:50:08.234: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 17.291424ms)
Jun 29 15:50:08.235: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 17.94417ms)
Jun 29 15:50:08.236: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 18.22113ms)
Jun 29 15:50:08.236: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 19.677998ms)
Jun 29 15:50:08.240: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 22.573154ms)
Jun 29 15:50:08.252: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 11.78139ms)
Jun 29 15:50:08.252: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 11.761201ms)
Jun 29 15:50:08.254: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 13.402798ms)
Jun 29 15:50:08.255: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.774139ms)
Jun 29 15:50:08.255: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 14.947178ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 21.553849ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 21.712535ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 21.150386ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 21.602217ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 21.543415ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 21.72302ms)
Jun 29 15:50:08.262: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 21.478617ms)
Jun 29 15:50:08.263: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 22.235029ms)
Jun 29 15:50:08.263: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 22.447095ms)
Jun 29 15:50:08.263: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 23.049533ms)
Jun 29 15:50:08.264: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 23.99727ms)
Jun 29 15:50:08.276: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 11.731283ms)
Jun 29 15:50:08.277: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 12.930528ms)
Jun 29 15:50:08.278: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 13.701197ms)
Jun 29 15:50:08.278: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 13.702688ms)
Jun 29 15:50:08.278: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 13.900905ms)
Jun 29 15:50:08.279: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.377447ms)
Jun 29 15:50:08.279: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 14.660975ms)
Jun 29 15:50:08.280: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 15.500197ms)
Jun 29 15:50:08.280: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 15.38312ms)
Jun 29 15:50:08.280: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 15.887626ms)
Jun 29 15:50:08.280: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 15.17676ms)
Jun 29 15:50:08.280: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 15.613162ms)
Jun 29 15:50:08.281: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 16.072748ms)
Jun 29 15:50:08.282: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 17.451102ms)
Jun 29 15:50:08.284: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 19.824373ms)
Jun 29 15:50:08.284: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 20.098637ms)
Jun 29 15:50:08.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 11.196642ms)
Jun 29 15:50:08.299: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 13.864552ms)
Jun 29 15:50:08.299: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 14.06446ms)
Jun 29 15:50:08.299: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 13.649928ms)
Jun 29 15:50:08.299: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 14.23352ms)
Jun 29 15:50:08.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 14.488601ms)
Jun 29 15:50:08.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 14.431332ms)
Jun 29 15:50:08.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 14.334116ms)
Jun 29 15:50:08.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 14.647557ms)
Jun 29 15:50:08.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 15.177563ms)
Jun 29 15:50:08.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 14.850466ms)
Jun 29 15:50:08.302: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 16.979546ms)
Jun 29 15:50:08.302: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 17.580961ms)
Jun 29 15:50:08.302: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 17.90138ms)
Jun 29 15:50:08.303: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 18.131463ms)
Jun 29 15:50:08.303: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 18.536597ms)
Jun 29 15:50:08.315: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 11.030722ms)
Jun 29 15:50:08.316: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 11.550184ms)
Jun 29 15:50:08.316: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 12.358817ms)
Jun 29 15:50:08.317: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 12.980168ms)
Jun 29 15:50:08.327: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 22.184734ms)
Jun 29 15:50:08.327: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 22.144762ms)
Jun 29 15:50:08.327: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 22.050464ms)
Jun 29 15:50:08.330: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 26.137694ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 33.954789ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 34.118044ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 33.371982ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 33.594238ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 33.009864ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 33.205898ms)
Jun 29 15:50:08.338: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 33.31373ms)
Jun 29 15:50:08.339: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 33.09607ms)
Jun 29 15:50:08.347: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 8.833241ms)
Jun 29 15:50:08.348: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 8.92876ms)
Jun 29 15:50:08.350: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 10.96312ms)
Jun 29 15:50:08.352: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 12.964914ms)
Jun 29 15:50:08.354: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 14.928593ms)
Jun 29 15:50:08.355: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 15.56061ms)
Jun 29 15:50:08.355: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 15.482749ms)
Jun 29 15:50:08.357: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 17.554887ms)
Jun 29 15:50:08.357: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 18.07369ms)
Jun 29 15:50:08.357: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 18.508841ms)
Jun 29 15:50:08.358: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 18.937861ms)
Jun 29 15:50:08.358: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 18.474132ms)
Jun 29 15:50:08.358: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 19.140456ms)
Jun 29 15:50:08.359: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 19.771862ms)
Jun 29 15:50:08.359: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 19.75194ms)
Jun 29 15:50:08.359: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 20.290214ms)
Jun 29 15:50:08.367: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 7.566254ms)
Jun 29 15:50:08.371: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 11.645306ms)
Jun 29 15:50:08.373: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 12.525836ms)
Jun 29 15:50:08.373: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 12.858376ms)
Jun 29 15:50:08.373: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 13.520504ms)
Jun 29 15:50:08.375: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 15.637703ms)
Jun 29 15:50:08.376: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 15.830196ms)
Jun 29 15:50:08.376: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 15.885684ms)
Jun 29 15:50:08.376: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 16.354039ms)
Jun 29 15:50:08.377: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 16.424144ms)
Jun 29 15:50:08.377: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 17.054649ms)
Jun 29 15:50:08.377: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 16.941041ms)
Jun 29 15:50:08.378: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 17.356794ms)
Jun 29 15:50:08.378: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 17.630114ms)
Jun 29 15:50:08.379: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 18.949ms)
Jun 29 15:50:08.379: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 19.409103ms)
Jun 29 15:50:08.389: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m/proxy/rewriteme"... (200; 9.688581ms)
Jun 29 15:50:08.394: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:1080/proxy/rewri... (200; 14.519248ms)
Jun 29 15:50:08.394: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname2/proxy/: bar (200; 14.904883ms)
Jun 29 15:50:08.395: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:1080/proxy/... (200; 15.477548ms)
Jun 29 15:50:08.396: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 15.378413ms)
Jun 29 15:50:08.396: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:443/proxy/... (200; 15.767123ms)
Jun 29 15:50:08.396: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:462/proxy/: tls qux (200; 17.279304ms)
Jun 29 15:50:08.397: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname2/proxy/: tls qux (200; 16.967274ms)
Jun 29 15:50:08.397: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname1/proxy/: foo (200; 17.246645ms)
Jun 29 15:50:08.397: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/https:proxy-service-4x8vc-d7t5m:460/proxy/: tls baz (200; 15.780127ms)
Jun 29 15:50:08.397: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 16.092153ms)
Jun 29 15:50:08.401: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/https:proxy-service-4x8vc:tlsportname1/proxy/: tls baz (200; 19.922054ms)
Jun 29 15:50:08.401: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/http:proxy-service-4x8vc-d7t5m:162/proxy/: bar (200; 20.338287ms)
Jun 29 15:50:08.401: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/pods/proxy-service-4x8vc-d7t5m:160/proxy/: foo (200; 21.367213ms)
Jun 29 15:50:08.402: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/http:proxy-service-4x8vc:portname1/proxy/: foo (200; 20.979903ms)
Jun 29 15:50:08.402: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gccfn/services/proxy-service-4x8vc:portname2/proxy/: bar (200; 21.206975ms)
STEP: deleting { ReplicationController} proxy-service-4x8vc in namespace e2e-tests-proxy-gccfn, will wait for the garbage collector to delete the pods
Jun 29 15:50:08.470: INFO: Deleting { ReplicationController} proxy-service-4x8vc took: 10.961886ms
Jun 29 15:50:08.570: INFO: Terminating { ReplicationController} proxy-service-4x8vc pods took: 100.3095ms
[AfterEach] version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:50:10.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gccfn" for this suite.
Jun 29 15:50:16.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:50:16.335: INFO: namespace: e2e-tests-proxy-gccfn, resource: bindings, ignored listing per whitelist
Jun 29 15:50:16.566: INFO: namespace e2e-tests-proxy-gccfn deletion completed in 6.284016194s

â€¢ [SLOW TEST:19.086 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:50:16.566: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-829hn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-1e5b8a08-7bb4-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 15:50:16.875: INFO: Waiting up to 5m0s for pod "pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-829hn" to be "success or failure"
Jun 29 15:50:16.889: INFO: Pod "pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.851684ms
Jun 29 15:50:18.903: INFO: Pod "pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02821521s
Jun 29 15:50:20.912: INFO: Pod "pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037159751s
STEP: Saw pod success
Jun 29 15:50:20.912: INFO: Pod "pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:50:20.918: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 15:50:20.954: INFO: Waiting for pod pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:50:20.958: INFO: Pod pod-secrets-1e5d8fda-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:50:20.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-829hn" for this suite.
Jun 29 15:50:26.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:50:27.050: INFO: namespace: e2e-tests-secrets-829hn, resource: bindings, ignored listing per whitelist
Jun 29 15:50:27.205: INFO: namespace e2e-tests-secrets-829hn deletion completed in 6.236292714s

â€¢ [SLOW TEST:10.639 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:50:27.207: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xtvxv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 29 15:50:27.516: INFO: Waiting up to 5m0s for pod "pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-xtvxv" to be "success or failure"
Jun 29 15:50:27.524: INFO: Pod "pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.026463ms
Jun 29 15:50:29.550: INFO: Pod "pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033211027s
STEP: Saw pod success
Jun 29 15:50:29.550: INFO: Pod "pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:50:29.558: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:50:29.630: INFO: Waiting for pod pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:50:29.645: INFO: Pod pod-24b56a90-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:50:29.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xtvxv" for this suite.
Jun 29 15:50:35.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:50:35.798: INFO: namespace: e2e-tests-emptydir-xtvxv, resource: bindings, ignored listing per whitelist
Jun 29 15:50:35.961: INFO: namespace e2e-tests-emptydir-xtvxv deletion completed in 6.297110572s

â€¢ [SLOW TEST:8.754 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:50:35.963: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-6pkrz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-6pkrz
I0629 15:50:36.243252      17 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-6pkrz, replica count: 1
I0629 15:50:37.303033      17 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0629 15:50:38.303414      17 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 29 15:50:38.425: INFO: Created: latency-svc-7xggj
Jun 29 15:50:38.451: INFO: Got endpoints: latency-svc-7xggj [47.074303ms]
Jun 29 15:50:38.474: INFO: Created: latency-svc-4wpvm
Jun 29 15:50:38.477: INFO: Got endpoints: latency-svc-4wpvm [25.665732ms]
Jun 29 15:50:38.481: INFO: Created: latency-svc-f77s5
Jun 29 15:50:38.487: INFO: Created: latency-svc-2k2fr
Jun 29 15:50:38.493: INFO: Got endpoints: latency-svc-f77s5 [40.810453ms]
Jun 29 15:50:38.497: INFO: Got endpoints: latency-svc-2k2fr [44.636909ms]
Jun 29 15:50:38.497: INFO: Created: latency-svc-l7cvl
Jun 29 15:50:38.504: INFO: Got endpoints: latency-svc-l7cvl [52.31233ms]
Jun 29 15:50:38.506: INFO: Created: latency-svc-ss44n
Jun 29 15:50:38.515: INFO: Got endpoints: latency-svc-ss44n [56.304169ms]
Jun 29 15:50:38.527: INFO: Created: latency-svc-km8tt
Jun 29 15:50:38.527: INFO: Created: latency-svc-d5bfk
Jun 29 15:50:38.540: INFO: Got endpoints: latency-svc-d5bfk [80.21288ms]
Jun 29 15:50:38.540: INFO: Got endpoints: latency-svc-km8tt [80.896144ms]
Jun 29 15:50:38.541: INFO: Created: latency-svc-m2db9
Jun 29 15:50:38.541: INFO: Created: latency-svc-7hcfp
Jun 29 15:50:38.550: INFO: Created: latency-svc-hckd8
Jun 29 15:50:38.550: INFO: Got endpoints: latency-svc-m2db9 [91.18135ms]
Jun 29 15:50:38.552: INFO: Got endpoints: latency-svc-7hcfp [92.595455ms]
Jun 29 15:50:38.557: INFO: Created: latency-svc-75rpq
Jun 29 15:50:38.561: INFO: Got endpoints: latency-svc-hckd8 [101.656895ms]
Jun 29 15:50:38.570: INFO: Got endpoints: latency-svc-75rpq [109.919121ms]
Jun 29 15:50:38.570: INFO: Created: latency-svc-26t9d
Jun 29 15:50:38.571: INFO: Got endpoints: latency-svc-26t9d [110.81292ms]
Jun 29 15:50:38.579: INFO: Created: latency-svc-kcgqr
Jun 29 15:50:38.583: INFO: Created: latency-svc-bzv9c
Jun 29 15:50:38.584: INFO: Got endpoints: latency-svc-kcgqr [124.996788ms]
Jun 29 15:50:38.592: INFO: Got endpoints: latency-svc-bzv9c [132.10266ms]
Jun 29 15:50:38.592: INFO: Created: latency-svc-hbh8s
Jun 29 15:50:38.594: INFO: Got endpoints: latency-svc-hbh8s [134.698582ms]
Jun 29 15:50:38.599: INFO: Created: latency-svc-pmhm8
Jun 29 15:50:38.606: INFO: Got endpoints: latency-svc-pmhm8 [128.550299ms]
Jun 29 15:50:38.612: INFO: Created: latency-svc-5ck64
Jun 29 15:50:38.625: INFO: Got endpoints: latency-svc-5ck64 [127.881075ms]
Jun 29 15:50:38.632: INFO: Created: latency-svc-zbpb7
Jun 29 15:50:38.633: INFO: Got endpoints: latency-svc-zbpb7 [140.500693ms]
Jun 29 15:50:38.648: INFO: Created: latency-svc-4zvkb
Jun 29 15:50:38.659: INFO: Got endpoints: latency-svc-4zvkb [154.172383ms]
Jun 29 15:50:38.708: INFO: Created: latency-svc-dfdsj
Jun 29 15:50:38.708: INFO: Got endpoints: latency-svc-dfdsj [83.502289ms]
Jun 29 15:50:38.716: INFO: Created: latency-svc-j8hwd
Jun 29 15:50:38.723: INFO: Got endpoints: latency-svc-j8hwd [207.472728ms]
Jun 29 15:50:38.728: INFO: Created: latency-svc-d2c8s
Jun 29 15:50:38.731: INFO: Got endpoints: latency-svc-d2c8s [191.674068ms]
Jun 29 15:50:38.733: INFO: Created: latency-svc-n4mlg
Jun 29 15:50:38.742: INFO: Created: latency-svc-kw9pt
Jun 29 15:50:38.742: INFO: Got endpoints: latency-svc-n4mlg [201.748822ms]
Jun 29 15:50:38.744: INFO: Got endpoints: latency-svc-kw9pt [194.174384ms]
Jun 29 15:50:38.748: INFO: Created: latency-svc-gdzmv
Jun 29 15:50:38.755: INFO: Created: latency-svc-82h4h
Jun 29 15:50:38.759: INFO: Got endpoints: latency-svc-gdzmv [207.182033ms]
Jun 29 15:50:38.763: INFO: Created: latency-svc-wd4kt
Jun 29 15:50:38.769: INFO: Created: latency-svc-fxx2t
Jun 29 15:50:38.775: INFO: Got endpoints: latency-svc-fxx2t [204.090928ms]
Jun 29 15:50:38.775: INFO: Got endpoints: latency-svc-82h4h [213.898063ms]
Jun 29 15:50:38.776: INFO: Got endpoints: latency-svc-wd4kt [205.953444ms]
Jun 29 15:50:38.781: INFO: Created: latency-svc-tdtqk
Jun 29 15:50:38.787: INFO: Created: latency-svc-wlpmf
Jun 29 15:50:38.789: INFO: Got endpoints: latency-svc-tdtqk [205.341723ms]
Jun 29 15:50:38.796: INFO: Got endpoints: latency-svc-wlpmf [204.296527ms]
Jun 29 15:50:38.796: INFO: Created: latency-svc-tc4cd
Jun 29 15:50:38.797: INFO: Got endpoints: latency-svc-tc4cd [202.361041ms]
Jun 29 15:50:38.806: INFO: Created: latency-svc-pq67t
Jun 29 15:50:38.812: INFO: Created: latency-svc-t8944
Jun 29 15:50:38.815: INFO: Got endpoints: latency-svc-pq67t [208.397223ms]
Jun 29 15:50:38.820: INFO: Got endpoints: latency-svc-t8944 [186.848789ms]
Jun 29 15:50:38.820: INFO: Created: latency-svc-gxnv8
Jun 29 15:50:38.826: INFO: Got endpoints: latency-svc-gxnv8 [166.697769ms]
Jun 29 15:50:38.837: INFO: Created: latency-svc-7zjnf
Jun 29 15:50:38.839: INFO: Created: latency-svc-jmbb6
Jun 29 15:50:38.846: INFO: Got endpoints: latency-svc-7zjnf [137.872356ms]
Jun 29 15:50:38.847: INFO: Got endpoints: latency-svc-jmbb6 [123.8267ms]
Jun 29 15:50:38.853: INFO: Created: latency-svc-ssxd9
Jun 29 15:50:38.855: INFO: Created: latency-svc-279vp
Jun 29 15:50:38.858: INFO: Got endpoints: latency-svc-ssxd9 [126.838452ms]
Jun 29 15:50:38.865: INFO: Created: latency-svc-wp9kd
Jun 29 15:50:38.875: INFO: Created: latency-svc-4c5f4
Jun 29 15:50:38.879: INFO: Created: latency-svc-wsnh5
Jun 29 15:50:38.891: INFO: Created: latency-svc-xckg2
Jun 29 15:50:38.893: INFO: Got endpoints: latency-svc-279vp [150.399992ms]
Jun 29 15:50:38.898: INFO: Created: latency-svc-sxwrv
Jun 29 15:50:38.905: INFO: Created: latency-svc-m6fqh
Jun 29 15:50:38.914: INFO: Created: latency-svc-zqzr2
Jun 29 15:50:38.925: INFO: Created: latency-svc-z9htc
Jun 29 15:50:38.937: INFO: Created: latency-svc-5ls4w
Jun 29 15:50:38.945: INFO: Got endpoints: latency-svc-wp9kd [200.384056ms]
Jun 29 15:50:38.948: INFO: Created: latency-svc-4h755
Jun 29 15:50:38.964: INFO: Created: latency-svc-hkmh5
Jun 29 15:50:38.992: INFO: Got endpoints: latency-svc-4c5f4 [232.05501ms]
Jun 29 15:50:38.997: INFO: Created: latency-svc-shn5s
Jun 29 15:50:38.997: INFO: Created: latency-svc-mn4tw
Jun 29 15:50:39.004: INFO: Created: latency-svc-4rm59
Jun 29 15:50:39.004: INFO: Created: latency-svc-cgxst
Jun 29 15:50:39.004: INFO: Created: latency-svc-599vk
Jun 29 15:50:39.010: INFO: Created: latency-svc-h8dhd
Jun 29 15:50:39.040: INFO: Got endpoints: latency-svc-wsnh5 [265.16729ms]
Jun 29 15:50:39.059: INFO: Created: latency-svc-c6nhw
Jun 29 15:50:39.090: INFO: Got endpoints: latency-svc-xckg2 [314.663588ms]
Jun 29 15:50:39.107: INFO: Created: latency-svc-dlvb6
Jun 29 15:50:39.140: INFO: Got endpoints: latency-svc-sxwrv [364.956278ms]
Jun 29 15:50:39.161: INFO: Created: latency-svc-z87cc
Jun 29 15:50:39.191: INFO: Got endpoints: latency-svc-m6fqh [395.48377ms]
Jun 29 15:50:39.209: INFO: Created: latency-svc-dqdbt
Jun 29 15:50:39.240: INFO: Got endpoints: latency-svc-zqzr2 [443.410472ms]
Jun 29 15:50:39.257: INFO: Created: latency-svc-xffjd
Jun 29 15:50:39.289: INFO: Got endpoints: latency-svc-z9htc [499.911315ms]
Jun 29 15:50:39.306: INFO: Created: latency-svc-flz2z
Jun 29 15:50:39.342: INFO: Got endpoints: latency-svc-5ls4w [527.230434ms]
Jun 29 15:50:39.357: INFO: Created: latency-svc-46qzk
Jun 29 15:50:39.391: INFO: Got endpoints: latency-svc-4h755 [570.540958ms]
Jun 29 15:50:39.405: INFO: Created: latency-svc-6hrwv
Jun 29 15:50:39.441: INFO: Got endpoints: latency-svc-hkmh5 [615.488536ms]
Jun 29 15:50:39.462: INFO: Created: latency-svc-kw7lc
Jun 29 15:50:39.490: INFO: Got endpoints: latency-svc-mn4tw [643.952095ms]
Jun 29 15:50:39.506: INFO: Created: latency-svc-tvzdx
Jun 29 15:50:39.558: INFO: Got endpoints: latency-svc-shn5s [711.58036ms]
Jun 29 15:50:39.597: INFO: Created: latency-svc-gkdbz
Jun 29 15:50:39.598: INFO: Got endpoints: latency-svc-4rm59 [739.128006ms]
Jun 29 15:50:39.615: INFO: Created: latency-svc-hmc84
Jun 29 15:50:39.642: INFO: Got endpoints: latency-svc-cgxst [749.243816ms]
Jun 29 15:50:39.668: INFO: Created: latency-svc-qftd5
Jun 29 15:50:39.720: INFO: Got endpoints: latency-svc-599vk [775.428267ms]
Jun 29 15:50:39.738: INFO: Created: latency-svc-vkh6r
Jun 29 15:50:39.739: INFO: Got endpoints: latency-svc-h8dhd [747.565126ms]
Jun 29 15:50:39.755: INFO: Created: latency-svc-wvrcl
Jun 29 15:50:39.790: INFO: Got endpoints: latency-svc-c6nhw [750.462252ms]
Jun 29 15:50:39.812: INFO: Created: latency-svc-fwf5p
Jun 29 15:50:39.841: INFO: Got endpoints: latency-svc-dlvb6 [750.811499ms]
Jun 29 15:50:39.866: INFO: Created: latency-svc-2l5s5
Jun 29 15:50:39.893: INFO: Got endpoints: latency-svc-z87cc [752.580799ms]
Jun 29 15:50:40.014: INFO: Got endpoints: latency-svc-xffjd [773.30001ms]
Jun 29 15:50:40.014: INFO: Got endpoints: latency-svc-dqdbt [822.574332ms]
Jun 29 15:50:40.036: INFO: Created: latency-svc-r6ptq
Jun 29 15:50:40.044: INFO: Got endpoints: latency-svc-flz2z [754.769934ms]
Jun 29 15:50:40.057: INFO: Created: latency-svc-64jrh
Jun 29 15:50:40.062: INFO: Created: latency-svc-8h76k
Jun 29 15:50:40.076: INFO: Created: latency-svc-wb8jd
Jun 29 15:50:40.093: INFO: Got endpoints: latency-svc-46qzk [751.214938ms]
Jun 29 15:50:40.117: INFO: Created: latency-svc-h5bnz
Jun 29 15:50:40.156: INFO: Got endpoints: latency-svc-6hrwv [765.088968ms]
Jun 29 15:50:40.174: INFO: Created: latency-svc-5j2bp
Jun 29 15:50:40.189: INFO: Got endpoints: latency-svc-kw7lc [748.371931ms]
Jun 29 15:50:40.211: INFO: Created: latency-svc-2wnlc
Jun 29 15:50:40.239: INFO: Got endpoints: latency-svc-tvzdx [748.511566ms]
Jun 29 15:50:40.257: INFO: Created: latency-svc-r267z
Jun 29 15:50:40.289: INFO: Got endpoints: latency-svc-gkdbz [730.803096ms]
Jun 29 15:50:40.310: INFO: Created: latency-svc-vvdmx
Jun 29 15:50:40.339: INFO: Got endpoints: latency-svc-hmc84 [741.625456ms]
Jun 29 15:50:40.354: INFO: Created: latency-svc-smqhd
Jun 29 15:50:40.394: INFO: Got endpoints: latency-svc-qftd5 [751.583996ms]
Jun 29 15:50:40.415: INFO: Created: latency-svc-2gscd
Jun 29 15:50:40.443: INFO: Got endpoints: latency-svc-vkh6r [722.254829ms]
Jun 29 15:50:40.461: INFO: Created: latency-svc-7747k
Jun 29 15:50:40.489: INFO: Got endpoints: latency-svc-wvrcl [750.019603ms]
Jun 29 15:50:40.507: INFO: Created: latency-svc-7d8cm
Jun 29 15:50:40.544: INFO: Got endpoints: latency-svc-fwf5p [752.667333ms]
Jun 29 15:50:40.561: INFO: Created: latency-svc-lkj5t
Jun 29 15:50:40.596: INFO: Got endpoints: latency-svc-2l5s5 [754.339954ms]
Jun 29 15:50:40.613: INFO: Created: latency-svc-wtlk2
Jun 29 15:50:40.639: INFO: Got endpoints: latency-svc-r6ptq [746.13451ms]
Jun 29 15:50:40.662: INFO: Created: latency-svc-2h5kb
Jun 29 15:50:40.696: INFO: Got endpoints: latency-svc-64jrh [682.205005ms]
Jun 29 15:50:40.738: INFO: Created: latency-svc-9dswh
Jun 29 15:50:40.742: INFO: Got endpoints: latency-svc-8h76k [727.897337ms]
Jun 29 15:50:40.759: INFO: Created: latency-svc-hx87d
Jun 29 15:50:40.794: INFO: Got endpoints: latency-svc-wb8jd [749.731845ms]
Jun 29 15:50:40.811: INFO: Created: latency-svc-65bwp
Jun 29 15:50:40.846: INFO: Got endpoints: latency-svc-h5bnz [752.517157ms]
Jun 29 15:50:40.864: INFO: Created: latency-svc-5rcwp
Jun 29 15:50:40.891: INFO: Got endpoints: latency-svc-5j2bp [735.175655ms]
Jun 29 15:50:40.913: INFO: Created: latency-svc-64rqc
Jun 29 15:50:40.941: INFO: Got endpoints: latency-svc-2wnlc [751.642413ms]
Jun 29 15:50:40.969: INFO: Created: latency-svc-22srq
Jun 29 15:50:40.993: INFO: Got endpoints: latency-svc-r267z [753.264646ms]
Jun 29 15:50:41.012: INFO: Created: latency-svc-2gdd7
Jun 29 15:50:41.039: INFO: Got endpoints: latency-svc-vvdmx [749.444884ms]
Jun 29 15:50:41.053: INFO: Created: latency-svc-dhgmd
Jun 29 15:50:41.092: INFO: Got endpoints: latency-svc-smqhd [752.933454ms]
Jun 29 15:50:41.117: INFO: Created: latency-svc-dnqd8
Jun 29 15:50:41.144: INFO: Got endpoints: latency-svc-2gscd [750.417959ms]
Jun 29 15:50:41.161: INFO: Created: latency-svc-nwjw6
Jun 29 15:50:41.195: INFO: Got endpoints: latency-svc-7747k [751.826712ms]
Jun 29 15:50:41.213: INFO: Created: latency-svc-vnjjs
Jun 29 15:50:41.244: INFO: Got endpoints: latency-svc-7d8cm [754.490475ms]
Jun 29 15:50:41.282: INFO: Created: latency-svc-z29v6
Jun 29 15:50:41.295: INFO: Got endpoints: latency-svc-lkj5t [750.906575ms]
Jun 29 15:50:41.313: INFO: Created: latency-svc-7cbfv
Jun 29 15:50:41.342: INFO: Got endpoints: latency-svc-wtlk2 [746.056695ms]
Jun 29 15:50:41.362: INFO: Created: latency-svc-vhm5z
Jun 29 15:50:41.393: INFO: Got endpoints: latency-svc-2h5kb [753.164309ms]
Jun 29 15:50:41.413: INFO: Created: latency-svc-krnwg
Jun 29 15:50:41.442: INFO: Got endpoints: latency-svc-9dswh [746.264647ms]
Jun 29 15:50:41.458: INFO: Created: latency-svc-vkbvs
Jun 29 15:50:41.493: INFO: Got endpoints: latency-svc-hx87d [750.894111ms]
Jun 29 15:50:41.510: INFO: Created: latency-svc-lc25r
Jun 29 15:50:41.539: INFO: Got endpoints: latency-svc-65bwp [745.596642ms]
Jun 29 15:50:41.556: INFO: Created: latency-svc-jlw92
Jun 29 15:50:41.603: INFO: Got endpoints: latency-svc-5rcwp [756.41962ms]
Jun 29 15:50:41.616: INFO: Created: latency-svc-kxvrk
Jun 29 15:50:41.640: INFO: Got endpoints: latency-svc-64rqc [748.564364ms]
Jun 29 15:50:41.665: INFO: Created: latency-svc-cg72d
Jun 29 15:50:41.692: INFO: Got endpoints: latency-svc-22srq [750.242401ms]
Jun 29 15:50:41.716: INFO: Created: latency-svc-8wtrz
Jun 29 15:50:41.750: INFO: Got endpoints: latency-svc-2gdd7 [756.898841ms]
Jun 29 15:50:41.787: INFO: Created: latency-svc-j59ln
Jun 29 15:50:41.791: INFO: Got endpoints: latency-svc-dhgmd [752.457488ms]
Jun 29 15:50:41.810: INFO: Created: latency-svc-jk4sz
Jun 29 15:50:41.842: INFO: Got endpoints: latency-svc-dnqd8 [749.454051ms]
Jun 29 15:50:41.860: INFO: Created: latency-svc-xfps6
Jun 29 15:50:41.891: INFO: Got endpoints: latency-svc-nwjw6 [746.484805ms]
Jun 29 15:50:41.914: INFO: Created: latency-svc-jf84d
Jun 29 15:50:41.944: INFO: Got endpoints: latency-svc-vnjjs [749.249917ms]
Jun 29 15:50:41.963: INFO: Created: latency-svc-bcclj
Jun 29 15:50:41.994: INFO: Got endpoints: latency-svc-z29v6 [750.246905ms]
Jun 29 15:50:42.016: INFO: Created: latency-svc-qjfbq
Jun 29 15:50:42.041: INFO: Got endpoints: latency-svc-7cbfv [746.208639ms]
Jun 29 15:50:42.058: INFO: Created: latency-svc-n794g
Jun 29 15:50:42.090: INFO: Got endpoints: latency-svc-vhm5z [747.971541ms]
Jun 29 15:50:42.106: INFO: Created: latency-svc-6kt62
Jun 29 15:50:42.145: INFO: Got endpoints: latency-svc-krnwg [752.022488ms]
Jun 29 15:50:42.164: INFO: Created: latency-svc-89ntt
Jun 29 15:50:42.193: INFO: Got endpoints: latency-svc-vkbvs [750.76483ms]
Jun 29 15:50:42.214: INFO: Created: latency-svc-jmp4r
Jun 29 15:50:42.239: INFO: Got endpoints: latency-svc-lc25r [745.97079ms]
Jun 29 15:50:42.255: INFO: Created: latency-svc-w2xm9
Jun 29 15:50:42.294: INFO: Got endpoints: latency-svc-jlw92 [754.672711ms]
Jun 29 15:50:42.309: INFO: Created: latency-svc-qntrc
Jun 29 15:50:42.344: INFO: Got endpoints: latency-svc-kxvrk [740.942146ms]
Jun 29 15:50:42.363: INFO: Created: latency-svc-99xdm
Jun 29 15:50:42.389: INFO: Got endpoints: latency-svc-cg72d [749.303438ms]
Jun 29 15:50:42.406: INFO: Created: latency-svc-gbz9q
Jun 29 15:50:42.446: INFO: Got endpoints: latency-svc-8wtrz [754.670395ms]
Jun 29 15:50:42.464: INFO: Created: latency-svc-nbn6z
Jun 29 15:50:42.494: INFO: Got endpoints: latency-svc-j59ln [744.753016ms]
Jun 29 15:50:42.510: INFO: Created: latency-svc-xgjvd
Jun 29 15:50:42.553: INFO: Got endpoints: latency-svc-jk4sz [761.320616ms]
Jun 29 15:50:42.572: INFO: Created: latency-svc-zsjsm
Jun 29 15:50:42.591: INFO: Got endpoints: latency-svc-xfps6 [749.051401ms]
Jun 29 15:50:42.610: INFO: Created: latency-svc-stwnc
Jun 29 15:50:42.643: INFO: Got endpoints: latency-svc-jf84d [752.376512ms]
Jun 29 15:50:42.666: INFO: Created: latency-svc-6qhqq
Jun 29 15:50:42.692: INFO: Got endpoints: latency-svc-bcclj [747.677424ms]
Jun 29 15:50:42.710: INFO: Created: latency-svc-6zs8f
Jun 29 15:50:42.742: INFO: Got endpoints: latency-svc-qjfbq [747.316462ms]
Jun 29 15:50:42.764: INFO: Created: latency-svc-2gn2g
Jun 29 15:50:42.793: INFO: Got endpoints: latency-svc-n794g [751.599076ms]
Jun 29 15:50:42.813: INFO: Created: latency-svc-skvnx
Jun 29 15:50:42.859: INFO: Got endpoints: latency-svc-6kt62 [769.158503ms]
Jun 29 15:50:42.876: INFO: Created: latency-svc-jnnmq
Jun 29 15:50:42.892: INFO: Got endpoints: latency-svc-89ntt [747.393523ms]
Jun 29 15:50:42.909: INFO: Created: latency-svc-44pjw
Jun 29 15:50:42.959: INFO: Got endpoints: latency-svc-jmp4r [765.940514ms]
Jun 29 15:50:42.985: INFO: Created: latency-svc-8hn7f
Jun 29 15:50:42.989: INFO: Got endpoints: latency-svc-w2xm9 [749.970844ms]
Jun 29 15:50:43.008: INFO: Created: latency-svc-wvcw2
Jun 29 15:50:43.040: INFO: Got endpoints: latency-svc-qntrc [745.699965ms]
Jun 29 15:50:43.057: INFO: Created: latency-svc-bvsmk
Jun 29 15:50:43.094: INFO: Got endpoints: latency-svc-99xdm [750.204349ms]
Jun 29 15:50:43.109: INFO: Created: latency-svc-wk22d
Jun 29 15:50:43.143: INFO: Got endpoints: latency-svc-gbz9q [753.542211ms]
Jun 29 15:50:43.160: INFO: Created: latency-svc-k6ksk
Jun 29 15:50:43.193: INFO: Got endpoints: latency-svc-nbn6z [746.178737ms]
Jun 29 15:50:43.210: INFO: Created: latency-svc-t9tdp
Jun 29 15:50:43.240: INFO: Got endpoints: latency-svc-xgjvd [744.981989ms]
Jun 29 15:50:43.257: INFO: Created: latency-svc-q865s
Jun 29 15:50:43.291: INFO: Got endpoints: latency-svc-zsjsm [738.308094ms]
Jun 29 15:50:43.330: INFO: Created: latency-svc-b57lj
Jun 29 15:50:43.342: INFO: Got endpoints: latency-svc-stwnc [750.220679ms]
Jun 29 15:50:43.359: INFO: Created: latency-svc-25qbz
Jun 29 15:50:43.391: INFO: Got endpoints: latency-svc-6qhqq [747.182068ms]
Jun 29 15:50:43.416: INFO: Created: latency-svc-ds722
Jun 29 15:50:43.443: INFO: Got endpoints: latency-svc-6zs8f [751.207545ms]
Jun 29 15:50:43.461: INFO: Created: latency-svc-fm466
Jun 29 15:50:43.491: INFO: Got endpoints: latency-svc-2gn2g [749.276761ms]
Jun 29 15:50:43.530: INFO: Created: latency-svc-pjfnw
Jun 29 15:50:43.551: INFO: Got endpoints: latency-svc-skvnx [757.576653ms]
Jun 29 15:50:43.597: INFO: Created: latency-svc-wz8ss
Jun 29 15:50:43.599: INFO: Got endpoints: latency-svc-jnnmq [739.807381ms]
Jun 29 15:50:43.623: INFO: Created: latency-svc-7nkr8
Jun 29 15:50:43.640: INFO: Got endpoints: latency-svc-44pjw [747.921947ms]
Jun 29 15:50:43.659: INFO: Created: latency-svc-fvblz
Jun 29 15:50:43.692: INFO: Got endpoints: latency-svc-8hn7f [732.347973ms]
Jun 29 15:50:43.707: INFO: Created: latency-svc-n9gfh
Jun 29 15:50:43.742: INFO: Got endpoints: latency-svc-wvcw2 [752.380095ms]
Jun 29 15:50:43.761: INFO: Created: latency-svc-bdcjp
Jun 29 15:50:43.792: INFO: Got endpoints: latency-svc-bvsmk [752.311617ms]
Jun 29 15:50:43.821: INFO: Created: latency-svc-g9zwj
Jun 29 15:50:43.844: INFO: Got endpoints: latency-svc-wk22d [749.638365ms]
Jun 29 15:50:43.861: INFO: Created: latency-svc-b4kgc
Jun 29 15:50:43.896: INFO: Got endpoints: latency-svc-k6ksk [753.736126ms]
Jun 29 15:50:43.917: INFO: Created: latency-svc-mtlwz
Jun 29 15:50:43.941: INFO: Got endpoints: latency-svc-t9tdp [748.690839ms]
Jun 29 15:50:43.963: INFO: Created: latency-svc-d68rd
Jun 29 15:50:43.992: INFO: Got endpoints: latency-svc-q865s [751.720307ms]
Jun 29 15:50:44.011: INFO: Created: latency-svc-ngvs7
Jun 29 15:50:44.043: INFO: Got endpoints: latency-svc-b57lj [751.554665ms]
Jun 29 15:50:44.058: INFO: Created: latency-svc-lz9tq
Jun 29 15:50:44.121: INFO: Got endpoints: latency-svc-25qbz [779.126664ms]
Jun 29 15:50:44.137: INFO: Created: latency-svc-l52vq
Jun 29 15:50:44.140: INFO: Got endpoints: latency-svc-ds722 [749.585532ms]
Jun 29 15:50:44.154: INFO: Created: latency-svc-n2b7r
Jun 29 15:50:44.194: INFO: Got endpoints: latency-svc-fm466 [751.038207ms]
Jun 29 15:50:44.210: INFO: Created: latency-svc-s9nhj
Jun 29 15:50:44.240: INFO: Got endpoints: latency-svc-pjfnw [748.800238ms]
Jun 29 15:50:44.255: INFO: Created: latency-svc-6c6zl
Jun 29 15:50:44.290: INFO: Got endpoints: latency-svc-wz8ss [739.762399ms]
Jun 29 15:50:44.306: INFO: Created: latency-svc-xl4fk
Jun 29 15:50:44.341: INFO: Got endpoints: latency-svc-7nkr8 [741.755754ms]
Jun 29 15:50:44.355: INFO: Created: latency-svc-rzzxg
Jun 29 15:50:44.394: INFO: Got endpoints: latency-svc-fvblz [753.375166ms]
Jun 29 15:50:44.422: INFO: Created: latency-svc-6n5vx
Jun 29 15:50:44.444: INFO: Got endpoints: latency-svc-n9gfh [751.884688ms]
Jun 29 15:50:44.467: INFO: Created: latency-svc-m9kq4
Jun 29 15:50:44.490: INFO: Got endpoints: latency-svc-bdcjp [748.132171ms]
Jun 29 15:50:44.508: INFO: Created: latency-svc-tbd2x
Jun 29 15:50:44.542: INFO: Got endpoints: latency-svc-g9zwj [749.33928ms]
Jun 29 15:50:44.556: INFO: Created: latency-svc-cg86g
Jun 29 15:50:44.589: INFO: Got endpoints: latency-svc-b4kgc [745.605694ms]
Jun 29 15:50:44.606: INFO: Created: latency-svc-4z7bh
Jun 29 15:50:44.642: INFO: Got endpoints: latency-svc-mtlwz [745.851789ms]
Jun 29 15:50:44.660: INFO: Created: latency-svc-hqr7x
Jun 29 15:50:44.695: INFO: Got endpoints: latency-svc-d68rd [753.517896ms]
Jun 29 15:50:44.715: INFO: Created: latency-svc-8bdvl
Jun 29 15:50:44.741: INFO: Got endpoints: latency-svc-ngvs7 [749.138052ms]
Jun 29 15:50:44.758: INFO: Created: latency-svc-lhf7j
Jun 29 15:50:44.790: INFO: Got endpoints: latency-svc-lz9tq [746.795541ms]
Jun 29 15:50:44.864: INFO: Got endpoints: latency-svc-l52vq [742.523665ms]
Jun 29 15:50:44.864: INFO: Created: latency-svc-77z4h
Jun 29 15:50:44.880: INFO: Created: latency-svc-bq6dr
Jun 29 15:50:44.895: INFO: Got endpoints: latency-svc-n2b7r [754.961546ms]
Jun 29 15:50:44.910: INFO: Created: latency-svc-rjzfg
Jun 29 15:50:44.954: INFO: Got endpoints: latency-svc-s9nhj [760.255529ms]
Jun 29 15:50:44.975: INFO: Created: latency-svc-7nqr4
Jun 29 15:50:44.995: INFO: Got endpoints: latency-svc-6c6zl [754.776617ms]
Jun 29 15:50:45.012: INFO: Created: latency-svc-mbvv9
Jun 29 15:50:45.043: INFO: Got endpoints: latency-svc-xl4fk [752.012886ms]
Jun 29 15:50:45.057: INFO: Created: latency-svc-zh529
Jun 29 15:50:45.091: INFO: Got endpoints: latency-svc-rzzxg [749.432311ms]
Jun 29 15:50:45.108: INFO: Created: latency-svc-mnz9h
Jun 29 15:50:45.140: INFO: Got endpoints: latency-svc-6n5vx [746.226718ms]
Jun 29 15:50:45.156: INFO: Created: latency-svc-8jvks
Jun 29 15:50:45.192: INFO: Got endpoints: latency-svc-m9kq4 [748.101454ms]
Jun 29 15:50:45.207: INFO: Created: latency-svc-kddqz
Jun 29 15:50:45.239: INFO: Got endpoints: latency-svc-tbd2x [748.23831ms]
Jun 29 15:50:45.257: INFO: Created: latency-svc-qjtt7
Jun 29 15:50:45.292: INFO: Got endpoints: latency-svc-cg86g [749.513793ms]
Jun 29 15:50:45.309: INFO: Created: latency-svc-5nrkz
Jun 29 15:50:45.341: INFO: Got endpoints: latency-svc-4z7bh [749.171001ms]
Jun 29 15:50:45.368: INFO: Created: latency-svc-qp9zl
Jun 29 15:50:45.391: INFO: Got endpoints: latency-svc-hqr7x [748.685035ms]
Jun 29 15:50:45.413: INFO: Created: latency-svc-z9pfr
Jun 29 15:50:45.442: INFO: Got endpoints: latency-svc-8bdvl [745.056031ms]
Jun 29 15:50:45.456: INFO: Created: latency-svc-sxkrt
Jun 29 15:50:45.512: INFO: Got endpoints: latency-svc-lhf7j [770.967846ms]
Jun 29 15:50:45.528: INFO: Created: latency-svc-gx25l
Jun 29 15:50:45.540: INFO: Got endpoints: latency-svc-77z4h [749.704948ms]
Jun 29 15:50:45.554: INFO: Created: latency-svc-wnc6w
Jun 29 15:50:45.592: INFO: Got endpoints: latency-svc-bq6dr [728.016561ms]
Jun 29 15:50:45.607: INFO: Created: latency-svc-4d2nr
Jun 29 15:50:45.641: INFO: Got endpoints: latency-svc-rjzfg [745.6775ms]
Jun 29 15:50:45.659: INFO: Created: latency-svc-v5q49
Jun 29 15:50:45.696: INFO: Got endpoints: latency-svc-7nqr4 [740.766123ms]
Jun 29 15:50:45.721: INFO: Created: latency-svc-rftvr
Jun 29 15:50:45.739: INFO: Got endpoints: latency-svc-mbvv9 [743.753504ms]
Jun 29 15:50:45.752: INFO: Created: latency-svc-bx4q8
Jun 29 15:50:45.791: INFO: Got endpoints: latency-svc-zh529 [748.511073ms]
Jun 29 15:50:45.808: INFO: Created: latency-svc-cr5rv
Jun 29 15:50:45.843: INFO: Got endpoints: latency-svc-mnz9h [751.996559ms]
Jun 29 15:50:45.878: INFO: Created: latency-svc-rw7c2
Jun 29 15:50:45.892: INFO: Got endpoints: latency-svc-8jvks [752.006934ms]
Jun 29 15:50:45.909: INFO: Created: latency-svc-f8b68
Jun 29 15:50:45.942: INFO: Got endpoints: latency-svc-kddqz [750.331497ms]
Jun 29 15:50:45.962: INFO: Created: latency-svc-vqf29
Jun 29 15:50:45.990: INFO: Got endpoints: latency-svc-qjtt7 [751.608136ms]
Jun 29 15:50:46.056: INFO: Got endpoints: latency-svc-5nrkz [764.105451ms]
Jun 29 15:50:46.059: INFO: Created: latency-svc-ltdzc
Jun 29 15:50:46.070: INFO: Created: latency-svc-pmv9k
Jun 29 15:50:46.092: INFO: Got endpoints: latency-svc-qp9zl [751.1429ms]
Jun 29 15:50:46.115: INFO: Created: latency-svc-db5zx
Jun 29 15:50:46.142: INFO: Got endpoints: latency-svc-z9pfr [750.533404ms]
Jun 29 15:50:46.166: INFO: Created: latency-svc-sbc2j
Jun 29 15:50:46.191: INFO: Got endpoints: latency-svc-sxkrt [749.577526ms]
Jun 29 15:50:46.207: INFO: Created: latency-svc-pp7q5
Jun 29 15:50:46.244: INFO: Got endpoints: latency-svc-gx25l [731.579752ms]
Jun 29 15:50:46.259: INFO: Created: latency-svc-d7q28
Jun 29 15:50:46.290: INFO: Got endpoints: latency-svc-wnc6w [749.928214ms]
Jun 29 15:50:46.347: INFO: Got endpoints: latency-svc-4d2nr [754.487281ms]
Jun 29 15:50:46.389: INFO: Got endpoints: latency-svc-v5q49 [747.515267ms]
Jun 29 15:50:46.439: INFO: Got endpoints: latency-svc-rftvr [742.96675ms]
Jun 29 15:50:46.490: INFO: Got endpoints: latency-svc-bx4q8 [751.455366ms]
Jun 29 15:50:46.542: INFO: Got endpoints: latency-svc-cr5rv [751.323522ms]
Jun 29 15:50:46.597: INFO: Got endpoints: latency-svc-rw7c2 [753.977999ms]
Jun 29 15:50:46.640: INFO: Got endpoints: latency-svc-f8b68 [747.365095ms]
Jun 29 15:50:46.705: INFO: Got endpoints: latency-svc-vqf29 [762.83136ms]
Jun 29 15:50:46.740: INFO: Got endpoints: latency-svc-ltdzc [749.37291ms]
Jun 29 15:50:46.800: INFO: Got endpoints: latency-svc-pmv9k [744.571164ms]
Jun 29 15:50:46.839: INFO: Got endpoints: latency-svc-db5zx [747.23639ms]
Jun 29 15:50:46.904: INFO: Got endpoints: latency-svc-sbc2j [761.220717ms]
Jun 29 15:50:46.951: INFO: Got endpoints: latency-svc-pp7q5 [759.530003ms]
Jun 29 15:50:46.992: INFO: Got endpoints: latency-svc-d7q28 [747.769948ms]
Jun 29 15:50:46.992: INFO: Latencies: [25.665732ms 40.810453ms 44.636909ms 52.31233ms 56.304169ms 80.21288ms 80.896144ms 83.502289ms 91.18135ms 92.595455ms 101.656895ms 109.919121ms 110.81292ms 123.8267ms 124.996788ms 126.838452ms 127.881075ms 128.550299ms 132.10266ms 134.698582ms 137.872356ms 140.500693ms 150.399992ms 154.172383ms 166.697769ms 186.848789ms 191.674068ms 194.174384ms 200.384056ms 201.748822ms 202.361041ms 204.090928ms 204.296527ms 205.341723ms 205.953444ms 207.182033ms 207.472728ms 208.397223ms 213.898063ms 232.05501ms 265.16729ms 314.663588ms 364.956278ms 395.48377ms 443.410472ms 499.911315ms 527.230434ms 570.540958ms 615.488536ms 643.952095ms 682.205005ms 711.58036ms 722.254829ms 727.897337ms 728.016561ms 730.803096ms 731.579752ms 732.347973ms 735.175655ms 738.308094ms 739.128006ms 739.762399ms 739.807381ms 740.766123ms 740.942146ms 741.625456ms 741.755754ms 742.523665ms 742.96675ms 743.753504ms 744.571164ms 744.753016ms 744.981989ms 745.056031ms 745.596642ms 745.605694ms 745.6775ms 745.699965ms 745.851789ms 745.97079ms 746.056695ms 746.13451ms 746.178737ms 746.208639ms 746.226718ms 746.264647ms 746.484805ms 746.795541ms 747.182068ms 747.23639ms 747.316462ms 747.365095ms 747.393523ms 747.515267ms 747.565126ms 747.677424ms 747.769948ms 747.921947ms 747.971541ms 748.101454ms 748.132171ms 748.23831ms 748.371931ms 748.511073ms 748.511566ms 748.564364ms 748.685035ms 748.690839ms 748.800238ms 749.051401ms 749.138052ms 749.171001ms 749.243816ms 749.249917ms 749.276761ms 749.303438ms 749.33928ms 749.37291ms 749.432311ms 749.444884ms 749.454051ms 749.513793ms 749.577526ms 749.585532ms 749.638365ms 749.704948ms 749.731845ms 749.928214ms 749.970844ms 750.019603ms 750.204349ms 750.220679ms 750.242401ms 750.246905ms 750.331497ms 750.417959ms 750.462252ms 750.533404ms 750.76483ms 750.811499ms 750.894111ms 750.906575ms 751.038207ms 751.1429ms 751.207545ms 751.214938ms 751.323522ms 751.455366ms 751.554665ms 751.583996ms 751.599076ms 751.608136ms 751.642413ms 751.720307ms 751.826712ms 751.884688ms 751.996559ms 752.006934ms 752.012886ms 752.022488ms 752.311617ms 752.376512ms 752.380095ms 752.457488ms 752.517157ms 752.580799ms 752.667333ms 752.933454ms 753.164309ms 753.264646ms 753.375166ms 753.517896ms 753.542211ms 753.736126ms 753.977999ms 754.339954ms 754.487281ms 754.490475ms 754.670395ms 754.672711ms 754.769934ms 754.776617ms 754.961546ms 756.41962ms 756.898841ms 757.576653ms 759.530003ms 760.255529ms 761.220717ms 761.320616ms 762.83136ms 764.105451ms 765.088968ms 765.940514ms 769.158503ms 770.967846ms 773.30001ms 775.428267ms 779.126664ms 822.574332ms]
Jun 29 15:50:46.992: INFO: 50 %ile: 748.132171ms
Jun 29 15:50:46.992: INFO: 90 %ile: 754.769934ms
Jun 29 15:50:46.992: INFO: 99 %ile: 779.126664ms
Jun 29 15:50:46.992: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:50:46.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-6pkrz" for this suite.
Jun 29 15:51:17.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:51:17.292: INFO: namespace: e2e-tests-svc-latency-6pkrz, resource: bindings, ignored listing per whitelist
Jun 29 15:51:17.376: INFO: namespace e2e-tests-svc-latency-6pkrz deletion completed in 30.370835198s

â€¢ [SLOW TEST:41.413 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:51:17.377: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2m8kz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 29 15:51:17.680: INFO: Waiting up to 5m0s for pod "pod-429c798c-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-2m8kz" to be "success or failure"
Jun 29 15:51:17.686: INFO: Pod "pod-429c798c-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.315133ms
Jun 29 15:51:19.694: INFO: Pod "pod-429c798c-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013861327s
Jun 29 15:51:21.706: INFO: Pod "pod-429c798c-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025753511s
STEP: Saw pod success
Jun 29 15:51:21.706: INFO: Pod "pod-429c798c-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:51:21.728: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-429c798c-7bb4-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:51:21.766: INFO: Waiting for pod pod-429c798c-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:51:21.772: INFO: Pod pod-429c798c-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:51:21.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2m8kz" for this suite.
Jun 29 15:51:27.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:51:27.839: INFO: namespace: e2e-tests-emptydir-2m8kz, resource: bindings, ignored listing per whitelist
Jun 29 15:51:28.091: INFO: namespace e2e-tests-emptydir-2m8kz deletion completed in 6.309059206s

â€¢ [SLOW TEST:10.714 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:51:28.093: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bb2ts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0629 15:51:58.990430      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 29 15:51:58.990: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:51:58.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bb2ts" for this suite.
Jun 29 15:52:05.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:52:05.260: INFO: namespace: e2e-tests-gc-bb2ts, resource: bindings, ignored listing per whitelist
Jun 29 15:52:05.362: INFO: namespace e2e-tests-gc-bb2ts deletion completed in 6.360711463s

â€¢ [SLOW TEST:37.269 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:52:05.364: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pvp64
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 29 15:52:05.685: INFO: Waiting up to 5m0s for pod "pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-pvp64" to be "success or failure"
Jun 29 15:52:05.708: INFO: Pod "pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 22.344725ms
Jun 29 15:52:07.718: INFO: Pod "pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032316315s
STEP: Saw pod success
Jun 29 15:52:07.718: INFO: Pod "pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:52:07.723: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:52:07.763: INFO: Waiting for pod pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:52:07.768: INFO: Pod pod-5f38eff3-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:52:07.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pvp64" for this suite.
Jun 29 15:52:13.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:52:13.828: INFO: namespace: e2e-tests-emptydir-pvp64, resource: bindings, ignored listing per whitelist
Jun 29 15:52:14.030: INFO: namespace e2e-tests-emptydir-pvp64 deletion completed in 6.251274807s

â€¢ [SLOW TEST:8.666 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:52:14.032: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k224k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:52:14.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-k224k" to be "success or failure"
Jun 29 15:52:14.305: INFO: Pod "downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.330869ms
Jun 29 15:52:16.351: INFO: Pod "downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053216547s
Jun 29 15:52:18.362: INFO: Pod "downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063623062s
Jun 29 15:52:20.395: INFO: Pod "downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.097092677s
STEP: Saw pod success
Jun 29 15:52:20.396: INFO: Pod "downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:52:20.426: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:52:20.493: INFO: Waiting for pod downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:52:20.498: INFO: Pod downwardapi-volume-645acdbe-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:52:20.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k224k" for this suite.
Jun 29 15:52:26.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:52:26.780: INFO: namespace: e2e-tests-projected-k224k, resource: bindings, ignored listing per whitelist
Jun 29 15:52:26.834: INFO: namespace e2e-tests-projected-k224k deletion completed in 6.323614842s

â€¢ [SLOW TEST:12.802 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:52:26.838: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ln5bw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:52:27.163: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-ln5bw" to be "success or failure"
Jun 29 15:52:27.217: INFO: Pod "downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 54.059948ms
Jun 29 15:52:29.226: INFO: Pod "downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063456511s
Jun 29 15:52:31.251: INFO: Pod "downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.088374947s
Jun 29 15:52:33.289: INFO: Pod "downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.125900238s
STEP: Saw pod success
Jun 29 15:52:33.290: INFO: Pod "downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:52:33.296: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:52:33.346: INFO: Waiting for pod downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:52:33.355: INFO: Pod downwardapi-volume-6c062b85-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:52:33.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ln5bw" for this suite.
Jun 29 15:52:39.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:52:39.434: INFO: namespace: e2e-tests-projected-ln5bw, resource: bindings, ignored listing per whitelist
Jun 29 15:52:39.625: INFO: namespace e2e-tests-projected-ln5bw deletion completed in 6.25904858s

â€¢ [SLOW TEST:12.787 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:52:39.627: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-w5bdn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 29 15:52:39.888: INFO: Waiting up to 5m0s for pod "pod-739c1254-7bb4-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-emptydir-w5bdn" to be "success or failure"
Jun 29 15:52:39.900: INFO: Pod "pod-739c1254-7bb4-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.67805ms
Jun 29 15:52:41.914: INFO: Pod "pod-739c1254-7bb4-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026007027s
STEP: Saw pod success
Jun 29 15:52:41.914: INFO: Pod "pod-739c1254-7bb4-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:52:41.921: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-739c1254-7bb4-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 15:52:41.959: INFO: Waiting for pod pod-739c1254-7bb4-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:52:41.965: INFO: Pod pod-739c1254-7bb4-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:52:41.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w5bdn" for this suite.
Jun 29 15:52:47.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:52:48.160: INFO: namespace: e2e-tests-emptydir-w5bdn, resource: bindings, ignored listing per whitelist
Jun 29 15:52:48.198: INFO: namespace e2e-tests-emptydir-w5bdn deletion completed in 6.22394417s

â€¢ [SLOW TEST:8.571 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:52:48.202: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qlz9w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-qlz9w
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qlz9w
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qlz9w
Jun 29 15:52:48.473: INFO: Found 0 stateful pods, waiting for 1
Jun 29 15:52:58.495: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun 29 15:52:58.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 15:52:58.887: INFO: stderr: ""
Jun 29 15:52:58.887: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 15:52:58.887: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 15:52:58.896: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 29 15:53:08.915: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 15:53:08.915: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 15:53:08.944: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999418s
Jun 29 15:53:09.951: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994300015s
Jun 29 15:53:10.959: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987150572s
Jun 29 15:53:11.968: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978716935s
Jun 29 15:53:12.977: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.969437831s
Jun 29 15:53:13.984: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961184707s
Jun 29 15:53:14.995: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.95309444s
Jun 29 15:53:16.003: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.942295793s
Jun 29 15:53:17.017: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.934638807s
Jun 29 15:53:18.029: INFO: Verifying statefulset ss doesn't scale past 1 for another 919.447304ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qlz9w
Jun 29 15:53:19.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 15:53:19.401: INFO: stderr: ""
Jun 29 15:53:19.401: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 15:53:19.401: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 15:53:19.408: INFO: Found 1 stateful pods, waiting for 3
Jun 29 15:53:29.425: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 15:53:29.426: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 15:53:29.426: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun 29 15:53:29.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 15:53:29.809: INFO: stderr: ""
Jun 29 15:53:29.809: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 15:53:29.809: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 15:53:29.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 15:53:30.246: INFO: stderr: ""
Jun 29 15:53:30.246: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 15:53:30.246: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 15:53:30.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 15:53:30.627: INFO: stderr: ""
Jun 29 15:53:30.627: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 15:53:30.627: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 15:53:30.627: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 15:53:30.635: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jun 29 15:53:40.663: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 15:53:40.663: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 15:53:40.663: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 15:53:40.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999917s
Jun 29 15:53:41.699: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987745504s
Jun 29 15:53:42.708: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979930527s
Jun 29 15:53:43.717: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970206669s
Jun 29 15:53:44.724: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.961758373s
Jun 29 15:53:45.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954864264s
Jun 29 15:53:46.745: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943511123s
Jun 29 15:53:47.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.934049181s
Jun 29 15:53:48.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924971759s
Jun 29 15:53:49.780: INFO: Verifying statefulset ss doesn't scale past 3 for another 907.482932ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qlz9w
Jun 29 15:53:50.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 15:53:51.215: INFO: stderr: ""
Jun 29 15:53:51.215: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 15:53:51.215: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 15:53:51.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 15:53:51.545: INFO: stderr: ""
Jun 29 15:53:51.545: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 15:53:51.545: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 15:53:51.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-qlz9w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 15:53:51.934: INFO: stderr: ""
Jun 29 15:53:51.934: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 15:53:51.934: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 15:53:51.934: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jun 29 15:54:02.007: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qlz9w
Jun 29 15:54:02.016: INFO: Scaling statefulset ss to 0
Jun 29 15:54:02.036: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 15:54:02.042: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:54:02.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qlz9w" for this suite.
Jun 29 15:54:08.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:54:08.360: INFO: namespace: e2e-tests-statefulset-qlz9w, resource: bindings, ignored listing per whitelist
Jun 29 15:54:08.381: INFO: namespace e2e-tests-statefulset-qlz9w deletion completed in 6.305484152s

â€¢ [SLOW TEST:80.179 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:54:08.382: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-sjfsw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:55:08.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sjfsw" for this suite.
Jun 29 15:55:32.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:55:32.875: INFO: namespace: e2e-tests-container-probe-sjfsw, resource: bindings, ignored listing per whitelist
Jun 29 15:55:32.988: INFO: namespace e2e-tests-container-probe-sjfsw deletion completed in 24.292792649s

â€¢ [SLOW TEST:84.606 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:55:32.990: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-csrgt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 29 15:55:33.243: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 29 15:56:33.332: INFO: Waiting for terminating namespaces to be deleted...
Jun 29 15:56:33.343: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 29 15:56:33.415: INFO: 44 / 44 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 29 15:56:33.419: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Jun 29 15:56:33.442: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jun 29 15:56:33.443: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-0 before test
Jun 29 15:56:33.472: INFO: default-http-backend-658c6856c5-vtlcw from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container default-http-backend ready: true, restart count 0
Jun 29 15:56:33.472: INFO: kube-state-metrics-8747876f4-2rt6h from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container addon-resizer ready: true, restart count 0
Jun 29 15:56:33.472: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jun 29 15:56:33.472: INFO: prometheus-operator-95bb8bdf9-wshj6 from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container prometheus-operator ready: true, restart count 0
Jun 29 15:56:33.472: INFO: registry-nginx-5fcb7bcccf-ktgcl from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container registry-nginx ready: true, restart count 0
Jun 29 15:56:33.472: INFO: kube-flannel-6tj5j from kube-system started at 2018-06-28 20:27:44 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container kube-flannel ready: true, restart count 2
Jun 29 15:56:33.472: INFO: configure-oom-kn8s9 from rackspace-system started at 2018-06-28 20:32:19 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:56:33.472: INFO: node-exporter-z7p55 from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:56:33.472: INFO: container-linux-update-agent-g2b29 from rackspace-system started at 2018-06-28 20:38:23 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container update-agent ready: true, restart count 2
Jun 29 15:56:33.472: INFO: alertmanager-main-1 from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.472: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:56:33.472: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:56:33.472: INFO: influxdb-545869c56c-ndhzm from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container influxdb ready: true, restart count 0
Jun 29 15:56:33.473: INFO: registry-job-6ff94bb84c-wpc5v from rackspace-system started at 2018-06-28 20:54:15 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container registry-job ready: true, restart count 0
Jun 29 15:56:33.473: INFO: alertmanager-main-2 from rackspace-system started at 2018-06-28 20:54:44 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:56:33.473: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:56:33.473: INFO: kube-proxy-8qt66 from kube-system started at 2018-06-28 20:27:44 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:56:33.473: INFO: npd-v0.4.1-fq8q4 from kube-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:56:33.473: INFO: fluentd-es-9thgd from rackspace-system started at 2018-06-28 20:36:33 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:56:33.473: INFO: es-data-1 from rackspace-system started at 2018-06-28 20:53:43 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container es-data ready: true, restart count 138
Jun 29 15:56:33.473: INFO: prometheus-customer-1 from monitoring started at 2018-06-28 20:54:23 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:56:33.473: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:56:33.473: INFO: prometheus-k8s-0 from rackspace-system started at 2018-06-28 20:54:20 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:56:33.473: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:56:33.473: INFO: prometheus-customer-0 from monitoring started at 2018-06-28 20:54:23 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:56:33.473: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:56:33.473: INFO: kube-calico-dhfwc from kube-system started at 2018-06-28 20:27:47 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:56:33.473: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:56:33.473: INFO: container-linux-update-operator-6df89667cb-4gwlh from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container update-operator ready: true, restart count 0
Jun 29 15:56:33.473: INFO: nginx-ingress-controller-7c7b8f746d-85lzp from rackspace-system started at 2018-06-28 20:54:14 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.473: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jun 29 15:56:33.473: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-1 before test
Jun 29 15:56:33.489: INFO: configure-oom-mbr5n from rackspace-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.489: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:56:33.489: INFO: grafana-0 from rackspace-system started at 2018-06-28 20:58:57 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.489: INFO: 	Container grafana ready: true, restart count 0
Jun 29 15:56:33.489: INFO: 	Container grafana-watcher ready: true, restart count 0
Jun 29 15:56:33.489: INFO: nginx-ingress-controller-7c7b8f746d-vjnl6 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.489: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jun 29 15:56:33.489: INFO: registry-admin-645ff5ff77-svlgr from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.489: INFO: 	Container registry-admin ready: true, restart count 0
Jun 29 15:56:33.489: INFO: kube-proxy-js89r from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:56:33.490: INFO: registry-image-scan-postgres-0 from rackspace-system started at 2018-06-28 20:58:32 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container registry-image-scan-postgres ready: true, restart count 0
Jun 29 15:56:33.490: INFO: prometheus-k8s-1 from rackspace-system started at 2018-06-28 20:58:31 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container prometheus ready: true, restart count 0
Jun 29 15:56:33.490: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jun 29 15:56:33.490: INFO: alertmanager-main-0 from rackspace-system started at 2018-06-28 20:58:53 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container alertmanager ready: true, restart count 0
Jun 29 15:56:33.490: INFO: 	Container config-reloader ready: true, restart count 0
Jun 29 15:56:33.490: INFO: es-data-0 from rackspace-system started at 2018-06-28 20:59:09 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container es-data ready: true, restart count 148
Jun 29 15:56:33.490: INFO: kube-calico-w8x5n from kube-system started at 2018-06-28 20:27:48 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:56:33.490: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:56:33.490: INFO: npd-v0.4.1-59zdt from kube-system started at 2018-06-28 20:32:21 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:56:33.490: INFO: fluentd-es-b4p8v from rackspace-system started at 2018-06-28 20:36:34 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:56:33.490: INFO: node-exporter-6ktxl from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:56:33.490: INFO: kube-flannel-2rvmq from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container kube-flannel ready: true, restart count 3
Jun 29 15:56:33.490: INFO: kibana-54898499fb-mqdg8 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container kibana ready: false, restart count 0
Jun 29 15:56:33.490: INFO: heapster-55f9c7bcb7-p62lz from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container heapster ready: true, restart count 0
Jun 29 15:56:33.490: INFO: elasticsearch-exporter-7449557bc-rtkgp from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container elasticsearch-exporter ready: true, restart count 0
Jun 29 15:56:33.490: INFO: kubernetes-dashboard-8f54b8b54-fs95w from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 29 15:56:33.490: INFO: registry-7758dd67d6-hn8bb from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container registry ready: true, restart count 0
Jun 29 15:56:33.490: INFO: 	Container registry-exporter ready: true, restart count 0
Jun 29 15:56:33.490: INFO: registry-ui-844884c845-bblj9 from rackspace-system started at 2018-06-28 20:58:54 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container registry-ui ready: true, restart count 3
Jun 29 15:56:33.490: INFO: container-linux-update-agent-qfmnq from rackspace-system started at 2018-06-28 20:38:24 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.490: INFO: 	Container update-agent ready: true, restart count 3
Jun 29 15:56:33.490: INFO: 
Logging pods the kubelet thinks is on node kubernetes-lblackstone-worker-2 before test
Jun 29 15:56:33.504: INFO: kube-flannel-m5kl7 from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container kube-flannel ready: true, restart count 2
Jun 29 15:56:33.504: INFO: registry-image-scan-8576ff96b4-ccbw2 from rackspace-system started at 2018-06-28 21:03:08 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container registry-image-scan ready: true, restart count 0
Jun 29 15:56:33.504: INFO: registry-mysql-0 from rackspace-system started at 2018-06-28 21:03:08 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container registry-mysql ready: true, restart count 0
Jun 29 15:56:33.504: INFO: es-data-2 from rackspace-system started at 2018-06-28 21:03:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container es-data ready: false, restart count 135
Jun 29 15:56:33.504: INFO: etcdsnapshot-1530230820-cgxrr from rackspace-system started at 2018-06-29 00:07:01 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container snapshot ready: false, restart count 0
Jun 29 15:56:33.504: INFO: kube-proxy-tg7sf from kube-system started at 2018-06-28 20:27:45 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container kube-proxy ready: true, restart count 1
Jun 29 15:56:33.504: INFO: configure-oom-ppn66 from rackspace-system started at 2018-06-28 20:32:20 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container configure-oom ready: true, restart count 1
Jun 29 15:56:33.504: INFO: fluentd-es-dn97d from rackspace-system started at 2018-06-28 20:36:34 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container fluentd-es ready: true, restart count 1
Jun 29 15:56:33.504: INFO: sonobuoy from sonobuoy started at 2018-06-29 15:20:46 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 29 15:56:33.504: INFO: node-exporter-5szrw from rackspace-system started at 2018-06-28 20:37:29 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container node-exporter ready: true, restart count 1
Jun 29 15:56:33.504: INFO: sonobuoy-e2e-job-51bfab993f0f4b31 from sonobuoy started at 2018-06-29 15:20:49 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.504: INFO: 	Container e2e ready: true, restart count 0
Jun 29 15:56:33.505: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 29 15:56:33.505: INFO: kube-calico-vtdww from kube-system started at 2018-06-28 20:27:48 +0000 UTC (2 container statuses recorded)
Jun 29 15:56:33.505: INFO: 	Container install-cni ready: true, restart count 1
Jun 29 15:56:33.505: INFO: 	Container kube-calico ready: true, restart count 1
Jun 29 15:56:33.505: INFO: npd-v0.4.1-57n7d from kube-system started at 2018-06-28 20:32:21 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.505: INFO: 	Container node-problem-detector ready: true, restart count 1
Jun 29 15:56:33.505: INFO: container-linux-update-agent-mhr9w from rackspace-system started at 2018-06-28 20:38:24 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.505: INFO: 	Container update-agent ready: true, restart count 2
Jun 29 15:56:33.505: INFO: etcdsnapshot-1530259620-852cf from rackspace-system started at 2018-06-29 08:07:07 +0000 UTC (1 container statuses recorded)
Jun 29 15:56:33.505: INFO: 	Container snapshot ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node kubernetes-lblackstone-worker-0
STEP: verifying the node has the label node kubernetes-lblackstone-worker-1
STEP: verifying the node has the label node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.627: INFO: Pod kube-calico-dhfwc requesting resource cpu=250m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.627: INFO: Pod kube-calico-vtdww requesting resource cpu=250m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.627: INFO: Pod kube-calico-w8x5n requesting resource cpu=250m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.627: INFO: Pod kube-flannel-2rvmq requesting resource cpu=0m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.627: INFO: Pod kube-flannel-6tj5j requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.627: INFO: Pod kube-flannel-m5kl7 requesting resource cpu=0m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.627: INFO: Pod kube-proxy-8qt66 requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.627: INFO: Pod kube-proxy-js89r requesting resource cpu=0m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.627: INFO: Pod kube-proxy-tg7sf requesting resource cpu=0m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.627: INFO: Pod npd-v0.4.1-57n7d requesting resource cpu=20m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.627: INFO: Pod npd-v0.4.1-59zdt requesting resource cpu=20m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.627: INFO: Pod npd-v0.4.1-fq8q4 requesting resource cpu=20m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.627: INFO: Pod prometheus-customer-0 requesting resource cpu=260m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.627: INFO: Pod prometheus-customer-1 requesting resource cpu=260m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod alertmanager-main-0 requesting resource cpu=5m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod alertmanager-main-1 requesting resource cpu=5m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod alertmanager-main-2 requesting resource cpu=5m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod configure-oom-kn8s9 requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod configure-oom-mbr5n requesting resource cpu=0m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod configure-oom-ppn66 requesting resource cpu=0m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.628: INFO: Pod container-linux-update-agent-g2b29 requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod container-linux-update-agent-mhr9w requesting resource cpu=0m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.628: INFO: Pod container-linux-update-agent-qfmnq requesting resource cpu=0m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod container-linux-update-operator-6df89667cb-4gwlh requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod default-http-backend-658c6856c5-vtlcw requesting resource cpu=10m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod elasticsearch-exporter-7449557bc-rtkgp requesting resource cpu=25m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod es-data-0 requesting resource cpu=25m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod es-data-1 requesting resource cpu=25m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod es-data-2 requesting resource cpu=25m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.628: INFO: Pod fluentd-es-9thgd requesting resource cpu=100m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod fluentd-es-b4p8v requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod fluentd-es-dn97d requesting resource cpu=100m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.628: INFO: Pod grafana-0 requesting resource cpu=150m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod heapster-55f9c7bcb7-p62lz requesting resource cpu=0m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod influxdb-545869c56c-ndhzm requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod kibana-54898499fb-mqdg8 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod kube-state-metrics-8747876f4-2rt6h requesting resource cpu=206m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod kubernetes-dashboard-8f54b8b54-fs95w requesting resource cpu=0m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod nginx-ingress-controller-7c7b8f746d-85lzp requesting resource cpu=100m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod nginx-ingress-controller-7c7b8f746d-vjnl6 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod node-exporter-5szrw requesting resource cpu=100m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.628: INFO: Pod node-exporter-6ktxl requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod node-exporter-z7p55 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod prometheus-k8s-0 requesting resource cpu=260m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.628: INFO: Pod prometheus-k8s-1 requesting resource cpu=260m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.628: INFO: Pod prometheus-operator-95bb8bdf9-wshj6 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.629: INFO: Pod registry-7758dd67d6-hn8bb requesting resource cpu=300m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.629: INFO: Pod registry-admin-645ff5ff77-svlgr requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.629: INFO: Pod registry-image-scan-8576ff96b4-ccbw2 requesting resource cpu=1500m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.629: INFO: Pod registry-image-scan-postgres-0 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.629: INFO: Pod registry-job-6ff94bb84c-wpc5v requesting resource cpu=0m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.629: INFO: Pod registry-mysql-0 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.629: INFO: Pod registry-nginx-5fcb7bcccf-ktgcl requesting resource cpu=300m on Node kubernetes-lblackstone-worker-0
Jun 29 15:56:33.629: INFO: Pod registry-ui-844884c845-bblj9 requesting resource cpu=100m on Node kubernetes-lblackstone-worker-1
Jun 29 15:56:33.629: INFO: Pod sonobuoy requesting resource cpu=0m on Node kubernetes-lblackstone-worker-2
Jun 29 15:56:33.629: INFO: Pod sonobuoy-e2e-job-51bfab993f0f4b31 requesting resource cpu=0m on Node kubernetes-lblackstone-worker-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef0556c-7bb4-11e8-8ddd-da371e372fc2.153caca3edb3ae22], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-ctjph" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef0556c-7bb4-11e8-8ddd-da371e372fc2.153caca43a352f36], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef0556c-7bb4-11e8-8ddd-da371e372fc2.153caca43dbbae42], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef0556c-7bb4-11e8-8ddd-da371e372fc2.153caca44e3aa677], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef0556c-7bb4-11e8-8ddd-da371e372fc2.153caca4a27845eb], Reason = [Scheduled], Message = [Successfully assigned filler-pod-fef0556c-7bb4-11e8-8ddd-da371e372fc2 to kubernetes-lblackstone-worker-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef36e3e-7bb4-11e8-8ddd-da371e372fc2.153caca3fb80455a], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-ctjph" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef36e3e-7bb4-11e8-8ddd-da371e372fc2.153caca434ddbde2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef36e3e-7bb4-11e8-8ddd-da371e372fc2.153caca43736a1b9], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef36e3e-7bb4-11e8-8ddd-da371e372fc2.153caca44731267f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef36e3e-7bb4-11e8-8ddd-da371e372fc2.153caca4a2fea06b], Reason = [Scheduled], Message = [Successfully assigned filler-pod-fef36e3e-7bb4-11e8-8ddd-da371e372fc2 to kubernetes-lblackstone-worker-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef4d280-7bb4-11e8-8ddd-da371e372fc2.153caca40a0acf8f], Reason = [SuccessfulMountVolume], Message = [MountVolume.SetUp succeeded for volume "default-token-ctjph" ]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef4d280-7bb4-11e8-8ddd-da371e372fc2.153caca440e0665d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef4d280-7bb4-11e8-8ddd-da371e372fc2.153caca4456e4386], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef4d280-7bb4-11e8-8ddd-da371e372fc2.153caca44f11342f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fef4d280-7bb4-11e8-8ddd-da371e372fc2.153caca4a3cdee87], Reason = [Scheduled], Message = [Successfully assigned filler-pod-fef4d280-7bb4-11e8-8ddd-da371e372fc2 to kubernetes-lblackstone-worker-2]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.153caca594eca0ee], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 Insufficient cpu.]
STEP: removing the label node off the node kubernetes-lblackstone-worker-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kubernetes-lblackstone-worker-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kubernetes-lblackstone-worker-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:56:38.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-csrgt" for this suite.
Jun 29 15:57:03.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:57:03.965: INFO: namespace: e2e-tests-sched-pred-csrgt, resource: bindings, ignored listing per whitelist
Jun 29 15:57:05.510: INFO: namespace e2e-tests-sched-pred-csrgt deletion completed in 26.677065531s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:92.521 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:57:05.512: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5jt5t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:57:05.793: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-5jt5t" to be "success or failure"
Jun 29 15:57:05.799: INFO: Pod "downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.523825ms
Jun 29 15:57:07.817: INFO: Pod "downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024037755s
Jun 29 15:57:09.834: INFO: Pod "downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040495243s
STEP: Saw pod success
Jun 29 15:57:09.834: INFO: Pod "downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:57:09.841: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:57:09.876: INFO: Waiting for pod downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:57:09.882: INFO: Pod downwardapi-volume-12199620-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:57:09.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5jt5t" for this suite.
Jun 29 15:57:16.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:57:17.216: INFO: namespace: e2e-tests-projected-5jt5t, resource: bindings, ignored listing per whitelist
Jun 29 15:57:18.015: INFO: namespace e2e-tests-projected-5jt5t deletion completed in 8.115257682s

â€¢ [SLOW TEST:12.504 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:57:18.017: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-6fsdl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0629 15:57:29.617893      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 29 15:57:29.618: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:57:29.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6fsdl" for this suite.
Jun 29 15:57:35.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:57:35.690: INFO: namespace: e2e-tests-gc-6fsdl, resource: bindings, ignored listing per whitelist
Jun 29 15:57:35.854: INFO: namespace e2e-tests-gc-6fsdl deletion completed in 6.226881635s

â€¢ [SLOW TEST:17.838 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:57:35.855: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bgx78
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-242f7e88-7bb5-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:57:36.149: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-bgx78" to be "success or failure"
Jun 29 15:57:36.156: INFO: Pod "pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.477427ms
Jun 29 15:57:38.163: INFO: Pod "pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014682736s
Jun 29 15:57:40.171: INFO: Pod "pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021872892s
STEP: Saw pod success
Jun 29 15:57:40.171: INFO: Pod "pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:57:40.179: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:57:40.237: INFO: Waiting for pod pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:57:40.242: INFO: Pod pod-projected-configmaps-24309fcb-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:57:40.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bgx78" for this suite.
Jun 29 15:57:46.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:57:46.452: INFO: namespace: e2e-tests-projected-bgx78, resource: bindings, ignored listing per whitelist
Jun 29 15:57:46.520: INFO: namespace e2e-tests-projected-bgx78 deletion completed in 6.264519501s

â€¢ [SLOW TEST:10.665 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:57:46.523: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-84wjj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-2a8b2ef1-7bb5-11e8-8ddd-da371e372fc2
STEP: Creating secret with name secret-projected-all-test-volume-2a8b2ed1-7bb5-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun 29 15:57:46.815: INFO: Waiting up to 5m0s for pod "projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-84wjj" to be "success or failure"
Jun 29 15:57:46.821: INFO: Pod "projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.463927ms
Jun 29 15:57:48.832: INFO: Pod "projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016658935s
Jun 29 15:57:50.841: INFO: Pod "projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025500018s
STEP: Saw pod success
Jun 29 15:57:50.841: INFO: Pod "projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:57:50.847: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2 container projected-all-volume-test: <nil>
STEP: delete the pod
Jun 29 15:57:50.881: INFO: Waiting for pod projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:57:50.886: INFO: Pod projected-volume-2a8b2e4c-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:57:50.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-84wjj" for this suite.
Jun 29 15:57:56.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:57:56.980: INFO: namespace: e2e-tests-projected-84wjj, resource: bindings, ignored listing per whitelist
Jun 29 15:57:57.158: INFO: namespace e2e-tests-projected-84wjj deletion completed in 6.263002603s

â€¢ [SLOW TEST:10.636 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:57:57.160: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2gmsl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-30df996f-7bb5-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 15:57:57.427: INFO: Waiting up to 5m0s for pod "pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-2gmsl" to be "success or failure"
Jun 29 15:57:57.433: INFO: Pod "pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.876439ms
Jun 29 15:57:59.440: INFO: Pod "pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012838424s
STEP: Saw pod success
Jun 29 15:57:59.440: INFO: Pod "pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:57:59.487: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 15:57:59.537: INFO: Waiting for pod pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:57:59.556: INFO: Pod pod-configmaps-30e0b51d-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:57:59.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2gmsl" for this suite.
Jun 29 15:58:05.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:58:05.652: INFO: namespace: e2e-tests-configmap-2gmsl, resource: bindings, ignored listing per whitelist
Jun 29 15:58:05.828: INFO: namespace e2e-tests-configmap-2gmsl deletion completed in 6.26111151s

â€¢ [SLOW TEST:8.668 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:58:05.828: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j8vg6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:58:06.082: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-j8vg6" to be "success or failure"
Jun 29 15:58:06.088: INFO: Pod "downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.524379ms
Jun 29 15:58:08.107: INFO: Pod "downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024758633s
Jun 29 15:58:10.115: INFO: Pod "downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032902473s
STEP: Saw pod success
Jun 29 15:58:10.115: INFO: Pod "downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:58:10.121: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:58:10.152: INFO: Waiting for pod downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:58:10.160: INFO: Pod downwardapi-volume-36092ce4-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:58:10.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j8vg6" for this suite.
Jun 29 15:58:16.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:58:16.222: INFO: namespace: e2e-tests-projected-j8vg6, resource: bindings, ignored listing per whitelist
Jun 29 15:58:16.398: INFO: namespace e2e-tests-projected-j8vg6 deletion completed in 6.22689291s

â€¢ [SLOW TEST:10.570 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:58:16.399: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-7q9b7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun 29 15:58:16.690: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7q9b7,SelfLink:/api/v1/namespaces/e2e-tests-watch-7q9b7/configmaps/e2e-watch-test-label-changed,UID:3c649647-7bb5-11e8-b9b2-fa163ec8ddce,ResourceVersion:169677,Generation:0,CreationTimestamp:2018-06-29 15:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 29 15:58:16.690: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7q9b7,SelfLink:/api/v1/namespaces/e2e-tests-watch-7q9b7/configmaps/e2e-watch-test-label-changed,UID:3c649647-7bb5-11e8-b9b2-fa163ec8ddce,ResourceVersion:169678,Generation:0,CreationTimestamp:2018-06-29 15:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 29 15:58:16.691: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7q9b7,SelfLink:/api/v1/namespaces/e2e-tests-watch-7q9b7/configmaps/e2e-watch-test-label-changed,UID:3c649647-7bb5-11e8-b9b2-fa163ec8ddce,ResourceVersion:169679,Generation:0,CreationTimestamp:2018-06-29 15:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun 29 15:58:26.778: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7q9b7,SelfLink:/api/v1/namespaces/e2e-tests-watch-7q9b7/configmaps/e2e-watch-test-label-changed,UID:3c649647-7bb5-11e8-b9b2-fa163ec8ddce,ResourceVersion:169699,Generation:0,CreationTimestamp:2018-06-29 15:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 29 15:58:26.778: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7q9b7,SelfLink:/api/v1/namespaces/e2e-tests-watch-7q9b7/configmaps/e2e-watch-test-label-changed,UID:3c649647-7bb5-11e8-b9b2-fa163ec8ddce,ResourceVersion:169700,Generation:0,CreationTimestamp:2018-06-29 15:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jun 29 15:58:26.779: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7q9b7,SelfLink:/api/v1/namespaces/e2e-tests-watch-7q9b7/configmaps/e2e-watch-test-label-changed,UID:3c649647-7bb5-11e8-b9b2-fa163ec8ddce,ResourceVersion:169701,Generation:0,CreationTimestamp:2018-06-29 15:58:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:58:26.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7q9b7" for this suite.
Jun 29 15:58:32.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:58:32.868: INFO: namespace: e2e-tests-watch-7q9b7, resource: bindings, ignored listing per whitelist
Jun 29 15:58:33.018: INFO: namespace e2e-tests-watch-7q9b7 deletion completed in 6.228475123s

â€¢ [SLOW TEST:16.619 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:58:33.020: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-l4jq4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 15:58:33.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-l4jq4" to be "success or failure"
Jun 29 15:58:33.284: INFO: Pod "downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.251103ms
Jun 29 15:58:35.292: INFO: Pod "downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012650731s
Jun 29 15:58:37.309: INFO: Pod "downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029919219s
STEP: Saw pod success
Jun 29 15:58:37.309: INFO: Pod "downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:58:37.315: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 15:58:37.352: INFO: Waiting for pod downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:58:37.358: INFO: Pod downwardapi-volume-463f4940-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:58:37.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l4jq4" for this suite.
Jun 29 15:58:43.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:58:43.526: INFO: namespace: e2e-tests-downward-api-l4jq4, resource: bindings, ignored listing per whitelist
Jun 29 15:58:43.648: INFO: namespace e2e-tests-downward-api-l4jq4 deletion completed in 6.280175792s

â€¢ [SLOW TEST:10.628 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:58:43.649: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-w6tnh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jun 29 15:58:45.991: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-4c9ce0ef-7bb5-11e8-8ddd-da371e372fc2", GenerateName:"", Namespace:"e2e-tests-pods-w6tnh", SelfLink:"/api/v1/namespaces/e2e-tests-pods-w6tnh/pods/pod-submit-remove-4c9ce0ef-7bb5-11e8-8ddd-da371e372fc2", UID:"4ca9d88f-7bb5-11e8-b9b2-fa163ec8ddce", ResourceVersion:"169795", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63665884724, loc:(*time.Location)(0x642c9a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"944681902"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7svtl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422f06fc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7svtl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422008ad8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kubernetes-lblackstone-worker-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422eb65a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422008b10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422008b40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63665884723, loc:(*time.Location)(0x642c9a0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63665884725, loc:(*time.Location)(0x642c9a0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63665884726, loc:(*time.Location)(0x642c9a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.8", PodIP:"10.2.5.100", StartTime:(*v1.Time)(0xc422eb48c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422eb48e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"docker://3a65058a1f9c6e89fe1f31a13d4642a5ef0cdcdeea04f44ee10ab165e33a02b3"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jun 29 15:58:51.040: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:58:51.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-w6tnh" for this suite.
Jun 29 15:58:57.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:58:57.254: INFO: namespace: e2e-tests-pods-w6tnh, resource: bindings, ignored listing per whitelist
Jun 29 15:58:57.373: INFO: namespace e2e-tests-pods-w6tnh deletion completed in 6.314683116s

â€¢ [SLOW TEST:13.725 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:58:57.374: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-bwh2b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 15:58:57.672: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun 29 15:58:57.686: INFO: Number of nodes with available pods: 0
Jun 29 15:58:57.686: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun 29 15:58:57.727: INFO: Number of nodes with available pods: 0
Jun 29 15:58:57.728: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:58:58.736: INFO: Number of nodes with available pods: 0
Jun 29 15:58:58.736: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:58:59.734: INFO: Number of nodes with available pods: 1
Jun 29 15:58:59.734: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun 29 15:58:59.771: INFO: Number of nodes with available pods: 1
Jun 29 15:58:59.771: INFO: Number of running nodes: 0, number of available pods: 1
Jun 29 15:59:00.779: INFO: Number of nodes with available pods: 0
Jun 29 15:59:00.779: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun 29 15:59:00.793: INFO: Number of nodes with available pods: 0
Jun 29 15:59:00.793: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:01.810: INFO: Number of nodes with available pods: 0
Jun 29 15:59:01.810: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:02.801: INFO: Number of nodes with available pods: 0
Jun 29 15:59:02.801: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:03.801: INFO: Number of nodes with available pods: 0
Jun 29 15:59:03.801: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:04.801: INFO: Number of nodes with available pods: 0
Jun 29 15:59:04.802: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:05.802: INFO: Number of nodes with available pods: 0
Jun 29 15:59:05.802: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:06.800: INFO: Number of nodes with available pods: 0
Jun 29 15:59:06.800: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:07.801: INFO: Number of nodes with available pods: 0
Jun 29 15:59:07.801: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:08.802: INFO: Number of nodes with available pods: 0
Jun 29 15:59:08.802: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:09.801: INFO: Number of nodes with available pods: 0
Jun 29 15:59:09.801: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 15:59:10.802: INFO: Number of nodes with available pods: 1
Jun 29 15:59:10.802: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-bwh2b, will wait for the garbage collector to delete the pods
Jun 29 15:59:10.890: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.057015ms
Jun 29 15:59:10.990: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.433135ms
Jun 29 15:59:14.410: INFO: Number of nodes with available pods: 0
Jun 29 15:59:14.411: INFO: Number of running nodes: 0, number of available pods: 0
Jun 29 15:59:14.421: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bwh2b/daemonsets","resourceVersion":"169915"},"items":null}

Jun 29 15:59:14.428: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bwh2b/pods","resourceVersion":"169915"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:59:14.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bwh2b" for this suite.
Jun 29 15:59:20.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:59:20.635: INFO: namespace: e2e-tests-daemonsets-bwh2b, resource: bindings, ignored listing per whitelist
Jun 29 15:59:20.743: INFO: namespace e2e-tests-daemonsets-bwh2b deletion completed in 6.253114945s

â€¢ [SLOW TEST:23.369 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:59:20.744: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ntg8h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:59:21.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ntg8h" for this suite.
Jun 29 15:59:45.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:59:45.234: INFO: namespace: e2e-tests-pods-ntg8h, resource: bindings, ignored listing per whitelist
Jun 29 15:59:45.295: INFO: namespace e2e-tests-pods-ntg8h deletion completed in 24.278869558s

â€¢ [SLOW TEST:24.551 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:59:45.299: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2cqzf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jun 29 15:59:45.580: INFO: Waiting up to 5m0s for pod "downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-2cqzf" to be "success or failure"
Jun 29 15:59:45.589: INFO: Pod "downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.366957ms
Jun 29 15:59:47.598: INFO: Pod "downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018265951s
STEP: Saw pod success
Jun 29 15:59:47.598: INFO: Pod "downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:59:47.606: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 15:59:47.647: INFO: Waiting for pod downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:59:47.656: INFO: Pod downward-api-71566601-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:59:47.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2cqzf" for this suite.
Jun 29 15:59:53.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 15:59:53.768: INFO: namespace: e2e-tests-downward-api-2cqzf, resource: bindings, ignored listing per whitelist
Jun 29 15:59:53.902: INFO: namespace e2e-tests-downward-api-2cqzf deletion completed in 6.235714901s

â€¢ [SLOW TEST:8.604 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 15:59:53.906: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-58khn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jun 29 15:59:54.177: INFO: Waiting up to 5m0s for pod "downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-58khn" to be "success or failure"
Jun 29 15:59:54.184: INFO: Pod "downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.065559ms
Jun 29 15:59:56.204: INFO: Pod "downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027513148s
STEP: Saw pod success
Jun 29 15:59:56.205: INFO: Pod "downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 15:59:56.211: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 15:59:56.257: INFO: Waiting for pod downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 15:59:56.264: INFO: Pod downward-api-7676bd4a-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 15:59:56.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-58khn" for this suite.
Jun 29 16:00:02.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:00:02.556: INFO: namespace: e2e-tests-downward-api-58khn, resource: bindings, ignored listing per whitelist
Jun 29 16:00:02.573: INFO: namespace e2e-tests-downward-api-58khn deletion completed in 6.282270506s

â€¢ [SLOW TEST:8.671 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:00:02.577: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-nz2cg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
Jun 29 16:00:02.837: INFO: Waiting up to 5m0s for pod "var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-var-expansion-nz2cg" to be "success or failure"
Jun 29 16:00:02.842: INFO: Pod "var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.073132ms
Jun 29 16:00:04.850: INFO: Pod "var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012520645s
Jun 29 16:00:06.868: INFO: Pod "var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03136916s
STEP: Saw pod success
Jun 29 16:00:06.869: INFO: Pod "var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:00:06.875: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 16:00:06.919: INFO: Waiting for pod var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:00:06.926: INFO: Pod var-expansion-7ba0b25d-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:00:06.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nz2cg" for this suite.
Jun 29 16:00:12.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:00:13.084: INFO: namespace: e2e-tests-var-expansion-nz2cg, resource: bindings, ignored listing per whitelist
Jun 29 16:00:13.206: INFO: namespace e2e-tests-var-expansion-nz2cg deletion completed in 6.267848208s

â€¢ [SLOW TEST:10.629 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:00:13.209: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dddqb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:00:13.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-dddqb" to be "success or failure"
Jun 29 16:00:13.549: INFO: Pod "downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.76068ms
Jun 29 16:00:15.558: INFO: Pod "downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014655574s
Jun 29 16:00:17.578: INFO: Pod "downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035252868s
STEP: Saw pod success
Jun 29 16:00:17.579: INFO: Pod "downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:00:17.585: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:00:17.633: INFO: Waiting for pod downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:00:17.648: INFO: Pod downwardapi-volume-8202554c-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:00:17.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dddqb" for this suite.
Jun 29 16:00:23.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:00:23.788: INFO: namespace: e2e-tests-projected-dddqb, resource: bindings, ignored listing per whitelist
Jun 29 16:00:23.947: INFO: namespace e2e-tests-projected-dddqb deletion completed in 6.289097283s

â€¢ [SLOW TEST:10.738 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:00:23.948: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-n5n6n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-n5n6n
Jun 29 16:00:26.260: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-n5n6n
STEP: checking the pod's current state and verifying that restartCount is present
Jun 29 16:00:26.266: INFO: Initial restart count of pod liveness-http is 0
Jun 29 16:00:42.401: INFO: Restart count of pod e2e-tests-container-probe-n5n6n/liveness-http is now 1 (16.135049671s elapsed)
Jun 29 16:01:02.522: INFO: Restart count of pod e2e-tests-container-probe-n5n6n/liveness-http is now 2 (36.255771398s elapsed)
Jun 29 16:01:22.662: INFO: Restart count of pod e2e-tests-container-probe-n5n6n/liveness-http is now 3 (56.396005108s elapsed)
Jun 29 16:01:42.828: INFO: Restart count of pod e2e-tests-container-probe-n5n6n/liveness-http is now 4 (1m16.561732843s elapsed)
Jun 29 16:02:55.232: INFO: Restart count of pod e2e-tests-container-probe-n5n6n/liveness-http is now 5 (2m28.965771105s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:02:55.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n5n6n" for this suite.
Jun 29 16:03:01.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:03:01.477: INFO: namespace: e2e-tests-container-probe-n5n6n, resource: bindings, ignored listing per whitelist
Jun 29 16:03:01.552: INFO: namespace e2e-tests-container-probe-n5n6n deletion completed in 6.2495834s

â€¢ [SLOW TEST:157.605 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:03:01.553: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5k6pn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:03:01.839: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-5k6pn" to be "success or failure"
Jun 29 16:03:01.845: INFO: Pod "downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.48816ms
Jun 29 16:03:03.852: INFO: Pod "downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012543232s
Jun 29 16:03:05.862: INFO: Pod "downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023218561s
STEP: Saw pod success
Jun 29 16:03:05.862: INFO: Pod "downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:03:05.868: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:03:05.936: INFO: Waiting for pod downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:03:05.946: INFO: Pod downwardapi-volume-e6525634-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:03:05.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5k6pn" for this suite.
Jun 29 16:03:11.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:03:12.070: INFO: namespace: e2e-tests-downward-api-5k6pn, resource: bindings, ignored listing per whitelist
Jun 29 16:03:12.211: INFO: namespace e2e-tests-downward-api-5k6pn deletion completed in 6.253609671s

â€¢ [SLOW TEST:10.658 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:03:12.211: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-kk4d7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kk4d7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kk4d7 to expose endpoints map[]
Jun 29 16:03:12.470: INFO: Get endpoints failed (7.842918ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jun 29 16:03:13.484: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kk4d7 exposes endpoints map[] (1.021246041s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kk4d7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kk4d7 to expose endpoints map[pod1:[80]]
Jun 29 16:03:16.562: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kk4d7 exposes endpoints map[pod1:[80]] (3.059958081s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kk4d7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kk4d7 to expose endpoints map[pod1:[80] pod2:[80]]
Jun 29 16:03:18.648: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kk4d7 exposes endpoints map[pod1:[80] pod2:[80]] (2.074430187s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kk4d7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kk4d7 to expose endpoints map[pod2:[80]]
Jun 29 16:03:18.745: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kk4d7 exposes endpoints map[pod2:[80]] (37.124567ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kk4d7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kk4d7 to expose endpoints map[]
Jun 29 16:03:18.765: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kk4d7 exposes endpoints map[] (4.917513ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:03:18.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kk4d7" for this suite.
Jun 29 16:03:42.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:03:42.955: INFO: namespace: e2e-tests-services-kk4d7, resource: bindings, ignored listing per whitelist
Jun 29 16:03:43.255: INFO: namespace e2e-tests-services-kk4d7 deletion completed in 24.415802867s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:31.044 seconds]
[sig-network] Services
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:03:43.256: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-q89qw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-ff31f6a3-7bb5-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 16:03:43.576: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-q89qw" to be "success or failure"
Jun 29 16:03:43.581: INFO: Pod "pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.890755ms
Jun 29 16:03:45.595: INFO: Pod "pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019415707s
STEP: Saw pod success
Jun 29 16:03:45.596: INFO: Pod "pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:03:45.632: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 16:03:45.673: INFO: Waiting for pod pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:03:45.678: INFO: Pod pod-configmaps-ff3319d8-7bb5-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:03:45.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q89qw" for this suite.
Jun 29 16:03:51.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:03:51.994: INFO: namespace: e2e-tests-configmap-q89qw, resource: bindings, ignored listing per whitelist
Jun 29 16:03:52.051: INFO: namespace e2e-tests-configmap-q89qw deletion completed in 6.361784889s

â€¢ [SLOW TEST:8.796 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:03:52.053: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-dlrzz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-dlrzz/configmap-test-04734ff8-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 16:03:52.424: INFO: Waiting up to 5m0s for pod "pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-dlrzz" to be "success or failure"
Jun 29 16:03:52.433: INFO: Pod "pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.215555ms
Jun 29 16:03:54.456: INFO: Pod "pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032249531s
Jun 29 16:03:56.467: INFO: Pod "pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042600721s
STEP: Saw pod success
Jun 29 16:03:56.467: INFO: Pod "pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:03:56.472: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2 container env-test: <nil>
STEP: delete the pod
Jun 29 16:03:56.544: INFO: Waiting for pod pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:03:56.553: INFO: Pod pod-configmaps-04750f62-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:03:56.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dlrzz" for this suite.
Jun 29 16:04:02.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:04:02.867: INFO: namespace: e2e-tests-configmap-dlrzz, resource: bindings, ignored listing per whitelist
Jun 29 16:04:02.978: INFO: namespace e2e-tests-configmap-dlrzz deletion completed in 6.414689436s

â€¢ [SLOW TEST:10.925 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:04:02.980: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-t94pt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-0af4545a-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating configMap with name cm-test-opt-upd-0af4556c-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0af4545a-7bb6-11e8-8ddd-da371e372fc2
STEP: Updating configmap cm-test-opt-upd-0af4556c-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating configMap with name cm-test-opt-create-0af45589-7bb6-11e8-8ddd-da371e372fc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:04:09.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t94pt" for this suite.
Jun 29 16:04:33.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:04:33.778: INFO: namespace: e2e-tests-projected-t94pt, resource: bindings, ignored listing per whitelist
Jun 29 16:04:33.951: INFO: namespace e2e-tests-projected-t94pt deletion completed in 24.361863383s

â€¢ [SLOW TEST:30.971 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:04:33.951: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ftsfg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-1d6c55b9-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 16:04:34.293: INFO: Waiting up to 5m0s for pod "pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-ftsfg" to be "success or failure"
Jun 29 16:04:34.303: INFO: Pod "pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.631384ms
Jun 29 16:04:36.312: INFO: Pod "pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018485343s
STEP: Saw pod success
Jun 29 16:04:36.312: INFO: Pod "pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:04:36.331: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 16:04:36.382: INFO: Waiting for pod pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:04:36.386: INFO: Pod pod-secrets-1d6d8dc9-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:04:36.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ftsfg" for this suite.
Jun 29 16:04:42.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:04:42.627: INFO: namespace: e2e-tests-secrets-ftsfg, resource: bindings, ignored listing per whitelist
Jun 29 16:04:42.742: INFO: namespace e2e-tests-secrets-ftsfg deletion completed in 6.34505874s

â€¢ [SLOW TEST:8.791 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:04:42.743: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k2jdj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-22a4eff8-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 16:04:43.051: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-k2jdj" to be "success or failure"
Jun 29 16:04:43.056: INFO: Pod "pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.162685ms
Jun 29 16:04:45.069: INFO: Pod "pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017862881s
Jun 29 16:04:47.076: INFO: Pod "pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024934456s
STEP: Saw pod success
Jun 29 16:04:47.076: INFO: Pod "pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:04:47.083: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 29 16:04:47.153: INFO: Waiting for pod pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:04:47.159: INFO: Pod pod-projected-secrets-22a61652-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:04:47.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k2jdj" for this suite.
Jun 29 16:04:53.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:04:53.426: INFO: namespace: e2e-tests-projected-k2jdj, resource: bindings, ignored listing per whitelist
Jun 29 16:04:53.433: INFO: namespace e2e-tests-projected-k2jdj deletion completed in 6.258986532s

â€¢ [SLOW TEST:10.690 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:04:53.434: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-xm6s6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-xm6s6
Jun 29 16:04:55.757: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-xm6s6
STEP: checking the pod's current state and verifying that restartCount is present
Jun 29 16:04:55.763: INFO: Initial restart count of pod liveness-exec is 0
Jun 29 16:05:44.154: INFO: Restart count of pod e2e-tests-container-probe-xm6s6/liveness-exec is now 1 (48.390936405s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:05:44.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xm6s6" for this suite.
Jun 29 16:05:50.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:05:50.375: INFO: namespace: e2e-tests-container-probe-xm6s6, resource: bindings, ignored listing per whitelist
Jun 29 16:05:50.510: INFO: namespace e2e-tests-container-probe-xm6s6 deletion completed in 6.289904843s

â€¢ [SLOW TEST:57.076 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:05:50.510: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-w6mpz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-w6mpz
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-w6mpz
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-w6mpz
Jun 29 16:05:50.804: INFO: Found 0 stateful pods, waiting for 1
Jun 29 16:06:00.826: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun 29 16:06:00.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 16:06:01.259: INFO: stderr: ""
Jun 29 16:06:01.259: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 16:06:01.259: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 16:06:01.266: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 16:06:01.266: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 16:06:01.276: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jun 29 16:06:11.317: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:11.317: INFO: ss-0  kubernetes-lblackstone-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:11.317: INFO: 
Jun 29 16:06:11.317: INFO: StatefulSet ss has not reached scale 3, at 1
Jun 29 16:06:12.333: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990784395s
Jun 29 16:06:13.352: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.976798284s
Jun 29 16:06:14.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.95845999s
Jun 29 16:06:15.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.933394501s
Jun 29 16:06:16.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.924914763s
Jun 29 16:06:17.404: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.914276396s
Jun 29 16:06:18.414: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.904207706s
Jun 29 16:06:19.427: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.896295099s
Jun 29 16:06:20.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 883.500756ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-w6mpz
Jun 29 16:06:21.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 16:06:21.840: INFO: stderr: ""
Jun 29 16:06:21.840: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 16:06:21.840: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 16:06:21.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 16:06:22.190: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Jun 29 16:06:22.190: INFO: stdout: ""
Jun 29 16:06:22.190: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Jun 29 16:06:22.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 16:06:22.583: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Jun 29 16:06:22.583: INFO: stdout: ""
Jun 29 16:06:22.583: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jun 29 16:06:22.592: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 16:06:22.592: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 16:06:22.592: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun 29 16:06:22.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 16:06:22.989: INFO: stderr: ""
Jun 29 16:06:22.989: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 16:06:22.989: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 16:06:22.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 16:06:23.323: INFO: stderr: ""
Jun 29 16:06:23.323: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 16:06:23.323: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 16:06:23.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-w6mpz ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 16:06:23.748: INFO: stderr: ""
Jun 29 16:06:23.748: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 16:06:23.748: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 16:06:23.748: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 16:06:23.757: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jun 29 16:06:33.808: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 16:06:33.808: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 16:06:33.808: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 29 16:06:33.838: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:33.838: INFO: ss-0  kubernetes-lblackstone-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:33.838: INFO: ss-1  kubernetes-lblackstone-worker-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:33.838: INFO: ss-2  kubernetes-lblackstone-worker-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:33.838: INFO: 
Jun 29 16:06:33.838: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 29 16:06:34.845: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:34.846: INFO: ss-0  kubernetes-lblackstone-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:34.846: INFO: ss-1  kubernetes-lblackstone-worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:34.846: INFO: ss-2  kubernetes-lblackstone-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:34.846: INFO: 
Jun 29 16:06:34.846: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 29 16:06:35.857: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:35.857: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:35.857: INFO: ss-1  kubernetes-lblackstone-worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:35.857: INFO: ss-2  kubernetes-lblackstone-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:35.857: INFO: 
Jun 29 16:06:35.857: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 29 16:06:36.865: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:36.865: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:36.865: INFO: ss-1  kubernetes-lblackstone-worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:36.865: INFO: 
Jun 29 16:06:36.865: INFO: StatefulSet ss has not reached scale 0, at 2
Jun 29 16:06:37.873: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:37.873: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:37.873: INFO: ss-1  kubernetes-lblackstone-worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:14 +0000 UTC  }]
Jun 29 16:06:37.873: INFO: 
Jun 29 16:06:37.873: INFO: StatefulSet ss has not reached scale 0, at 2
Jun 29 16:06:38.880: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:38.880: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:38.880: INFO: 
Jun 29 16:06:38.880: INFO: StatefulSet ss has not reached scale 0, at 1
Jun 29 16:06:39.887: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:39.887: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:39.887: INFO: 
Jun 29 16:06:39.887: INFO: StatefulSet ss has not reached scale 0, at 1
Jun 29 16:06:40.901: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:40.901: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:40.901: INFO: 
Jun 29 16:06:40.901: INFO: StatefulSet ss has not reached scale 0, at 1
Jun 29 16:06:41.922: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:41.922: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:41.922: INFO: 
Jun 29 16:06:41.922: INFO: StatefulSet ss has not reached scale 0, at 1
Jun 29 16:06:42.931: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Jun 29 16:06:42.931: INFO: ss-0  kubernetes-lblackstone-worker-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:06:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-06-29 16:05:53 +0000 UTC  }]
Jun 29 16:06:42.931: INFO: 
Jun 29 16:06:42.931: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-w6mpz
Jun 29 16:06:43.948: INFO: Scaling statefulset ss to 0
Jun 29 16:06:43.966: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jun 29 16:06:43.973: INFO: Deleting all statefulset in ns e2e-tests-statefulset-w6mpz
Jun 29 16:06:43.979: INFO: Scaling statefulset ss to 0
Jun 29 16:06:43.997: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 16:06:44.003: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:06:44.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-w6mpz" for this suite.
Jun 29 16:06:50.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:06:50.254: INFO: namespace: e2e-tests-statefulset-w6mpz, resource: bindings, ignored listing per whitelist
Jun 29 16:06:50.282: INFO: namespace e2e-tests-statefulset-w6mpz deletion completed in 6.244500953s

â€¢ [SLOW TEST:59.772 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:06:50.284: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rp62v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jun 29 16:06:55.254: INFO: Successfully updated pod "labelsupdate6eb1b2b6-7bb6-11e8-8ddd-da371e372fc2"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:06:57.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rp62v" for this suite.
Jun 29 16:07:17.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:07:17.436: INFO: namespace: e2e-tests-projected-rp62v, resource: bindings, ignored listing per whitelist
Jun 29 16:07:17.567: INFO: namespace e2e-tests-projected-rp62v deletion completed in 20.2699491s

â€¢ [SLOW TEST:27.284 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:07:17.568: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qqlkx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun 29 16:07:17.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qqlkx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qqlkx/configmaps/e2e-watch-test-watch-closed,UID:7ef3d287-7bb6-11e8-b9b2-fa163ec8ddce,ResourceVersion:171618,Generation:0,CreationTimestamp:2018-06-29 16:07:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 29 16:07:17.842: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qqlkx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qqlkx/configmaps/e2e-watch-test-watch-closed,UID:7ef3d287-7bb6-11e8-b9b2-fa163ec8ddce,ResourceVersion:171619,Generation:0,CreationTimestamp:2018-06-29 16:07:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun 29 16:07:17.867: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qqlkx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qqlkx/configmaps/e2e-watch-test-watch-closed,UID:7ef3d287-7bb6-11e8-b9b2-fa163ec8ddce,ResourceVersion:171620,Generation:0,CreationTimestamp:2018-06-29 16:07:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 29 16:07:17.867: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qqlkx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qqlkx/configmaps/e2e-watch-test-watch-closed,UID:7ef3d287-7bb6-11e8-b9b2-fa163ec8ddce,ResourceVersion:171621,Generation:0,CreationTimestamp:2018-06-29 16:07:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:07:17.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qqlkx" for this suite.
Jun 29 16:07:23.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:07:23.935: INFO: namespace: e2e-tests-watch-qqlkx, resource: bindings, ignored listing per whitelist
Jun 29 16:07:24.114: INFO: namespace e2e-tests-watch-qqlkx deletion completed in 6.237669963s

â€¢ [SLOW TEST:6.545 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:07:24.114: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tn9mb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-82cad066-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume secrets
Jun 29 16:07:24.365: INFO: Waiting up to 5m0s for pod "pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-secrets-tn9mb" to be "success or failure"
Jun 29 16:07:24.372: INFO: Pod "pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.626546ms
Jun 29 16:07:26.382: INFO: Pod "pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016584649s
Jun 29 16:07:28.402: INFO: Pod "pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036059893s
STEP: Saw pod success
Jun 29 16:07:28.402: INFO: Pod "pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:07:28.407: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 29 16:07:28.444: INFO: Waiting for pod pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:07:28.449: INFO: Pod pod-secrets-82cbd6f2-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:07:28.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tn9mb" for this suite.
Jun 29 16:07:34.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:07:34.621: INFO: namespace: e2e-tests-secrets-tn9mb, resource: bindings, ignored listing per whitelist
Jun 29 16:07:34.733: INFO: namespace e2e-tests-secrets-tn9mb deletion completed in 6.272703284s

â€¢ [SLOW TEST:10.619 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:07:34.734: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zkl6b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:07:35.000: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-zkl6b" to be "success or failure"
Jun 29 16:07:35.006: INFO: Pod "downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.916689ms
Jun 29 16:07:37.023: INFO: Pod "downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022907056s
STEP: Saw pod success
Jun 29 16:07:37.023: INFO: Pod "downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:07:37.028: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:07:37.069: INFO: Waiting for pod downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:07:37.095: INFO: Pod downwardapi-volume-89235daf-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:07:37.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zkl6b" for this suite.
Jun 29 16:07:43.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:07:43.157: INFO: namespace: e2e-tests-downward-api-zkl6b, resource: bindings, ignored listing per whitelist
Jun 29 16:07:43.360: INFO: namespace e2e-tests-downward-api-zkl6b deletion completed in 6.254134354s

â€¢ [SLOW TEST:8.626 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:07:43.361: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-j9xjx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 16:07:45.717: INFO: Waiting up to 5m0s for pod "client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-pods-j9xjx" to be "success or failure"
Jun 29 16:07:45.722: INFO: Pod "client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.235187ms
Jun 29 16:07:47.729: INFO: Pod "client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011878273s
STEP: Saw pod success
Jun 29 16:07:47.729: INFO: Pod "client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:07:47.735: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2 container env3cont: <nil>
STEP: delete the pod
Jun 29 16:07:47.807: INFO: Waiting for pod client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:07:47.813: INFO: Pod client-envvars-8f86f507-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:07:47.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j9xjx" for this suite.
Jun 29 16:08:11.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:08:11.988: INFO: namespace: e2e-tests-pods-j9xjx, resource: bindings, ignored listing per whitelist
Jun 29 16:08:12.135: INFO: namespace e2e-tests-pods-j9xjx deletion completed in 24.312052478s

â€¢ [SLOW TEST:28.774 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:08:12.137: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ccx5v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-9f6ea97c-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 16:08:12.415: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-ccx5v" to be "success or failure"
Jun 29 16:08:12.423: INFO: Pod "pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.434115ms
Jun 29 16:08:14.435: INFO: Pod "pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01994653s
STEP: Saw pod success
Jun 29 16:08:14.435: INFO: Pod "pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:08:14.441: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 16:08:14.479: INFO: Waiting for pod pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:08:14.485: INFO: Pod pod-configmaps-9f6fc6f7-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:08:14.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ccx5v" for this suite.
Jun 29 16:08:20.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:08:20.546: INFO: namespace: e2e-tests-configmap-ccx5v, resource: bindings, ignored listing per whitelist
Jun 29 16:08:20.747: INFO: namespace e2e-tests-configmap-ccx5v deletion completed in 6.250900025s

â€¢ [SLOW TEST:8.611 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:08:20.747: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-flggw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:08:21.033: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-flggw" to be "success or failure"
Jun 29 16:08:21.039: INFO: Pod "downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.98635ms
Jun 29 16:08:23.056: INFO: Pod "downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023111309s
STEP: Saw pod success
Jun 29 16:08:23.056: INFO: Pod "downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:08:23.063: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:08:23.099: INFO: Waiting for pod downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:08:23.104: INFO: Pod downwardapi-volume-a49385ad-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:08:23.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-flggw" for this suite.
Jun 29 16:08:29.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:08:29.178: INFO: namespace: e2e-tests-projected-flggw, resource: bindings, ignored listing per whitelist
Jun 29 16:08:29.374: INFO: namespace e2e-tests-projected-flggw deletion completed in 6.258944764s

â€¢ [SLOW TEST:8.627 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:08:29.376: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-p976h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jun 29 16:08:29.639: INFO: Waiting up to 5m0s for pod "downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-p976h" to be "success or failure"
Jun 29 16:08:29.652: INFO: Pod "downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.245283ms
Jun 29 16:08:31.660: INFO: Pod "downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020682012s
STEP: Saw pod success
Jun 29 16:08:31.660: INFO: Pod "downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:08:31.668: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 16:08:31.701: INFO: Waiting for pod downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:08:31.706: INFO: Pod downward-api-a9b46630-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:08:31.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p976h" for this suite.
Jun 29 16:08:37.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:08:37.862: INFO: namespace: e2e-tests-downward-api-p976h, resource: bindings, ignored listing per whitelist
Jun 29 16:08:37.980: INFO: namespace e2e-tests-downward-api-p976h deletion completed in 6.264607849s

â€¢ [SLOW TEST:8.604 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:08:37.982: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bxfzf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:08:38.241: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-bxfzf" to be "success or failure"
Jun 29 16:08:38.247: INFO: Pod "downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.470523ms
Jun 29 16:08:40.255: INFO: Pod "downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013591362s
STEP: Saw pod success
Jun 29 16:08:40.255: INFO: Pod "downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:08:40.261: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:08:40.309: INFO: Waiting for pod downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:08:40.316: INFO: Pod downwardapi-volume-aed4dded-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:08:40.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bxfzf" for this suite.
Jun 29 16:08:46.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:08:46.550: INFO: namespace: e2e-tests-projected-bxfzf, resource: bindings, ignored listing per whitelist
Jun 29 16:08:46.560: INFO: namespace e2e-tests-projected-bxfzf deletion completed in 6.235215275s

â€¢ [SLOW TEST:8.579 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:08:46.562: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-ncskk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 16:09:04.839: INFO: Container started at 2018-06-29 16:08:47 +0000 UTC, pod became ready at 2018-06-29 16:09:03 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:09:04.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ncskk" for this suite.
Jun 29 16:09:28.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:09:29.100: INFO: namespace: e2e-tests-container-probe-ncskk, resource: bindings, ignored listing per whitelist
Jun 29 16:09:29.123: INFO: namespace e2e-tests-container-probe-ncskk deletion completed in 24.258491059s

â€¢ [SLOW TEST:42.561 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:09:29.128: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-t6zpg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t6zpg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 29 16:09:29.415: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 29 16:09:51.577: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.15:8080/dial?request=hostName&protocol=http&host=10.2.5.111&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t6zpg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:09:51.577: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:09:51.773: INFO: Waiting for endpoints: map[]
Jun 29 16:09:51.780: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.15:8080/dial?request=hostName&protocol=http&host=10.2.1.14&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t6zpg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:09:51.780: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:09:51.935: INFO: Waiting for endpoints: map[]
Jun 29 16:09:51.943: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.15:8080/dial?request=hostName&protocol=http&host=10.2.3.216&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t6zpg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:09:51.943: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:09:52.105: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:09:52.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t6zpg" for this suite.
Jun 29 16:10:16.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:10:16.168: INFO: namespace: e2e-tests-pod-network-test-t6zpg, resource: bindings, ignored listing per whitelist
Jun 29 16:10:16.358: INFO: namespace e2e-tests-pod-network-test-t6zpg deletion completed in 24.242061144s

â€¢ [SLOW TEST:47.230 seconds]
[sig-network] Networking
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:10:16.358: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6jfhh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
Jun 29 16:10:16.628: INFO: Waiting up to 5m0s for pod "client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-containers-6jfhh" to be "success or failure"
Jun 29 16:10:16.635: INFO: Pod "client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.08607ms
Jun 29 16:10:18.643: INFO: Pod "client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014073604s
Jun 29 16:10:20.650: INFO: Pod "client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021515563s
STEP: Saw pod success
Jun 29 16:10:20.650: INFO: Pod "client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:10:20.681: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 16:10:20.731: INFO: Waiting for pod client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:10:20.737: INFO: Pod client-containers-e979e775-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:10:20.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6jfhh" for this suite.
Jun 29 16:10:26.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:10:26.828: INFO: namespace: e2e-tests-containers-6jfhh, resource: bindings, ignored listing per whitelist
Jun 29 16:10:27.064: INFO: namespace e2e-tests-containers-6jfhh deletion completed in 6.314276876s

â€¢ [SLOW TEST:10.706 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:10:27.071: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8xqp5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-8xqp5/configmap-test-efe5705c-7bb6-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 16:10:27.418: INFO: Waiting up to 5m0s for pod "pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-8xqp5" to be "success or failure"
Jun 29 16:10:27.475: INFO: Pod "pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.419358ms
Jun 29 16:10:29.571: INFO: Pod "pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.111392689s
STEP: Saw pod success
Jun 29 16:10:29.572: INFO: Pod "pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:10:29.578: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2 container env-test: <nil>
STEP: delete the pod
Jun 29 16:10:29.782: INFO: Waiting for pod pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:10:29.798: INFO: Pod pod-configmaps-efe6711b-7bb6-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:10:29.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8xqp5" for this suite.
Jun 29 16:10:35.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:10:36.056: INFO: namespace: e2e-tests-configmap-8xqp5, resource: bindings, ignored listing per whitelist
Jun 29 16:10:36.182: INFO: namespace e2e-tests-configmap-8xqp5 deletion completed in 6.370681883s

â€¢ [SLOW TEST:9.111 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:10:36.186: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-x8rqt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 29 16:10:41.058: INFO: Successfully updated pod "pod-update-f54e911c-7bb6-11e8-8ddd-da371e372fc2"
STEP: verifying the updated pod is in kubernetes
Jun 29 16:10:41.071: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:10:41.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-x8rqt" for this suite.
Jun 29 16:11:05.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:11:05.124: INFO: namespace: e2e-tests-pods-x8rqt, resource: bindings, ignored listing per whitelist
Jun 29 16:11:05.350: INFO: namespace e2e-tests-pods-x8rqt deletion completed in 24.268353557s

â€¢ [SLOW TEST:29.165 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:11:05.352: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-q7c8z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jun 29 16:11:06.212: INFO: Waiting up to 5m0s for pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s" in namespace "e2e-tests-svcaccounts-q7c8z" to be "success or failure"
Jun 29 16:11:06.223: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s": Phase="Pending", Reason="", readiness=false. Elapsed: 10.961607ms
Jun 29 16:11:08.265: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052705304s
Jun 29 16:11:10.287: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07465764s
STEP: Saw pod success
Jun 29 16:11:10.287: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s" satisfied condition "success or failure"
Jun 29 16:11:10.296: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s container token-test: <nil>
STEP: delete the pod
Jun 29 16:11:10.340: INFO: Waiting for pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s to disappear
Jun 29 16:11:10.351: INFO: Pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-zz56s no longer exists
STEP: Creating a pod to test consume service account root CA
Jun 29 16:11:10.362: INFO: Waiting up to 5m0s for pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54" in namespace "e2e-tests-svcaccounts-q7c8z" to be "success or failure"
Jun 29 16:11:10.368: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54": Phase="Pending", Reason="", readiness=false. Elapsed: 5.983131ms
Jun 29 16:11:12.378: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015563566s
Jun 29 16:11:14.387: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024792362s
STEP: Saw pod success
Jun 29 16:11:14.387: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54" satisfied condition "success or failure"
Jun 29 16:11:14.394: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54 container root-ca-test: <nil>
STEP: delete the pod
Jun 29 16:11:14.466: INFO: Waiting for pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54 to disappear
Jun 29 16:11:14.474: INFO: Pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vmv54 no longer exists
STEP: Creating a pod to test consume service account namespace
Jun 29 16:11:14.485: INFO: Waiting up to 5m0s for pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk" in namespace "e2e-tests-svcaccounts-q7c8z" to be "success or failure"
Jun 29 16:11:14.490: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk": Phase="Pending", Reason="", readiness=false. Elapsed: 5.542796ms
Jun 29 16:11:16.555: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07027206s
Jun 29 16:11:18.573: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.087873844s
STEP: Saw pod success
Jun 29 16:11:18.573: INFO: Pod "pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk" satisfied condition "success or failure"
Jun 29 16:11:18.579: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk container namespace-test: <nil>
STEP: delete the pod
Jun 29 16:11:18.633: INFO: Waiting for pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk to disappear
Jun 29 16:11:18.645: INFO: Pod pod-service-account-070707db-7bb7-11e8-8ddd-da371e372fc2-vpnjk no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:11:18.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-q7c8z" for this suite.
Jun 29 16:11:24.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:11:24.912: INFO: namespace: e2e-tests-svcaccounts-q7c8z, resource: bindings, ignored listing per whitelist
Jun 29 16:11:24.956: INFO: namespace e2e-tests-svcaccounts-q7c8z deletion completed in 6.28930369s

â€¢ [SLOW TEST:19.604 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:11:24.959: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-cp4jn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-cp4jn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cp4jn to expose endpoints map[]
Jun 29 16:11:25.259: INFO: Get endpoints failed (8.032059ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jun 29 16:11:26.266: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cp4jn exposes endpoints map[] (1.015028003s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-cp4jn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cp4jn to expose endpoints map[pod1:[100]]
Jun 29 16:11:29.346: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cp4jn exposes endpoints map[pod1:[100]] (3.066028287s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-cp4jn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cp4jn to expose endpoints map[pod1:[100] pod2:[101]]
Jun 29 16:11:31.415: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cp4jn exposes endpoints map[pod2:[101] pod1:[100]] (2.059470403s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-cp4jn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cp4jn to expose endpoints map[pod2:[101]]
Jun 29 16:11:32.465: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cp4jn exposes endpoints map[pod2:[101]] (1.036304095s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-cp4jn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cp4jn to expose endpoints map[]
Jun 29 16:11:33.493: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cp4jn exposes endpoints map[] (1.013870404s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:11:33.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-cp4jn" for this suite.
Jun 29 16:11:39.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:11:39.878: INFO: namespace: e2e-tests-services-cp4jn, resource: bindings, ignored listing per whitelist
Jun 29 16:11:40.052: INFO: namespace e2e-tests-services-cp4jn deletion completed in 6.478002363s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:15.094 seconds]
[sig-network] Services
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:11:40.055: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-ffhkz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:11:40.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ffhkz" for this suite.
Jun 29 16:11:46.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:11:46.686: INFO: namespace: e2e-tests-services-ffhkz, resource: bindings, ignored listing per whitelist
Jun 29 16:11:46.769: INFO: namespace e2e-tests-services-ffhkz deletion completed in 6.375164355s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:6.714 seconds]
[sig-network] Services
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:11:46.769: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hl95s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hl95s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 29 16:11:47.087: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 29 16:12:09.451: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.2.3.219:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hl95s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:12:09.451: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:12:09.750: INFO: Found all expected endpoints: [netserver-0]
Jun 29 16:12:09.757: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.2.5.116:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hl95s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:12:09.757: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:12:09.974: INFO: Found all expected endpoints: [netserver-1]
Jun 29 16:12:09.980: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.2.1.18:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hl95s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:12:09.980: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:12:10.179: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:12:10.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hl95s" for this suite.
Jun 29 16:12:34.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:12:34.478: INFO: namespace: e2e-tests-pod-network-test-hl95s, resource: bindings, ignored listing per whitelist
Jun 29 16:12:34.497: INFO: namespace e2e-tests-pod-network-test-hl95s deletion completed in 24.305007029s

â€¢ [SLOW TEST:47.727 seconds]
[sig-network] Networking
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:12:34.497: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5knqh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:12:34.824: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-5knqh" to be "success or failure"
Jun 29 16:12:34.830: INFO: Pod "downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.828457ms
Jun 29 16:12:36.864: INFO: Pod "downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039987317s
Jun 29 16:12:38.877: INFO: Pod "downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052593936s
STEP: Saw pod success
Jun 29 16:12:38.877: INFO: Pod "downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:12:38.882: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:12:38.926: INFO: Waiting for pod downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:12:38.931: INFO: Pod downwardapi-volume-3bd86e70-7bb7-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:12:38.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5knqh" for this suite.
Jun 29 16:12:44.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:12:45.128: INFO: namespace: e2e-tests-downward-api-5knqh, resource: bindings, ignored listing per whitelist
Jun 29 16:12:45.204: INFO: namespace e2e-tests-downward-api-5knqh deletion completed in 6.26421804s

â€¢ [SLOW TEST:10.706 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:12:45.208: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-77jfp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 16:12:45.480: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun 29 16:12:45.497: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:45.497: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:45.497: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:45.527: INFO: Number of nodes with available pods: 0
Jun 29 16:12:45.527: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 16:12:46.540: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:46.541: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:46.541: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:46.549: INFO: Number of nodes with available pods: 0
Jun 29 16:12:46.549: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 16:12:47.539: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:47.539: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:47.539: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:47.546: INFO: Number of nodes with available pods: 1
Jun 29 16:12:47.546: INFO: Node kubernetes-lblackstone-worker-0 is running more than one daemon pod
Jun 29 16:12:48.564: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:48.564: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:48.564: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:48.570: INFO: Number of nodes with available pods: 3
Jun 29 16:12:48.570: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun 29 16:12:48.645: INFO: Wrong image for pod: daemon-set-f7rnf. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:48.645: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:48.645: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:48.654: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:48.654: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:48.654: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:49.663: INFO: Wrong image for pod: daemon-set-f7rnf. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:49.663: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:49.663: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:49.673: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:49.673: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:49.673: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:50.664: INFO: Wrong image for pod: daemon-set-f7rnf. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:50.664: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:50.664: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:50.750: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:50.750: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:50.750: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:51.662: INFO: Wrong image for pod: daemon-set-f7rnf. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:51.662: INFO: Pod daemon-set-f7rnf is not available
Jun 29 16:12:51.662: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:51.662: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:51.672: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:51.672: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:51.672: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:52.671: INFO: Pod daemon-set-pz9f5 is not available
Jun 29 16:12:52.672: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:52.672: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:52.686: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:52.686: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:52.686: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:53.661: INFO: Pod daemon-set-pz9f5 is not available
Jun 29 16:12:53.661: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:53.661: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:53.669: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:53.669: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:53.669: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:54.692: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:54.692: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:54.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:54.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:54.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:55.686: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:55.686: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:55.736: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:55.736: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:55.736: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:56.671: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:56.671: INFO: Wrong image for pod: daemon-set-wxbwd. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:56.671: INFO: Pod daemon-set-wxbwd is not available
Jun 29 16:12:56.694: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:56.695: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:56.695: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:57.667: INFO: Pod daemon-set-7hzmp is not available
Jun 29 16:12:57.668: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:57.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:57.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:57.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:58.667: INFO: Pod daemon-set-7hzmp is not available
Jun 29 16:12:58.667: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:58.679: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:58.679: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:58.680: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:59.668: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:12:59.679: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:59.679: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:12:59.679: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:00.668: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:13:00.668: INFO: Pod daemon-set-whgn5 is not available
Jun 29 16:13:00.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:00.684: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:00.684: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:01.661: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:13:01.661: INFO: Pod daemon-set-whgn5 is not available
Jun 29 16:13:01.671: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:01.671: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:01.671: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:02.666: INFO: Wrong image for pod: daemon-set-whgn5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jun 29 16:13:02.666: INFO: Pod daemon-set-whgn5 is not available
Jun 29 16:13:02.677: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:02.678: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:02.678: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:03.662: INFO: Pod daemon-set-dqgg7 is not available
Jun 29 16:13:03.673: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:03.674: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:03.674: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jun 29 16:13:03.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:03.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:03.683: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:03.691: INFO: Number of nodes with available pods: 2
Jun 29 16:13:03.691: INFO: Node kubernetes-lblackstone-worker-1 is running more than one daemon pod
Jun 29 16:13:04.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:04.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:04.755: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:04.761: INFO: Number of nodes with available pods: 2
Jun 29 16:13:04.761: INFO: Node kubernetes-lblackstone-worker-1 is running more than one daemon pod
Jun 29 16:13:05.753: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:05.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:05.754: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:05.762: INFO: Number of nodes with available pods: 2
Jun 29 16:13:05.762: INFO: Node kubernetes-lblackstone-worker-1 is running more than one daemon pod
Jun 29 16:13:06.720: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:06.720: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:06.720: INFO: DaemonSet pods can't tolerate node kubernetes-lblackstone-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jun 29 16:13:06.732: INFO: Number of nodes with available pods: 3
Jun 29 16:13:06.732: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-77jfp, will wait for the garbage collector to delete the pods
Jun 29 16:13:06.861: INFO: Deleting {extensions DaemonSet} daemon-set took: 25.16564ms
Jun 29 16:13:06.961: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.333854ms
Jun 29 16:13:17.877: INFO: Number of nodes with available pods: 0
Jun 29 16:13:17.877: INFO: Number of running nodes: 0, number of available pods: 0
Jun 29 16:13:17.883: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-77jfp/daemonsets","resourceVersion":"173217"},"items":null}

Jun 29 16:13:17.888: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-77jfp/pods","resourceVersion":"173217"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:13:17.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-77jfp" for this suite.
Jun 29 16:13:23.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:13:24.034: INFO: namespace: e2e-tests-daemonsets-77jfp, resource: bindings, ignored listing per whitelist
Jun 29 16:13:24.190: INFO: namespace e2e-tests-daemonsets-77jfp deletion completed in 6.247620154s

â€¢ [SLOW TEST:38.983 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:13:24.190: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-44p9t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jun 29 16:13:24.496: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"597f1055-7bb7-11e8-b9b2-fa163ec8ddce", Controller:(*bool)(0xc4219f7dba), BlockOwnerDeletion:(*bool)(0xc4219f7dbb)}}
Jun 29 16:13:24.516: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"597c355c-7bb7-11e8-b9b2-fa163ec8ddce", Controller:(*bool)(0xc4219f7f5a), BlockOwnerDeletion:(*bool)(0xc4219f7f5b)}}
Jun 29 16:13:24.537: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"597d9e02-7bb7-11e8-b9b2-fa163ec8ddce", Controller:(*bool)(0xc421d8be4a), BlockOwnerDeletion:(*bool)(0xc421d8be4b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:13:29.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-44p9t" for this suite.
Jun 29 16:13:35.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:13:35.914: INFO: namespace: e2e-tests-gc-44p9t, resource: bindings, ignored listing per whitelist
Jun 29 16:13:35.927: INFO: namespace e2e-tests-gc-44p9t deletion completed in 6.27657254s

â€¢ [SLOW TEST:11.737 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:13:35.930: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kg7r8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0629 16:13:42.379747      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 29 16:13:42.381: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:13:42.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kg7r8" for this suite.
Jun 29 16:13:48.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:13:48.518: INFO: namespace: e2e-tests-gc-kg7r8, resource: bindings, ignored listing per whitelist
Jun 29 16:13:48.694: INFO: namespace e2e-tests-gc-kg7r8 deletion completed in 6.301564726s

â€¢ [SLOW TEST:12.764 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:13:48.695: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cjh2f
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-upd-681013fc-7bb7-11e8-8ddd-da371e372fc2
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-681013fc-7bb7-11e8-8ddd-da371e372fc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:13:53.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cjh2f" for this suite.
Jun 29 16:14:17.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:14:17.287: INFO: namespace: e2e-tests-configmap-cjh2f, resource: bindings, ignored listing per whitelist
Jun 29 16:14:17.424: INFO: namespace e2e-tests-configmap-cjh2f deletion completed in 24.267570717s

â€¢ [SLOW TEST:28.730 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:14:17.426: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m92tt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-792f540a-7bb7-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 16:14:17.744: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-m92tt" to be "success or failure"
Jun 29 16:14:17.751: INFO: Pod "pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.1822ms
Jun 29 16:14:19.769: INFO: Pod "pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025219222s
Jun 29 16:14:21.801: INFO: Pod "pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057401754s
STEP: Saw pod success
Jun 29 16:14:21.811: INFO: Pod "pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:14:21.821: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 16:14:21.859: INFO: Waiting for pod pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:14:21.875: INFO: Pod pod-projected-configmaps-7930d79f-7bb7-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:14:21.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m92tt" for this suite.
Jun 29 16:14:27.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:14:28.025: INFO: namespace: e2e-tests-projected-m92tt, resource: bindings, ignored listing per whitelist
Jun 29 16:14:28.141: INFO: namespace e2e-tests-projected-m92tt deletion completed in 6.249984622s

â€¢ [SLOW TEST:10.716 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:14:28.143: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-9pp2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-9pp2p
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
Jun 29 16:14:28.474: INFO: Found 0 stateful pods, waiting for 3
Jun 29 16:14:38.496: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 16:14:38.499: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 16:14:38.499: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun 29 16:14:38.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-9pp2p ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 16:14:39.032: INFO: stderr: ""
Jun 29 16:14:39.032: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 16:14:39.032: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Jun 29 16:14:49.099: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun 29 16:14:59.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-9pp2p ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 16:14:59.792: INFO: stderr: ""
Jun 29 16:14:59.792: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 16:14:59.792: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 16:15:09.855: INFO: Waiting for StatefulSet e2e-tests-statefulset-9pp2p/ss2 to complete update
Jun 29 16:15:09.855: INFO: Waiting for Pod e2e-tests-statefulset-9pp2p/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Rolling back to a previous revision
Jun 29 16:15:19.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-9pp2p ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 29 16:15:20.230: INFO: stderr: ""
Jun 29 16:15:20.230: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 29 16:15:20.230: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 29 16:15:30.296: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun 29 16:15:40.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-092945569 exec --namespace=e2e-tests-statefulset-9pp2p ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 29 16:15:40.690: INFO: stderr: ""
Jun 29 16:15:40.690: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 29 16:15:40.690: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 29 16:16:10.752: INFO: Waiting for StatefulSet e2e-tests-statefulset-9pp2p/ss2 to complete update
Jun 29 16:16:10.752: INFO: Waiting for Pod e2e-tests-statefulset-9pp2p/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jun 29 16:16:20.781: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9pp2p
Jun 29 16:16:20.787: INFO: Scaling statefulset ss2 to 0
Jun 29 16:16:50.817: INFO: Waiting for statefulset status.replicas updated to 0
Jun 29 16:16:50.825: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:16:50.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9pp2p" for this suite.
Jun 29 16:16:58.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:16:59.062: INFO: namespace: e2e-tests-statefulset-9pp2p, resource: bindings, ignored listing per whitelist
Jun 29 16:16:59.129: INFO: namespace e2e-tests-statefulset-9pp2p deletion completed in 8.258247609s

â€¢ [SLOW TEST:150.987 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:16:59.130: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5mp8p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:16:59.404: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-downward-api-5mp8p" to be "success or failure"
Jun 29 16:16:59.410: INFO: Pod "downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.086949ms
Jun 29 16:17:01.635: INFO: Pod "downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230852116s
Jun 29 16:17:03.745: INFO: Pod "downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.340779292s
STEP: Saw pod success
Jun 29 16:17:03.745: INFO: Pod "downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:17:03.765: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:17:06.932: INFO: Waiting for pod downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:17:08.722: INFO: Pod downwardapi-volume-d98c2cbe-7bb7-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:17:08.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5mp8p" for this suite.
Jun 29 16:17:15.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:17:15.564: INFO: namespace: e2e-tests-downward-api-5mp8p, resource: bindings, ignored listing per whitelist
Jun 29 16:17:15.746: INFO: namespace e2e-tests-downward-api-5mp8p deletion completed in 6.644667794s

â€¢ [SLOW TEST:16.616 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:17:15.748: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-k6tmq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2
Jun 29 16:17:16.047: INFO: Pod name my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2: Found 0 pods out of 1
Jun 29 16:17:21.055: INFO: Pod name my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2: Found 1 pods out of 1
Jun 29 16:17:21.055: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2" are running
Jun 29 16:17:21.062: INFO: Pod "my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2-6z499" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-06-29 16:17:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-06-29 16:17:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-06-29 16:17:18 +0000 UTC Reason: Message:}])
Jun 29 16:17:21.062: INFO: Trying to dial the pod
Jun 29 16:17:26.101: INFO: Controller my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2: Got expected result from replica 1 [my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2-6z499]: "my-hostname-basic-e377715a-7bb7-11e8-8ddd-da371e372fc2-6z499", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:17:26.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-k6tmq" for this suite.
Jun 29 16:17:32.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:17:32.397: INFO: namespace: e2e-tests-replication-controller-k6tmq, resource: bindings, ignored listing per whitelist
Jun 29 16:17:32.413: INFO: namespace e2e-tests-replication-controller-k6tmq deletion completed in 6.300618871s

â€¢ [SLOW TEST:16.666 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:17:32.414: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rmqc4
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-ed63f0f3-7bb7-11e8-8ddd-da371e372fc2
STEP: Creating secret with name s-test-opt-upd-ed63f14b-7bb7-11e8-8ddd-da371e372fc2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ed63f0f3-7bb7-11e8-8ddd-da371e372fc2
STEP: Updating secret s-test-opt-upd-ed63f14b-7bb7-11e8-8ddd-da371e372fc2
STEP: Creating secret with name s-test-opt-create-ed63f166-7bb7-11e8-8ddd-da371e372fc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:18:59.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rmqc4" for this suite.
Jun 29 16:19:23.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:19:23.995: INFO: namespace: e2e-tests-secrets-rmqc4, resource: bindings, ignored listing per whitelist
Jun 29 16:19:24.127: INFO: namespace e2e-tests-secrets-rmqc4 deletion completed in 24.344487105s

â€¢ [SLOW TEST:111.717 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:19:24.133: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-j6hdd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0629 16:19:34.647257      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 29 16:19:34.647: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:19:34.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j6hdd" for this suite.
Jun 29 16:19:42.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:19:42.790: INFO: namespace: e2e-tests-gc-j6hdd, resource: bindings, ignored listing per whitelist
Jun 29 16:19:43.001: INFO: namespace e2e-tests-gc-j6hdd deletion completed in 8.323028916s

â€¢ [SLOW TEST:18.868 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:19:43.032: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hck9s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hck9s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 29 16:19:43.336: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 29 16:20:09.595: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.49:8080/dial?request=hostName&protocol=udp&host=10.2.5.132&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hck9s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:20:09.596: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:20:09.868: INFO: Waiting for endpoints: map[]
Jun 29 16:20:09.875: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.49:8080/dial?request=hostName&protocol=udp&host=10.2.1.48&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hck9s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:20:09.875: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:20:10.095: INFO: Waiting for endpoints: map[]
Jun 29 16:20:10.133: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.1.49:8080/dial?request=hostName&protocol=udp&host=10.2.3.233&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hck9s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 29 16:20:10.133: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
Jun 29 16:20:10.375: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:20:10.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hck9s" for this suite.
Jun 29 16:20:34.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:20:34.596: INFO: namespace: e2e-tests-pod-network-test-hck9s, resource: bindings, ignored listing per whitelist
Jun 29 16:20:34.785: INFO: namespace e2e-tests-pod-network-test-hck9s deletion completed in 24.398101078s

â€¢ [SLOW TEST:51.753 seconds]
[sig-network] Networking
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:20:34.786: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-sqddx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
Jun 29 16:20:35.180: INFO: Waiting up to 5m0s for pod "var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-var-expansion-sqddx" to be "success or failure"
Jun 29 16:20:35.185: INFO: Pod "var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.273204ms
Jun 29 16:20:37.196: INFO: Pod "var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015766169s
Jun 29 16:20:39.210: INFO: Pod "var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030232857s
STEP: Saw pod success
Jun 29 16:20:39.210: INFO: Pod "var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:20:39.226: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 16:20:39.260: INFO: Waiting for pod var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:20:39.264: INFO: Pod var-expansion-5a28a6a2-7bb8-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:20:39.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-sqddx" for this suite.
Jun 29 16:20:45.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:20:45.405: INFO: namespace: e2e-tests-var-expansion-sqddx, resource: bindings, ignored listing per whitelist
Jun 29 16:20:45.591: INFO: namespace e2e-tests-var-expansion-sqddx deletion completed in 6.31420913s

â€¢ [SLOW TEST:10.806 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:20:45.596: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f98hz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with configMap that has name projected-configmap-test-upd-609badf9-7bb8-11e8-8ddd-da371e372fc2
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-609badf9-7bb8-11e8-8ddd-da371e372fc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:22:07.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f98hz" for this suite.
Jun 29 16:22:31.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:22:31.375: INFO: namespace: e2e-tests-projected-f98hz, resource: bindings, ignored listing per whitelist
Jun 29 16:22:31.486: INFO: namespace e2e-tests-projected-f98hz deletion completed in 24.261902804s

â€¢ [SLOW TEST:105.891 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:22:31.487: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-4cwkv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
Jun 29 16:22:31.758: INFO: Waiting up to 5m0s for pod "var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-var-expansion-4cwkv" to be "success or failure"
Jun 29 16:22:31.763: INFO: Pod "var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507293ms
Jun 29 16:22:33.773: INFO: Pod "var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015427931s
STEP: Saw pod success
Jun 29 16:22:33.773: INFO: Pod "var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:22:33.779: INFO: Trying to get logs from node kubernetes-lblackstone-worker-2 pod var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2 container dapi-container: <nil>
STEP: delete the pod
Jun 29 16:22:33.815: INFO: Waiting for pod var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:22:33.824: INFO: Pod var-expansion-9fa5a814-7bb8-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:22:33.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4cwkv" for this suite.
Jun 29 16:22:39.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:22:39.992: INFO: namespace: e2e-tests-var-expansion-4cwkv, resource: bindings, ignored listing per whitelist
Jun 29 16:22:40.106: INFO: namespace e2e-tests-var-expansion-4cwkv deletion completed in 6.248525295s

â€¢ [SLOW TEST:8.619 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:22:40.109: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-47tqs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
Jun 29 16:22:40.374: INFO: Waiting up to 5m0s for pod "client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-containers-47tqs" to be "success or failure"
Jun 29 16:22:40.380: INFO: Pod "client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.670265ms
Jun 29 16:22:42.388: INFO: Pod "client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014537589s
STEP: Saw pod success
Jun 29 16:22:42.389: INFO: Pod "client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:22:42.395: INFO: Trying to get logs from node kubernetes-lblackstone-worker-1 pod client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2 container test-container: <nil>
STEP: delete the pod
Jun 29 16:22:42.430: INFO: Waiting for pod client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:22:42.437: INFO: Pod client-containers-a4c87e7b-7bb8-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:22:42.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-47tqs" for this suite.
Jun 29 16:22:48.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:22:48.520: INFO: namespace: e2e-tests-containers-47tqs, resource: bindings, ignored listing per whitelist
Jun 29 16:22:48.685: INFO: namespace e2e-tests-containers-47tqs deletion completed in 6.238020861s

â€¢ [SLOW TEST:8.576 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:22:48.685: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vb7zf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jun 29 16:22:48.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-projected-vb7zf" to be "success or failure"
Jun 29 16:22:48.982: INFO: Pod "downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.11509ms
Jun 29 16:22:50.991: INFO: Pod "downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013725617s
STEP: Saw pod success
Jun 29 16:22:50.991: INFO: Pod "downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:22:50.997: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2 container client-container: <nil>
STEP: delete the pod
Jun 29 16:22:51.049: INFO: Waiting for pod downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:22:51.076: INFO: Pod downwardapi-volume-a9e8f41c-7bb8-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:22:51.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vb7zf" for this suite.
Jun 29 16:22:57.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:22:57.248: INFO: namespace: e2e-tests-projected-vb7zf, resource: bindings, ignored listing per whitelist
Jun 29 16:22:57.440: INFO: namespace e2e-tests-projected-vb7zf deletion completed in 6.355434562s

â€¢ [SLOW TEST:8.755 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:22:57.449: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-f9xqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 29 16:23:02.471: INFO: Successfully updated pod "pod-update-activedeadlineseconds-af35096d-7bb8-11e8-8ddd-da371e372fc2"
Jun 29 16:23:02.471: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-af35096d-7bb8-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-pods-f9xqz" to be "terminated due to deadline exceeded"
Jun 29 16:23:02.478: INFO: Pod "pod-update-activedeadlineseconds-af35096d-7bb8-11e8-8ddd-da371e372fc2": Phase="Running", Reason="", readiness=true. Elapsed: 6.432242ms
Jun 29 16:23:04.488: INFO: Pod "pod-update-activedeadlineseconds-af35096d-7bb8-11e8-8ddd-da371e372fc2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.016497807s
Jun 29 16:23:04.488: INFO: Pod "pod-update-activedeadlineseconds-af35096d-7bb8-11e8-8ddd-da371e372fc2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:23:04.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f9xqz" for this suite.
Jun 29 16:23:10.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:23:10.658: INFO: namespace: e2e-tests-pods-f9xqz, resource: bindings, ignored listing per whitelist
Jun 29 16:23:10.868: INFO: namespace e2e-tests-pods-f9xqz deletion completed in 6.324138888s

â€¢ [SLOW TEST:13.419 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:23:10.871: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-llf2c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-llf2c
Jun 29 16:23:15.311: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-llf2c
STEP: checking the pod's current state and verifying that restartCount is present
Jun 29 16:23:15.316: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:27:16.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-llf2c" for this suite.
Jun 29 16:27:22.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:27:22.447: INFO: namespace: e2e-tests-container-probe-llf2c, resource: bindings, ignored listing per whitelist
Jun 29 16:27:22.529: INFO: namespace e2e-tests-container-probe-llf2c deletion completed in 6.249167551s

â€¢ [SLOW TEST:251.658 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jun 29 16:27:22.530: INFO: >>> kubeConfig: /tmp/kubeconfig-092945569
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tffr2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-4d2171d1-7bb9-11e8-8ddd-da371e372fc2
STEP: Creating a pod to test consume configMaps
Jun 29 16:27:22.822: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2" in namespace "e2e-tests-configmap-tffr2" to be "success or failure"
Jun 29 16:27:22.841: INFO: Pod "pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.973551ms
Jun 29 16:27:24.848: INFO: Pod "pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026407207s
STEP: Saw pod success
Jun 29 16:27:24.848: INFO: Pod "pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2" satisfied condition "success or failure"
Jun 29 16:27:24.855: INFO: Trying to get logs from node kubernetes-lblackstone-worker-0 pod pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 29 16:27:24.891: INFO: Waiting for pod pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2 to disappear
Jun 29 16:27:24.896: INFO: Pod pod-configmaps-4d22722e-7bb9-11e8-8ddd-da371e372fc2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jun 29 16:27:24.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tffr2" for this suite.
Jun 29 16:27:30.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 29 16:27:30.960: INFO: namespace: e2e-tests-configmap-tffr2, resource: bindings, ignored listing per whitelist
Jun 29 16:27:31.192: INFO: namespace e2e-tests-configmap-tffr2 deletion completed in 6.287284646s

â€¢ [SLOW TEST:8.662 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
Jun 29 16:27:31.193: INFO: Running AfterSuite actions on all node
Jun 29 16:27:31.193: INFO: Running AfterSuite actions on node 1
Jun 29 16:27:31.193: INFO: Skipping dumping logs from cluster

Ran 143 of 998 Specs in 3999.506 seconds
SUCCESS! -- 143 Passed | 0 Failed | 0 Pending | 855 Skipped PASS

Ginkgo ran 1 suite in 1h6m40.320242044s
Test Suite Passed
