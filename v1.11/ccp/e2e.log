Feb 13 21:35:24.938: INFO: Overriding default scale value of zero to 1
Feb 13 21:35:24.938: INFO: Overriding default milliseconds value of zero to 5000
I0213 21:35:25.034638      17 test_context.go:382] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-208905800
I0213 21:35:25.034765      17 e2e.go:333] Starting e2e run "45e889f8-2fd7-11e9-aeb1-a6e9e8347cdc" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550093724 - Will randomize all specs
Will run 166 of 996 specs

Feb 13 21:35:25.095: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 21:35:25.096: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 13 21:35:25.103: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 21:35:25.119: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 21:35:25.119: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 13 21:35:25.120: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Feb 13 21:35:25.121: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt
Feb 13 21:35:25.122: INFO: e2e test version: v1.11.3
Feb 13 21:35:25.123: INFO: kube-apiserver version: v1.11.5
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:35:25.123: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
Feb 13 21:35:25.155: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 13 21:35:25.162: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-r5gqt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 21:35:29.297: INFO: Waiting up to 5m0s for pod "client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-pods-r5gqt" to be "success or failure"
Feb 13 21:35:29.299: INFO: Pod "client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.597972ms
Feb 13 21:35:31.301: INFO: Pod "client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003500775s
Feb 13 21:35:33.303: INFO: Pod "client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 4.005410232s
Feb 13 21:35:35.305: INFO: Pod "client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00738697s
STEP: Saw pod success
Feb 13 21:35:35.305: INFO: Pod "client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:35:35.306: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc container env3cont: <nil>
STEP: delete the pod
Feb 13 21:35:35.321: INFO: Waiting for pod client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:35:35.322: INFO: Pod client-envvars-48893b74-2fd7-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:35:35.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r5gqt" for this suite.
Feb 13 21:35:57.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:35:57.377: INFO: namespace: e2e-tests-pods-r5gqt, resource: bindings, ignored listing per whitelist
Feb 13 21:35:57.382: INFO: namespace e2e-tests-pods-r5gqt deletion completed in 22.056437837s

• [SLOW TEST:32.259 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:35:57.382: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-h79q5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 13 21:35:57.526: INFO: Waiting up to 5m0s for pod "pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-h79q5" to be "success or failure"
Feb 13 21:35:57.530: INFO: Pod "pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.530261ms
Feb 13 21:35:59.531: INFO: Pod "pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005197076s
Feb 13 21:36:01.533: INFO: Pod "pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006966169s
STEP: Saw pod success
Feb 13 21:36:01.533: INFO: Pod "pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:36:01.534: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 21:36:01.547: INFO: Waiting for pod pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:36:01.549: INFO: Pod pod-595c878e-2fd7-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:36:01.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h79q5" for this suite.
Feb 13 21:36:07.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:07.582: INFO: namespace: e2e-tests-emptydir-h79q5, resource: bindings, ignored listing per whitelist
Feb 13 21:36:07.592: INFO: namespace e2e-tests-emptydir-h79q5 deletion completed in 6.040486746s

• [SLOW TEST:10.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:36:07.592: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-khxlr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:36:07.730: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-khxlr" to be "success or failure"
Feb 13 21:36:07.735: INFO: Pod "downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.826516ms
Feb 13 21:36:09.737: INFO: Pod "downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006530931s
STEP: Saw pod success
Feb 13 21:36:09.737: INFO: Pod "downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:36:09.738: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 21:36:09.748: INFO: Waiting for pod downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:36:09.749: INFO: Pod downwardapi-volume-5f715ba0-2fd7-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:36:09.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-khxlr" for this suite.
Feb 13 21:36:15.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:15.798: INFO: namespace: e2e-tests-downward-api-khxlr, resource: bindings, ignored listing per whitelist
Feb 13 21:36:15.800: INFO: namespace e2e-tests-downward-api-khxlr deletion completed in 6.049295884s

• [SLOW TEST:8.208 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:36:15.800: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-dg7vf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-dg7vf
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-dg7vf
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-dg7vf
Feb 13 21:36:15.943: INFO: Found 0 stateful pods, waiting for 1
Feb 13 21:36:25.945: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 13 21:36:25.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:36:26.059: INFO: stderr: ""
Feb 13 21:36:26.059: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:36:26.059: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:36:26.061: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 21:36:36.063: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:36:36.063: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:36:36.072: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:36:36.072: INFO: ss-0  alex-300-cp1-vsp2-workerbe2ca38349  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  }]
Feb 13 21:36:36.072: INFO: 
Feb 13 21:36:36.072: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 13 21:36:37.074: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996504877s
Feb 13 21:36:38.076: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994543176s
Feb 13 21:36:39.078: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992805464s
Feb 13 21:36:40.081: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.990677412s
Feb 13 21:36:41.083: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987880068s
Feb 13 21:36:42.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985800506s
Feb 13 21:36:43.086: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983934864s
Feb 13 21:36:44.088: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.982032119s
Feb 13 21:36:45.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 980.237195ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-dg7vf
Feb 13 21:36:46.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:36:46.198: INFO: stderr: ""
Feb 13 21:36:46.198: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:36:46.198: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:36:46.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:36:46.338: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Feb 13 21:36:46.338: INFO: stdout: ""
Feb 13 21:36:46.338: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Feb 13 21:36:46.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:36:46.445: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Feb 13 21:36:46.445: INFO: stdout: ""
Feb 13 21:36:46.445: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 13 21:36:46.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:36:46.446: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:36:46.446: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 13 21:36:46.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:36:46.549: INFO: stderr: ""
Feb 13 21:36:46.549: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:36:46.549: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:36:46.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:36:46.672: INFO: stderr: ""
Feb 13 21:36:46.672: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:36:46.672: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:36:46.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:36:46.790: INFO: stderr: ""
Feb 13 21:36:46.790: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:36:46.790: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:36:46.790: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:36:46.792: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 13 21:36:56.796: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:36:56.796: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:36:56.796: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:36:56.803: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:36:56.803: INFO: ss-0  alex-300-cp1-vsp2-workerbe2ca38349  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  }]
Feb 13 21:36:56.803: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:56.803: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:56.804: INFO: 
Feb 13 21:36:56.804: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 21:36:57.806: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:36:57.806: INFO: ss-0  alex-300-cp1-vsp2-workerbe2ca38349  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  }]
Feb 13 21:36:57.806: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:57.806: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:57.806: INFO: 
Feb 13 21:36:57.806: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 21:36:58.808: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:36:58.808: INFO: ss-0  alex-300-cp1-vsp2-workerbe2ca38349  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  }]
Feb 13 21:36:58.808: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:58.808: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:58.809: INFO: 
Feb 13 21:36:58.809: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 21:36:59.810: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:36:59.810: INFO: ss-0  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:15 +0000 UTC  }]
Feb 13 21:36:59.811: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:59.811: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:36:59.811: INFO: 
Feb 13 21:36:59.811: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 21:37:00.813: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:37:00.813: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:00.813: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:00.813: INFO: 
Feb 13 21:37:00.813: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 13 21:37:01.815: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:37:01.815: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:01.815: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:01.815: INFO: 
Feb 13 21:37:01.815: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 13 21:37:02.817: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:37:02.817: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:02.817: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:02.817: INFO: 
Feb 13 21:37:02.817: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 13 21:37:03.819: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:37:03.819: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:03.819: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:03.819: INFO: 
Feb 13 21:37:03.819: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 13 21:37:04.821: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:37:04.821: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:04.821: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:04.821: INFO: 
Feb 13 21:37:04.821: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 13 21:37:05.823: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 21:37:05.823: INFO: ss-1  alex-300-cp1-vsp2-workerd2381a81c9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:05.824: INFO: ss-2  alex-300-cp1-vsp2-workerbe2ca38349  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:36:36 +0000 UTC  }]
Feb 13 21:37:05.824: INFO: 
Feb 13 21:37:05.824: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-dg7vf
Feb 13 21:37:06.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:37:06.904: INFO: rc: 1
Feb 13 21:37:06.904: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421524ba0 exit status 1 <nil> <nil> true [0xc420923e58 0xc420923e70 0xc420923e88] [0xc420923e58 0xc420923e70 0xc420923e88] [0xc420923e68 0xc420923e80] [0x8f9b60 0x8f9b60] 0xc421a4f4a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 13 21:37:16.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:37:16.962: INFO: rc: 1
Feb 13 21:37:16.963: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420cb4120 exit status 1 <nil> <nil> true [0xc42102ae38 0xc42102ae50 0xc42102ae68] [0xc42102ae38 0xc42102ae50 0xc42102ae68] [0xc42102ae48 0xc42102ae60] [0x8f9b60 0x8f9b60] 0xc421d574a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:37:26.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:37:27.021: INFO: rc: 1
Feb 13 21:37:27.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420cb44e0 exit status 1 <nil> <nil> true [0xc42102ae70 0xc42102ae88 0xc42102aea0] [0xc42102ae70 0xc42102ae88 0xc42102aea0] [0xc42102ae80 0xc42102ae98] [0x8f9b60 0x8f9b60] 0xc421d575c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:37:37.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:37:37.090: INFO: rc: 1
Feb 13 21:37:37.090: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420cb48a0 exit status 1 <nil> <nil> true [0xc42102aea8 0xc42102aec0 0xc42102aed8] [0xc42102aea8 0xc42102aec0 0xc42102aed8] [0xc42102aeb8 0xc42102aed0] [0x8f9b60 0x8f9b60] 0xc421d576e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:37:47.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:37:47.173: INFO: rc: 1
Feb 13 21:37:47.173: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420cb4c60 exit status 1 <nil> <nil> true [0xc42102aee0 0xc42102aef8 0xc42102af10] [0xc42102aee0 0xc42102aef8 0xc42102af10] [0xc42102aef0 0xc42102af08] [0x8f9b60 0x8f9b60] 0xc421d57800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:37:57.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:37:57.228: INFO: rc: 1
Feb 13 21:37:57.228: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421524f30 exit status 1 <nil> <nil> true [0xc420923e90 0xc420923ea8 0xc420923ec0] [0xc420923e90 0xc420923ea8 0xc420923ec0] [0xc420923ea0 0xc420923eb8] [0x8f9b60 0x8f9b60] 0xc421a4f5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:38:07.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:38:07.292: INFO: rc: 1
Feb 13 21:38:07.292: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421940420 exit status 1 <nil> <nil> true [0xc42000e0c8 0xc42000e160 0xc42000e250] [0xc42000e0c8 0xc42000e160 0xc42000e250] [0xc42000e158 0xc42000e248] [0x8f9b60 0x8f9b60] 0xc421a240c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:38:17.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:38:17.341: INFO: rc: 1
Feb 13 21:38:17.341: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4219407e0 exit status 1 <nil> <nil> true [0xc42000e270 0xc42000e3e0 0xc42020e000] [0xc42000e270 0xc42000e3e0 0xc42020e000] [0xc42000e2b0 0xc42000e450] [0x8f9b60 0x8f9b60] 0xc421a241e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:38:27.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:38:27.399: INFO: rc: 1
Feb 13 21:38:27.399: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4390 exit status 1 <nil> <nil> true [0xc420cd6028 0xc420cd60b0 0xc420cd6118] [0xc420cd6028 0xc420cd60b0 0xc420cd6118] [0xc420cd6070 0xc420cd6100] [0x8f9b60 0x8f9b60] 0xc42193c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:38:37.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:38:37.446: INFO: rc: 1
Feb 13 21:38:37.446: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421940ba0 exit status 1 <nil> <nil> true [0xc42020fa10 0xc42020faf8 0xc42020fb48] [0xc42020fa10 0xc42020faf8 0xc42020fb48] [0xc42020fae0 0xc42020fb30] [0x8f9b60 0x8f9b60] 0xc421a24420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:38:47.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:38:47.521: INFO: rc: 1
Feb 13 21:38:47.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4750 exit status 1 <nil> <nil> true [0xc420cd6120 0xc420cd6158 0xc420cd6180] [0xc420cd6120 0xc420cd6158 0xc420cd6180] [0xc420cd6138 0xc420cd6170] [0x8f9b60 0x8f9b60] 0xc42193c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:38:57.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:38:57.578: INFO: rc: 1
Feb 13 21:38:57.578: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421940f60 exit status 1 <nil> <nil> true [0xc42020fbd8 0xc42020fc98 0xc42020fd38] [0xc42020fbd8 0xc42020fc98 0xc42020fd38] [0xc42020fc48 0xc42020fd00] [0x8f9b60 0x8f9b60] 0xc421a24540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:39:07.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:39:07.630: INFO: rc: 1
Feb 13 21:39:07.630: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421941320 exit status 1 <nil> <nil> true [0xc42020fd58 0xc42020fe00 0xc42020fea8] [0xc42020fd58 0xc42020fe00 0xc42020fea8] [0xc42020fdb8 0xc42020fea0] [0x8f9b60 0x8f9b60] 0xc421a24780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:39:17.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:39:17.682: INFO: rc: 1
Feb 13 21:39:17.682: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4b40 exit status 1 <nil> <nil> true [0xc420cd6188 0xc420cd61a8 0xc420cd61d0] [0xc420cd6188 0xc420cd61a8 0xc420cd61d0] [0xc420cd61a0 0xc420cd61c0] [0x8f9b60 0x8f9b60] 0xc42193c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:39:27.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:39:27.735: INFO: rc: 1
Feb 13 21:39:27.735: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4219416b0 exit status 1 <nil> <nil> true [0xc42020feb0 0xc42020fed8 0xc42020ff78] [0xc42020feb0 0xc42020fed8 0xc42020ff78] [0xc42020fec8 0xc42020ff68] [0x8f9b60 0x8f9b60] 0xc421a24ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:39:37.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:39:37.799: INFO: rc: 1
Feb 13 21:39:37.799: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421941a40 exit status 1 <nil> <nil> true [0xc42020ff88 0xc420786030 0xc420786088] [0xc42020ff88 0xc420786030 0xc420786088] [0xc420786020 0xc420786080] [0x8f9b60 0x8f9b60] 0xc421a24c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:39:47.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:39:47.872: INFO: rc: 1
Feb 13 21:39:47.872: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4f30 exit status 1 <nil> <nil> true [0xc420cd61f0 0xc420cd6288 0xc420cd62f8] [0xc420cd61f0 0xc420cd6288 0xc420cd62f8] [0xc420cd6240 0xc420cd62a8] [0x8f9b60 0x8f9b60] 0xc42193c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:39:57.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:39:57.945: INFO: rc: 1
Feb 13 21:39:57.946: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421941e30 exit status 1 <nil> <nil> true [0xc4207860c0 0xc420786110 0xc420786130] [0xc4207860c0 0xc420786110 0xc420786130] [0xc420786108 0xc420786128] [0x8f9b60 0x8f9b60] 0xc421a24d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:40:07.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:40:08.008: INFO: rc: 1
Feb 13 21:40:08.008: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4360 exit status 1 <nil> <nil> true [0xc42020e000 0xc42020fae0 0xc42020fb30] [0xc42020e000 0xc42020fae0 0xc42020fb30] [0xc42020faa0 0xc42020fb08] [0x8f9b60 0x8f9b60] 0xc421a240c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:40:18.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:40:18.060: INFO: rc: 1
Feb 13 21:40:18.060: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4780 exit status 1 <nil> <nil> true [0xc42020fb48 0xc42020fc48 0xc42020fd00] [0xc42020fb48 0xc42020fc48 0xc42020fd00] [0xc42020fbf8 0xc42020fce0] [0x8f9b60 0x8f9b60] 0xc421a241e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:40:28.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:40:28.124: INFO: rc: 1
Feb 13 21:40:28.124: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421940450 exit status 1 <nil> <nil> true [0xc42000e0b0 0xc42000e158 0xc42000e248] [0xc42000e0b0 0xc42000e158 0xc42000e248] [0xc42000e0d0 0xc42000e1b8] [0x8f9b60 0x8f9b60] 0xc42193c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:40:38.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:40:38.195: INFO: rc: 1
Feb 13 21:40:38.195: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d4b70 exit status 1 <nil> <nil> true [0xc42020fd38 0xc42020fdb8 0xc42020fea0] [0xc42020fd38 0xc42020fdb8 0xc42020fea0] [0xc42020fd98 0xc42020fe58] [0x8f9b60 0x8f9b60] 0xc421a24420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:40:48.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:40:48.261: INFO: rc: 1
Feb 13 21:40:48.262: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421940840 exit status 1 <nil> <nil> true [0xc42000e250 0xc42000e2b0 0xc42000e450] [0xc42000e250 0xc42000e2b0 0xc42000e450] [0xc42000e278 0xc42000e3f0] [0x8f9b60 0x8f9b60] 0xc42193c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:40:58.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:40:58.318: INFO: rc: 1
Feb 13 21:40:58.318: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d5200 exit status 1 <nil> <nil> true [0xc42020fea8 0xc42020fec8 0xc42020ff68] [0xc42020fea8 0xc42020fec8 0xc42020ff68] [0xc42020feb8 0xc42020ff30] [0x8f9b60 0x8f9b60] 0xc421a24540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:41:08.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:41:08.380: INFO: rc: 1
Feb 13 21:41:08.380: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421940c30 exit status 1 <nil> <nil> true [0xc420786020 0xc420786080 0xc420786160] [0xc420786020 0xc420786080 0xc420786160] [0xc420786040 0xc420786148] [0x8f9b60 0x8f9b60] 0xc42193c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:41:18.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:41:18.436: INFO: rc: 1
Feb 13 21:41:18.436: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d5650 exit status 1 <nil> <nil> true [0xc42020ff78 0xc420cd6028 0xc420cd60b0] [0xc42020ff78 0xc420cd6028 0xc420cd60b0] [0xc42020ffb8 0xc420cd6070] [0x8f9b60 0x8f9b60] 0xc421a24780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:41:28.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:41:28.500: INFO: rc: 1
Feb 13 21:41:28.500: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421941020 exit status 1 <nil> <nil> true [0xc420786180 0xc4207861b0 0xc420786200] [0xc420786180 0xc4207861b0 0xc420786200] [0xc4207861a0 0xc4207861d0] [0x8f9b60 0x8f9b60] 0xc42193c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:41:38.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:41:38.552: INFO: rc: 1
Feb 13 21:41:38.552: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4208d5aa0 exit status 1 <nil> <nil> true [0xc420cd60e0 0xc420cd6120 0xc420cd6158] [0xc420cd60e0 0xc420cd6120 0xc420cd6158] [0xc420cd6118 0xc420cd6138] [0x8f9b60 0x8f9b60] 0xc421a24ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:41:48.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:41:48.612: INFO: rc: 1
Feb 13 21:41:48.612: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421941410 exit status 1 <nil> <nil> true [0xc420786220 0xc420786270 0xc4207862e0] [0xc420786220 0xc420786270 0xc4207862e0] [0xc420786260 0xc420786290] [0x8f9b60 0x8f9b60] 0xc42193c8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:41:58.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:41:58.677: INFO: rc: 1
Feb 13 21:41:58.677: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4219417d0 exit status 1 <nil> <nil> true [0xc420786308 0xc4207863b8 0xc420786448] [0xc420786308 0xc4207863b8 0xc420786448] [0xc4207863b0 0xc420786438] [0x8f9b60 0x8f9b60] 0xc42193cc60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Feb 13 21:42:08.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dg7vf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:42:08.732: INFO: rc: 1
Feb 13 21:42:08.732: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Feb 13 21:42:08.732: INFO: Scaling statefulset ss to 0
Feb 13 21:42:08.737: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Feb 13 21:42:08.738: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dg7vf
Feb 13 21:42:08.739: INFO: Scaling statefulset ss to 0
Feb 13 21:42:08.742: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:42:08.743: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:42:08.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dg7vf" for this suite.
Feb 13 21:42:14.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:42:14.789: INFO: namespace: e2e-tests-statefulset-dg7vf, resource: bindings, ignored listing per whitelist
Feb 13 21:42:14.799: INFO: namespace e2e-tests-statefulset-dg7vf deletion completed in 6.045791239s

• [SLOW TEST:358.999 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:42:14.799: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-62scq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-62scq;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-62scq;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-62scq.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-62scq.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-62scq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 237.15.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.15.237_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 237.15.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.15.237_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-62scq;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-62scq;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-62scq.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-62scq.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-62scq.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-62scq.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-62scq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 237.15.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.15.237_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 237.15.104.10.in-addr.arpa. PTR)" && echo OK > /results/10.104.15.237_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 13 21:42:40.979: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.981: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.983: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-62scq from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.985: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-62scq from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.988: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.989: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.991: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:40.992: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.003: INFO: Unable to read jessie_udp@dns-test-service from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.004: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.006: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-62scq from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.007: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-62scq from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.009: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.010: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.012: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.013: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:41.025: INFO: Lookups using dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-62scq wheezy_tcp@dns-test-service.e2e-tests-dns-62scq wheezy_udp@dns-test-service.e2e-tests-dns-62scq.svc wheezy_tcp@dns-test-service.e2e-tests-dns-62scq.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-62scq jessie_tcp@dns-test-service.e2e-tests-dns-62scq jessie_udp@dns-test-service.e2e-tests-dns-62scq.svc jessie_tcp@dns-test-service.e2e-tests-dns-62scq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc]

Feb 13 21:42:51.002: INFO: Unable to read jessie_udp@dns-test-service from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.003: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.005: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-62scq from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.007: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-62scq from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.008: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.009: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.011: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.012: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc from pod dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc: the server could not find the requested resource (get pods dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc)
Feb 13 21:42:51.020: INFO: Lookups using dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-62scq jessie_tcp@dns-test-service.e2e-tests-dns-62scq jessie_udp@dns-test-service.e2e-tests-dns-62scq.svc jessie_tcp@dns-test-service.e2e-tests-dns-62scq.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-62scq.svc]

Feb 13 21:43:01.017: INFO: DNS probes using dns-test-3a552a68-2fd8-11e9-aeb1-a6e9e8347cdc succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:43:01.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-62scq" for this suite.
Feb 13 21:43:07.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:43:07.095: INFO: namespace: e2e-tests-dns-62scq, resource: bindings, ignored listing per whitelist
Feb 13 21:43:07.114: INFO: namespace e2e-tests-dns-62scq deletion completed in 6.045645565s

• [SLOW TEST:52.315 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:43:07.114: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-vbt5w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Feb 13 21:43:07.247: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 21:44:07.264: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 21:44:07.266: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 21:44:07.271: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 21:44:07.271: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 13 21:44:07.273: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Feb 13 21:44:07.273: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp1-vsp2-workerbe2ca38349 before test
Feb 13 21:44:07.282: INFO: kube-proxy-h97kt from kube-system started at 2019-02-13 20:25:59 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 21:44:07.282: INFO: nginx-ingress-controller-fr4dw from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 21:44:07.282: INFO: calico-typha-7745977f6c-nnddh from kube-system started at 2019-02-13 20:26:09 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 21:44:07.282: INFO: nginx-ingress-default-backend-54786554b4-c8glf from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb 13 21:44:07.282: INFO: metallb-speaker-tqj8d from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container speaker ready: true, restart count 0
Feb 13 21:44:07.282: INFO: kubernetes-dashboard-5888c7c865-6fw6h from ccp started at 2019-02-13 20:26:56 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 13 21:44:07.282: INFO: ccp-monitor-prometheus-node-exporter-jp7s4 from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 21:44:07.282: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 21:34:56 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 21:44:07.282: INFO: ccp-monitor-prometheus-kube-state-metrics-5b6855c558-bvftk from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.282: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Feb 13 21:44:07.283: INFO: ccp-monitor-grafana-598bcf54f9-28w8c from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.283: INFO: 	Container grafana ready: true, restart count 0
Feb 13 21:44:07.283: INFO: fluentd-es-v2.0.2-78sgd from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.283: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 21:44:07.283: INFO: ccp-efk-kibana-594754b75-6fg7f from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.283: INFO: 	Container kibana ready: true, restart count 0
Feb 13 21:44:07.283: INFO: calico-node-wbc5b from kube-system started at 2019-02-13 20:25:59 +0000 UTC (2 container statuses recorded)
Feb 13 21:44:07.283: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 21:44:07.283: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 21:44:07.283: INFO: cert-manager-d98996f46-7gj72 from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.283: INFO: 	Container cert-manager ready: true, restart count 0
Feb 13 21:44:07.283: INFO: sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-tpdfj from heptio-sonobuoy started at 2019-02-13 21:35:01 +0000 UTC (2 container statuses recorded)
Feb 13 21:44:07.283: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 21:44:07.283: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 21:44:07.283: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp1-vsp2-workerd2381a81c9 before test
Feb 13 21:44:07.290: INFO: sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-2mkgp from heptio-sonobuoy started at 2019-02-13 21:35:01 +0000 UTC (2 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 21:44:07.290: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 21:44:07.290: INFO: coredns-6c59c84b9c-mbqwk from kube-system started at 2019-02-13 20:26:16 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container coredns ready: true, restart count 0
Feb 13 21:44:07.290: INFO: calico-node-ns8hh from kube-system started at 2019-02-13 20:25:57 +0000 UTC (2 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 21:44:07.290: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 21:44:07.290: INFO: metallb-speaker-9sx8b from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container speaker ready: true, restart count 0
Feb 13 21:44:07.290: INFO: metallb-controller-54559b4447-zjhc6 from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container controller ready: true, restart count 0
Feb 13 21:44:07.290: INFO: ccp-monitor-prometheus-pushgateway-7cfbcd8dfd-tlw5g from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
Feb 13 21:44:07.290: INFO: ccp-monitor-prometheus-server-6fb9957f87-r8ftg from ccp started at 2019-02-13 20:26:58 +0000 UTC (2 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container prometheus-server ready: true, restart count 0
Feb 13 21:44:07.290: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Feb 13 21:44:07.290: INFO: ccp-monitor-prometheus-alertmanager-64c4f944cb-gvrlv from ccp started at 2019-02-13 20:26:58 +0000 UTC (2 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Feb 13 21:44:07.290: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Feb 13 21:44:07.290: INFO: fluentd-es-v2.0.2-92kwr from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 21:44:07.290: INFO: kube-proxy-xrp4h from kube-system started at 2019-02-13 20:25:57 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 21:44:07.290: INFO: calico-typha-7745977f6c-52zql from kube-system started at 2019-02-13 20:26:07 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 21:44:07.290: INFO: nginx-ingress-controller-ckzrj from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 21:44:07.290: INFO: ccp-monitor-prometheus-node-exporter-cktg2 from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 21:44:07.290: INFO: elasticsearch-logging-0 from ccp started at 2019-02-13 20:27:11 +0000 UTC (1 container statuses recorded)
Feb 13 21:44:07.290: INFO: 	Container elasticsearch-logging ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15830a8152d72151], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:44:08.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-vbt5w" for this suite.
Feb 13 21:44:14.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:44:14.346: INFO: namespace: e2e-tests-sched-pred-vbt5w, resource: bindings, ignored listing per whitelist
Feb 13 21:44:14.360: INFO: namespace e2e-tests-sched-pred-vbt5w deletion completed in 6.053654873s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:67.246 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:44:14.361: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-l9khr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 13 21:44:14.502: INFO: Waiting up to 5m0s for pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-l9khr" to be "success or failure"
Feb 13 21:44:14.505: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.426755ms
Feb 13 21:44:16.507: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005477725s
Feb 13 21:44:18.509: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007325044s
Feb 13 21:44:20.511: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009425159s
Feb 13 21:44:22.513: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011507713s
Feb 13 21:44:24.515: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013194944s
Feb 13 21:44:26.516: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014699825s
Feb 13 21:44:28.518: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.016107948s
STEP: Saw pod success
Feb 13 21:44:28.518: INFO: Pod "pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:44:28.519: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 21:44:28.530: INFO: Waiting for pod pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:44:28.531: INFO: Pod pod-8194f693-2fd8-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:44:28.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l9khr" for this suite.
Feb 13 21:44:34.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:44:34.564: INFO: namespace: e2e-tests-emptydir-l9khr, resource: bindings, ignored listing per whitelist
Feb 13 21:44:34.574: INFO: namespace e2e-tests-emptydir-l9khr deletion completed in 6.041201255s

• [SLOW TEST:20.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:44:34.575: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fglx9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-8da13330-2fd8-11e9-aeb1-a6e9e8347cdc
STEP: Creating secret with name s-test-opt-upd-8da1335f-2fd8-11e9-aeb1-a6e9e8347cdc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8da13330-2fd8-11e9-aeb1-a6e9e8347cdc
STEP: Updating secret s-test-opt-upd-8da1335f-2fd8-11e9-aeb1-a6e9e8347cdc
STEP: Creating secret with name s-test-opt-create-8da1336d-2fd8-11e9-aeb1-a6e9e8347cdc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:46:05.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fglx9" for this suite.
Feb 13 21:46:27.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:46:27.107: INFO: namespace: e2e-tests-projected-fglx9, resource: bindings, ignored listing per whitelist
Feb 13 21:46:27.134: INFO: namespace e2e-tests-projected-fglx9 deletion completed in 22.054674027s

• [SLOW TEST:112.559 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:46:27.135: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-r45ll
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
Feb 13 21:46:27.269: INFO: Waiting up to 5m0s for pod "var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-var-expansion-r45ll" to be "success or failure"
Feb 13 21:46:27.272: INFO: Pod "var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.794356ms
Feb 13 21:46:29.274: INFO: Pod "var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005836725s
Feb 13 21:46:31.277: INFO: Pod "var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008126342s
STEP: Saw pod success
Feb 13 21:46:31.277: INFO: Pod "var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:46:31.281: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 21:46:31.293: INFO: Waiting for pod var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:46:31.295: INFO: Pod var-expansion-d0b7a117-2fd8-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:46:31.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-r45ll" for this suite.
Feb 13 21:46:37.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:46:37.337: INFO: namespace: e2e-tests-var-expansion-r45ll, resource: bindings, ignored listing per whitelist
Feb 13 21:46:37.343: INFO: namespace e2e-tests-var-expansion-r45ll deletion completed in 6.045773156s

• [SLOW TEST:10.208 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:46:37.344: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-t48x6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-t48x6
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-t48x6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-t48x6
Feb 13 21:46:37.487: INFO: Found 0 stateful pods, waiting for 1
Feb 13 21:46:47.491: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 13 21:46:47.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:46:47.598: INFO: stderr: ""
Feb 13 21:46:47.598: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:46:47.598: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:46:47.600: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 21:46:57.602: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:46:57.602: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:46:57.610: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999824s
Feb 13 21:46:58.612: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996832103s
Feb 13 21:46:59.614: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994869711s
Feb 13 21:47:00.616: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992857096s
Feb 13 21:47:01.618: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.991048919s
Feb 13 21:47:02.620: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.989322774s
Feb 13 21:47:03.622: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.987227675s
Feb 13 21:47:04.624: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.985337199s
Feb 13 21:47:05.626: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.983089867s
Feb 13 21:47:06.630: INFO: Verifying statefulset ss doesn't scale past 1 for another 980.365309ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-t48x6
Feb 13 21:47:07.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:47:07.739: INFO: stderr: ""
Feb 13 21:47:07.739: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:47:07.739: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:47:07.741: INFO: Found 1 stateful pods, waiting for 3
Feb 13 21:47:17.744: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:47:17.744: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:47:17.744: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 13 21:47:17.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:47:17.863: INFO: stderr: ""
Feb 13 21:47:17.863: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:47:17.863: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:47:17.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:47:18.002: INFO: stderr: ""
Feb 13 21:47:18.002: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:47:18.002: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:47:18.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:47:18.133: INFO: stderr: ""
Feb 13 21:47:18.133: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:47:18.133: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:47:18.133: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:47:18.134: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 13 21:47:28.138: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:47:28.138: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:47:28.138: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:47:28.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999838s
Feb 13 21:47:29.151: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99600967s
Feb 13 21:47:30.153: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99387563s
Feb 13 21:47:31.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991743111s
Feb 13 21:47:32.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989619727s
Feb 13 21:47:33.159: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987482308s
Feb 13 21:47:34.161: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985415394s
Feb 13 21:47:35.164: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983144667s
Feb 13 21:47:36.166: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.980674564s
Feb 13 21:47:37.168: INFO: Verifying statefulset ss doesn't scale past 3 for another 978.766224ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-t48x6
Feb 13 21:47:38.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:47:38.280: INFO: stderr: ""
Feb 13 21:47:38.280: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:47:38.280: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:47:38.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:47:38.411: INFO: stderr: ""
Feb 13 21:47:38.411: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:47:38.411: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:47:38.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-t48x6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:47:38.545: INFO: stderr: ""
Feb 13 21:47:38.545: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:47:38.545: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:47:38.545: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Feb 13 21:47:58.553: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t48x6
Feb 13 21:47:58.554: INFO: Scaling statefulset ss to 0
Feb 13 21:47:58.558: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:47:58.559: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:47:58.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t48x6" for this suite.
Feb 13 21:48:04.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:48:04.606: INFO: namespace: e2e-tests-statefulset-t48x6, resource: bindings, ignored listing per whitelist
Feb 13 21:48:04.609: INFO: namespace e2e-tests-statefulset-t48x6 deletion completed in 6.039888024s

• [SLOW TEST:87.266 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:48:04.610: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4qzxn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-0ad17288-2fd9-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 21:48:04.748: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-4qzxn" to be "success or failure"
Feb 13 21:48:04.751: INFO: Pod "pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.917297ms
Feb 13 21:48:06.753: INFO: Pod "pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 2.004770633s
Feb 13 21:48:08.760: INFO: Pod "pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011759015s
STEP: Saw pod success
Feb 13 21:48:08.760: INFO: Pod "pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:48:08.762: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:48:08.772: INFO: Waiting for pod pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:48:08.779: INFO: Pod pod-projected-secrets-0ad1cb1f-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:48:08.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qzxn" for this suite.
Feb 13 21:48:14.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:48:14.804: INFO: namespace: e2e-tests-projected-4qzxn, resource: bindings, ignored listing per whitelist
Feb 13 21:48:14.830: INFO: namespace e2e-tests-projected-4qzxn deletion completed in 6.048704102s

• [SLOW TEST:10.220 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:48:14.831: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2qvxj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc
Feb 13 21:48:14.975: INFO: Pod name my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc: Found 0 pods out of 1
Feb 13 21:48:19.977: INFO: Pod name my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc: Found 1 pods out of 1
Feb 13 21:48:19.977: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc" are running
Feb 13 21:48:19.978: INFO: Pod "my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc-2cl4p" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 21:48:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 21:48:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 21:48:14 +0000 UTC Reason: Message:}])
Feb 13 21:48:19.978: INFO: Trying to dial the pod
Feb 13 21:48:24.988: INFO: Controller my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc: Got expected result from replica 1 [my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc-2cl4p]: "my-hostname-basic-10e97de7-2fd9-11e9-aeb1-a6e9e8347cdc-2cl4p", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:48:24.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2qvxj" for this suite.
Feb 13 21:48:31.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:48:31.030: INFO: namespace: e2e-tests-replication-controller-2qvxj, resource: bindings, ignored listing per whitelist
Feb 13 21:48:31.049: INFO: namespace e2e-tests-replication-controller-2qvxj deletion completed in 6.05781203s

• [SLOW TEST:16.219 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:48:31.050: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xhjh9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Feb 13 21:48:31.183: INFO: namespace e2e-tests-kubectl-xhjh9
Feb 13 21:48:31.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-xhjh9'
Feb 13 21:48:31.555: INFO: stderr: ""
Feb 13 21:48:31.555: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 21:48:32.557: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:48:32.557: INFO: Found 0 / 1
Feb 13 21:48:33.557: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:48:33.557: INFO: Found 0 / 1
Feb 13 21:48:34.557: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:48:34.557: INFO: Found 1 / 1
Feb 13 21:48:34.557: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 21:48:34.559: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:48:34.559: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 21:48:34.559: INFO: wait on redis-master startup in e2e-tests-kubectl-xhjh9 
Feb 13 21:48:34.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 logs redis-master-2wz94 redis-master --namespace=e2e-tests-kubectl-xhjh9'
Feb 13 21:48:34.642: INFO: stderr: ""
Feb 13 21:48:34.642: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 21:48:33.367 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 21:48:33.367 # Server started, Redis version 3.2.12\n1:M 13 Feb 21:48:33.368 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 21:48:33.368 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 13 21:48:34.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-xhjh9'
Feb 13 21:48:34.734: INFO: stderr: ""
Feb 13 21:48:34.734: INFO: stdout: "service/rm2 exposed\n"
Feb 13 21:48:34.737: INFO: Service rm2 in namespace e2e-tests-kubectl-xhjh9 found.
STEP: exposing service
Feb 13 21:48:36.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-xhjh9'
Feb 13 21:48:36.826: INFO: stderr: ""
Feb 13 21:48:36.826: INFO: stdout: "service/rm3 exposed\n"
Feb 13 21:48:36.828: INFO: Service rm3 in namespace e2e-tests-kubectl-xhjh9 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:48:38.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xhjh9" for this suite.
Feb 13 21:49:00.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:00.862: INFO: namespace: e2e-tests-kubectl-xhjh9, resource: bindings, ignored listing per whitelist
Feb 13 21:49:00.881: INFO: namespace e2e-tests-kubectl-xhjh9 deletion completed in 22.047182534s

• [SLOW TEST:29.832 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create services for rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:49:00.882: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-zd7nl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 13 21:49:01.524: INFO: Waiting up to 5m0s for pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm" in namespace "e2e-tests-svcaccounts-zd7nl" to be "success or failure"
Feb 13 21:49:01.528: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm": Phase="Pending", Reason="", readiness=false. Elapsed: 3.777549ms
Feb 13 21:49:03.530: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006261837s
Feb 13 21:49:05.532: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007752246s
STEP: Saw pod success
Feb 13 21:49:05.532: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm" satisfied condition "success or failure"
Feb 13 21:49:05.533: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm container token-test: <nil>
STEP: delete the pod
Feb 13 21:49:05.550: INFO: Waiting for pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm to disappear
Feb 13 21:49:05.551: INFO: Pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-mdzwm no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 13 21:49:05.555: INFO: Waiting up to 5m0s for pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl" in namespace "e2e-tests-svcaccounts-zd7nl" to be "success or failure"
Feb 13 21:49:05.558: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.20975ms
Feb 13 21:49:07.559: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004664818s
STEP: Saw pod success
Feb 13 21:49:07.559: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl" satisfied condition "success or failure"
Feb 13 21:49:07.561: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl container root-ca-test: <nil>
STEP: delete the pod
Feb 13 21:49:07.577: INFO: Waiting for pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl to disappear
Feb 13 21:49:07.578: INFO: Pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-jbmzl no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 13 21:49:07.581: INFO: Waiting up to 5m0s for pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww" in namespace "e2e-tests-svcaccounts-zd7nl" to be "success or failure"
Feb 13 21:49:07.585: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000093ms
Feb 13 21:49:09.587: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005834932s
Feb 13 21:49:11.589: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007618974s
STEP: Saw pod success
Feb 13 21:49:11.589: INFO: Pod "pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww" satisfied condition "success or failure"
Feb 13 21:49:11.590: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww container namespace-test: <nil>
STEP: delete the pod
Feb 13 21:49:11.606: INFO: Waiting for pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww to disappear
Feb 13 21:49:11.607: INFO: Pod pod-service-account-2ca93b3e-2fd9-11e9-aeb1-a6e9e8347cdc-wfxww no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:49:11.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-zd7nl" for this suite.
Feb 13 21:49:17.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:17.634: INFO: namespace: e2e-tests-svcaccounts-zd7nl, resource: bindings, ignored listing per whitelist
Feb 13 21:49:17.650: INFO: namespace e2e-tests-svcaccounts-zd7nl deletion completed in 6.041035223s

• [SLOW TEST:16.768 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:49:17.651: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-964ht
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 13 21:49:17.787: INFO: Waiting up to 5m0s for pod "pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-964ht" to be "success or failure"
Feb 13 21:49:17.792: INFO: Pod "pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.652962ms
Feb 13 21:49:19.793: INFO: Pod "pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006414832s
STEP: Saw pod success
Feb 13 21:49:19.793: INFO: Pod "pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:49:19.795: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 21:49:19.809: INFO: Waiting for pod pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:49:19.811: INFO: Pod pod-365aa494-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:49:19.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-964ht" for this suite.
Feb 13 21:49:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:25.838: INFO: namespace: e2e-tests-emptydir-964ht, resource: bindings, ignored listing per whitelist
Feb 13 21:49:25.866: INFO: namespace e2e-tests-emptydir-964ht deletion completed in 6.053246976s

• [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:49:25.867: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-lmkb6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
Feb 13 21:49:26.050: INFO: Waiting up to 5m0s for pod "var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-var-expansion-lmkb6" to be "success or failure"
Feb 13 21:49:26.053: INFO: Pod "var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.309098ms
Feb 13 21:49:28.055: INFO: Pod "var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004428969s
Feb 13 21:49:30.057: INFO: Pod "var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006229873s
STEP: Saw pod success
Feb 13 21:49:30.057: INFO: Pod "var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:49:30.058: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 21:49:30.069: INFO: Waiting for pod var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:49:30.073: INFO: Pod var-expansion-3b4781d9-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:49:30.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-lmkb6" for this suite.
Feb 13 21:49:36.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:36.087: INFO: namespace: e2e-tests-var-expansion-lmkb6, resource: bindings, ignored listing per whitelist
Feb 13 21:49:36.118: INFO: namespace e2e-tests-var-expansion-lmkb6 deletion completed in 6.042887412s

• [SLOW TEST:10.251 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:49:36.119: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-95zxz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:49:36.256: INFO: Waiting up to 5m0s for pod "downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-95zxz" to be "success or failure"
Feb 13 21:49:36.260: INFO: Pod "downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.630429ms
Feb 13 21:49:38.262: INFO: Pod "downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005385089s
STEP: Saw pod success
Feb 13 21:49:38.262: INFO: Pod "downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:49:38.263: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 21:49:38.275: INFO: Waiting for pod downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:49:38.276: INFO: Pod downwardapi-volume-415cbadf-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:49:38.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95zxz" for this suite.
Feb 13 21:49:44.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:44.315: INFO: namespace: e2e-tests-projected-95zxz, resource: bindings, ignored listing per whitelist
Feb 13 21:49:44.325: INFO: namespace e2e-tests-projected-95zxz deletion completed in 6.0459377s

• [SLOW TEST:8.206 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:49:44.326: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rb2x5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Feb 13 21:49:46.977: INFO: Successfully updated pod "labelsupdate464091c9-2fd9-11e9-aeb1-a6e9e8347cdc"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:49:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rb2x5" for this suite.
Feb 13 21:50:10.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:50:11.002: INFO: namespace: e2e-tests-downward-api-rb2x5, resource: bindings, ignored listing per whitelist
Feb 13 21:50:11.032: INFO: namespace e2e-tests-downward-api-rb2x5 deletion completed in 22.0430837s

• [SLOW TEST:26.706 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:50:11.032: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fgvts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 21:50:11.191: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"562dd13d-2fd9-11e9-80e0-0050569e5ced", Controller:(*bool)(0xc421d89d42), BlockOwnerDeletion:(*bool)(0xc421d89d43)}}
Feb 13 21:50:11.199: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"562c63f6-2fd9-11e9-80e0-0050569e5ced", Controller:(*bool)(0xc4211b164e), BlockOwnerDeletion:(*bool)(0xc4211b164f)}}
Feb 13 21:50:11.202: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"562d1042-2fd9-11e9-80e0-0050569e5ced", Controller:(*bool)(0xc421d89f5e), BlockOwnerDeletion:(*bool)(0xc421d89f5f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:50:16.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fgvts" for this suite.
Feb 13 21:50:22.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:50:22.246: INFO: namespace: e2e-tests-gc-fgvts, resource: bindings, ignored listing per whitelist
Feb 13 21:50:22.251: INFO: namespace e2e-tests-gc-fgvts deletion completed in 6.04100506s

• [SLOW TEST:11.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:50:22.251: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-9xzbl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 21:50:22.389: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 21:50:22.403: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:22.416: INFO: Number of nodes with available pods: 0
Feb 13 21:50:22.416: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 21:50:23.419: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:23.421: INFO: Number of nodes with available pods: 0
Feb 13 21:50:23.421: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 21:50:24.419: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:24.421: INFO: Number of nodes with available pods: 1
Feb 13 21:50:24.421: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 21:50:25.419: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:25.421: INFO: Number of nodes with available pods: 1
Feb 13 21:50:25.421: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 21:50:26.419: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:26.424: INFO: Number of nodes with available pods: 1
Feb 13 21:50:26.424: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 21:50:27.419: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:27.421: INFO: Number of nodes with available pods: 2
Feb 13 21:50:27.421: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 13 21:50:27.436: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:27.436: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:27.438: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:28.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:28.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:28.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:29.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:29.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:29.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:30.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:30.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:30.440: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:30.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:31.447: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:31.447: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:31.447: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:31.450: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:32.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:32.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:32.440: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:32.445: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:33.439: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:33.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:33.440: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:33.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:34.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:34.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:34.440: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:34.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:35.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:35.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:35.440: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:35.444: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:36.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:36.440: INFO: Wrong image for pod: daemon-set-9gkk5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:36.440: INFO: Pod daemon-set-9gkk5 is not available
Feb 13 21:50:36.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:37.439: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:37.439: INFO: Pod daemon-set-wgrpr is not available
Feb 13 21:50:37.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:38.439: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:38.439: INFO: Pod daemon-set-wgrpr is not available
Feb 13 21:50:38.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:39.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:39.440: INFO: Pod daemon-set-wgrpr is not available
Feb 13 21:50:39.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:40.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:40.440: INFO: Pod daemon-set-wgrpr is not available
Feb 13 21:50:40.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:41.439: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:41.441: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:42.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:42.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:42.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:43.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:43.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:43.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:44.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:44.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:44.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:45.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:45.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:45.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:46.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:46.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:46.441: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:47.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:47.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:47.442: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:48.440: INFO: Wrong image for pod: daemon-set-8kdxl. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Feb 13 21:50:48.440: INFO: Pod daemon-set-8kdxl is not available
Feb 13 21:50:48.444: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:49.559: INFO: Pod daemon-set-cxz4t is not available
Feb 13 21:50:49.562: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 13 21:50:49.565: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:49.566: INFO: Number of nodes with available pods: 1
Feb 13 21:50:49.566: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 21:50:50.569: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:50.570: INFO: Number of nodes with available pods: 1
Feb 13 21:50:50.570: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 21:50:51.568: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:50:51.570: INFO: Number of nodes with available pods: 2
Feb 13 21:50:51.570: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9xzbl, will wait for the garbage collector to delete the pods
Feb 13 21:50:51.633: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.021985ms
Feb 13 21:50:51.734: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.652663ms
Feb 13 21:50:59.235: INFO: Number of nodes with available pods: 0
Feb 13 21:50:59.236: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 21:50:59.237: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9xzbl/daemonsets","resourceVersion":"11785"},"items":null}

Feb 13 21:50:59.238: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9xzbl/pods","resourceVersion":"11785"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:50:59.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9xzbl" for this suite.
Feb 13 21:51:05.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:05.269: INFO: namespace: e2e-tests-daemonsets-9xzbl, resource: bindings, ignored listing per whitelist
Feb 13 21:51:05.297: INFO: namespace e2e-tests-daemonsets-9xzbl deletion completed in 6.052189983s

• [SLOW TEST:43.046 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:51:05.298: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k7gph
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:51:05.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-k7gph" to be "success or failure"
Feb 13 21:51:05.448: INFO: Pod "downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.12838ms
Feb 13 21:51:07.449: INFO: Pod "downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002766354s
STEP: Saw pod success
Feb 13 21:51:07.449: INFO: Pod "downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:51:07.451: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 21:51:07.463: INFO: Waiting for pod downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:51:07.464: INFO: Pod downwardapi-volume-7685ac6f-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:51:07.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k7gph" for this suite.
Feb 13 21:51:13.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:13.498: INFO: namespace: e2e-tests-downward-api-k7gph, resource: bindings, ignored listing per whitelist
Feb 13 21:51:13.511: INFO: namespace e2e-tests-downward-api-k7gph deletion completed in 6.045130915s

• [SLOW TEST:8.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:51:13.511: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-pknx6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-7b6933cd-2fd9-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 21:51:13.647: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-pknx6" to be "success or failure"
Feb 13 21:51:13.650: INFO: Pod "pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334842ms
Feb 13 21:51:15.652: INFO: Pod "pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005263633s
STEP: Saw pod success
Feb 13 21:51:15.652: INFO: Pod "pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:51:15.654: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:51:15.665: INFO: Waiting for pod pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:51:15.666: INFO: Pod pod-configmaps-7b698972-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:51:15.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pknx6" for this suite.
Feb 13 21:51:21.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:21.712: INFO: namespace: e2e-tests-configmap-pknx6, resource: bindings, ignored listing per whitelist
Feb 13 21:51:21.721: INFO: namespace e2e-tests-configmap-pknx6 deletion completed in 6.052215816s

• [SLOW TEST:8.210 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:51:21.721: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-jkwv2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jkwv2.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jkwv2.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jkwv2.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-jkwv2.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-jkwv2.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-jkwv2.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 13 21:51:33.913: INFO: DNS probes using dns-test-804e69f4-2fd9-11e9-aeb1-a6e9e8347cdc succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:51:33.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-jkwv2" for this suite.
Feb 13 21:51:39.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:39.940: INFO: namespace: e2e-tests-dns-jkwv2, resource: bindings, ignored listing per whitelist
Feb 13 21:51:39.967: INFO: namespace e2e-tests-dns-jkwv2 deletion completed in 6.044077958s

• [SLOW TEST:18.246 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:51:39.967: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wq2d4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0213 21:51:50.177941      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 21:51:50.177: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:51:50.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wq2d4" for this suite.
Feb 13 21:51:56.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:56.219: INFO: namespace: e2e-tests-gc-wq2d4, resource: bindings, ignored listing per whitelist
Feb 13 21:51:56.222: INFO: namespace e2e-tests-gc-wq2d4 deletion completed in 6.042660372s

• [SLOW TEST:16.255 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:51:56.222: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tvhr5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:52:56.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tvhr5" for this suite.
Feb 13 21:53:18.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:18.381: INFO: namespace: e2e-tests-container-probe-tvhr5, resource: bindings, ignored listing per whitelist
Feb 13 21:53:18.407: INFO: namespace e2e-tests-container-probe-tvhr5 deletion completed in 22.04559969s

• [SLOW TEST:82.184 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:53:18.408: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jbb7m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Feb 13 21:53:18.543: INFO: Waiting up to 5m0s for pod "downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-jbb7m" to be "success or failure"
Feb 13 21:53:18.545: INFO: Pod "downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.500434ms
Feb 13 21:53:20.548: INFO: Pod "downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005086452s
Feb 13 21:53:22.550: INFO: Pod "downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006875375s
STEP: Saw pod success
Feb 13 21:53:22.550: INFO: Pod "downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:53:22.551: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 21:53:22.563: INFO: Waiting for pod downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:53:22.564: INFO: Pod downward-api-c5db0194-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:53:22.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jbb7m" for this suite.
Feb 13 21:53:28.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:28.582: INFO: namespace: e2e-tests-downward-api-jbb7m, resource: bindings, ignored listing per whitelist
Feb 13 21:53:28.638: INFO: namespace e2e-tests-downward-api-jbb7m deletion completed in 6.069664154s

• [SLOW TEST:10.230 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:53:28.638: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-xf8kr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-cbf47009-2fd9-11e9-aeb1-a6e9e8347cdc,GenerateName:,Namespace:e2e-tests-events-xf8kr,SelfLink:/api/v1/namespaces/e2e-tests-events-xf8kr/pods/send-events-cbf47009-2fd9-11e9-aeb1-a6e9e8347cdc,UID:cbf4b64a-2fd9-11e9-80e0-0050569e5ced,ResourceVersion:12320,Generation:0,CreationTimestamp:2019-02-13 21:53:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 771383687,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.34/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xkhmf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xkhmf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xkhmf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp1-vsp2-workerbe2ca38349,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42099e070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42099e090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:53:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:53:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:53:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.53,PodIP:192.168.2.34,StartTime:2019-02-13 21:53:28 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-13 21:53:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 docker://2b6443087b662d31aca2950c5e3a6c70955f59ebf071fc1c1e89c1534eb53e1c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:53:34.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xf8kr" for this suite.
Feb 13 21:53:40.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:40.830: INFO: namespace: e2e-tests-events-xf8kr, resource: bindings, ignored listing per whitelist
Feb 13 21:53:40.846: INFO: namespace e2e-tests-events-xf8kr deletion completed in 6.049604434s

• [SLOW TEST:12.208 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:53:40.847: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6w5z6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
STEP: creating an rc
Feb 13 21:53:40.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-6w5z6'
Feb 13 21:53:41.132: INFO: stderr: ""
Feb 13 21:53:41.132: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Waiting for Redis master to start.
Feb 13 21:53:42.133: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:53:42.133: INFO: Found 0 / 1
Feb 13 21:53:43.134: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:53:43.134: INFO: Found 1 / 1
Feb 13 21:53:43.134: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 21:53:43.136: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:53:43.136: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 13 21:53:43.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 logs redis-master-mfbls redis-master --namespace=e2e-tests-kubectl-6w5z6'
Feb 13 21:53:43.209: INFO: stderr: ""
Feb 13 21:53:43.209: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 21:53:41.950 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 21:53:41.950 # Server started, Redis version 3.2.12\n1:M 13 Feb 21:53:41.950 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 21:53:41.950 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 13 21:53:43.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 log redis-master-mfbls redis-master --namespace=e2e-tests-kubectl-6w5z6 --tail=1'
Feb 13 21:53:43.273: INFO: stderr: ""
Feb 13 21:53:43.273: INFO: stdout: "1:M 13 Feb 21:53:41.950 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 13 21:53:43.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 log redis-master-mfbls redis-master --namespace=e2e-tests-kubectl-6w5z6 --limit-bytes=1'
Feb 13 21:53:43.355: INFO: stderr: ""
Feb 13 21:53:43.355: INFO: stdout: " "
STEP: exposing timestamps
Feb 13 21:53:43.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 log redis-master-mfbls redis-master --namespace=e2e-tests-kubectl-6w5z6 --tail=1 --timestamps'
Feb 13 21:53:43.442: INFO: stderr: ""
Feb 13 21:53:43.442: INFO: stdout: "2019-02-13T21:53:41.951055741Z 1:M 13 Feb 21:53:41.950 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 13 21:53:45.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 log redis-master-mfbls redis-master --namespace=e2e-tests-kubectl-6w5z6 --since=1s'
Feb 13 21:53:46.015: INFO: stderr: ""
Feb 13 21:53:46.015: INFO: stdout: ""
Feb 13 21:53:46.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 log redis-master-mfbls redis-master --namespace=e2e-tests-kubectl-6w5z6 --since=24h'
Feb 13 21:53:46.077: INFO: stderr: ""
Feb 13 21:53:46.077: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 21:53:41.950 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 21:53:41.950 # Server started, Redis version 3.2.12\n1:M 13 Feb 21:53:41.950 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 21:53:41.950 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
STEP: using delete to clean up resources
Feb 13 21:53:46.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6w5z6'
Feb 13 21:53:46.163: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:53:46.163: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 13 21:53:46.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-6w5z6'
Feb 13 21:53:46.229: INFO: stderr: "No resources found.\n"
Feb 13 21:53:46.229: INFO: stdout: ""
Feb 13 21:53:46.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -l name=nginx --namespace=e2e-tests-kubectl-6w5z6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 21:53:46.300: INFO: stderr: ""
Feb 13 21:53:46.300: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:53:46.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6w5z6" for this suite.
Feb 13 21:53:52.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:52.329: INFO: namespace: e2e-tests-kubectl-6w5z6, resource: bindings, ignored listing per whitelist
Feb 13 21:53:52.350: INFO: namespace e2e-tests-kubectl-6w5z6 deletion completed in 6.047555655s

• [SLOW TEST:11.504 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:53:52.352: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6r6bq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:53:52.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-6r6bq" to be "success or failure"
Feb 13 21:53:52.494: INFO: Pod "downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.810841ms
Feb 13 21:53:54.496: INFO: Pod "downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005450292s
STEP: Saw pod success
Feb 13 21:53:54.496: INFO: Pod "downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:53:54.497: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 21:53:54.510: INFO: Waiting for pod downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:53:54.511: INFO: Pod downwardapi-volume-da16edc9-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:53:54.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6r6bq" for this suite.
Feb 13 21:54:00.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:54:00.551: INFO: namespace: e2e-tests-downward-api-6r6bq, resource: bindings, ignored listing per whitelist
Feb 13 21:54:00.558: INFO: namespace e2e-tests-downward-api-6r6bq deletion completed in 6.04487418s

• [SLOW TEST:8.206 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:54:00.559: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vdv98
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-defb0803-2fd9-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 21:54:00.698: INFO: Waiting up to 5m0s for pod "pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-vdv98" to be "success or failure"
Feb 13 21:54:00.700: INFO: Pod "pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.761287ms
Feb 13 21:54:02.702: INFO: Pod "pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004525595s
STEP: Saw pod success
Feb 13 21:54:02.702: INFO: Pod "pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:54:02.704: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:54:02.728: INFO: Waiting for pod pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:54:02.729: INFO: Pod pod-secrets-defb5ecd-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:54:02.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vdv98" for this suite.
Feb 13 21:54:08.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:54:08.756: INFO: namespace: e2e-tests-secrets-vdv98, resource: bindings, ignored listing per whitelist
Feb 13 21:54:08.776: INFO: namespace e2e-tests-secrets-vdv98 deletion completed in 6.044427083s

• [SLOW TEST:8.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:54:08.776: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-nztr2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0213 21:54:18.953696      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 21:54:18.953: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:54:18.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nztr2" for this suite.
Feb 13 21:54:24.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:54:24.988: INFO: namespace: e2e-tests-gc-nztr2, resource: bindings, ignored listing per whitelist
Feb 13 21:54:25.001: INFO: namespace e2e-tests-gc-nztr2 deletion completed in 6.045322544s

• [SLOW TEST:16.224 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:54:25.001: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-npghn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-ed8cc83c-2fd9-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 21:54:25.141: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-npghn" to be "success or failure"
Feb 13 21:54:25.147: INFO: Pod "pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.950077ms
Feb 13 21:54:27.149: INFO: Pod "pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008038063s
STEP: Saw pod success
Feb 13 21:54:27.150: INFO: Pod "pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:54:27.151: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:54:27.165: INFO: Waiting for pod pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:54:27.166: INFO: Pod pod-projected-configmaps-ed8d3963-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:54:27.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-npghn" for this suite.
Feb 13 21:54:33.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:54:33.190: INFO: namespace: e2e-tests-projected-npghn, resource: bindings, ignored listing per whitelist
Feb 13 21:54:33.214: INFO: namespace e2e-tests-projected-npghn deletion completed in 6.046011321s

• [SLOW TEST:8.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:54:33.215: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9ph9l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-f2722179-2fd9-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 21:54:33.353: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-9ph9l" to be "success or failure"
Feb 13 21:54:33.357: INFO: Pod "pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.259512ms
Feb 13 21:54:35.359: INFO: Pod "pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005705267s
STEP: Saw pod success
Feb 13 21:54:35.359: INFO: Pod "pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:54:35.360: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:54:35.372: INFO: Waiting for pod pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:54:35.373: INFO: Pod pod-configmaps-f2727cb5-2fd9-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:54:35.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9ph9l" for this suite.
Feb 13 21:54:41.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:54:41.413: INFO: namespace: e2e-tests-configmap-9ph9l, resource: bindings, ignored listing per whitelist
Feb 13 21:54:41.428: INFO: namespace e2e-tests-configmap-9ph9l deletion completed in 6.045472048s

• [SLOW TEST:8.213 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:54:41.429: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-69lfp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
Feb 13 21:54:45.572: INFO: Pod pod-hostip-f75746e1-2fd9-11e9-aeb1-a6e9e8347cdc has hostIP: 10.10.100.53
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:54:45.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-69lfp" for this suite.
Feb 13 21:55:07.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:55:07.588: INFO: namespace: e2e-tests-pods-69lfp, resource: bindings, ignored listing per whitelist
Feb 13 21:55:07.621: INFO: namespace e2e-tests-pods-69lfp deletion completed in 22.04644156s

• [SLOW TEST:26.193 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:55:07.621: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mqql2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 Pods, got 2 Pods
STEP: Gathering metrics
W0213 21:55:08.781857      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 21:55:08.781: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:55:08.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mqql2" for this suite.
Feb 13 21:55:14.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:55:14.825: INFO: namespace: e2e-tests-gc-mqql2, resource: bindings, ignored listing per whitelist
Feb 13 21:55:14.830: INFO: namespace e2e-tests-gc-mqql2 deletion completed in 6.047125886s

• [SLOW TEST:7.209 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:55:14.831: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-q9ckw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-q9ckw
Feb 13 21:55:18.979: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-q9ckw
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 21:55:18.981: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:59:19.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q9ckw" for this suite.
Feb 13 21:59:25.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:59:25.247: INFO: namespace: e2e-tests-container-probe-q9ckw, resource: bindings, ignored listing per whitelist
Feb 13 21:59:25.270: INFO: namespace e2e-tests-container-probe-q9ckw deletion completed in 6.05012739s

• [SLOW TEST:250.439 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:59:25.270: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gxp4v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-a0878564-2fda-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 21:59:25.419: INFO: Waiting up to 5m0s for pod "pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-gxp4v" to be "success or failure"
Feb 13 21:59:25.422: INFO: Pod "pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.447583ms
Feb 13 21:59:27.423: INFO: Pod "pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004099762s
STEP: Saw pod success
Feb 13 21:59:27.423: INFO: Pod "pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 21:59:27.425: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:59:27.436: INFO: Waiting for pod pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 21:59:27.437: INFO: Pod pod-configmaps-a087e7c2-2fda-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:59:27.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gxp4v" for this suite.
Feb 13 21:59:33.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:59:33.473: INFO: namespace: e2e-tests-configmap-gxp4v, resource: bindings, ignored listing per whitelist
Feb 13 21:59:33.479: INFO: namespace e2e-tests-configmap-gxp4v deletion completed in 6.0396926s

• [SLOW TEST:8.209 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 21:59:33.480: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-nfts6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nfts6
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 21:59:33.610: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 21:59:55.778: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.1.30:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nfts6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 21:59:55.778: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 21:59:55.819: INFO: Found all expected endpoints: [netserver-0]
Feb 13 21:59:55.820: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.2.48:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nfts6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 21:59:55.821: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 21:59:55.859: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 21:59:55.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nfts6" for this suite.
Feb 13 22:00:17.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:17.904: INFO: namespace: e2e-tests-pod-network-test-nfts6, resource: bindings, ignored listing per whitelist
Feb 13 22:00:17.906: INFO: namespace e2e-tests-pod-network-test-nfts6 deletion completed in 22.044638345s

• [SLOW TEST:44.425 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:00:17.906: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rlnzj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-rlnzj
Feb 13 22:00:22.044: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-rlnzj
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:00:22.045: INFO: Initial restart count of pod liveness-exec is 0
Feb 13 22:01:10.089: INFO: Restart count of pod e2e-tests-container-probe-rlnzj/liveness-exec is now 1 (48.043858189s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:01:10.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rlnzj" for this suite.
Feb 13 22:01:16.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:16.111: INFO: namespace: e2e-tests-container-probe-rlnzj, resource: bindings, ignored listing per whitelist
Feb 13 22:01:16.142: INFO: namespace e2e-tests-container-probe-rlnzj deletion completed in 6.043453017s

• [SLOW TEST:58.237 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:01:16.143: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-44n8h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-44n8h/secret-test-e29bc1c7-2fda-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:01:16.281: INFO: Waiting up to 5m0s for pod "pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-44n8h" to be "success or failure"
Feb 13 22:01:16.284: INFO: Pod "pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.19698ms
Feb 13 22:01:18.286: INFO: Pod "pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004948429s
Feb 13 22:01:20.287: INFO: Pod "pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006829924s
STEP: Saw pod success
Feb 13 22:01:20.287: INFO: Pod "pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:01:20.289: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc container env-test: <nil>
STEP: delete the pod
Feb 13 22:01:20.303: INFO: Waiting for pod pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:01:20.305: INFO: Pod pod-configmaps-e29c1b4f-2fda-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:01:20.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-44n8h" for this suite.
Feb 13 22:01:26.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:26.349: INFO: namespace: e2e-tests-secrets-44n8h, resource: bindings, ignored listing per whitelist
Feb 13 22:01:26.350: INFO: namespace e2e-tests-secrets-44n8h deletion completed in 6.043211871s

• [SLOW TEST:10.207 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:01:26.351: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bpc7x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0213 22:01:32.502975      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 22:01:32.503: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:01:32.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bpc7x" for this suite.
Feb 13 22:01:38.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:38.548: INFO: namespace: e2e-tests-gc-bpc7x, resource: bindings, ignored listing per whitelist
Feb 13 22:01:38.552: INFO: namespace e2e-tests-gc-bpc7x deletion completed in 6.047623054s

• [SLOW TEST:12.202 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:01:38.552: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bxftf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:01:38.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-bxftf" to be "success or failure"
Feb 13 22:01:38.698: INFO: Pod "downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.775803ms
Feb 13 22:01:40.699: INFO: Pod "downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006487287s
STEP: Saw pod success
Feb 13 22:01:40.699: INFO: Pod "downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:01:40.701: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:01:40.712: INFO: Waiting for pod downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:01:40.713: INFO: Pod downwardapi-volume-eff7d456-2fda-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:01:40.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bxftf" for this suite.
Feb 13 22:01:46.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:46.731: INFO: namespace: e2e-tests-projected-bxftf, resource: bindings, ignored listing per whitelist
Feb 13 22:01:46.764: INFO: namespace e2e-tests-projected-bxftf deletion completed in 6.049210685s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:01:46.765: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-w5pg8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:01:46.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-w5pg8" to be "success or failure"
Feb 13 22:01:46.916: INFO: Pod "downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.84002ms
Feb 13 22:01:48.918: INFO: Pod "downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00695372s
STEP: Saw pod success
Feb 13 22:01:48.918: INFO: Pod "downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:01:48.920: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:01:48.931: INFO: Waiting for pod downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:01:48.933: INFO: Pod downwardapi-volume-f4ddbaa9-2fda-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:01:48.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w5pg8" for this suite.
Feb 13 22:01:54.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:54.976: INFO: namespace: e2e-tests-projected-w5pg8, resource: bindings, ignored listing per whitelist
Feb 13 22:01:54.988: INFO: namespace e2e-tests-projected-w5pg8 deletion completed in 6.053346728s

• [SLOW TEST:8.224 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:01:54.990: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9ndk2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-f9c44c0d-2fda-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:01:55.133: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-9ndk2" to be "success or failure"
Feb 13 22:01:55.140: INFO: Pod "pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.556819ms
Feb 13 22:01:57.142: INFO: Pod "pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 2.009444323s
Feb 13 22:01:59.144: INFO: Pod "pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011475379s
STEP: Saw pod success
Feb 13 22:01:59.144: INFO: Pod "pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:01:59.146: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:01:59.158: INFO: Waiting for pod pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:01:59.161: INFO: Pod pod-configmaps-f9c49b0b-2fda-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:01:59.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9ndk2" for this suite.
Feb 13 22:02:05.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:02:05.187: INFO: namespace: e2e-tests-configmap-9ndk2, resource: bindings, ignored listing per whitelist
Feb 13 22:02:05.210: INFO: namespace e2e-tests-configmap-9ndk2 deletion completed in 6.041690327s

• [SLOW TEST:10.220 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:02:05.210: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7t8dq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 13 22:02:05.352: INFO: Waiting up to 5m0s for pod "pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-7t8dq" to be "success or failure"
Feb 13 22:02:05.356: INFO: Pod "pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.977111ms
Feb 13 22:02:07.357: INFO: Pod "pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005424267s
STEP: Saw pod success
Feb 13 22:02:07.357: INFO: Pod "pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:02:07.358: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:02:07.369: INFO: Waiting for pod pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:02:07.371: INFO: Pod pod-ffdb7d69-2fda-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:02:07.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7t8dq" for this suite.
Feb 13 22:02:13.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:02:13.383: INFO: namespace: e2e-tests-emptydir-7t8dq, resource: bindings, ignored listing per whitelist
Feb 13 22:02:13.416: INFO: namespace e2e-tests-emptydir-7t8dq deletion completed in 6.043938392s

• [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:02:13.417: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-bgh6x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bgh6x
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 22:02:13.545: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 22:02:35.587: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.38:8080/dial?request=hostName&protocol=udp&host=192.168.1.37&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bgh6x PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:02:35.587: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:02:35.626: INFO: Waiting for endpoints: map[]
Feb 13 22:02:35.627: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.38:8080/dial?request=hostName&protocol=udp&host=192.168.2.60&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bgh6x PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:02:35.628: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:02:35.665: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:02:35.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bgh6x" for this suite.
Feb 13 22:02:57.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:02:57.701: INFO: namespace: e2e-tests-pod-network-test-bgh6x, resource: bindings, ignored listing per whitelist
Feb 13 22:02:57.722: INFO: namespace e2e-tests-pod-network-test-bgh6x deletion completed in 22.054829161s

• [SLOW TEST:44.305 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:02:57.722: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bzrrf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Feb 13 22:03:00.379: INFO: Successfully updated pod "annotationupdate1f27bdc3-2fdb-11e9-aeb1-a6e9e8347cdc"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:03:02.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bzrrf" for this suite.
Feb 13 22:03:24.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:03:24.428: INFO: namespace: e2e-tests-projected-bzrrf, resource: bindings, ignored listing per whitelist
Feb 13 22:03:24.436: INFO: namespace e2e-tests-projected-bzrrf deletion completed in 22.043575242s

• [SLOW TEST:26.714 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:03:24.437: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-d5d7v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 13 22:03:24.575: INFO: Waiting up to 5m0s for pod "pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-d5d7v" to be "success or failure"
Feb 13 22:03:24.577: INFO: Pod "pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.769824ms
Feb 13 22:03:26.579: INFO: Pod "pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004680057s
STEP: Saw pod success
Feb 13 22:03:26.579: INFO: Pod "pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:03:26.581: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:03:26.593: INFO: Waiting for pod pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:03:26.594: INFO: Pod pod-2f140939-2fdb-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:03:26.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d5d7v" for this suite.
Feb 13 22:03:32.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:03:32.638: INFO: namespace: e2e-tests-emptydir-d5d7v, resource: bindings, ignored listing per whitelist
Feb 13 22:03:32.645: INFO: namespace e2e-tests-emptydir-d5d7v deletion completed in 6.048621428s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:03:32.645: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mwpkg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0213 22:04:03.299705      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 22:04:03.299: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:04:03.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mwpkg" for this suite.
Feb 13 22:04:09.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:09.337: INFO: namespace: e2e-tests-gc-mwpkg, resource: bindings, ignored listing per whitelist
Feb 13 22:04:09.351: INFO: namespace e2e-tests-gc-mwpkg deletion completed in 6.049367543s

• [SLOW TEST:36.706 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:04:09.351: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ddrft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-49d98461-2fdb-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:04:09.491: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-ddrft" to be "success or failure"
Feb 13 22:04:09.495: INFO: Pod "pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.282407ms
Feb 13 22:04:11.497: INFO: Pod "pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005328662s
STEP: Saw pod success
Feb 13 22:04:11.497: INFO: Pod "pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:04:11.498: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:04:11.511: INFO: Waiting for pod pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:04:11.512: INFO: Pod pod-projected-configmaps-49d9d5c5-2fdb-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:04:11.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ddrft" for this suite.
Feb 13 22:04:17.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:17.534: INFO: namespace: e2e-tests-projected-ddrft, resource: bindings, ignored listing per whitelist
Feb 13 22:04:17.559: INFO: namespace e2e-tests-projected-ddrft deletion completed in 6.044859176s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:04:17.560: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-q7d2z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:04:17.695: INFO: (0) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.727466ms)
Feb 13 22:04:17.697: INFO: (1) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.787626ms)
Feb 13 22:04:17.698: INFO: (2) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.666769ms)
Feb 13 22:04:17.700: INFO: (3) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.580394ms)
Feb 13 22:04:17.702: INFO: (4) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.538108ms)
Feb 13 22:04:17.704: INFO: (5) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.810879ms)
Feb 13 22:04:17.705: INFO: (6) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.738585ms)
Feb 13 22:04:17.707: INFO: (7) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.658507ms)
Feb 13 22:04:17.709: INFO: (8) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.900902ms)
Feb 13 22:04:17.711: INFO: (9) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.630498ms)
Feb 13 22:04:17.712: INFO: (10) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.496799ms)
Feb 13 22:04:17.714: INFO: (11) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.510161ms)
Feb 13 22:04:17.715: INFO: (12) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.554059ms)
Feb 13 22:04:17.717: INFO: (13) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.561836ms)
Feb 13 22:04:17.719: INFO: (14) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.691752ms)
Feb 13 22:04:17.720: INFO: (15) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.591296ms)
Feb 13 22:04:17.722: INFO: (16) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.726326ms)
Feb 13 22:04:17.724: INFO: (17) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.542783ms)
Feb 13 22:04:17.725: INFO: (18) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.419864ms)
Feb 13 22:04:17.727: INFO: (19) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.700503ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:04:17.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-q7d2z" for this suite.
Feb 13 22:04:23.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:23.768: INFO: namespace: e2e-tests-proxy-q7d2z, resource: bindings, ignored listing per whitelist
Feb 13 22:04:23.769: INFO: namespace e2e-tests-proxy-q7d2z deletion completed in 6.040365363s

• [SLOW TEST:6.210 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:04:23.770: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xhjkz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating cluster-info
Feb 13 22:04:23.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 cluster-info'
Feb 13 22:04:24.143: INFO: stderr: ""
Feb 13 22:04:24.143: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:04:24.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xhjkz" for this suite.
Feb 13 22:04:30.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:30.175: INFO: namespace: e2e-tests-kubectl-xhjkz, resource: bindings, ignored listing per whitelist
Feb 13 22:04:30.207: INFO: namespace e2e-tests-kubectl-xhjkz deletion completed in 6.051484101s

• [SLOW TEST:6.437 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:04:30.207: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-9kfs9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
Feb 13 22:04:30.346: INFO: Waiting up to 5m0s for pod "client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-containers-9kfs9" to be "success or failure"
Feb 13 22:04:30.348: INFO: Pod "client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.366805ms
Feb 13 22:04:32.350: INFO: Pod "client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004182423s
Feb 13 22:04:34.352: INFO: Pod "client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005913221s
STEP: Saw pod success
Feb 13 22:04:34.352: INFO: Pod "client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:04:34.353: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:04:34.366: INFO: Waiting for pod client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:04:34.367: INFO: Pod client-containers-56478456-2fdb-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:04:34.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9kfs9" for this suite.
Feb 13 22:04:40.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:40.400: INFO: namespace: e2e-tests-containers-9kfs9, resource: bindings, ignored listing per whitelist
Feb 13 22:04:40.414: INFO: namespace e2e-tests-containers-9kfs9 deletion completed in 6.04529551s

• [SLOW TEST:10.207 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:04:40.415: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-slsbf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-slsbf
Feb 13 22:04:42.569: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-slsbf
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:04:42.570: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:08:42.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-slsbf" for this suite.
Feb 13 22:08:48.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:08:48.864: INFO: namespace: e2e-tests-container-probe-slsbf, resource: bindings, ignored listing per whitelist
Feb 13 22:08:48.867: INFO: namespace e2e-tests-container-probe-slsbf deletion completed in 6.045425113s

• [SLOW TEST:248.451 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:08:48.868: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-hm4th
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-hm4th
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hm4th to expose endpoints map[]
Feb 13 22:08:49.016: INFO: Get endpoints failed (1.409984ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 13 22:08:50.018: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hm4th exposes endpoints map[] (1.003216353s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-hm4th
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hm4th to expose endpoints map[pod1:[100]]
Feb 13 22:08:52.035: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hm4th exposes endpoints map[pod1:[100]] (2.011516171s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-hm4th
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hm4th to expose endpoints map[pod2:[101] pod1:[100]]
Feb 13 22:08:55.060: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hm4th exposes endpoints map[pod1:[100] pod2:[101]] (3.021075686s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-hm4th
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hm4th to expose endpoints map[pod2:[101]]
Feb 13 22:08:55.072: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hm4th exposes endpoints map[pod2:[101]] (6.960008ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-hm4th
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hm4th to expose endpoints map[]
Feb 13 22:08:55.082: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hm4th exposes endpoints map[] (2.974348ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:08:55.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hm4th" for this suite.
Feb 13 22:09:01.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:09:01.132: INFO: namespace: e2e-tests-services-hm4th, resource: bindings, ignored listing per whitelist
Feb 13 22:09:01.145: INFO: namespace e2e-tests-services-hm4th deletion completed in 6.046265252s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:12.277 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:09:01.145: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d2d42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:09:01.288: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-d2d42" to be "success or failure"
Feb 13 22:09:01.293: INFO: Pod "downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.21721ms
Feb 13 22:09:03.295: INFO: Pod "downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005990831s
STEP: Saw pod success
Feb 13 22:09:03.295: INFO: Pod "downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:09:03.296: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:09:03.308: INFO: Waiting for pod downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:09:03.309: INFO: Pod downwardapi-volume-f7c683eb-2fdb-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:09:03.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d2d42" for this suite.
Feb 13 22:09:09.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:09:09.337: INFO: namespace: e2e-tests-downward-api-d2d42, resource: bindings, ignored listing per whitelist
Feb 13 22:09:09.354: INFO: namespace e2e-tests-downward-api-d2d42 deletion completed in 6.04329899s

• [SLOW TEST:8.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:09:09.354: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rhrtk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:09:09.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-rhrtk'
Feb 13 22:09:09.555: INFO: stderr: ""
Feb 13 22:09:09.555: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 13 22:09:09.562: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 13 22:09:09.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-rhrtk'
Feb 13 22:09:25.319: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 13 22:09:25.319: INFO: stdout: "Created e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638\nScaling up e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 13 22:09:25.319: INFO: stdout: "Created e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638\nScaling up e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 13 22:09:25.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rhrtk'
Feb 13 22:09:25.386: INFO: stderr: ""
Feb 13 22:09:25.386: INFO: stdout: "e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638-5rc6l "
Feb 13 22:09:25.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638-5rc6l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rhrtk'
Feb 13 22:09:25.459: INFO: stderr: ""
Feb 13 22:09:25.459: INFO: stdout: "true"
Feb 13 22:09:25.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638-5rc6l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rhrtk'
Feb 13 22:09:25.532: INFO: stderr: ""
Feb 13 22:09:25.532: INFO: stdout: "k8s.gcr.io/nginx-slim-amd64:0.20"
Feb 13 22:09:25.532: INFO: e2e-test-nginx-rc-f34089080083049ce02c02a4548e6638-5rc6l is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
Feb 13 22:09:25.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rhrtk'
Feb 13 22:09:25.621: INFO: stderr: ""
Feb 13 22:09:25.621: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:09:25.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rhrtk" for this suite.
Feb 13 22:09:31.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:09:31.667: INFO: namespace: e2e-tests-kubectl-rhrtk, resource: bindings, ignored listing per whitelist
Feb 13 22:09:31.671: INFO: namespace e2e-tests-kubectl-rhrtk deletion completed in 6.046281817s

• [SLOW TEST:22.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:09:31.672: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5jpk9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating all guestbook components
Feb 13 22:09:31.804: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 13 22:09:31.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:31.953: INFO: stderr: ""
Feb 13 22:09:31.953: INFO: stdout: "service/redis-slave created\n"
Feb 13 22:09:31.954: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 13 22:09:31.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:32.107: INFO: stderr: ""
Feb 13 22:09:32.107: INFO: stdout: "service/redis-master created\n"
Feb 13 22:09:32.107: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 13 22:09:32.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:32.261: INFO: stderr: ""
Feb 13 22:09:32.261: INFO: stdout: "service/frontend created\n"
Feb 13 22:09:32.261: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 13 22:09:32.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:32.404: INFO: stderr: ""
Feb 13 22:09:32.404: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 13 22:09:32.404: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 13 22:09:32.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:32.580: INFO: stderr: ""
Feb 13 22:09:32.580: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 13 22:09:32.580: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 13 22:09:32.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:32.725: INFO: stderr: ""
Feb 13 22:09:32.726: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 13 22:09:32.726: INFO: Waiting for all frontend pods to be Running.
Feb 13 22:09:52.776: INFO: Waiting for frontend to serve content.
Feb 13 22:09:52.787: INFO: Trying to add a new entry to the guestbook.
Feb 13 22:09:52.794: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 13 22:09:52.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:52.901: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:09:52.901: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 22:09:52.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:52.974: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:09:52.974: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 22:09:52.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:53.127: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:09:53.127: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 22:09:53.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:53.193: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:09:53.193: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 22:09:53.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:53.269: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:09:53.269: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 22:09:53.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5jpk9'
Feb 13 22:09:53.367: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:09:53.367: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:09:53.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5jpk9" for this suite.
Feb 13 22:10:31.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:10:31.406: INFO: namespace: e2e-tests-kubectl-5jpk9, resource: bindings, ignored listing per whitelist
Feb 13 22:10:31.416: INFO: namespace e2e-tests-kubectl-5jpk9 deletion completed in 38.043639838s

• [SLOW TEST:59.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:10:31.417: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-c8g8j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 13 22:10:31.563: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c8g8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-c8g8j/configmaps/e2e-watch-test-watch-closed,UID:2d956fda-2fdc-11e9-80e0-0050569e5ced,ResourceVersion:15846,Generation:0,CreationTimestamp:2019-02-13 22:10:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 22:10:31.563: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c8g8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-c8g8j/configmaps/e2e-watch-test-watch-closed,UID:2d956fda-2fdc-11e9-80e0-0050569e5ced,ResourceVersion:15847,Generation:0,CreationTimestamp:2019-02-13 22:10:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 13 22:10:31.570: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c8g8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-c8g8j/configmaps/e2e-watch-test-watch-closed,UID:2d956fda-2fdc-11e9-80e0-0050569e5ced,ResourceVersion:15848,Generation:0,CreationTimestamp:2019-02-13 22:10:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 22:10:31.570: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c8g8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-c8g8j/configmaps/e2e-watch-test-watch-closed,UID:2d956fda-2fdc-11e9-80e0-0050569e5ced,ResourceVersion:15849,Generation:0,CreationTimestamp:2019-02-13 22:10:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:10:31.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-c8g8j" for this suite.
Feb 13 22:10:37.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:10:37.602: INFO: namespace: e2e-tests-watch-c8g8j, resource: bindings, ignored listing per whitelist
Feb 13 22:10:37.623: INFO: namespace e2e-tests-watch-c8g8j deletion completed in 6.050354704s

• [SLOW TEST:6.206 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:10:37.623: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tx9c2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:10:37.759: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-tx9c2" to be "success or failure"
Feb 13 22:10:37.763: INFO: Pod "downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.156999ms
Feb 13 22:10:39.765: INFO: Pod "downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004969467s
STEP: Saw pod success
Feb 13 22:10:39.765: INFO: Pod "downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:10:39.766: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:10:39.780: INFO: Waiting for pod downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:10:39.781: INFO: Pod downwardapi-volume-3146c782-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:10:39.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tx9c2" for this suite.
Feb 13 22:10:45.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:10:45.821: INFO: namespace: e2e-tests-projected-tx9c2, resource: bindings, ignored listing per whitelist
Feb 13 22:10:45.830: INFO: namespace e2e-tests-projected-tx9c2 deletion completed in 6.04750731s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:10:45.831: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-6bxpg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
Feb 13 22:10:45.970: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6bxpg" to be "success or failure"
Feb 13 22:10:45.976: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36697ms
Feb 13 22:10:47.978: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.008348396s
Feb 13 22:10:49.980: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01050802s
STEP: Saw pod success
Feb 13 22:10:49.980: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 13 22:10:49.982: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 13 22:10:49.993: INFO: Waiting for pod pod-host-path-test to disappear
Feb 13 22:10:49.994: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:10:49.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6bxpg" for this suite.
Feb 13 22:10:56.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:10:56.034: INFO: namespace: e2e-tests-hostpath-6bxpg, resource: bindings, ignored listing per whitelist
Feb 13 22:10:56.048: INFO: namespace e2e-tests-hostpath-6bxpg deletion completed in 6.05140251s

• [SLOW TEST:10.217 seconds]
[sig-storage] HostPath
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:10:56.048: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cfb8v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:10:56.184: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-cfb8v" to be "success or failure"
Feb 13 22:10:56.189: INFO: Pod "downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.440612ms
Feb 13 22:10:58.191: INFO: Pod "downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006706549s
STEP: Saw pod success
Feb 13 22:10:58.191: INFO: Pod "downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:10:58.193: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:10:58.207: INFO: Waiting for pod downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:10:58.208: INFO: Pod downwardapi-volume-3c423d0a-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:10:58.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cfb8v" for this suite.
Feb 13 22:11:04.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:11:04.225: INFO: namespace: e2e-tests-downward-api-cfb8v, resource: bindings, ignored listing per whitelist
Feb 13 22:11:04.251: INFO: namespace e2e-tests-downward-api-cfb8v deletion completed in 6.041520269s

• [SLOW TEST:8.203 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:11:04.251: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-nx7jv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nx7jv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 22:11:04.380: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 22:11:24.423: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.78:8080/dial?request=hostName&protocol=http&host=192.168.1.45&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nx7jv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:11:24.423: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:11:24.486: INFO: Waiting for endpoints: map[]
Feb 13 22:11:24.487: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.78:8080/dial?request=hostName&protocol=http&host=192.168.2.77&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nx7jv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:11:24.487: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:11:24.548: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:11:24.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nx7jv" for this suite.
Feb 13 22:11:46.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:11:46.565: INFO: namespace: e2e-tests-pod-network-test-nx7jv, resource: bindings, ignored listing per whitelist
Feb 13 22:11:46.599: INFO: namespace e2e-tests-pod-network-test-nx7jv deletion completed in 22.048644106s

• [SLOW TEST:42.348 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:11:46.600: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tmm6w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Feb 13 22:11:46.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:46.902: INFO: stderr: ""
Feb 13 22:11:46.902: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:11:46.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:46.994: INFO: stderr: ""
Feb 13 22:11:46.994: INFO: stdout: "update-demo-nautilus-7zv69 update-demo-nautilus-dtdtj "
Feb 13 22:11:46.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-7zv69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:47.049: INFO: stderr: ""
Feb 13 22:11:47.049: INFO: stdout: ""
Feb 13 22:11:47.049: INFO: update-demo-nautilus-7zv69 is created but not running
Feb 13 22:11:52.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:52.118: INFO: stderr: ""
Feb 13 22:11:52.118: INFO: stdout: "update-demo-nautilus-7zv69 update-demo-nautilus-dtdtj "
Feb 13 22:11:52.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-7zv69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:52.180: INFO: stderr: ""
Feb 13 22:11:52.180: INFO: stdout: ""
Feb 13 22:11:52.180: INFO: update-demo-nautilus-7zv69 is created but not running
Feb 13 22:11:57.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:57.251: INFO: stderr: ""
Feb 13 22:11:57.251: INFO: stdout: "update-demo-nautilus-7zv69 update-demo-nautilus-dtdtj "
Feb 13 22:11:57.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-7zv69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:57.331: INFO: stderr: ""
Feb 13 22:11:57.331: INFO: stdout: "true"
Feb 13 22:11:57.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-7zv69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:57.394: INFO: stderr: ""
Feb 13 22:11:57.394: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:11:57.394: INFO: validating pod update-demo-nautilus-7zv69
Feb 13 22:11:57.397: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:11:57.397: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:11:57.397: INFO: update-demo-nautilus-7zv69 is verified up and running
Feb 13 22:11:57.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-dtdtj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:57.455: INFO: stderr: ""
Feb 13 22:11:57.455: INFO: stdout: "true"
Feb 13 22:11:57.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-dtdtj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:57.521: INFO: stderr: ""
Feb 13 22:11:57.521: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:11:57.521: INFO: validating pod update-demo-nautilus-dtdtj
Feb 13 22:11:57.524: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:11:57.524: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:11:57.524: INFO: update-demo-nautilus-dtdtj is verified up and running
STEP: scaling down the replication controller
Feb 13 22:11:57.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:58.612: INFO: stderr: ""
Feb 13 22:11:58.612: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:11:58.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:11:58.680: INFO: stderr: ""
Feb 13 22:11:58.680: INFO: stdout: "update-demo-nautilus-7zv69 update-demo-nautilus-dtdtj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 22:12:03.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:03.770: INFO: stderr: ""
Feb 13 22:12:03.770: INFO: stdout: "update-demo-nautilus-7zv69 update-demo-nautilus-dtdtj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 22:12:08.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:08.830: INFO: stderr: ""
Feb 13 22:12:08.830: INFO: stdout: "update-demo-nautilus-7zv69 update-demo-nautilus-dtdtj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 22:12:13.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:13.887: INFO: stderr: ""
Feb 13 22:12:13.887: INFO: stdout: "update-demo-nautilus-dtdtj "
Feb 13 22:12:13.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-dtdtj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:13.949: INFO: stderr: ""
Feb 13 22:12:13.949: INFO: stdout: "true"
Feb 13 22:12:13.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-dtdtj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:14.031: INFO: stderr: ""
Feb 13 22:12:14.031: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:12:14.031: INFO: validating pod update-demo-nautilus-dtdtj
Feb 13 22:12:14.034: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:12:14.034: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:12:14.034: INFO: update-demo-nautilus-dtdtj is verified up and running
STEP: scaling up the replication controller
Feb 13 22:12:14.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.132: INFO: stderr: ""
Feb 13 22:12:15.132: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:12:15.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.208: INFO: stderr: ""
Feb 13 22:12:15.208: INFO: stdout: "update-demo-nautilus-9sh2w update-demo-nautilus-dtdtj "
Feb 13 22:12:15.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-9sh2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.270: INFO: stderr: ""
Feb 13 22:12:15.270: INFO: stdout: "true"
Feb 13 22:12:15.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-9sh2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.341: INFO: stderr: ""
Feb 13 22:12:15.341: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:12:15.341: INFO: validating pod update-demo-nautilus-9sh2w
Feb 13 22:12:15.344: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:12:15.344: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:12:15.344: INFO: update-demo-nautilus-9sh2w is verified up and running
Feb 13 22:12:15.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-dtdtj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.417: INFO: stderr: ""
Feb 13 22:12:15.417: INFO: stdout: "true"
Feb 13 22:12:15.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-dtdtj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.477: INFO: stderr: ""
Feb 13 22:12:15.477: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:12:15.477: INFO: validating pod update-demo-nautilus-dtdtj
Feb 13 22:12:15.479: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:12:15.479: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:12:15.479: INFO: update-demo-nautilus-dtdtj is verified up and running
STEP: using delete to clean up resources
Feb 13 22:12:15.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.566: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:12:15.567: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 22:12:15.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-tmm6w'
Feb 13 22:12:15.639: INFO: stderr: "No resources found.\n"
Feb 13 22:12:15.639: INFO: stdout: ""
Feb 13 22:12:15.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -l name=update-demo --namespace=e2e-tests-kubectl-tmm6w -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 22:12:15.716: INFO: stderr: ""
Feb 13 22:12:15.716: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:12:15.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tmm6w" for this suite.
Feb 13 22:12:37.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:12:37.750: INFO: namespace: e2e-tests-kubectl-tmm6w, resource: bindings, ignored listing per whitelist
Feb 13 22:12:37.763: INFO: namespace e2e-tests-kubectl-tmm6w deletion completed in 22.044633675s

• [SLOW TEST:51.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:12:37.764: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-557nb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:12:37.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-557nb'
Feb 13 22:12:37.982: INFO: stderr: ""
Feb 13 22:12:37.982: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
Feb 13 22:12:37.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-557nb'
Feb 13 22:12:49.237: INFO: stderr: ""
Feb 13 22:12:49.237: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:12:49.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-557nb" for this suite.
Feb 13 22:12:55.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:12:55.261: INFO: namespace: e2e-tests-kubectl-557nb, resource: bindings, ignored listing per whitelist
Feb 13 22:12:55.286: INFO: namespace e2e-tests-kubectl-557nb deletion completed in 6.045829264s

• [SLOW TEST:17.522 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:12:55.286: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qlhr9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:12:55.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-qlhr9" to be "success or failure"
Feb 13 22:12:55.435: INFO: Pod "downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.989068ms
Feb 13 22:12:57.437: INFO: Pod "downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 2.007120203s
Feb 13 22:12:59.439: INFO: Pod "downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008736506s
STEP: Saw pod success
Feb 13 22:12:59.439: INFO: Pod "downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:12:59.441: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:12:59.458: INFO: Waiting for pod downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:12:59.460: INFO: Pod downwardapi-volume-8355a14a-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:12:59.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qlhr9" for this suite.
Feb 13 22:13:05.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:05.491: INFO: namespace: e2e-tests-projected-qlhr9, resource: bindings, ignored listing per whitelist
Feb 13 22:13:05.509: INFO: namespace e2e-tests-projected-qlhr9 deletion completed in 6.04715766s

• [SLOW TEST:10.223 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:13:05.509: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fnc8p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Feb 13 22:13:05.650: INFO: Waiting up to 5m0s for pod "downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-fnc8p" to be "success or failure"
Feb 13 22:13:05.654: INFO: Pod "downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117586ms
Feb 13 22:13:07.656: INFO: Pod "downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005061336s
Feb 13 22:13:09.657: INFO: Pod "downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006573338s
STEP: Saw pod success
Feb 13 22:13:09.657: INFO: Pod "downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:13:09.658: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:13:09.671: INFO: Waiting for pod downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:13:09.673: INFO: Pod downward-api-896ceef3-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:13:09.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fnc8p" for this suite.
Feb 13 22:13:15.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:15.713: INFO: namespace: e2e-tests-downward-api-fnc8p, resource: bindings, ignored listing per whitelist
Feb 13 22:13:15.716: INFO: namespace e2e-tests-downward-api-fnc8p deletion completed in 6.041933879s

• [SLOW TEST:10.207 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:13:15.716: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-25l7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Feb 13 22:13:15.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-25l7r'
Feb 13 22:13:15.987: INFO: stderr: ""
Feb 13 22:13:15.987: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 22:13:16.989: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:13:16.989: INFO: Found 0 / 1
Feb 13 22:13:17.993: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:13:17.993: INFO: Found 1 / 1
Feb 13 22:13:17.993: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 13 22:13:17.994: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:13:17.994: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 22:13:17.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 patch pod redis-master-7kjls --namespace=e2e-tests-kubectl-25l7r -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 13 22:13:18.077: INFO: stderr: ""
Feb 13 22:13:18.077: INFO: stdout: "pod/redis-master-7kjls patched\n"
STEP: checking annotations
Feb 13 22:13:18.079: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:13:18.079: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:13:18.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-25l7r" for this suite.
Feb 13 22:13:40.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:40.113: INFO: namespace: e2e-tests-kubectl-25l7r, resource: bindings, ignored listing per whitelist
Feb 13 22:13:40.127: INFO: namespace e2e-tests-kubectl-25l7r deletion completed in 22.045075572s

• [SLOW TEST:24.411 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:13:40.128: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-vj9kb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
Feb 13 22:13:40.276: INFO: Waiting up to 5m0s for pod "var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-var-expansion-vj9kb" to be "success or failure"
Feb 13 22:13:40.279: INFO: Pod "var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619386ms
Feb 13 22:13:42.281: INFO: Pod "var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005444238s
Feb 13 22:13:44.283: INFO: Pod "var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007127814s
STEP: Saw pod success
Feb 13 22:13:44.283: INFO: Pod "var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:13:44.284: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:13:44.295: INFO: Waiting for pod var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:13:44.297: INFO: Pod var-expansion-9e10c508-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:13:44.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vj9kb" for this suite.
Feb 13 22:13:50.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:50.333: INFO: namespace: e2e-tests-var-expansion-vj9kb, resource: bindings, ignored listing per whitelist
Feb 13 22:13:50.344: INFO: namespace e2e-tests-var-expansion-vj9kb deletion completed in 6.045368691s

• [SLOW TEST:10.216 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:13:50.345: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tvpwj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the initial replication controller
Feb 13 22:13:50.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:50.616: INFO: stderr: ""
Feb 13 22:13:50.616: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:13:50.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:50.717: INFO: stderr: ""
Feb 13 22:13:50.717: INFO: stdout: "update-demo-nautilus-hrb7v update-demo-nautilus-mrdmn "
Feb 13 22:13:50.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-hrb7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:50.788: INFO: stderr: ""
Feb 13 22:13:50.788: INFO: stdout: ""
Feb 13 22:13:50.788: INFO: update-demo-nautilus-hrb7v is created but not running
Feb 13 22:13:55.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:55.866: INFO: stderr: ""
Feb 13 22:13:55.866: INFO: stdout: "update-demo-nautilus-hrb7v update-demo-nautilus-mrdmn "
Feb 13 22:13:55.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-hrb7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:55.929: INFO: stderr: ""
Feb 13 22:13:55.929: INFO: stdout: "true"
Feb 13 22:13:55.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-hrb7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:56.007: INFO: stderr: ""
Feb 13 22:13:56.007: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:13:56.007: INFO: validating pod update-demo-nautilus-hrb7v
Feb 13 22:13:56.009: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:13:56.009: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:13:56.009: INFO: update-demo-nautilus-hrb7v is verified up and running
Feb 13 22:13:56.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-mrdmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:56.069: INFO: stderr: ""
Feb 13 22:13:56.069: INFO: stdout: "true"
Feb 13 22:13:56.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-mrdmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:13:56.140: INFO: stderr: ""
Feb 13 22:13:56.141: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:13:56.141: INFO: validating pod update-demo-nautilus-mrdmn
Feb 13 22:13:56.143: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:13:56.143: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:13:56.143: INFO: update-demo-nautilus-mrdmn is verified up and running
STEP: rolling-update to new replication controller
Feb 13 22:13:56.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:18.410: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 13 22:14:18.410: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:14:18.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:18.488: INFO: stderr: ""
Feb 13 22:14:18.488: INFO: stdout: "update-demo-kitten-64ktk update-demo-kitten-7brs5 update-demo-nautilus-mrdmn "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb 13 22:14:23.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:23.546: INFO: stderr: ""
Feb 13 22:14:23.546: INFO: stdout: "update-demo-kitten-64ktk update-demo-kitten-7brs5 "
Feb 13 22:14:23.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-kitten-64ktk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:23.608: INFO: stderr: ""
Feb 13 22:14:23.608: INFO: stdout: "true"
Feb 13 22:14:23.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-kitten-64ktk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:23.685: INFO: stderr: ""
Feb 13 22:14:23.685: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Feb 13 22:14:23.685: INFO: validating pod update-demo-kitten-64ktk
Feb 13 22:14:23.687: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 13 22:14:23.687: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 13 22:14:23.687: INFO: update-demo-kitten-64ktk is verified up and running
Feb 13 22:14:23.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-kitten-7brs5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:23.772: INFO: stderr: ""
Feb 13 22:14:23.772: INFO: stdout: "true"
Feb 13 22:14:23.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-kitten-7brs5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tvpwj'
Feb 13 22:14:23.827: INFO: stderr: ""
Feb 13 22:14:23.827: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Feb 13 22:14:23.827: INFO: validating pod update-demo-kitten-7brs5
Feb 13 22:14:23.830: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 13 22:14:23.830: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 13 22:14:23.830: INFO: update-demo-kitten-7brs5 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:14:23.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tvpwj" for this suite.
Feb 13 22:14:45.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:14:45.890: INFO: namespace: e2e-tests-kubectl-tvpwj, resource: bindings, ignored listing per whitelist
Feb 13 22:14:45.890: INFO: namespace e2e-tests-kubectl-tvpwj deletion completed in 22.057155406s

• [SLOW TEST:55.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:14:45.890: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-sxrzn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Feb 13 22:14:46.029: INFO: Waiting up to 5m0s for pod "downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-sxrzn" to be "success or failure"
Feb 13 22:14:46.033: INFO: Pod "downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.001477ms
Feb 13 22:14:48.035: INFO: Pod "downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005845446s
Feb 13 22:14:50.037: INFO: Pod "downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007936857s
STEP: Saw pod success
Feb 13 22:14:50.037: INFO: Pod "downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:14:50.038: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:14:50.050: INFO: Waiting for pod downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:14:50.052: INFO: Pod downward-api-c541a92a-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:14:50.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sxrzn" for this suite.
Feb 13 22:14:56.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:14:56.072: INFO: namespace: e2e-tests-downward-api-sxrzn, resource: bindings, ignored listing per whitelist
Feb 13 22:14:56.098: INFO: namespace e2e-tests-downward-api-sxrzn deletion completed in 6.043875899s

• [SLOW TEST:10.209 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:14:56.099: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lngdh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting the proxy server
Feb 13 22:14:56.233: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-208905800 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:14:56.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lngdh" for this suite.
Feb 13 22:15:02.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:02.310: INFO: namespace: e2e-tests-kubectl-lngdh, resource: bindings, ignored listing per whitelist
Feb 13 22:15:02.335: INFO: namespace e2e-tests-kubectl-lngdh deletion completed in 6.04648893s

• [SLOW TEST:6.236 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:15:02.336: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nbndp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-cf0f2fc3-2fdc-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:15:02.477: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-nbndp" to be "success or failure"
Feb 13 22:15:02.481: INFO: Pod "pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.491357ms
Feb 13 22:15:04.483: INFO: Pod "pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006197554s
STEP: Saw pod success
Feb 13 22:15:04.483: INFO: Pod "pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:15:04.485: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:15:04.495: INFO: Waiting for pod pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:15:04.498: INFO: Pod pod-configmaps-cf0f8c3d-2fdc-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:15:04.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nbndp" for this suite.
Feb 13 22:15:10.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:10.527: INFO: namespace: e2e-tests-configmap-nbndp, resource: bindings, ignored listing per whitelist
Feb 13 22:15:10.555: INFO: namespace e2e-tests-configmap-nbndp deletion completed in 6.055540211s

• [SLOW TEST:8.220 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:15:10.555: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-9jk8v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:15:10.685: INFO: Creating ReplicaSet my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc
Feb 13 22:15:10.689: INFO: Pod name my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc: Found 0 pods out of 1
Feb 13 22:15:15.691: INFO: Pod name my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc: Found 1 pods out of 1
Feb 13 22:15:15.691: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc" is running
Feb 13 22:15:15.693: INFO: Pod "my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc-sfv5m" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:15:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:15:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:15:10 +0000 UTC Reason: Message:}])
Feb 13 22:15:15.693: INFO: Trying to dial the pod
Feb 13 22:15:20.697: INFO: Controller my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc: Got expected result from replica 1 [my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc-sfv5m]: "my-hostname-basic-d3f4beff-2fdc-11e9-aeb1-a6e9e8347cdc-sfv5m", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:15:20.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9jk8v" for this suite.
Feb 13 22:15:26.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:26.719: INFO: namespace: e2e-tests-replicaset-9jk8v, resource: bindings, ignored listing per whitelist
Feb 13 22:15:26.746: INFO: namespace e2e-tests-replicaset-9jk8v deletion completed in 6.04627318s

• [SLOW TEST:16.191 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:15:26.746: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9pm4f
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-upd-dd9b78c9-2fdc-11e9-aeb1-a6e9e8347cdc
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-dd9b78c9-2fdc-11e9-aeb1-a6e9e8347cdc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:15:30.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9pm4f" for this suite.
Feb 13 22:15:52.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:52.936: INFO: namespace: e2e-tests-configmap-9pm4f, resource: bindings, ignored listing per whitelist
Feb 13 22:15:52.951: INFO: namespace e2e-tests-configmap-9pm4f deletion completed in 22.042247966s

• [SLOW TEST:26.204 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:15:52.951: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vxzdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
STEP: creating the pod
Feb 13 22:15:53.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:53.436: INFO: stderr: ""
Feb 13 22:15:53.436: INFO: stdout: "pod/pause created\n"
Feb 13 22:15:53.436: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 13 22:15:53.436: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-vxzdn" to be "running and ready"
Feb 13 22:15:53.439: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.572013ms
Feb 13 22:15:55.440: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004263882s
Feb 13 22:15:55.440: INFO: Pod "pause" satisfied condition "running and ready"
Feb 13 22:15:55.440: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 13 22:15:55.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:55.504: INFO: stderr: ""
Feb 13 22:15:55.504: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 13 22:15:55.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:55.579: INFO: stderr: ""
Feb 13 22:15:55.579: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          2s        testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 13 22:15:55.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 label pods pause testing-label- --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:55.653: INFO: stderr: ""
Feb 13 22:15:55.653: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 13 22:15:55.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:55.728: INFO: stderr: ""
Feb 13 22:15:55.728: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          2s        \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
STEP: using delete to clean up resources
Feb 13 22:15:55.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:55.804: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:15:55.804: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 13 22:15:55.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-vxzdn'
Feb 13 22:15:55.877: INFO: stderr: "No resources found.\n"
Feb 13 22:15:55.877: INFO: stdout: ""
Feb 13 22:15:55.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -l name=pause --namespace=e2e-tests-kubectl-vxzdn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 22:15:55.952: INFO: stderr: ""
Feb 13 22:15:55.952: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:15:55.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vxzdn" for this suite.
Feb 13 22:16:01.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:01.989: INFO: namespace: e2e-tests-kubectl-vxzdn, resource: bindings, ignored listing per whitelist
Feb 13 22:16:01.993: INFO: namespace e2e-tests-kubectl-vxzdn deletion completed in 6.038956957s

• [SLOW TEST:9.042 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:16:01.994: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ggk6c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:16:02.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 version --client'
Feb 13 22:16:02.172: INFO: stderr: ""
Feb 13 22:16:02.172: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 13 22:16:02.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-ggk6c'
Feb 13 22:16:02.296: INFO: stderr: ""
Feb 13 22:16:02.296: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 13 22:16:02.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-ggk6c'
Feb 13 22:16:02.453: INFO: stderr: ""
Feb 13 22:16:02.453: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 22:16:03.455: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:16:03.455: INFO: Found 0 / 1
Feb 13 22:16:04.455: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:16:04.455: INFO: Found 1 / 1
Feb 13 22:16:04.455: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 22:16:04.456: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:16:04.456: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 22:16:04.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 describe pod redis-master-n4lgt --namespace=e2e-tests-kubectl-ggk6c'
Feb 13 22:16:04.522: INFO: stderr: ""
Feb 13 22:16:04.522: INFO: stdout: "Name:               redis-master-n4lgt\nNamespace:          e2e-tests-kubectl-ggk6c\nPriority:           0\nPriorityClassName:  <none>\nNode:               alex-300-cp1-vsp2-workerbe2ca38349/10.10.100.53\nStart Time:         Wed, 13 Feb 2019 22:16:02 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP=192.168.2.93/32\nStatus:             Running\nIP:                 192.168.2.93\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://78c21407dca4a1401a4716c3d521a731792e19cfc3251c65d135c7297682c43c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis-amd64@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 13 Feb 2019 22:16:03 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-x5j4r (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-x5j4r:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-x5j4r\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                         Message\n  ----    ------     ----  ----                                         -------\n  Normal  Scheduled  2s    default-scheduler                            Successfully assigned e2e-tests-kubectl-ggk6c/redis-master-n4lgt to alex-300-cp1-vsp2-workerbe2ca38349\n  Normal  Pulled     2s    kubelet, alex-300-cp1-vsp2-workerbe2ca38349  Container image \"gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\" already present on machine\n  Normal  Created    1s    kubelet, alex-300-cp1-vsp2-workerbe2ca38349  Created container\n  Normal  Started    1s    kubelet, alex-300-cp1-vsp2-workerbe2ca38349  Started container\n"
Feb 13 22:16:04.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 describe rc redis-master --namespace=e2e-tests-kubectl-ggk6c'
Feb 13 22:16:04.595: INFO: stderr: ""
Feb 13 22:16:04.595: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-ggk6c\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-n4lgt\n"
Feb 13 22:16:04.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 describe service redis-master --namespace=e2e-tests-kubectl-ggk6c'
Feb 13 22:16:04.671: INFO: stderr: ""
Feb 13 22:16:04.671: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-ggk6c\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.24.188\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.2.93:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 13 22:16:04.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 describe node alex-300-cp1-vsp2-master3588ea178a'
Feb 13 22:16:04.753: INFO: stderr: ""
Feb 13 22:16:04.753: INFO: stdout: "Name:               alex-300-cp1-vsp2-master3588ea178a\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=alex-300-cp1-vsp2-master3588ea178a\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket=/var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl=0\n                    projectcalico.org/IPv4Address=10.10.100.52/22\n                    volumes.kubernetes.io/controller-managed-attach-detach=true\nCreationTimestamp:  Wed, 13 Feb 2019 20:25:36 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 13 Feb 2019 22:16:03 +0000   Wed, 13 Feb 2019 20:25:36 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 13 Feb 2019 22:16:03 +0000   Wed, 13 Feb 2019 20:25:36 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 13 Feb 2019 22:16:03 +0000   Wed, 13 Feb 2019 20:25:36 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 13 Feb 2019 22:16:03 +0000   Wed, 13 Feb 2019 20:25:36 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 13 Feb 2019 22:16:03 +0000   Wed, 13 Feb 2019 20:26:06 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  10.10.100.55\n  InternalIP:  10.10.100.52\n  InternalIP:  10.10.100.55\n  Hostname:    alex-300-cp1-vsp2-master3588ea178a\nCapacity:\n cpu:                2\n ephemeral-storage:  40470732Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16426364Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37297826550\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16323964Ki\n pods:               110\nSystem Info:\n Machine ID:                 0e75e79d77414c8c95ce7005cd6ff7be\n System UUID:                421E921F-2CC9-C685-75B2-83838D876EDD\n Boot ID:                    cf6fd67a-5cc1-4ad1-8a3f-1dbb89e7fa64\n Kernel Version:             4.15.0-43-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.11.5\n Kube-Proxy Version:         v1.11.5\nPodCIDR:                     192.168.0.0/24\nProviderID:                  vsphere://421e921f-2cc9-c685-75b2-83838d876edd\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                          ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-fec6a7bb1af74180                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-psbhm       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-kdmq4                                             250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-6c59c84b9c-72f2n                                      100m (5%)     0 (0%)      70Mi (0%)        170Mi (1%)\n  kube-system                etcd-alex-300-cp1-vsp2-master3588ea178a                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-alex-300-cp1-vsp2-master3588ea178a             250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-alex-300-cp1-vsp2-master3588ea178a    200m (10%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-xw9h8                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-alex-300-cp1-vsp2-master3588ea178a             100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                tiller-deploy-7f758f4c-x6qxm                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       900m (45%)  0 (0%)\n  memory    70Mi (0%)   170Mi (1%)\nEvents:     <none>\n"
Feb 13 22:16:04.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 describe namespace e2e-tests-kubectl-ggk6c'
Feb 13 22:16:04.834: INFO: stderr: ""
Feb 13 22:16:04.834: INFO: stdout: "Name:         e2e-tests-kubectl-ggk6c\nLabels:       e2e-framework=kubectl\n              e2e-run=45e889f8-2fd7-11e9-aeb1-a6e9e8347cdc\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:16:04.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ggk6c" for this suite.
Feb 13 22:16:26.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:26.860: INFO: namespace: e2e-tests-kubectl-ggk6c, resource: bindings, ignored listing per whitelist
Feb 13 22:16:26.881: INFO: namespace e2e-tests-kubectl-ggk6c deletion completed in 22.043162387s

• [SLOW TEST:24.887 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:16:26.882: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-8njlw
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:16:27.090: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:16:28.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-8njlw" for this suite.
Feb 13 22:16:34.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:34.155: INFO: namespace: e2e-tests-custom-resource-definition-8njlw, resource: bindings, ignored listing per whitelist
Feb 13 22:16:34.163: INFO: namespace e2e-tests-custom-resource-definition-8njlw deletion completed in 6.045634913s

• [SLOW TEST:7.282 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:16:34.163: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-94m9b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0213 22:17:14.322086      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 22:17:14.322: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:17:14.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-94m9b" for this suite.
Feb 13 22:17:20.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:17:20.354: INFO: namespace: e2e-tests-gc-94m9b, resource: bindings, ignored listing per whitelist
Feb 13 22:17:20.387: INFO: namespace e2e-tests-gc-94m9b deletion completed in 6.063426695s

• [SLOW TEST:46.224 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:17:20.387: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-l5bwz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-l5bwz
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
Feb 13 22:17:20.535: INFO: Found 0 stateful pods, waiting for 3
Feb 13 22:17:30.537: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:17:30.537: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:17:30.537: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Feb 13 22:17:30.558: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 13 22:17:40.589: INFO: Updating stateful set ss2
Feb 13 22:17:40.607: INFO: Waiting for Pod e2e-tests-statefulset-l5bwz/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
Feb 13 22:17:50.647: INFO: Found 2 stateful pods, waiting for 3
Feb 13 22:18:00.649: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:18:00.650: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:18:00.650: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 13 22:18:00.666: INFO: Updating stateful set ss2
Feb 13 22:18:00.679: INFO: Waiting for Pod e2e-tests-statefulset-l5bwz/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Feb 13 22:18:10.696: INFO: Updating stateful set ss2
Feb 13 22:18:10.699: INFO: Waiting for StatefulSet e2e-tests-statefulset-l5bwz/ss2 to complete update
Feb 13 22:18:10.699: INFO: Waiting for Pod e2e-tests-statefulset-l5bwz/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Feb 13 22:18:20.703: INFO: Waiting for StatefulSet e2e-tests-statefulset-l5bwz/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Feb 13 22:18:30.703: INFO: Deleting all statefulset in ns e2e-tests-statefulset-l5bwz
Feb 13 22:18:30.704: INFO: Scaling statefulset ss2 to 0
Feb 13 22:18:50.719: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 22:18:50.720: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:18:50.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-l5bwz" for this suite.
Feb 13 22:18:56.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:18:56.773: INFO: namespace: e2e-tests-statefulset-l5bwz, resource: bindings, ignored listing per whitelist
Feb 13 22:18:56.782: INFO: namespace e2e-tests-statefulset-l5bwz deletion completed in 6.042567717s

• [SLOW TEST:96.394 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:18:56.782: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l95jd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:18:56.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-l95jd'
Feb 13 22:18:57.015: INFO: stderr: ""
Feb 13 22:18:57.015: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
Feb 13 22:18:57.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-l95jd'
Feb 13 22:18:57.134: INFO: stderr: ""
Feb 13 22:18:57.134: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:18:57.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l95jd" for this suite.
Feb 13 22:19:19.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:19.235: INFO: namespace: e2e-tests-kubectl-l95jd, resource: bindings, ignored listing per whitelist
Feb 13 22:19:19.257: INFO: namespace e2e-tests-kubectl-l95jd deletion completed in 22.113106123s

• [SLOW TEST:22.476 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:19:19.259: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-hdzn4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-6833be83-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:19:19.408: INFO: Waiting up to 5m0s for pod "pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-hdzn4" to be "success or failure"
Feb 13 22:19:19.411: INFO: Pod "pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.602472ms
Feb 13 22:19:21.413: INFO: Pod "pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005189622s
STEP: Saw pod success
Feb 13 22:19:21.413: INFO: Pod "pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:19:21.414: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:21.427: INFO: Waiting for pod pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:19:21.428: INFO: Pod pod-configmaps-68342b40-2fdd-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:19:21.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hdzn4" for this suite.
Feb 13 22:19:27.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:27.465: INFO: namespace: e2e-tests-configmap-hdzn4, resource: bindings, ignored listing per whitelist
Feb 13 22:19:27.481: INFO: namespace e2e-tests-configmap-hdzn4 deletion completed in 6.050560606s

• [SLOW TEST:8.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:19:27.482: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fm4n2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 13 22:19:30.136: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6d19bf9b-2fdd-11e9-aeb1-a6e9e8347cdc"
Feb 13 22:19:30.136: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6d19bf9b-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-pods-fm4n2" to be "terminated due to deadline exceeded"
Feb 13 22:19:30.137: INFO: Pod "pod-update-activedeadlineseconds-6d19bf9b-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 1.221425ms
Feb 13 22:19:32.139: INFO: Pod "pod-update-activedeadlineseconds-6d19bf9b-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 2.002913826s
Feb 13 22:19:34.141: INFO: Pod "pod-update-activedeadlineseconds-6d19bf9b-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.004772426s
Feb 13 22:19:34.141: INFO: Pod "pod-update-activedeadlineseconds-6d19bf9b-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:19:34.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fm4n2" for this suite.
Feb 13 22:19:40.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:40.186: INFO: namespace: e2e-tests-pods-fm4n2, resource: bindings, ignored listing per whitelist
Feb 13 22:19:40.202: INFO: namespace e2e-tests-pods-fm4n2 deletion completed in 6.059312335s

• [SLOW TEST:12.720 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:19:40.203: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qw4pt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-74afb2ee-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:19:40.352: INFO: Waiting up to 5m0s for pod "pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-qw4pt" to be "success or failure"
Feb 13 22:19:40.356: INFO: Pod "pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.871623ms
Feb 13 22:19:42.358: INFO: Pod "pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005555198s
Feb 13 22:19:44.360: INFO: Pod "pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007346016s
STEP: Saw pod success
Feb 13 22:19:44.360: INFO: Pod "pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:19:44.361: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:44.371: INFO: Waiting for pod pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:19:44.372: INFO: Pod pod-secrets-74b0090b-2fdd-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:19:44.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qw4pt" for this suite.
Feb 13 22:19:50.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:50.421: INFO: namespace: e2e-tests-secrets-qw4pt, resource: bindings, ignored listing per whitelist
Feb 13 22:19:50.425: INFO: namespace e2e-tests-secrets-qw4pt deletion completed in 6.050212333s

• [SLOW TEST:10.222 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:19:50.425: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j2qg5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-7ac686ee-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:19:50.569: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-j2qg5" to be "success or failure"
Feb 13 22:19:50.575: INFO: Pod "pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.541654ms
Feb 13 22:19:52.577: INFO: Pod "pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007634596s
STEP: Saw pod success
Feb 13 22:19:52.577: INFO: Pod "pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:19:52.578: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:52.594: INFO: Waiting for pod pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:19:52.595: INFO: Pod pod-projected-secrets-7ac6e9a0-2fdd-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:19:52.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j2qg5" for this suite.
Feb 13 22:19:58.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:58.651: INFO: namespace: e2e-tests-projected-j2qg5, resource: bindings, ignored listing per whitelist
Feb 13 22:19:58.657: INFO: namespace e2e-tests-projected-j2qg5 deletion completed in 6.059957362s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:19:58.657: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-m6gzp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-7fad9c32-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:19:58.794: INFO: Waiting up to 5m0s for pod "pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-m6gzp" to be "success or failure"
Feb 13 22:19:58.796: INFO: Pod "pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.832428ms
Feb 13 22:20:00.798: INFO: Pod "pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004782467s
STEP: Saw pod success
Feb 13 22:20:00.798: INFO: Pod "pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:20:00.800: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:20:00.812: INFO: Waiting for pod pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:20:00.813: INFO: Pod pod-secrets-7fadef64-2fdd-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:20:00.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m6gzp" for this suite.
Feb 13 22:20:06.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:20:06.831: INFO: namespace: e2e-tests-secrets-m6gzp, resource: bindings, ignored listing per whitelist
Feb 13 22:20:06.857: INFO: namespace e2e-tests-secrets-m6gzp deletion completed in 6.042861455s

• [SLOW TEST:8.200 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:20:06.858: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lrrzz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: executing a command with run --rm and attach with stdin
Feb 13 22:20:06.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 --namespace=e2e-tests-kubectl-lrrzz run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 13 22:20:10.020: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
Feb 13 22:20:10.020: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:20:12.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lrrzz" for this suite.
Feb 13 22:20:18.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:20:18.042: INFO: namespace: e2e-tests-kubectl-lrrzz, resource: bindings, ignored listing per whitelist
Feb 13 22:20:18.069: INFO: namespace e2e-tests-kubectl-lrrzz deletion completed in 6.045063189s

• [SLOW TEST:11.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:20:18.070: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-724vx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:20:18.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-724vx'
Feb 13 22:20:18.307: INFO: stderr: ""
Feb 13 22:20:18.307: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
Feb 13 22:20:20.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-724vx'
Feb 13 22:20:20.386: INFO: stderr: ""
Feb 13 22:20:20.386: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:20:20.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-724vx" for this suite.
Feb 13 22:20:26.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:20:26.428: INFO: namespace: e2e-tests-kubectl-724vx, resource: bindings, ignored listing per whitelist
Feb 13 22:20:26.435: INFO: namespace e2e-tests-kubectl-724vx deletion completed in 6.044754463s

• [SLOW TEST:8.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:20:26.435: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-qsnnv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Feb 13 22:20:26.566: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 22:21:26.578: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 22:21:26.581: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 22:21:26.586: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 22:21:26.586: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 13 22:21:26.587: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Feb 13 22:21:26.587: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp1-vsp2-workerbe2ca38349 before test
Feb 13 22:21:26.592: INFO: calico-typha-7745977f6c-nnddh from kube-system started at 2019-02-13 20:26:09 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:21:26.592: INFO: nginx-ingress-default-backend-54786554b4-c8glf from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb 13 22:21:26.592: INFO: metallb-speaker-tqj8d from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:21:26.592: INFO: kubernetes-dashboard-5888c7c865-6fw6h from ccp started at 2019-02-13 20:26:56 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 13 22:21:26.592: INFO: ccp-monitor-prometheus-node-exporter-jp7s4 from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:21:26.592: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 21:34:56 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 22:21:26.592: INFO: ccp-monitor-prometheus-kube-state-metrics-5b6855c558-bvftk from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Feb 13 22:21:26.592: INFO: ccp-monitor-grafana-598bcf54f9-28w8c from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.592: INFO: 	Container grafana ready: true, restart count 0
Feb 13 22:21:26.592: INFO: fluentd-es-v2.0.2-78sgd from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:21:26.593: INFO: ccp-efk-kibana-594754b75-6fg7f from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container kibana ready: true, restart count 0
Feb 13 22:21:26.593: INFO: calico-node-wbc5b from kube-system started at 2019-02-13 20:25:59 +0000 UTC (2 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:21:26.593: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:21:26.593: INFO: cert-manager-d98996f46-7gj72 from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container cert-manager ready: true, restart count 0
Feb 13 22:21:26.593: INFO: sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-tpdfj from heptio-sonobuoy started at 2019-02-13 21:35:01 +0000 UTC (2 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 22:21:26.593: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 22:21:26.593: INFO: kube-proxy-h97kt from kube-system started at 2019-02-13 20:25:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:21:26.593: INFO: nginx-ingress-controller-fr4dw from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.593: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:21:26.593: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp1-vsp2-workerd2381a81c9 before test
Feb 13 22:21:26.600: INFO: metallb-speaker-9sx8b from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.600: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:21:26.600: INFO: metallb-controller-54559b4447-zjhc6 from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.600: INFO: 	Container controller ready: true, restart count 0
Feb 13 22:21:26.600: INFO: ccp-monitor-prometheus-pushgateway-7cfbcd8dfd-tlw5g from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
Feb 13 22:21:26.601: INFO: ccp-monitor-prometheus-server-6fb9957f87-r8ftg from ccp started at 2019-02-13 20:26:58 +0000 UTC (2 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container prometheus-server ready: true, restart count 0
Feb 13 22:21:26.601: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Feb 13 22:21:26.601: INFO: ccp-monitor-prometheus-alertmanager-64c4f944cb-gvrlv from ccp started at 2019-02-13 20:26:58 +0000 UTC (2 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Feb 13 22:21:26.601: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Feb 13 22:21:26.601: INFO: fluentd-es-v2.0.2-92kwr from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:21:26.601: INFO: calico-node-ns8hh from kube-system started at 2019-02-13 20:25:57 +0000 UTC (2 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:21:26.601: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:21:26.601: INFO: calico-typha-7745977f6c-52zql from kube-system started at 2019-02-13 20:26:07 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:21:26.601: INFO: nginx-ingress-controller-ckzrj from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:21:26.601: INFO: ccp-monitor-prometheus-node-exporter-cktg2 from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:21:26.601: INFO: elasticsearch-logging-0 from ccp started at 2019-02-13 20:27:11 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Feb 13 22:21:26.601: INFO: kube-proxy-xrp4h from kube-system started at 2019-02-13 20:25:57 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.601: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:21:26.601: INFO: sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-2mkgp from heptio-sonobuoy started at 2019-02-13 21:35:01 +0000 UTC (2 container statuses recorded)
Feb 13 22:21:26.602: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 22:21:26.602: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 22:21:26.602: INFO: coredns-6c59c84b9c-mbqwk from kube-system started at 2019-02-13 20:26:16 +0000 UTC (1 container statuses recorded)
Feb 13 22:21:26.602: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b538bf7f-2fdd-11e9-aeb1-a6e9e8347cdc 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b538bf7f-2fdd-11e9-aeb1-a6e9e8347cdc off the node alex-300-cp1-vsp2-workerbe2ca38349
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b538bf7f-2fdd-11e9-aeb1-a6e9e8347cdc
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:21:30.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qsnnv" for this suite.
Feb 13 22:21:38.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:21:38.704: INFO: namespace: e2e-tests-sched-pred-qsnnv, resource: bindings, ignored listing per whitelist
Feb 13 22:21:38.707: INFO: namespace e2e-tests-sched-pred-qsnnv deletion completed in 8.051439628s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:72.272 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:21:38.707: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-shw7x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 22:21:38.854: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:38.860: INFO: Number of nodes with available pods: 0
Feb 13 22:21:38.860: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:21:39.862: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:39.863: INFO: Number of nodes with available pods: 0
Feb 13 22:21:39.863: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:21:40.862: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:40.864: INFO: Number of nodes with available pods: 2
Feb 13 22:21:40.864: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 13 22:21:40.873: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:40.874: INFO: Number of nodes with available pods: 1
Feb 13 22:21:40.875: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 22:21:41.877: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:41.878: INFO: Number of nodes with available pods: 1
Feb 13 22:21:41.878: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 22:21:42.881: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:42.884: INFO: Number of nodes with available pods: 1
Feb 13 22:21:42.884: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 22:21:43.876: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:43.878: INFO: Number of nodes with available pods: 1
Feb 13 22:21:43.878: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 22:21:44.877: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:44.878: INFO: Number of nodes with available pods: 1
Feb 13 22:21:44.878: INFO: Node alex-300-cp1-vsp2-workerd2381a81c9 is running more than one daemon pod
Feb 13 22:21:45.877: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:21:45.879: INFO: Number of nodes with available pods: 2
Feb 13 22:21:45.879: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-shw7x, will wait for the garbage collector to delete the pods
Feb 13 22:21:45.934: INFO: Deleting {extensions DaemonSet} daemon-set took: 2.809342ms
Feb 13 22:21:46.035: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.476777ms
Feb 13 22:21:57.537: INFO: Number of nodes with available pods: 0
Feb 13 22:21:57.537: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 22:21:57.538: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-shw7x/daemonsets","resourceVersion":"18704"},"items":null}

Feb 13 22:21:57.539: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-shw7x/pods","resourceVersion":"18704"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:21:57.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-shw7x" for this suite.
Feb 13 22:22:03.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:22:03.567: INFO: namespace: e2e-tests-daemonsets-shw7x, resource: bindings, ignored listing per whitelist
Feb 13 22:22:03.586: INFO: namespace e2e-tests-daemonsets-shw7x deletion completed in 6.041592299s

• [SLOW TEST:24.879 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:22:03.587: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6jtdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-ca25003d-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating secret with name secret-projected-all-test-volume-ca250030-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 13 22:22:03.731: INFO: Waiting up to 5m0s for pod "projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-6jtdn" to be "success or failure"
Feb 13 22:22:03.735: INFO: Pod "projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.351894ms
Feb 13 22:22:05.737: INFO: Pod "projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005849138s
Feb 13 22:22:07.739: INFO: Pod "projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008065657s
STEP: Saw pod success
Feb 13 22:22:07.739: INFO: Pod "projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:22:07.741: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 13 22:22:07.757: INFO: Waiting for pod projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:22:07.758: INFO: Pod projected-volume-ca24fff6-2fdd-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:22:07.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jtdn" for this suite.
Feb 13 22:22:13.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:22:13.813: INFO: namespace: e2e-tests-projected-6jtdn, resource: bindings, ignored listing per whitelist
Feb 13 22:22:13.821: INFO: namespace e2e-tests-projected-6jtdn deletion completed in 6.060567124s

• [SLOW TEST:10.234 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:22:13.822: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-pbwkp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 13 22:22:13.958: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18794,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 22:22:13.958: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18794,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 13 22:22:23.962: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18813,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 13 22:22:23.962: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18813,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 13 22:22:33.967: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18832,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 22:22:33.967: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18832,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 13 22:22:43.970: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18850,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 22:22:43.970: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-a,UID:d03ed04c-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18850,Generation:0,CreationTimestamp:2019-02-13 22:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 13 22:22:53.984: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-b,UID:e81a36cd-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18869,Generation:0,CreationTimestamp:2019-02-13 22:22:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 22:22:53.984: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-b,UID:e81a36cd-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18869,Generation:0,CreationTimestamp:2019-02-13 22:22:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 13 22:23:03.992: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-b,UID:e81a36cd-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18889,Generation:0,CreationTimestamp:2019-02-13 22:22:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 22:23:03.992: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-pbwkp,SelfLink:/api/v1/namespaces/e2e-tests-watch-pbwkp/configmaps/e2e-watch-test-configmap-b,UID:e81a36cd-2fdd-11e9-80e0-0050569e5ced,ResourceVersion:18889,Generation:0,CreationTimestamp:2019-02-13 22:22:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:23:13.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-pbwkp" for this suite.
Feb 13 22:23:20.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:23:20.037: INFO: namespace: e2e-tests-watch-pbwkp, resource: bindings, ignored listing per whitelist
Feb 13 22:23:20.040: INFO: namespace e2e-tests-watch-pbwkp deletion completed in 6.040859477s

• [SLOW TEST:66.218 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:23:20.041: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2nbxk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-2nbxk/configmap-test-f7b73809-2fdd-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:23:20.184: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-2nbxk" to be "success or failure"
Feb 13 22:23:20.186: INFO: Pod "pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.485817ms
Feb 13 22:23:22.188: INFO: Pod "pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004288317s
Feb 13 22:23:24.190: INFO: Pod "pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006253623s
STEP: Saw pod success
Feb 13 22:23:24.190: INFO: Pod "pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:23:24.191: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc container env-test: <nil>
STEP: delete the pod
Feb 13 22:23:24.203: INFO: Waiting for pod pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:23:24.204: INFO: Pod pod-configmaps-f7b778ea-2fdd-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:23:24.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2nbxk" for this suite.
Feb 13 22:23:30.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:23:30.238: INFO: namespace: e2e-tests-configmap-2nbxk, resource: bindings, ignored listing per whitelist
Feb 13 22:23:30.252: INFO: namespace e2e-tests-configmap-2nbxk deletion completed in 6.046728299s

• [SLOW TEST:10.212 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:23:30.253: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rj9tp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Starting the proxy
Feb 13 22:23:30.386: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-208905800 proxy --unix-socket=/tmp/kubectl-proxy-unix841465607/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:23:30.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rj9tp" for this suite.
Feb 13 22:23:36.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:23:36.468: INFO: namespace: e2e-tests-kubectl-rj9tp, resource: bindings, ignored listing per whitelist
Feb 13 22:23:36.501: INFO: namespace e2e-tests-kubectl-rj9tp deletion completed in 6.043217039s

• [SLOW TEST:6.248 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:23:36.501: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wl7hm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Feb 13 22:23:39.160: INFO: Successfully updated pod "labelsupdate0185b833-2fde-11e9-aeb1-a6e9e8347cdc"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:23:41.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wl7hm" for this suite.
Feb 13 22:24:03.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:24:03.193: INFO: namespace: e2e-tests-projected-wl7hm, resource: bindings, ignored listing per whitelist
Feb 13 22:24:03.231: INFO: namespace e2e-tests-projected-wl7hm deletion completed in 22.059672756s

• [SLOW TEST:26.730 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:24:03.231: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jbb4q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-1175879e-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:24:03.372: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-jbb4q" to be "success or failure"
Feb 13 22:24:03.374: INFO: Pod "pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.561644ms
Feb 13 22:24:05.375: INFO: Pod "pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00317028s
STEP: Saw pod success
Feb 13 22:24:05.375: INFO: Pod "pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:24:05.377: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:24:05.386: INFO: Waiting for pod pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:24:05.387: INFO: Pod pod-projected-configmaps-1175daf8-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:24:05.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jbb4q" for this suite.
Feb 13 22:24:11.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:24:11.402: INFO: namespace: e2e-tests-projected-jbb4q, resource: bindings, ignored listing per whitelist
Feb 13 22:24:11.430: INFO: namespace e2e-tests-projected-jbb4q deletion completed in 6.041129313s

• [SLOW TEST:8.199 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:24:11.431: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8dh4r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-165844f5-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:24:11.569: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-8dh4r" to be "success or failure"
Feb 13 22:24:11.573: INFO: Pod "pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.586295ms
Feb 13 22:24:13.574: INFO: Pod "pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Running", Reason="", readiness=true. Elapsed: 2.004991474s
Feb 13 22:24:15.577: INFO: Pod "pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007027201s
STEP: Saw pod success
Feb 13 22:24:15.577: INFO: Pod "pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:24:15.578: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:24:15.595: INFO: Waiting for pod pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:24:15.596: INFO: Pod pod-projected-configmaps-165893e3-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:24:15.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8dh4r" for this suite.
Feb 13 22:24:21.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:24:21.637: INFO: namespace: e2e-tests-projected-8dh4r, resource: bindings, ignored listing per whitelist
Feb 13 22:24:21.638: INFO: namespace e2e-tests-projected-8dh4r deletion completed in 6.040966875s

• [SLOW TEST:10.208 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:24:21.639: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-zdnzh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:24:21.779: INFO: (0) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.882083ms)
Feb 13 22:24:21.780: INFO: (1) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.549112ms)
Feb 13 22:24:21.782: INFO: (2) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.546048ms)
Feb 13 22:24:21.784: INFO: (3) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.811068ms)
Feb 13 22:24:21.786: INFO: (4) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.661565ms)
Feb 13 22:24:21.787: INFO: (5) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.527719ms)
Feb 13 22:24:21.789: INFO: (6) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.9279ms)
Feb 13 22:24:21.791: INFO: (7) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.009078ms)
Feb 13 22:24:21.793: INFO: (8) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.657372ms)
Feb 13 22:24:21.794: INFO: (9) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.461248ms)
Feb 13 22:24:21.796: INFO: (10) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.699581ms)
Feb 13 22:24:21.798: INFO: (11) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.563985ms)
Feb 13 22:24:21.799: INFO: (12) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.651478ms)
Feb 13 22:24:21.801: INFO: (13) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.792527ms)
Feb 13 22:24:21.803: INFO: (14) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.806196ms)
Feb 13 22:24:21.804: INFO: (15) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.443927ms)
Feb 13 22:24:21.806: INFO: (16) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.412763ms)
Feb 13 22:24:21.807: INFO: (17) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.428117ms)
Feb 13 22:24:21.809: INFO: (18) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.514871ms)
Feb 13 22:24:21.810: INFO: (19) /api/v1/nodes/alex-300-cp1-vsp2-workerbe2ca38349/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.627396ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:24:21.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zdnzh" for this suite.
Feb 13 22:24:27.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:24:27.851: INFO: namespace: e2e-tests-proxy-zdnzh, resource: bindings, ignored listing per whitelist
Feb 13 22:24:27.856: INFO: namespace e2e-tests-proxy-zdnzh deletion completed in 6.044070196s

• [SLOW TEST:6.218 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:24:27.857: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mjrvz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-20227b78-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating configMap with name cm-test-opt-upd-20227ba0-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-20227b78-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Updating configmap cm-test-opt-upd-20227ba0-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating configMap with name cm-test-opt-create-20227bb5-2fde-11e9-aeb1-a6e9e8347cdc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:24:32.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mjrvz" for this suite.
Feb 13 22:24:54.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:24:54.057: INFO: namespace: e2e-tests-projected-mjrvz, resource: bindings, ignored listing per whitelist
Feb 13 22:24:54.087: INFO: namespace e2e-tests-projected-mjrvz deletion completed in 22.045899097s

• [SLOW TEST:26.230 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:24:54.087: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-l79wm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:24:54.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-l79wm" for this suite.
Feb 13 22:25:00.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:00.276: INFO: namespace: e2e-tests-services-l79wm, resource: bindings, ignored listing per whitelist
Feb 13 22:25:00.278: INFO: namespace e2e-tests-services-l79wm deletion completed in 6.044569155s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.191 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:25:00.279: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-w5pp8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:25:00.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-w5pp8" to be "success or failure"
Feb 13 22:25:00.477: INFO: Pod "downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.790434ms
Feb 13 22:25:02.479: INFO: Pod "downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005638173s
STEP: Saw pod success
Feb 13 22:25:02.479: INFO: Pod "downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:25:02.481: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:25:02.495: INFO: Waiting for pod downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:25:02.496: INFO: Pod downwardapi-volume-337e8759-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:25:02.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w5pp8" for this suite.
Feb 13 22:25:08.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:08.528: INFO: namespace: e2e-tests-downward-api-w5pp8, resource: bindings, ignored listing per whitelist
Feb 13 22:25:08.540: INFO: namespace e2e-tests-downward-api-w5pp8 deletion completed in 6.04203031s

• [SLOW TEST:8.261 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:25:08.540: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bgbpk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 13 22:25:08.684: INFO: Waiting up to 5m0s for pod "pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-bgbpk" to be "success or failure"
Feb 13 22:25:08.688: INFO: Pod "pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.775701ms
Feb 13 22:25:10.690: INFO: Pod "pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005816339s
STEP: Saw pod success
Feb 13 22:25:10.690: INFO: Pod "pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:25:10.692: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:25:10.706: INFO: Waiting for pod pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:25:10.708: INFO: Pod pod-38637450-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:25:10.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bgbpk" for this suite.
Feb 13 22:25:16.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:16.726: INFO: namespace: e2e-tests-emptydir-bgbpk, resource: bindings, ignored listing per whitelist
Feb 13 22:25:16.768: INFO: namespace e2e-tests-emptydir-bgbpk deletion completed in 6.058244393s

• [SLOW TEST:8.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:25:16.768: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rtbh9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Feb 13 22:25:16.907: INFO: Waiting up to 5m0s for pod "downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-rtbh9" to be "success or failure"
Feb 13 22:25:16.910: INFO: Pod "downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.573137ms
Feb 13 22:25:18.912: INFO: Pod "downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005467342s
Feb 13 22:25:20.914: INFO: Pod "downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007294263s
STEP: Saw pod success
Feb 13 22:25:20.914: INFO: Pod "downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:25:20.916: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:25:20.931: INFO: Waiting for pod downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:25:20.932: INFO: Pod downward-api-3d4a0284-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:25:20.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rtbh9" for this suite.
Feb 13 22:25:26.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:26.948: INFO: namespace: e2e-tests-downward-api-rtbh9, resource: bindings, ignored listing per whitelist
Feb 13 22:25:26.977: INFO: namespace e2e-tests-downward-api-rtbh9 deletion completed in 6.042653517s

• [SLOW TEST:10.209 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:25:26.977: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6tgcr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
Feb 13 22:25:27.113: INFO: Waiting up to 5m0s for pod "client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-containers-6tgcr" to be "success or failure"
Feb 13 22:25:27.118: INFO: Pod "client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.152259ms
Feb 13 22:25:29.120: INFO: Pod "client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00655855s
STEP: Saw pod success
Feb 13 22:25:29.120: INFO: Pod "client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:25:29.121: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:25:29.131: INFO: Waiting for pod client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:25:29.132: INFO: Pod client-containers-435fb57a-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:25:29.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6tgcr" for this suite.
Feb 13 22:25:35.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:35.171: INFO: namespace: e2e-tests-containers-6tgcr, resource: bindings, ignored listing per whitelist
Feb 13 22:25:35.178: INFO: namespace e2e-tests-containers-6tgcr deletion completed in 6.044195973s

• [SLOW TEST:8.201 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:25:35.180: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-mgjmc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Feb 13 22:25:37.834: INFO: Successfully updated pod "annotationupdate48437640-2fde-11e9-aeb1-a6e9e8347cdc"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:25:39.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mgjmc" for this suite.
Feb 13 22:26:01.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:01.876: INFO: namespace: e2e-tests-downward-api-mgjmc, resource: bindings, ignored listing per whitelist
Feb 13 22:26:01.893: INFO: namespace e2e-tests-downward-api-mgjmc deletion completed in 22.047155951s

• [SLOW TEST:26.713 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:26:01.893: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qq9b7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:26:02.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qq9b7'
Feb 13 22:26:02.305: INFO: stderr: ""
Feb 13 22:26:02.305: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 13 22:26:07.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qq9b7 -o json'
Feb 13 22:26:07.428: INFO: stderr: ""
Feb 13 22:26:07.428: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.2.125/32\"\n        },\n        \"creationTimestamp\": \"2019-02-13T22:26:02Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-qq9b7\",\n        \"resourceVersion\": \"19576\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-qq9b7/pods/e2e-test-nginx-pod\",\n        \"uid\": \"5857d3ec-2fde-11e9-80e0-0050569e5ced\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-k6vf9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"alex-300-cp1-vsp2-workerbe2ca38349\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-k6vf9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-k6vf9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:26:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:26:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:26:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://457a0dff289a147779e4d52744ae1c534233faffc0753a60632e5a125a08847b\",\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-13T22:26:03Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.100.53\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.2.125\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-13T22:26:02Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 13 22:26:07.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 replace -f - --namespace=e2e-tests-kubectl-qq9b7'
Feb 13 22:26:07.570: INFO: stderr: ""
Feb 13 22:26:07.570: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
Feb 13 22:26:07.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qq9b7'
Feb 13 22:26:09.405: INFO: stderr: ""
Feb 13 22:26:09.405: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:26:09.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qq9b7" for this suite.
Feb 13 22:26:15.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:15.431: INFO: namespace: e2e-tests-kubectl-qq9b7, resource: bindings, ignored listing per whitelist
Feb 13 22:26:15.451: INFO: namespace e2e-tests-kubectl-qq9b7 deletion completed in 6.043897553s

• [SLOW TEST:13.558 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:26:15.452: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-shbc5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:26:15.590: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 13 22:26:15.594: INFO: Number of nodes with available pods: 0
Feb 13 22:26:15.594: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 13 22:26:15.609: INFO: Number of nodes with available pods: 0
Feb 13 22:26:15.609: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:16.611: INFO: Number of nodes with available pods: 0
Feb 13 22:26:16.611: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:17.611: INFO: Number of nodes with available pods: 1
Feb 13 22:26:17.611: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 13 22:26:17.622: INFO: Number of nodes with available pods: 1
Feb 13 22:26:17.622: INFO: Number of running nodes: 0, number of available pods: 1
Feb 13 22:26:18.624: INFO: Number of nodes with available pods: 0
Feb 13 22:26:18.624: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 13 22:26:18.631: INFO: Number of nodes with available pods: 0
Feb 13 22:26:18.631: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:19.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:19.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:20.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:20.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:21.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:21.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:22.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:22.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:23.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:23.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:24.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:24.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:25.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:25.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:26.632: INFO: Number of nodes with available pods: 0
Feb 13 22:26:26.632: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:27.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:27.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:28.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:28.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:29.633: INFO: Number of nodes with available pods: 0
Feb 13 22:26:29.633: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:26:30.633: INFO: Number of nodes with available pods: 1
Feb 13 22:26:30.633: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-shbc5, will wait for the garbage collector to delete the pods
Feb 13 22:26:30.691: INFO: Deleting {extensions DaemonSet} daemon-set took: 2.929769ms
Feb 13 22:26:30.791: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.115846ms
Feb 13 22:26:33.592: INFO: Number of nodes with available pods: 0
Feb 13 22:26:33.592: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 22:26:33.594: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-shbc5/daemonsets","resourceVersion":"19701"},"items":null}

Feb 13 22:26:33.594: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-shbc5/pods","resourceVersion":"19701"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:26:33.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-shbc5" for this suite.
Feb 13 22:26:39.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:39.650: INFO: namespace: e2e-tests-daemonsets-shbc5, resource: bindings, ignored listing per whitelist
Feb 13 22:26:39.668: INFO: namespace e2e-tests-daemonsets-shbc5 deletion completed in 6.060439602s

• [SLOW TEST:24.215 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:26:39.668: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-f6fn4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-f6fn4
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-f6fn4
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-f6fn4
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-f6fn4
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-f6fn4
Feb 13 22:26:43.825: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-f6fn4, name: ss-0, uid: 702b2d58-2fde-11e9-80e0-0050569e5ced, status phase: Pending. Waiting for statefulset controller to delete.
Feb 13 22:26:43.853: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-f6fn4, name: ss-0, uid: 702b2d58-2fde-11e9-80e0-0050569e5ced, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 22:26:43.859: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-f6fn4, name: ss-0, uid: 702b2d58-2fde-11e9-80e0-0050569e5ced, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 22:26:43.865: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-f6fn4
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-f6fn4
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-f6fn4 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Feb 13 22:26:45.880: INFO: Deleting all statefulset in ns e2e-tests-statefulset-f6fn4
Feb 13 22:26:45.882: INFO: Scaling statefulset ss to 0
Feb 13 22:27:05.890: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 22:27:05.891: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:27:05.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-f6fn4" for this suite.
Feb 13 22:27:11.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:11.938: INFO: namespace: e2e-tests-statefulset-f6fn4, resource: bindings, ignored listing per whitelist
Feb 13 22:27:11.949: INFO: namespace e2e-tests-statefulset-f6fn4 deletion completed in 6.048114294s

• [SLOW TEST:32.281 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:27:11.949: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tbc8c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-81f1136f-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:27:12.088: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-tbc8c" to be "success or failure"
Feb 13 22:27:12.092: INFO: Pod "pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005885ms
Feb 13 22:27:14.094: INFO: Pod "pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005395017s
STEP: Saw pod success
Feb 13 22:27:14.094: INFO: Pod "pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:27:14.095: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:27:14.106: INFO: Waiting for pod pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:27:14.107: INFO: Pod pod-projected-secrets-81f16610-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:27:14.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tbc8c" for this suite.
Feb 13 22:27:20.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:20.145: INFO: namespace: e2e-tests-projected-tbc8c, resource: bindings, ignored listing per whitelist
Feb 13 22:27:20.158: INFO: namespace e2e-tests-projected-tbc8c deletion completed in 6.048709345s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:27:20.158: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v4l2v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:27:20.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-v4l2v" to be "success or failure"
Feb 13 22:27:20.299: INFO: Pod "downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.479524ms
Feb 13 22:27:22.301: INFO: Pod "downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006218182s
STEP: Saw pod success
Feb 13 22:27:22.301: INFO: Pod "downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:27:22.302: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:27:22.315: INFO: Waiting for pod downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:27:22.317: INFO: Pod downwardapi-volume-86d57af4-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:27:22.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v4l2v" for this suite.
Feb 13 22:27:28.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:28.363: INFO: namespace: e2e-tests-downward-api-v4l2v, resource: bindings, ignored listing per whitelist
Feb 13 22:27:28.363: INFO: namespace e2e-tests-downward-api-v4l2v deletion completed in 6.043493224s

• [SLOW TEST:8.205 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:27:28.363: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wg7qk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-8bb9cbdf-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:27:28.503: INFO: Waiting up to 5m0s for pod "pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-wg7qk" to be "success or failure"
Feb 13 22:27:28.505: INFO: Pod "pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.703854ms
Feb 13 22:27:30.507: INFO: Pod "pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003687668s
STEP: Saw pod success
Feb 13 22:27:30.507: INFO: Pod "pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:27:30.508: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:27:30.519: INFO: Waiting for pod pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:27:30.520: INFO: Pod pod-secrets-8bba3557-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:27:30.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wg7qk" for this suite.
Feb 13 22:27:36.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:36.562: INFO: namespace: e2e-tests-secrets-wg7qk, resource: bindings, ignored listing per whitelist
Feb 13 22:27:36.574: INFO: namespace e2e-tests-secrets-wg7qk deletion completed in 6.051143241s

• [SLOW TEST:8.211 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:27:36.574: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-8nq9n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-8nq9n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-8nq9n to expose endpoints map[]
Feb 13 22:27:36.830: INFO: Get endpoints failed (2.100249ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 13 22:27:37.832: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-8nq9n exposes endpoints map[] (1.003831757s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-8nq9n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-8nq9n to expose endpoints map[pod1:[80]]
Feb 13 22:27:39.849: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-8nq9n exposes endpoints map[pod1:[80]] (2.011274016s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-8nq9n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-8nq9n to expose endpoints map[pod1:[80] pod2:[80]]
Feb 13 22:27:41.866: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-8nq9n exposes endpoints map[pod1:[80] pod2:[80]] (2.013143076s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-8nq9n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-8nq9n to expose endpoints map[pod2:[80]]
Feb 13 22:27:41.875: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-8nq9n exposes endpoints map[pod2:[80]] (3.686615ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-8nq9n
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-8nq9n to expose endpoints map[]
Feb 13 22:27:41.885: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-8nq9n exposes endpoints map[] (4.237124ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:27:41.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-8nq9n" for this suite.
Feb 13 22:28:03.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:03.922: INFO: namespace: e2e-tests-services-8nq9n, resource: bindings, ignored listing per whitelist
Feb 13 22:28:03.951: INFO: namespace e2e-tests-services-8nq9n deletion completed in 22.045147723s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.376 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:28:03.951: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2fb9p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:28:04.092: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-2fb9p" to be "success or failure"
Feb 13 22:28:04.093: INFO: Pod "downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.336785ms
Feb 13 22:28:06.096: INFO: Pod "downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003494088s
STEP: Saw pod success
Feb 13 22:28:06.096: INFO: Pod "downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:28:06.098: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:28:06.116: INFO: Waiting for pod downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:28:06.117: INFO: Pod downwardapi-volume-a0f0679f-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:28:06.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2fb9p" for this suite.
Feb 13 22:28:12.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:12.178: INFO: namespace: e2e-tests-projected-2fb9p, resource: bindings, ignored listing per whitelist
Feb 13 22:28:12.186: INFO: namespace e2e-tests-projected-2fb9p deletion completed in 6.066236428s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:28:12.187: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h5s92
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-a5d83fb4-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:28:12.324: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-h5s92" to be "success or failure"
Feb 13 22:28:12.326: INFO: Pod "pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145972ms
Feb 13 22:28:14.328: INFO: Pod "pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004012125s
STEP: Saw pod success
Feb 13 22:28:14.328: INFO: Pod "pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:28:14.329: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:28:14.354: INFO: Waiting for pod pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:28:14.357: INFO: Pod pod-projected-configmaps-a5d89fc1-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:28:14.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h5s92" for this suite.
Feb 13 22:28:20.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:20.402: INFO: namespace: e2e-tests-projected-h5s92, resource: bindings, ignored listing per whitelist
Feb 13 22:28:20.410: INFO: namespace e2e-tests-projected-h5s92 deletion completed in 6.051110482s

• [SLOW TEST:8.223 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:28:20.411: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-rld8r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rld8r
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 22:28:20.545: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 22:28:44.585: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.1.62 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rld8r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:28:44.585: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:28:45.636: INFO: Found all expected endpoints: [netserver-0]
Feb 13 22:28:45.638: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.2.136 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rld8r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:28:45.638: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:28:46.731: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:28:46.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rld8r" for this suite.
Feb 13 22:29:08.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:29:08.786: INFO: namespace: e2e-tests-pod-network-test-rld8r, resource: bindings, ignored listing per whitelist
Feb 13 22:29:08.788: INFO: namespace e2e-tests-pod-network-test-rld8r deletion completed in 22.050504214s

• [SLOW TEST:48.378 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:29:08.789: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-j85sc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:29:08.928: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-j85sc" to be "success or failure"
Feb 13 22:29:08.932: INFO: Pod "downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320815ms
Feb 13 22:29:10.933: INFO: Pod "downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005023444s
STEP: Saw pod success
Feb 13 22:29:10.934: INFO: Pod "downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:29:10.935: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:29:10.948: INFO: Waiting for pod downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:29:10.951: INFO: Pod downwardapi-volume-c795f7a4-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:29:10.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j85sc" for this suite.
Feb 13 22:29:16.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:29:16.968: INFO: namespace: e2e-tests-downward-api-j85sc, resource: bindings, ignored listing per whitelist
Feb 13 22:29:16.998: INFO: namespace e2e-tests-downward-api-j85sc deletion completed in 6.045069199s

• [SLOW TEST:8.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:29:17.000: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2ck74
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-cc79d0a2-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:29:17.140: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-2ck74" to be "success or failure"
Feb 13 22:29:17.143: INFO: Pod "pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.080576ms
Feb 13 22:29:19.145: INFO: Pod "pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004912446s
STEP: Saw pod success
Feb 13 22:29:19.145: INFO: Pod "pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:29:19.146: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:29:19.161: INFO: Waiting for pod pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:29:19.162: INFO: Pod pod-projected-secrets-cc7a3111-2fde-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:29:19.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2ck74" for this suite.
Feb 13 22:29:25.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:29:25.204: INFO: namespace: e2e-tests-projected-2ck74, resource: bindings, ignored listing per whitelist
Feb 13 22:29:25.209: INFO: namespace e2e-tests-projected-2ck74 deletion completed in 6.045238956s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:29:25.210: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wpqb2
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-d160dac5-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating configMap with name cm-test-opt-upd-d160daee-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d160dac5-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Updating configmap cm-test-opt-upd-d160daee-2fde-11e9-aeb1-a6e9e8347cdc
STEP: Creating configMap with name cm-test-opt-create-d160dafd-2fde-11e9-aeb1-a6e9e8347cdc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:30:57.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wpqb2" for this suite.
Feb 13 22:31:19.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:19.684: INFO: namespace: e2e-tests-configmap-wpqb2, resource: bindings, ignored listing per whitelist
Feb 13 22:31:19.692: INFO: namespace e2e-tests-configmap-wpqb2 deletion completed in 22.042612973s

• [SLOW TEST:114.482 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:31:19.692: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xv49j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-159b9456-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:31:19.831: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-xv49j" to be "success or failure"
Feb 13 22:31:19.836: INFO: Pod "pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.399763ms
Feb 13 22:31:21.838: INFO: Pod "pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006244686s
STEP: Saw pod success
Feb 13 22:31:21.838: INFO: Pod "pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:31:21.839: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:31:21.851: INFO: Waiting for pod pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:31:21.852: INFO: Pod pod-projected-secrets-159bfc22-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:31:21.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xv49j" for this suite.
Feb 13 22:31:27.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:27.881: INFO: namespace: e2e-tests-projected-xv49j, resource: bindings, ignored listing per whitelist
Feb 13 22:31:27.902: INFO: namespace e2e-tests-projected-xv49j deletion completed in 6.047957725s

• [SLOW TEST:8.210 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:31:27.903: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qmp25
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-1a80afc4-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:31:28.043: INFO: Waiting up to 5m0s for pod "pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-qmp25" to be "success or failure"
Feb 13 22:31:28.048: INFO: Pod "pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.351098ms
Feb 13 22:31:30.050: INFO: Pod "pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006316405s
STEP: Saw pod success
Feb 13 22:31:30.050: INFO: Pod "pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:31:30.051: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:31:30.063: INFO: Waiting for pod pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:31:30.065: INFO: Pod pod-secrets-1a8102b9-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:31:30.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qmp25" for this suite.
Feb 13 22:31:36.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:36.097: INFO: namespace: e2e-tests-secrets-qmp25, resource: bindings, ignored listing per whitelist
Feb 13 22:31:36.112: INFO: namespace e2e-tests-secrets-qmp25 deletion completed in 6.044620079s

• [SLOW TEST:8.209 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:31:36.112: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-8jqp5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
Feb 13 22:31:36.253: INFO: Waiting up to 5m0s for pod "client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-containers-8jqp5" to be "success or failure"
Feb 13 22:31:36.257: INFO: Pod "client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.84065ms
Feb 13 22:31:38.259: INFO: Pod "client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005690216s
STEP: Saw pod success
Feb 13 22:31:38.259: INFO: Pod "client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:31:38.261: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:31:38.275: INFO: Waiting for pod client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:31:38.277: INFO: Pod client-containers-1f65b2b8-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:31:38.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8jqp5" for this suite.
Feb 13 22:31:44.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:44.305: INFO: namespace: e2e-tests-containers-8jqp5, resource: bindings, ignored listing per whitelist
Feb 13 22:31:44.332: INFO: namespace e2e-tests-containers-8jqp5 deletion completed in 6.053385873s

• [SLOW TEST:8.220 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:31:44.333: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ldhs6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:31:44.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-ldhs6'
Feb 13 22:31:44.539: INFO: stderr: ""
Feb 13 22:31:44.539: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 13 22:31:44.555: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xpcwj]
Feb 13 22:31:44.555: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xpcwj" in namespace "e2e-tests-kubectl-ldhs6" to be "running and ready"
Feb 13 22:31:44.557: INFO: Pod "e2e-test-nginx-rc-xpcwj": Phase="Pending", Reason="", readiness=false. Elapsed: 1.210013ms
Feb 13 22:31:46.558: INFO: Pod "e2e-test-nginx-rc-xpcwj": Phase="Running", Reason="", readiness=true. Elapsed: 2.002602796s
Feb 13 22:31:46.558: INFO: Pod "e2e-test-nginx-rc-xpcwj" satisfied condition "running and ready"
Feb 13 22:31:46.558: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xpcwj]
Feb 13 22:31:46.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ldhs6'
Feb 13 22:31:46.637: INFO: stderr: ""
Feb 13 22:31:46.637: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
Feb 13 22:31:46.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ldhs6'
Feb 13 22:31:46.738: INFO: stderr: ""
Feb 13 22:31:46.738: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:31:46.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ldhs6" for this suite.
Feb 13 22:32:08.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:08.787: INFO: namespace: e2e-tests-kubectl-ldhs6, resource: bindings, ignored listing per whitelist
Feb 13 22:32:08.800: INFO: namespace e2e-tests-kubectl-ldhs6 deletion completed in 22.055960074s

• [SLOW TEST:24.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:32:08.800: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2c46f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating api versions
Feb 13 22:32:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 api-versions'
Feb 13 22:32:09.022: INFO: stderr: ""
Feb 13 22:32:09.022: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:32:09.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2c46f" for this suite.
Feb 13 22:32:15.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:15.042: INFO: namespace: e2e-tests-kubectl-2c46f, resource: bindings, ignored listing per whitelist
Feb 13 22:32:15.065: INFO: namespace e2e-tests-kubectl-2c46f deletion completed in 6.039461878s

• [SLOW TEST:6.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:32:15.065: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fpp4z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-369c6d8f-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:32:15.204: INFO: Waiting up to 5m0s for pod "pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-fpp4z" to be "success or failure"
Feb 13 22:32:15.208: INFO: Pod "pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.867231ms
Feb 13 22:32:17.210: INFO: Pod "pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005668027s
STEP: Saw pod success
Feb 13 22:32:17.210: INFO: Pod "pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:32:17.211: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:32:17.221: INFO: Waiting for pod pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:32:17.223: INFO: Pod pod-secrets-369cc77b-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:32:17.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fpp4z" for this suite.
Feb 13 22:32:23.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:23.253: INFO: namespace: e2e-tests-secrets-fpp4z, resource: bindings, ignored listing per whitelist
Feb 13 22:32:23.272: INFO: namespace e2e-tests-secrets-fpp4z deletion completed in 6.046951492s

• [SLOW TEST:8.207 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:32:23.272: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7gs77
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 13 22:32:23.413: INFO: Waiting up to 5m0s for pod "pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-7gs77" to be "success or failure"
Feb 13 22:32:23.417: INFO: Pod "pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.886427ms
Feb 13 22:32:25.419: INFO: Pod "pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005518271s
STEP: Saw pod success
Feb 13 22:32:25.419: INFO: Pod "pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:32:25.420: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:32:25.432: INFO: Waiting for pod pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:32:25.434: INFO: Pod pod-3b81e286-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:32:25.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7gs77" for this suite.
Feb 13 22:32:31.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:31.456: INFO: namespace: e2e-tests-emptydir-7gs77, resource: bindings, ignored listing per whitelist
Feb 13 22:32:31.489: INFO: namespace e2e-tests-emptydir-7gs77 deletion completed in 6.052949987s

• [SLOW TEST:8.218 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:32:31.490: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pjrwx
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 13 22:32:31.626: INFO: Waiting up to 5m0s for pod "pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-pjrwx" to be "success or failure"
Feb 13 22:32:31.629: INFO: Pod "pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.879186ms
Feb 13 22:32:33.632: INFO: Pod "pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006061606s
STEP: Saw pod success
Feb 13 22:32:33.632: INFO: Pod "pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:32:33.633: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:32:33.646: INFO: Waiting for pod pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:32:33.648: INFO: Pod pod-40672633-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:32:33.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pjrwx" for this suite.
Feb 13 22:32:39.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:39.672: INFO: namespace: e2e-tests-emptydir-pjrwx, resource: bindings, ignored listing per whitelist
Feb 13 22:32:39.776: INFO: namespace e2e-tests-emptydir-pjrwx deletion completed in 6.1263589s

• [SLOW TEST:8.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:32:39.777: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-mc98j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:32:39.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mc98j" for this suite.
Feb 13 22:33:01.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:33:01.953: INFO: namespace: e2e-tests-pods-mc98j, resource: bindings, ignored listing per whitelist
Feb 13 22:33:01.975: INFO: namespace e2e-tests-pods-mc98j deletion completed in 22.052472103s

• [SLOW TEST:22.198 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:33:01.976: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-b5qvv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 13 22:33:04.633: INFO: Successfully updated pod "pod-update-529318c9-2fdf-11e9-aeb1-a6e9e8347cdc"
STEP: verifying the updated pod is in kubernetes
Feb 13 22:33:04.638: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:33:04.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b5qvv" for this suite.
Feb 13 22:33:26.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:33:26.669: INFO: namespace: e2e-tests-pods-b5qvv, resource: bindings, ignored listing per whitelist
Feb 13 22:33:26.685: INFO: namespace e2e-tests-pods-b5qvv deletion completed in 22.044421149s

• [SLOW TEST:24.709 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:33:26.686: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pfxj8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pfxj8
Feb 13 22:33:30.829: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pfxj8
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:33:30.830: INFO: Initial restart count of pod liveness-http is 0
Feb 13 22:33:48.846: INFO: Restart count of pod e2e-tests-container-probe-pfxj8/liveness-http is now 1 (18.015542701s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:33:48.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pfxj8" for this suite.
Feb 13 22:33:54.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:33:54.896: INFO: namespace: e2e-tests-container-probe-pfxj8, resource: bindings, ignored listing per whitelist
Feb 13 22:33:54.899: INFO: namespace e2e-tests-container-probe-pfxj8 deletion completed in 6.043169401s

• [SLOW TEST:28.214 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:33:54.900: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-npl9q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Feb 13 22:33:55.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 create -f - --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:33:55.185: INFO: stderr: ""
Feb 13 22:33:55.185: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:33:55.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:33:55.275: INFO: stderr: ""
Feb 13 22:33:55.275: INFO: stdout: "update-demo-nautilus-4mrlc update-demo-nautilus-ftrzm "
Feb 13 22:33:55.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-4mrlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:33:55.335: INFO: stderr: ""
Feb 13 22:33:55.335: INFO: stdout: ""
Feb 13 22:33:55.335: INFO: update-demo-nautilus-4mrlc is created but not running
Feb 13 22:34:00.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.398: INFO: stderr: ""
Feb 13 22:34:00.398: INFO: stdout: "update-demo-nautilus-4mrlc update-demo-nautilus-ftrzm "
Feb 13 22:34:00.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-4mrlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.469: INFO: stderr: ""
Feb 13 22:34:00.469: INFO: stdout: "true"
Feb 13 22:34:00.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-4mrlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.538: INFO: stderr: ""
Feb 13 22:34:00.539: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:34:00.539: INFO: validating pod update-demo-nautilus-4mrlc
Feb 13 22:34:00.544: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:34:00.544: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:34:00.544: INFO: update-demo-nautilus-4mrlc is verified up and running
Feb 13 22:34:00.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-ftrzm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.622: INFO: stderr: ""
Feb 13 22:34:00.622: INFO: stdout: "true"
Feb 13 22:34:00.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods update-demo-nautilus-ftrzm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.694: INFO: stderr: ""
Feb 13 22:34:00.694: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Feb 13 22:34:00.694: INFO: validating pod update-demo-nautilus-ftrzm
Feb 13 22:34:00.697: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:34:00.697: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:34:00.697: INFO: update-demo-nautilus-ftrzm is verified up and running
STEP: using delete to clean up resources
Feb 13 22:34:00.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.770: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:34:00.770: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 22:34:00.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-npl9q'
Feb 13 22:34:00.843: INFO: stderr: "No resources found.\n"
Feb 13 22:34:00.843: INFO: stdout: ""
Feb 13 22:34:00.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 get pods -l name=update-demo --namespace=e2e-tests-kubectl-npl9q -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 22:34:00.926: INFO: stderr: ""
Feb 13 22:34:00.926: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:34:00.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-npl9q" for this suite.
Feb 13 22:34:22.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:34:22.953: INFO: namespace: e2e-tests-kubectl-npl9q, resource: bindings, ignored listing per whitelist
Feb 13 22:34:22.972: INFO: namespace e2e-tests-kubectl-npl9q deletion completed in 22.043222176s

• [SLOW TEST:28.072 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:34:22.973: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-v6lv7
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 13 22:34:23.121: INFO: Waiting up to 5m0s for pod "pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-v6lv7" to be "success or failure"
Feb 13 22:34:23.124: INFO: Pod "pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.90164ms
Feb 13 22:34:25.126: INFO: Pod "pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005419447s
STEP: Saw pod success
Feb 13 22:34:25.126: INFO: Pod "pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:34:25.128: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:34:25.144: INFO: Waiting for pod pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:34:25.145: INFO: Pod pod-82dbbcc6-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:34:25.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v6lv7" for this suite.
Feb 13 22:34:31.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:34:31.180: INFO: namespace: e2e-tests-emptydir-v6lv7, resource: bindings, ignored listing per whitelist
Feb 13 22:34:31.189: INFO: namespace e2e-tests-emptydir-v6lv7 deletion completed in 6.042190329s

• [SLOW TEST:8.217 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:34:31.190: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fm6q4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 22:34:31.338: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:34:31.348: INFO: Number of nodes with available pods: 0
Feb 13 22:34:31.348: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:34:32.353: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:34:32.354: INFO: Number of nodes with available pods: 0
Feb 13 22:34:32.354: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:34:33.352: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:34:33.353: INFO: Number of nodes with available pods: 2
Feb 13 22:34:33.353: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 13 22:34:33.369: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:34:33.375: INFO: Number of nodes with available pods: 1
Feb 13 22:34:33.375: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:34:34.377: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:34:34.378: INFO: Number of nodes with available pods: 1
Feb 13 22:34:34.378: INFO: Node alex-300-cp1-vsp2-workerbe2ca38349 is running more than one daemon pod
Feb 13 22:34:35.378: INFO: DaemonSet pods can't tolerate node alex-300-cp1-vsp2-master3588ea178a with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:34:35.379: INFO: Number of nodes with available pods: 2
Feb 13 22:34:35.379: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-fm6q4, will wait for the garbage collector to delete the pods
Feb 13 22:34:35.444: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.971257ms
Feb 13 22:34:35.545: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.27619ms
Feb 13 22:34:49.246: INFO: Number of nodes with available pods: 0
Feb 13 22:34:49.246: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 22:34:49.248: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fm6q4/daemonsets","resourceVersion":"21545"},"items":null}

Feb 13 22:34:49.249: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fm6q4/pods","resourceVersion":"21545"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:34:49.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fm6q4" for this suite.
Feb 13 22:34:55.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:34:55.274: INFO: namespace: e2e-tests-daemonsets-fm6q4, resource: bindings, ignored listing per whitelist
Feb 13 22:34:55.309: INFO: namespace e2e-tests-daemonsets-fm6q4 deletion completed in 6.052596782s

• [SLOW TEST:24.119 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:34:55.309: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6jc88
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9620cc82-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9620cc82-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:34:59.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jc88" for this suite.
Feb 13 22:35:21.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:35:21.516: INFO: namespace: e2e-tests-projected-6jc88, resource: bindings, ignored listing per whitelist
Feb 13 22:35:21.523: INFO: namespace e2e-tests-projected-6jc88 deletion completed in 22.044984146s

• [SLOW TEST:26.214 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:35:21.524: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ks894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-a5c0c93a-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:35:21.666: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-ks894" to be "success or failure"
Feb 13 22:35:21.673: INFO: Pod "pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.201199ms
Feb 13 22:35:23.676: INFO: Pod "pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009839832s
STEP: Saw pod success
Feb 13 22:35:23.676: INFO: Pod "pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:35:23.678: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:35:23.700: INFO: Waiting for pod pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:35:23.703: INFO: Pod pod-projected-configmaps-a5c120a6-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:35:23.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ks894" for this suite.
Feb 13 22:35:29.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:35:29.751: INFO: namespace: e2e-tests-projected-ks894, resource: bindings, ignored listing per whitelist
Feb 13 22:35:29.765: INFO: namespace e2e-tests-projected-ks894 deletion completed in 6.047491024s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:35:29.766: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-s69gv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 13 22:35:31.913: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-aaa95f32-2fdf-11e9-aeb1-a6e9e8347cdc", GenerateName:"", Namespace:"e2e-tests-pods-s69gv", SelfLink:"/api/v1/namespaces/e2e-tests-pods-s69gv/pods/pod-submit-remove-aaa95f32-2fdf-11e9-aeb1-a6e9e8347cdc", UID:"aaa9dd19-2fdf-11e9-80e0-0050569e5ced", ResourceVersion:"21765", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685694129, loc:(*time.Location)(0x642e6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"894997381", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.2.157/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rtk9p", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421b6bb00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rtk9p", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421017738), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"alex-300-cp1-vsp2-workerbe2ca38349", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420d28d20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421017780)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421017800)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421017808), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685694129, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685694130, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685694129, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.100.53", PodIP:"192.168.2.157", StartTime:(*v1.Time)(0xc421ddb540), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421ddb560), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"docker://8fe8f171d869507d08e7b43091b1e4481ad348fe12ff71449591e1b18c15801b"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:35:39.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-s69gv" for this suite.
Feb 13 22:35:45.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:35:45.291: INFO: namespace: e2e-tests-pods-s69gv, resource: bindings, ignored listing per whitelist
Feb 13 22:35:45.296: INFO: namespace e2e-tests-pods-s69gv deletion completed in 6.049950551s

• [SLOW TEST:15.531 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:35:45.297: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sktdh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 13 22:35:45.435: INFO: Waiting up to 5m0s for pod "pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-sktdh" to be "success or failure"
Feb 13 22:35:45.438: INFO: Pod "pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.941929ms
Feb 13 22:35:47.440: INFO: Pod "pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004714373s
STEP: Saw pod success
Feb 13 22:35:47.440: INFO: Pod "pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:35:47.442: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:35:47.452: INFO: Waiting for pod pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:35:47.453: INFO: Pod pod-b3ebdf21-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:35:47.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sktdh" for this suite.
Feb 13 22:35:53.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:35:53.566: INFO: namespace: e2e-tests-emptydir-sktdh, resource: bindings, ignored listing per whitelist
Feb 13 22:35:53.578: INFO: namespace e2e-tests-emptydir-sktdh deletion completed in 6.10166109s

• [SLOW TEST:8.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:35:53.579: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cxjcw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 13 22:35:53.716: INFO: Waiting up to 5m0s for pod "pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-cxjcw" to be "success or failure"
Feb 13 22:35:53.719: INFO: Pod "pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.588828ms
Feb 13 22:35:55.721: INFO: Pod "pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005386218s
STEP: Saw pod success
Feb 13 22:35:55.721: INFO: Pod "pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:35:55.722: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:35:55.736: INFO: Waiting for pod pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:35:55.737: INFO: Pod pod-b8db59e5-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:35:55.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cxjcw" for this suite.
Feb 13 22:36:01.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:01.780: INFO: namespace: e2e-tests-emptydir-cxjcw, resource: bindings, ignored listing per whitelist
Feb 13 22:36:01.783: INFO: namespace e2e-tests-emptydir-cxjcw deletion completed in 6.043705307s

• [SLOW TEST:8.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:01.784: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jwg4v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Feb 13 22:36:01.927: INFO: Waiting up to 5m0s for pod "downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-jwg4v" to be "success or failure"
Feb 13 22:36:01.929: INFO: Pod "downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.19026ms
Feb 13 22:36:03.931: INFO: Pod "downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004187609s
Feb 13 22:36:05.933: INFO: Pod "downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005952197s
STEP: Saw pod success
Feb 13 22:36:05.933: INFO: Pod "downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:36:05.934: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:36:05.950: INFO: Waiting for pod downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:36:05.952: INFO: Pod downward-api-bdbf6164-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:36:05.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jwg4v" for this suite.
Feb 13 22:36:11.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:11.984: INFO: namespace: e2e-tests-downward-api-jwg4v, resource: bindings, ignored listing per whitelist
Feb 13 22:36:12.002: INFO: namespace e2e-tests-downward-api-jwg4v deletion completed in 6.048091457s

• [SLOW TEST:10.218 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:12.003: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-q649c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 13 22:36:12.144: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q649c,SelfLink:/api/v1/namespaces/e2e-tests-watch-q649c/configmaps/e2e-watch-test-label-changed,UID:c3d6df8e-2fdf-11e9-80e0-0050569e5ced,ResourceVersion:21948,Generation:0,CreationTimestamp:2019-02-13 22:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 22:36:12.144: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q649c,SelfLink:/api/v1/namespaces/e2e-tests-watch-q649c/configmaps/e2e-watch-test-label-changed,UID:c3d6df8e-2fdf-11e9-80e0-0050569e5ced,ResourceVersion:21949,Generation:0,CreationTimestamp:2019-02-13 22:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 13 22:36:12.144: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q649c,SelfLink:/api/v1/namespaces/e2e-tests-watch-q649c/configmaps/e2e-watch-test-label-changed,UID:c3d6df8e-2fdf-11e9-80e0-0050569e5ced,ResourceVersion:21950,Generation:0,CreationTimestamp:2019-02-13 22:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 13 22:36:22.157: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q649c,SelfLink:/api/v1/namespaces/e2e-tests-watch-q649c/configmaps/e2e-watch-test-label-changed,UID:c3d6df8e-2fdf-11e9-80e0-0050569e5ced,ResourceVersion:21970,Generation:0,CreationTimestamp:2019-02-13 22:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 22:36:22.157: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q649c,SelfLink:/api/v1/namespaces/e2e-tests-watch-q649c/configmaps/e2e-watch-test-label-changed,UID:c3d6df8e-2fdf-11e9-80e0-0050569e5ced,ResourceVersion:21971,Generation:0,CreationTimestamp:2019-02-13 22:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 13 22:36:22.157: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q649c,SelfLink:/api/v1/namespaces/e2e-tests-watch-q649c/configmaps/e2e-watch-test-label-changed,UID:c3d6df8e-2fdf-11e9-80e0-0050569e5ced,ResourceVersion:21972,Generation:0,CreationTimestamp:2019-02-13 22:36:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:36:22.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-q649c" for this suite.
Feb 13 22:36:28.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:28.177: INFO: namespace: e2e-tests-watch-q649c, resource: bindings, ignored listing per whitelist
Feb 13 22:36:28.206: INFO: namespace e2e-tests-watch-q649c deletion completed in 6.045473288s

• [SLOW TEST:16.203 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:28.206: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pxbdw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-cd7f1635-2fdf-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:36:28.347: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-pxbdw" to be "success or failure"
Feb 13 22:36:28.351: INFO: Pod "pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024619ms
Feb 13 22:36:30.353: INFO: Pod "pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006035906s
STEP: Saw pod success
Feb 13 22:36:30.353: INFO: Pod "pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:36:30.354: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:36:30.367: INFO: Waiting for pod pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:36:30.368: INFO: Pod pod-projected-secrets-cd7f7154-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:36:30.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pxbdw" for this suite.
Feb 13 22:36:36.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:36.385: INFO: namespace: e2e-tests-projected-pxbdw, resource: bindings, ignored listing per whitelist
Feb 13 22:36:36.413: INFO: namespace e2e-tests-projected-pxbdw deletion completed in 6.043370918s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:36.414: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-jfmzl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:36:36.549: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
Feb 13 22:36:36.551: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jfmzl/daemonsets","resourceVersion":"22037"},"items":null}

Feb 13 22:36:36.552: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jfmzl/pods","resourceVersion":"22037"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:36:36.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jfmzl" for this suite.
Feb 13 22:36:42.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:42.605: INFO: namespace: e2e-tests-daemonsets-jfmzl, resource: bindings, ignored listing per whitelist
Feb 13 22:36:42.610: INFO: namespace e2e-tests-daemonsets-jfmzl deletion completed in 6.050453886s

S [SKIPPING] [6.196 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

  Feb 13 22:36:36.549: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:42.611: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-2x72l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
Feb 13 22:36:43.263: INFO: created pod pod-service-account-defaultsa
Feb 13 22:36:43.263: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 13 22:36:43.269: INFO: created pod pod-service-account-mountsa
Feb 13 22:36:43.269: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 13 22:36:43.274: INFO: created pod pod-service-account-nomountsa
Feb 13 22:36:43.274: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 13 22:36:43.295: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 13 22:36:43.295: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 13 22:36:43.303: INFO: created pod pod-service-account-mountsa-mountspec
Feb 13 22:36:43.303: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 13 22:36:43.319: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 13 22:36:43.319: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 13 22:36:43.330: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 13 22:36:43.330: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 13 22:36:43.338: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 13 22:36:43.338: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 13 22:36:43.344: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 13 22:36:43.344: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:36:43.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-2x72l" for this suite.
Feb 13 22:36:49.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:49.382: INFO: namespace: e2e-tests-svcaccounts-2x72l, resource: bindings, ignored listing per whitelist
Feb 13 22:36:49.400: INFO: namespace e2e-tests-svcaccounts-2x72l deletion completed in 6.050202734s

• [SLOW TEST:6.789 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:49.401: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-8d9j9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
Feb 13 22:36:49.537: INFO: Waiting up to 5m0s for pod "client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-containers-8d9j9" to be "success or failure"
Feb 13 22:36:49.542: INFO: Pod "client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.152429ms
Feb 13 22:36:51.544: INFO: Pod "client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006729336s
Feb 13 22:36:53.546: INFO: Pod "client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008815541s
STEP: Saw pod success
Feb 13 22:36:53.546: INFO: Pod "client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:36:53.547: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:36:53.562: INFO: Waiting for pod client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:36:53.563: INFO: Pod client-containers-da212f2e-2fdf-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:36:53.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8d9j9" for this suite.
Feb 13 22:36:59.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:59.578: INFO: namespace: e2e-tests-containers-8d9j9, resource: bindings, ignored listing per whitelist
Feb 13 22:36:59.609: INFO: namespace e2e-tests-containers-8d9j9 deletion completed in 6.04422123s

• [SLOW TEST:10.208 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:36:59.610: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-dwn6s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-dwn6s
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
Feb 13 22:36:59.762: INFO: Found 0 stateful pods, waiting for 3
Feb 13 22:37:09.764: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:37:09.764: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:37:09.764: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:37:09.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dwn6s ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 22:37:09.897: INFO: stderr: ""
Feb 13 22:37:09.897: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 22:37:09.897: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Feb 13 22:37:19.919: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 13 22:37:29.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dwn6s ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 22:37:30.053: INFO: stderr: ""
Feb 13 22:37:30.053: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 22:37:30.053: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 22:37:50.061: INFO: Waiting for StatefulSet e2e-tests-statefulset-dwn6s/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 13 22:38:00.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dwn6s ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 22:38:00.197: INFO: stderr: ""
Feb 13 22:38:00.197: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 22:38:00.197: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 22:38:10.222: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 13 22:38:20.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 exec --namespace=e2e-tests-statefulset-dwn6s ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 22:38:20.364: INFO: stderr: ""
Feb 13 22:38:20.364: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 22:38:20.364: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 22:38:40.373: INFO: Waiting for StatefulSet e2e-tests-statefulset-dwn6s/ss2 to complete update
Feb 13 22:38:40.373: INFO: Waiting for Pod e2e-tests-statefulset-dwn6s/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
Feb 13 22:38:50.376: INFO: Waiting for StatefulSet e2e-tests-statefulset-dwn6s/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Feb 13 22:39:00.377: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dwn6s
Feb 13 22:39:00.379: INFO: Scaling statefulset ss2 to 0
Feb 13 22:39:10.388: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 22:39:10.390: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:39:10.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dwn6s" for this suite.
Feb 13 22:39:16.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:39:16.424: INFO: namespace: e2e-tests-statefulset-dwn6s, resource: bindings, ignored listing per whitelist
Feb 13 22:39:16.452: INFO: namespace e2e-tests-statefulset-dwn6s deletion completed in 6.047204032s

• [SLOW TEST:136.843 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:39:16.453: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-t2cjj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Feb 13 22:39:16.586: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 13 22:40:16.599: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 22:40:16.602: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 22:40:16.606: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 22:40:16.606: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 13 22:40:16.608: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Feb 13 22:40:16.608: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp1-vsp2-workerbe2ca38349 before test
Feb 13 22:40:16.613: INFO: metallb-speaker-tqj8d from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:40:16.613: INFO: kubernetes-dashboard-5888c7c865-6fw6h from ccp started at 2019-02-13 20:26:56 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 13 22:40:16.613: INFO: ccp-monitor-prometheus-node-exporter-jp7s4 from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:40:16.613: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 21:34:56 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 22:40:16.613: INFO: calico-typha-7745977f6c-nnddh from kube-system started at 2019-02-13 20:26:09 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:40:16.613: INFO: nginx-ingress-default-backend-54786554b4-c8glf from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb 13 22:40:16.613: INFO: fluentd-es-v2.0.2-78sgd from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:40:16.613: INFO: ccp-efk-kibana-594754b75-6fg7f from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container kibana ready: true, restart count 0
Feb 13 22:40:16.613: INFO: ccp-monitor-prometheus-kube-state-metrics-5b6855c558-bvftk from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Feb 13 22:40:16.613: INFO: ccp-monitor-grafana-598bcf54f9-28w8c from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container grafana ready: true, restart count 0
Feb 13 22:40:16.613: INFO: sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-tpdfj from heptio-sonobuoy started at 2019-02-13 21:35:01 +0000 UTC (2 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 22:40:16.613: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 13 22:40:16.613: INFO: calico-node-wbc5b from kube-system started at 2019-02-13 20:25:59 +0000 UTC (2 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:40:16.613: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:40:16.613: INFO: cert-manager-d98996f46-7gj72 from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container cert-manager ready: true, restart count 0
Feb 13 22:40:16.613: INFO: kube-proxy-h97kt from kube-system started at 2019-02-13 20:25:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:40:16.613: INFO: nginx-ingress-controller-fr4dw from ccp started at 2019-02-13 20:26:54 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.613: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:40:16.613: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp1-vsp2-workerd2381a81c9 before test
Feb 13 22:40:16.618: INFO: coredns-6c59c84b9c-mbqwk from kube-system started at 2019-02-13 20:26:16 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container coredns ready: true, restart count 0
Feb 13 22:40:16.618: INFO: ccp-monitor-prometheus-alertmanager-64c4f944cb-gvrlv from ccp started at 2019-02-13 20:26:58 +0000 UTC (2 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Feb 13 22:40:16.618: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Feb 13 22:40:16.618: INFO: fluentd-es-v2.0.2-92kwr from ccp started at 2019-02-13 20:26:59 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:40:16.618: INFO: calico-node-ns8hh from kube-system started at 2019-02-13 20:25:57 +0000 UTC (2 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:40:16.618: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:40:16.618: INFO: metallb-speaker-9sx8b from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:40:16.618: INFO: metallb-controller-54559b4447-zjhc6 from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container controller ready: true, restart count 0
Feb 13 22:40:16.618: INFO: ccp-monitor-prometheus-pushgateway-7cfbcd8dfd-tlw5g from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
Feb 13 22:40:16.618: INFO: ccp-monitor-prometheus-server-6fb9957f87-r8ftg from ccp started at 2019-02-13 20:26:58 +0000 UTC (2 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container prometheus-server ready: true, restart count 0
Feb 13 22:40:16.618: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Feb 13 22:40:16.618: INFO: kube-proxy-xrp4h from kube-system started at 2019-02-13 20:25:57 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.618: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:40:16.618: INFO: calico-typha-7745977f6c-52zql from kube-system started at 2019-02-13 20:26:07 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.619: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:40:16.619: INFO: nginx-ingress-controller-ckzrj from ccp started at 2019-02-13 20:26:55 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.619: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:40:16.619: INFO: ccp-monitor-prometheus-node-exporter-cktg2 from ccp started at 2019-02-13 20:26:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.619: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:40:16.619: INFO: elasticsearch-logging-0 from ccp started at 2019-02-13 20:27:11 +0000 UTC (1 container statuses recorded)
Feb 13 22:40:16.619: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Feb 13 22:40:16.619: INFO: sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-2mkgp from heptio-sonobuoy started at 2019-02-13 21:35:01 +0000 UTC (2 container statuses recorded)
Feb 13 22:40:16.619: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 22:40:16.619: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node alex-300-cp1-vsp2-workerbe2ca38349
STEP: verifying the node has the label node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.646: INFO: Pod ccp-efk-kibana-594754b75-6fg7f requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-grafana-598bcf54f9-28w8c requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-prometheus-alertmanager-64c4f944cb-gvrlv requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-prometheus-kube-state-metrics-5b6855c558-bvftk requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-prometheus-node-exporter-cktg2 requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-prometheus-node-exporter-jp7s4 requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-prometheus-pushgateway-7cfbcd8dfd-tlw5g requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod ccp-monitor-prometheus-server-6fb9957f87-r8ftg requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod cert-manager-d98996f46-7gj72 requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod elasticsearch-logging-0 requesting resource cpu=100m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod fluentd-es-v2.0.2-78sgd requesting resource cpu=100m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod fluentd-es-v2.0.2-92kwr requesting resource cpu=100m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod kubernetes-dashboard-5888c7c865-6fw6h requesting resource cpu=100m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod metallb-controller-54559b4447-zjhc6 requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod metallb-speaker-9sx8b requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod metallb-speaker-tqj8d requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod nginx-ingress-controller-ckzrj requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod nginx-ingress-controller-fr4dw requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod nginx-ingress-default-backend-54786554b4-c8glf requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod sonobuoy requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-2mkgp requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.647: INFO: Pod sonobuoy-systemd-logs-daemon-set-1f9c23b73d994599-tpdfj requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.647: INFO: Pod calico-node-ns8hh requesting resource cpu=250m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.648: INFO: Pod calico-node-wbc5b requesting resource cpu=250m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.648: INFO: Pod calico-typha-7745977f6c-52zql requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.648: INFO: Pod calico-typha-7745977f6c-nnddh requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.648: INFO: Pod coredns-6c59c84b9c-mbqwk requesting resource cpu=100m on Node alex-300-cp1-vsp2-workerd2381a81c9
Feb 13 22:40:16.648: INFO: Pod kube-proxy-h97kt requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerbe2ca38349
Feb 13 22:40:16.648: INFO: Pod kube-proxy-xrp4h requesting resource cpu=0m on Node alex-300-cp1-vsp2-workerd2381a81c9
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55947391-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91cff7e06e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-t2cjj/filler-pod-55947391-2fe0-11e9-aeb1-a6e9e8347cdc to alex-300-cp1-vsp2-workerbe2ca38349]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55947391-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91fb19aefa], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55947391-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91ff59ebb9], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55947391-2fe0-11e9-aeb1-a6e9e8347cdc.15830d92038c11ad], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55953bbd-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91d02c7099], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-t2cjj/filler-pod-55953bbd-2fe0-11e9-aeb1-a6e9e8347cdc to alex-300-cp1-vsp2-workerd2381a81c9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55953bbd-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91f568a34f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55953bbd-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91f9589ccd], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55953bbd-2fe0-11e9-aeb1-a6e9e8347cdc.15830d91ff567367], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15830d9248627236], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node alex-300-cp1-vsp2-workerbe2ca38349
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node alex-300-cp1-vsp2-workerd2381a81c9
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:40:19.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-t2cjj" for this suite.
Feb 13 22:40:25.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:40:25.725: INFO: namespace: e2e-tests-sched-pred-t2cjj, resource: bindings, ignored listing per whitelist
Feb 13 22:40:25.752: INFO: namespace e2e-tests-sched-pred-t2cjj deletion completed in 6.04394015s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:69.300 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:40:25.753: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-q55wg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-lgtbc in namespace e2e-tests-proxy-q55wg
I0213 22:40:25.898771      17 runners.go:177] Created replication controller with name: proxy-service-lgtbc, namespace: e2e-tests-proxy-q55wg, replica count: 1
I0213 22:40:26.949029      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 22:40:27.949193      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 22:40:28.949347      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 22:40:29.949478      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 22:40:30.949650      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 22:40:31.949805      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 22:40:32.949942      17 runners.go:177] proxy-service-lgtbc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 22:40:32.951: INFO: setup took 7.066211512s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 13 22:40:32.965: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 1.502693ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 12.191982ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 12.01348ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 11.457838ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 10.237356ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 13.429303ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 14.26796ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 10.09149ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 6.532514ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 11.01457ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 6.121375ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 5.669271ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 5.339344ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 6.162448ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 7.55837ms)
Feb 13 22:40:32.966: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 2.608607ms)
Feb 13 22:40:32.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 2.03654ms)
Feb 13 22:40:32.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 10.849843ms)
Feb 13 22:40:32.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 10.461791ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 9.724714ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 9.556752ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 9.203971ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 8.297929ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 7.791815ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 5.967541ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.262065ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 6.415643ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 5.619843ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 5.73617ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 3.223528ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.1268ms)
Feb 13 22:40:32.978: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 2.836615ms)
Feb 13 22:40:32.985: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 4.65794ms)
Feb 13 22:40:32.985: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 6.768958ms)
Feb 13 22:40:32.985: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 6.51703ms)
Feb 13 22:40:32.986: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 3.779237ms)
Feb 13 22:40:32.986: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.570424ms)
Feb 13 22:40:32.986: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 7.098039ms)
Feb 13 22:40:32.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 4.839963ms)
Feb 13 22:40:32.988: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 4.542931ms)
Feb 13 22:40:32.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 4.51557ms)
Feb 13 22:40:32.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.593667ms)
Feb 13 22:40:32.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.692822ms)
Feb 13 22:40:32.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 8.922284ms)
Feb 13 22:40:32.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 8.770345ms)
Feb 13 22:40:32.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 8.268108ms)
Feb 13 22:40:32.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 6.814449ms)
Feb 13 22:40:32.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 8.019413ms)
Feb 13 22:40:32.994: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 3.148232ms)
Feb 13 22:40:32.994: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 3.359259ms)
Feb 13 22:40:32.994: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 3.389388ms)
Feb 13 22:40:32.994: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 3.35558ms)
Feb 13 22:40:32.995: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 3.036494ms)
Feb 13 22:40:32.997: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.532261ms)
Feb 13 22:40:32.997: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 5.940086ms)
Feb 13 22:40:32.997: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 5.73561ms)
Feb 13 22:40:32.997: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 5.472491ms)
Feb 13 22:40:32.997: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 3.031646ms)
Feb 13 22:40:32.997: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 6.37731ms)
Feb 13 22:40:32.998: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 7.425377ms)
Feb 13 22:40:32.998: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 7.191044ms)
Feb 13 22:40:32.998: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.394452ms)
Feb 13 22:40:32.999: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 7.454416ms)
Feb 13 22:40:33.000: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 8.467526ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 7.364876ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 8.258473ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 9.404103ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 8.33186ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 9.716159ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.50254ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 8.653079ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 9.546398ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 9.654292ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.372239ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 7.480073ms)
Feb 13 22:40:33.009: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 9.549754ms)
Feb 13 22:40:33.010: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 7.60485ms)
Feb 13 22:40:33.010: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 9.618068ms)
Feb 13 22:40:33.010: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 10.582992ms)
Feb 13 22:40:33.011: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 11.277715ms)
Feb 13 22:40:33.014: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 2.839587ms)
Feb 13 22:40:33.015: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 3.49866ms)
Feb 13 22:40:33.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.277326ms)
Feb 13 22:40:33.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 8.822581ms)
Feb 13 22:40:33.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 8.643091ms)
Feb 13 22:40:33.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 8.630127ms)
Feb 13 22:40:33.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.896475ms)
Feb 13 22:40:33.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 8.780999ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 9.003878ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 8.979031ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 9.188814ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 9.036965ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 9.153994ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 9.125047ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 9.250006ms)
Feb 13 22:40:33.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 9.193355ms)
Feb 13 22:40:33.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 10.940634ms)
Feb 13 22:40:33.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 11.23876ms)
Feb 13 22:40:33.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 11.195706ms)
Feb 13 22:40:33.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 11.196147ms)
Feb 13 22:40:33.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 11.334262ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 11.255276ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 11.280212ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 11.477665ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 11.371818ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 11.458881ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 11.596965ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 11.617787ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 11.814709ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 11.790384ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 11.774584ms)
Feb 13 22:40:33.033: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 11.891612ms)
Feb 13 22:40:33.039: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.711057ms)
Feb 13 22:40:33.039: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 5.037463ms)
Feb 13 22:40:33.039: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 5.556494ms)
Feb 13 22:40:33.039: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 4.881099ms)
Feb 13 22:40:33.039: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 5.992999ms)
Feb 13 22:40:33.041: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.29196ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 11.363882ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 11.461985ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 11.540222ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 11.578533ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 11.680577ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 11.622949ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 11.779764ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 11.766548ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 11.944527ms)
Feb 13 22:40:33.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 11.8846ms)
Feb 13 22:40:33.047: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 1.209901ms)
Feb 13 22:40:33.052: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 5.55932ms)
Feb 13 22:40:33.052: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 4.691615ms)
Feb 13 22:40:33.052: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.965785ms)
Feb 13 22:40:33.053: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 6.0289ms)
Feb 13 22:40:33.053: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 5.516206ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.54132ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 7.593144ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 7.506703ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 7.488073ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 7.217062ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 7.644994ms)
Feb 13 22:40:33.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 7.491589ms)
Feb 13 22:40:33.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 8.184822ms)
Feb 13 22:40:33.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 7.994913ms)
Feb 13 22:40:33.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 8.257233ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 5.024672ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 5.340204ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.112114ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.210697ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 5.326236ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 5.191277ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 5.25056ms)
Feb 13 22:40:33.060: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 5.465043ms)
Feb 13 22:40:33.062: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 6.382989ms)
Feb 13 22:40:33.062: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 6.377072ms)
Feb 13 22:40:33.062: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 6.657257ms)
Feb 13 22:40:33.062: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 6.655658ms)
Feb 13 22:40:33.064: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 8.471274ms)
Feb 13 22:40:33.064: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 8.585974ms)
Feb 13 22:40:33.064: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 9.069286ms)
Feb 13 22:40:33.064: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 9.404937ms)
Feb 13 22:40:33.072: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 7.143906ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 7.831308ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 7.869879ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 8.259902ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.088749ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 7.798031ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 7.899121ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 8.715676ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 8.641763ms)
Feb 13 22:40:33.073: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.640501ms)
Feb 13 22:40:33.074: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 8.782469ms)
Feb 13 22:40:33.074: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 8.683566ms)
Feb 13 22:40:33.074: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 8.633763ms)
Feb 13 22:40:33.074: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 9.241686ms)
Feb 13 22:40:33.074: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 9.24881ms)
Feb 13 22:40:33.074: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 9.147411ms)
Feb 13 22:40:33.079: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 4.797501ms)
Feb 13 22:40:33.079: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.662908ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.989051ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 6.62416ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 6.970562ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 6.514298ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 6.670638ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 6.600625ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 7.168627ms)
Feb 13 22:40:33.081: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 6.842101ms)
Feb 13 22:40:33.082: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 7.23802ms)
Feb 13 22:40:33.082: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.289422ms)
Feb 13 22:40:33.083: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 7.698514ms)
Feb 13 22:40:33.083: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 8.203261ms)
Feb 13 22:40:33.083: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 8.678884ms)
Feb 13 22:40:33.083: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 8.851578ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.176766ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 8.425545ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 8.433964ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 8.399516ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 8.383436ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 8.377083ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 8.356226ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 8.288556ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 8.325923ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 8.352332ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 8.24468ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 8.307507ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 8.246061ms)
Feb 13 22:40:33.092: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 8.977419ms)
Feb 13 22:40:33.093: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 9.530134ms)
Feb 13 22:40:33.093: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 9.677702ms)
Feb 13 22:40:33.096: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 3.146738ms)
Feb 13 22:40:33.096: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 2.995538ms)
Feb 13 22:40:33.096: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 2.973894ms)
Feb 13 22:40:33.099: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 5.855779ms)
Feb 13 22:40:33.099: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.802516ms)
Feb 13 22:40:33.099: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 5.906116ms)
Feb 13 22:40:33.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 7.14306ms)
Feb 13 22:40:33.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 7.668369ms)
Feb 13 22:40:33.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.783497ms)
Feb 13 22:40:33.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 7.777554ms)
Feb 13 22:40:33.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.927312ms)
Feb 13 22:40:33.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 8.58481ms)
Feb 13 22:40:33.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 8.753928ms)
Feb 13 22:40:33.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 8.743755ms)
Feb 13 22:40:33.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 8.851253ms)
Feb 13 22:40:33.103: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 8.927255ms)
Feb 13 22:40:33.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 3.714527ms)
Feb 13 22:40:33.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.100324ms)
Feb 13 22:40:33.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 4.069949ms)
Feb 13 22:40:33.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.109443ms)
Feb 13 22:40:33.109: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 5.993334ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 8.189308ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 8.303507ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 8.361738ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 8.511319ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 8.617068ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 8.437754ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 8.509122ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 8.480332ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 8.558935ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 8.473038ms)
Feb 13 22:40:33.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 8.68096ms)
Feb 13 22:40:33.115: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 3.339814ms)
Feb 13 22:40:33.115: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 3.394086ms)
Feb 13 22:40:33.115: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 3.517416ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 6.946557ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 7.765183ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 7.5541ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 7.509826ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 7.679514ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.39793ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 7.57031ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 7.490892ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 7.634519ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 7.52852ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 7.766653ms)
Feb 13 22:40:33.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 7.460067ms)
Feb 13 22:40:33.120: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 8.310456ms)
Feb 13 22:40:33.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.429946ms)
Feb 13 22:40:33.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 4.559585ms)
Feb 13 22:40:33.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.625951ms)
Feb 13 22:40:33.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 4.77039ms)
Feb 13 22:40:33.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.763592ms)
Feb 13 22:40:33.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 4.790973ms)
Feb 13 22:40:33.126: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 5.909555ms)
Feb 13 22:40:33.127: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 6.008041ms)
Feb 13 22:40:33.127: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 6.435523ms)
Feb 13 22:40:33.127: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 6.176445ms)
Feb 13 22:40:33.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.639318ms)
Feb 13 22:40:33.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 7.681331ms)
Feb 13 22:40:33.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.799893ms)
Feb 13 22:40:33.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 7.885789ms)
Feb 13 22:40:33.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 7.951864ms)
Feb 13 22:40:33.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 7.863296ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.035434ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.116689ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.049012ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.18075ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 4.310059ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 4.165242ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 3.977802ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 4.146358ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 4.183527ms)
Feb 13 22:40:33.133: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 4.429674ms)
Feb 13 22:40:33.136: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.263182ms)
Feb 13 22:40:33.136: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 7.309742ms)
Feb 13 22:40:33.136: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 7.898576ms)
Feb 13 22:40:33.136: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 7.556389ms)
Feb 13 22:40:33.136: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 7.418991ms)
Feb 13 22:40:33.137: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 7.998492ms)
Feb 13 22:40:33.138: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 1.742163ms)
Feb 13 22:40:33.141: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.141841ms)
Feb 13 22:40:33.141: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 4.540383ms)
Feb 13 22:40:33.141: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.579355ms)
Feb 13 22:40:33.141: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 4.583621ms)
Feb 13 22:40:33.141: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 4.647109ms)
Feb 13 22:40:33.142: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 4.754454ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 7.972496ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 7.767923ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 7.893916ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 7.82032ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 7.952714ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 7.853952ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 7.810355ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 7.790105ms)
Feb 13 22:40:33.145: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 7.920231ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.522598ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:162/proxy/: bar (200; 4.504837ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 5.057876ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:462/proxy/: tls qux (200; 4.392301ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:1080/proxy/rewri... (200; 5.104492ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:443/proxy/... (200; 4.923124ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj/proxy/rewriteme"... (200; 4.860434ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/proxy-service-lgtbc-jndlj:160/proxy/: foo (200; 4.971444ms)
Feb 13 22:40:33.150: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/https:proxy-service-lgtbc-jndlj:460/proxy/: tls baz (200; 5.031588ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname2/proxy/: bar (200; 7.083342ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname1/proxy/: foo (200; 6.953523ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-q55wg/pods/http:proxy-service-lgtbc-jndlj:1080/proxy/... (200; 7.207804ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname1/proxy/: tls baz (200; 6.660453ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/http:proxy-service-lgtbc:portname1/proxy/: foo (200; 6.799053ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/https:proxy-service-lgtbc:tlsportname2/proxy/: tls qux (200; 6.863424ms)
Feb 13 22:40:33.152: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-q55wg/services/proxy-service-lgtbc:portname2/proxy/: bar (200; 6.345857ms)
STEP: deleting { ReplicationController} proxy-service-lgtbc in namespace e2e-tests-proxy-q55wg, will wait for the garbage collector to delete the pods
Feb 13 22:40:33.207: INFO: Deleting { ReplicationController} proxy-service-lgtbc took: 3.722261ms
Feb 13 22:40:33.307: INFO: Terminating { ReplicationController} proxy-service-lgtbc pods took: 100.138095ms
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:40:39.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-q55wg" for this suite.
Feb 13 22:40:45.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:40:45.345: INFO: namespace: e2e-tests-proxy-q55wg, resource: bindings, ignored listing per whitelist
Feb 13 22:40:45.355: INFO: namespace e2e-tests-proxy-q55wg deletion completed in 6.045219455s

• [SLOW TEST:19.602 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:40:45.356: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x5mgc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:40:45.499: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-x5mgc" to be "success or failure"
Feb 13 22:40:45.501: INFO: Pod "downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.290724ms
Feb 13 22:40:47.503: INFO: Pod "downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003825196s
STEP: Saw pod success
Feb 13 22:40:47.503: INFO: Pod "downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:40:47.504: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:40:47.515: INFO: Waiting for pod downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:40:47.516: INFO: Pod downwardapi-volume-66c60645-2fe0-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:40:47.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5mgc" for this suite.
Feb 13 22:40:53.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:40:53.549: INFO: namespace: e2e-tests-projected-x5mgc, resource: bindings, ignored listing per whitelist
Feb 13 22:40:53.574: INFO: namespace e2e-tests-projected-x5mgc deletion completed in 6.055501871s

• [SLOW TEST:8.218 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:40:53.574: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sdgwx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:40:53.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 version'
Feb 13 22:40:53.796: INFO: stderr: ""
Feb 13 22:40:53.796: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.5\", GitCommit:\"753b2dbc622f5cc417845f0ff8a77f539a4213ea\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T14:31:35Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:40:53.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sdgwx" for this suite.
Feb 13 22:40:59.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:40:59.846: INFO: namespace: e2e-tests-kubectl-sdgwx, resource: bindings, ignored listing per whitelist
Feb 13 22:40:59.851: INFO: namespace e2e-tests-kubectl-sdgwx deletion completed in 6.044114735s

• [SLOW TEST:6.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:40:59.852: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-52hvx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-6f68adf8-2fe0-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:40:59.988: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-52hvx" to be "success or failure"
Feb 13 22:40:59.992: INFO: Pod "pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.509072ms
Feb 13 22:41:01.993: INFO: Pod "pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005427454s
STEP: Saw pod success
Feb 13 22:41:01.994: INFO: Pod "pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:41:01.995: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:41:02.006: INFO: Waiting for pod pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:41:02.007: INFO: Pod pod-configmaps-6f690c6c-2fe0-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:41:02.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-52hvx" for this suite.
Feb 13 22:41:08.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:41:08.045: INFO: namespace: e2e-tests-configmap-52hvx, resource: bindings, ignored listing per whitelist
Feb 13 22:41:08.060: INFO: namespace e2e-tests-configmap-52hvx deletion completed in 6.050906478s

• [SLOW TEST:8.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:41:08.061: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-85mm8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-85mm8
I0213 22:41:08.198192      17 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-85mm8, replica count: 1
I0213 22:41:09.248490      17 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 22:41:10.248685      17 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 22:41:10.361: INFO: Created: latency-svc-qn7kz
Feb 13 22:41:10.363: INFO: Got endpoints: latency-svc-qn7kz [14.770324ms]
Feb 13 22:41:10.378: INFO: Created: latency-svc-74sww
Feb 13 22:41:10.381: INFO: Got endpoints: latency-svc-74sww [17.324806ms]
Feb 13 22:41:10.392: INFO: Created: latency-svc-4mw4z
Feb 13 22:41:10.401: INFO: Created: latency-svc-8c7mw
Feb 13 22:41:10.402: INFO: Got endpoints: latency-svc-8c7mw [37.652021ms]
Feb 13 22:41:10.402: INFO: Got endpoints: latency-svc-4mw4z [38.701642ms]
Feb 13 22:41:10.412: INFO: Created: latency-svc-jz84n
Feb 13 22:41:10.412: INFO: Got endpoints: latency-svc-jz84n [47.954649ms]
Feb 13 22:41:10.424: INFO: Created: latency-svc-4dtm6
Feb 13 22:41:10.426: INFO: Got endpoints: latency-svc-4dtm6 [62.576578ms]
Feb 13 22:41:10.438: INFO: Created: latency-svc-bqt6l
Feb 13 22:41:10.444: INFO: Got endpoints: latency-svc-bqt6l [80.149701ms]
Feb 13 22:41:10.451: INFO: Created: latency-svc-mvx5r
Feb 13 22:41:10.451: INFO: Got endpoints: latency-svc-mvx5r [87.186629ms]
Feb 13 22:41:10.482: INFO: Created: latency-svc-sjct2
Feb 13 22:41:10.482: INFO: Got endpoints: latency-svc-sjct2 [118.08023ms]
Feb 13 22:41:10.493: INFO: Created: latency-svc-rkq6h
Feb 13 22:41:10.498: INFO: Got endpoints: latency-svc-rkq6h [133.42022ms]
Feb 13 22:41:10.503: INFO: Created: latency-svc-d5wkd
Feb 13 22:41:10.507: INFO: Got endpoints: latency-svc-d5wkd [142.560932ms]
Feb 13 22:41:10.515: INFO: Created: latency-svc-bbfdv
Feb 13 22:41:10.520: INFO: Got endpoints: latency-svc-bbfdv [155.939704ms]
Feb 13 22:41:10.534: INFO: Created: latency-svc-rk9sh
Feb 13 22:41:10.540: INFO: Got endpoints: latency-svc-rk9sh [176.046994ms]
Feb 13 22:41:10.547: INFO: Created: latency-svc-chb8b
Feb 13 22:41:10.556: INFO: Got endpoints: latency-svc-chb8b [191.338232ms]
Feb 13 22:41:10.562: INFO: Created: latency-svc-6n4km
Feb 13 22:41:10.567: INFO: Got endpoints: latency-svc-6n4km [202.177037ms]
Feb 13 22:41:10.586: INFO: Created: latency-svc-mhwsh
Feb 13 22:41:10.589: INFO: Got endpoints: latency-svc-mhwsh [225.589785ms]
Feb 13 22:41:10.598: INFO: Created: latency-svc-4fnj2
Feb 13 22:41:10.604: INFO: Got endpoints: latency-svc-4fnj2 [222.824775ms]
Feb 13 22:41:10.613: INFO: Created: latency-svc-8tndh
Feb 13 22:41:10.615: INFO: Got endpoints: latency-svc-8tndh [213.133211ms]
Feb 13 22:41:10.625: INFO: Created: latency-svc-mlq5r
Feb 13 22:41:10.628: INFO: Got endpoints: latency-svc-mlq5r [225.339624ms]
Feb 13 22:41:10.642: INFO: Created: latency-svc-8pldj
Feb 13 22:41:10.644: INFO: Got endpoints: latency-svc-8pldj [231.707502ms]
Feb 13 22:41:10.673: INFO: Created: latency-svc-b2z8r
Feb 13 22:41:10.673: INFO: Got endpoints: latency-svc-b2z8r [246.837366ms]
Feb 13 22:41:10.687: INFO: Created: latency-svc-528cz
Feb 13 22:41:10.689: INFO: Got endpoints: latency-svc-528cz [245.102671ms]
Feb 13 22:41:10.702: INFO: Created: latency-svc-r7975
Feb 13 22:41:10.702: INFO: Got endpoints: latency-svc-r7975 [250.559901ms]
Feb 13 22:41:10.714: INFO: Created: latency-svc-v4vr4
Feb 13 22:41:10.734: INFO: Created: latency-svc-rxq7w
Feb 13 22:41:10.734: INFO: Got endpoints: latency-svc-v4vr4 [251.788718ms]
Feb 13 22:41:10.740: INFO: Got endpoints: latency-svc-rxq7w [242.297808ms]
Feb 13 22:41:10.757: INFO: Created: latency-svc-8r9x8
Feb 13 22:41:10.758: INFO: Got endpoints: latency-svc-8r9x8 [250.730572ms]
Feb 13 22:41:10.781: INFO: Created: latency-svc-g9kq9
Feb 13 22:41:10.782: INFO: Got endpoints: latency-svc-g9kq9 [261.975318ms]
Feb 13 22:41:10.792: INFO: Created: latency-svc-h9gl4
Feb 13 22:41:10.795: INFO: Got endpoints: latency-svc-h9gl4 [254.460444ms]
Feb 13 22:41:10.802: INFO: Created: latency-svc-627jw
Feb 13 22:41:10.807: INFO: Got endpoints: latency-svc-627jw [251.54752ms]
Feb 13 22:41:10.817: INFO: Created: latency-svc-ndg8w
Feb 13 22:41:10.817: INFO: Got endpoints: latency-svc-ndg8w [250.594417ms]
Feb 13 22:41:10.830: INFO: Created: latency-svc-5n6n2
Feb 13 22:41:10.831: INFO: Got endpoints: latency-svc-5n6n2 [241.642886ms]
Feb 13 22:41:10.844: INFO: Created: latency-svc-sdbgl
Feb 13 22:41:10.854: INFO: Got endpoints: latency-svc-sdbgl [250.440123ms]
Feb 13 22:41:10.859: INFO: Created: latency-svc-rhfrf
Feb 13 22:41:10.859: INFO: Got endpoints: latency-svc-rhfrf [244.074579ms]
Feb 13 22:41:10.869: INFO: Created: latency-svc-fv55k
Feb 13 22:41:10.872: INFO: Got endpoints: latency-svc-fv55k [243.800411ms]
Feb 13 22:41:10.888: INFO: Created: latency-svc-hjr5l
Feb 13 22:41:10.891: INFO: Got endpoints: latency-svc-hjr5l [246.857504ms]
Feb 13 22:41:10.902: INFO: Created: latency-svc-l45lh
Feb 13 22:41:10.902: INFO: Got endpoints: latency-svc-l45lh [228.268735ms]
Feb 13 22:41:10.909: INFO: Created: latency-svc-trbb7
Feb 13 22:41:10.915: INFO: Got endpoints: latency-svc-trbb7 [225.277427ms]
Feb 13 22:41:10.922: INFO: Created: latency-svc-7vpwh
Feb 13 22:41:10.924: INFO: Got endpoints: latency-svc-7vpwh [222.36264ms]
Feb 13 22:41:10.934: INFO: Created: latency-svc-bkc8m
Feb 13 22:41:10.941: INFO: Got endpoints: latency-svc-bkc8m [206.64662ms]
Feb 13 22:41:10.941: INFO: Created: latency-svc-vnbk9
Feb 13 22:41:10.943: INFO: Got endpoints: latency-svc-vnbk9 [203.055822ms]
Feb 13 22:41:10.946: INFO: Created: latency-svc-xnqm7
Feb 13 22:41:10.948: INFO: Got endpoints: latency-svc-xnqm7 [190.572668ms]
Feb 13 22:41:10.957: INFO: Created: latency-svc-gd9jg
Feb 13 22:41:10.964: INFO: Got endpoints: latency-svc-gd9jg [181.346625ms]
Feb 13 22:41:10.966: INFO: Created: latency-svc-4bsjp
Feb 13 22:41:10.972: INFO: Created: latency-svc-74r5z
Feb 13 22:41:10.981: INFO: Created: latency-svc-wf5f2
Feb 13 22:41:10.988: INFO: Created: latency-svc-dmhb7
Feb 13 22:41:11.057: INFO: Got endpoints: latency-svc-4bsjp [261.662909ms]
Feb 13 22:41:11.057: INFO: Created: latency-svc-m5pl6
Feb 13 22:41:11.082: INFO: Got endpoints: latency-svc-74r5z [274.207575ms]
Feb 13 22:41:11.092: INFO: Created: latency-svc-nl4z6
Feb 13 22:41:11.107: INFO: Created: latency-svc-7nrgc
Feb 13 22:41:11.113: INFO: Got endpoints: latency-svc-wf5f2 [295.302519ms]
Feb 13 22:41:11.114: INFO: Created: latency-svc-zq8sg
Feb 13 22:41:11.123: INFO: Created: latency-svc-rt6th
Feb 13 22:41:11.130: INFO: Created: latency-svc-qzjb7
Feb 13 22:41:11.144: INFO: Created: latency-svc-psmzs
Feb 13 22:41:11.152: INFO: Created: latency-svc-9d5lp
Feb 13 22:41:11.161: INFO: Created: latency-svc-ksjmc
Feb 13 22:41:11.162: INFO: Got endpoints: latency-svc-dmhb7 [331.187122ms]
Feb 13 22:41:11.168: INFO: Created: latency-svc-bsgq2
Feb 13 22:41:11.176: INFO: Created: latency-svc-dtcv9
Feb 13 22:41:11.186: INFO: Created: latency-svc-pnrzv
Feb 13 22:41:11.203: INFO: Created: latency-svc-fc72j
Feb 13 22:41:11.213: INFO: Got endpoints: latency-svc-m5pl6 [359.00579ms]
Feb 13 22:41:11.217: INFO: Created: latency-svc-zzg82
Feb 13 22:41:11.221: INFO: Created: latency-svc-bbfgh
Feb 13 22:41:11.232: INFO: Created: latency-svc-r5c25
Feb 13 22:41:11.260: INFO: Got endpoints: latency-svc-nl4z6 [400.533983ms]
Feb 13 22:41:11.270: INFO: Created: latency-svc-75s28
Feb 13 22:41:11.310: INFO: Got endpoints: latency-svc-7nrgc [437.837113ms]
Feb 13 22:41:11.321: INFO: Created: latency-svc-snxr6
Feb 13 22:41:11.360: INFO: Got endpoints: latency-svc-zq8sg [469.07588ms]
Feb 13 22:41:11.368: INFO: Created: latency-svc-r8n2q
Feb 13 22:41:11.410: INFO: Got endpoints: latency-svc-rt6th [508.277254ms]
Feb 13 22:41:11.418: INFO: Created: latency-svc-qvb65
Feb 13 22:41:11.460: INFO: Got endpoints: latency-svc-qzjb7 [545.895983ms]
Feb 13 22:41:11.472: INFO: Created: latency-svc-wpzkq
Feb 13 22:41:11.511: INFO: Got endpoints: latency-svc-psmzs [586.295819ms]
Feb 13 22:41:11.518: INFO: Created: latency-svc-ssjz6
Feb 13 22:41:11.560: INFO: Got endpoints: latency-svc-9d5lp [618.977954ms]
Feb 13 22:41:11.571: INFO: Created: latency-svc-xdbpk
Feb 13 22:41:11.610: INFO: Got endpoints: latency-svc-ksjmc [666.63318ms]
Feb 13 22:41:11.618: INFO: Created: latency-svc-h8rrv
Feb 13 22:41:11.661: INFO: Got endpoints: latency-svc-bsgq2 [712.046164ms]
Feb 13 22:41:11.670: INFO: Created: latency-svc-zmvfc
Feb 13 22:41:11.710: INFO: Got endpoints: latency-svc-dtcv9 [746.905854ms]
Feb 13 22:41:11.722: INFO: Created: latency-svc-dhpg4
Feb 13 22:41:11.760: INFO: Got endpoints: latency-svc-pnrzv [702.901686ms]
Feb 13 22:41:11.772: INFO: Created: latency-svc-tbd9l
Feb 13 22:41:11.810: INFO: Got endpoints: latency-svc-fc72j [727.866795ms]
Feb 13 22:41:11.823: INFO: Created: latency-svc-jpgsf
Feb 13 22:41:11.862: INFO: Got endpoints: latency-svc-zzg82 [748.77783ms]
Feb 13 22:41:11.874: INFO: Created: latency-svc-swc6k
Feb 13 22:41:11.911: INFO: Got endpoints: latency-svc-bbfgh [748.774951ms]
Feb 13 22:41:11.926: INFO: Created: latency-svc-g8mkb
Feb 13 22:41:11.961: INFO: Got endpoints: latency-svc-r5c25 [747.860258ms]
Feb 13 22:41:11.977: INFO: Created: latency-svc-pxjhl
Feb 13 22:41:12.012: INFO: Got endpoints: latency-svc-75s28 [751.435191ms]
Feb 13 22:41:12.028: INFO: Created: latency-svc-8w6wl
Feb 13 22:41:12.068: INFO: Got endpoints: latency-svc-snxr6 [757.942646ms]
Feb 13 22:41:12.085: INFO: Created: latency-svc-pdd4h
Feb 13 22:41:12.112: INFO: Got endpoints: latency-svc-r8n2q [752.093856ms]
Feb 13 22:41:12.134: INFO: Created: latency-svc-88tt8
Feb 13 22:41:12.160: INFO: Got endpoints: latency-svc-qvb65 [750.212201ms]
Feb 13 22:41:12.176: INFO: Created: latency-svc-xckst
Feb 13 22:41:12.211: INFO: Got endpoints: latency-svc-wpzkq [750.128669ms]
Feb 13 22:41:12.224: INFO: Created: latency-svc-2l77p
Feb 13 22:41:12.260: INFO: Got endpoints: latency-svc-ssjz6 [749.799816ms]
Feb 13 22:41:12.275: INFO: Created: latency-svc-bwgc8
Feb 13 22:41:12.314: INFO: Got endpoints: latency-svc-xdbpk [753.111366ms]
Feb 13 22:41:12.336: INFO: Created: latency-svc-hpqh2
Feb 13 22:41:12.360: INFO: Got endpoints: latency-svc-h8rrv [749.595358ms]
Feb 13 22:41:12.370: INFO: Created: latency-svc-8s4xw
Feb 13 22:41:12.412: INFO: Got endpoints: latency-svc-zmvfc [751.350825ms]
Feb 13 22:41:12.428: INFO: Created: latency-svc-h6blk
Feb 13 22:41:12.462: INFO: Got endpoints: latency-svc-dhpg4 [751.336531ms]
Feb 13 22:41:12.476: INFO: Created: latency-svc-2784k
Feb 13 22:41:12.517: INFO: Got endpoints: latency-svc-tbd9l [757.310183ms]
Feb 13 22:41:12.529: INFO: Created: latency-svc-rwtg7
Feb 13 22:41:12.561: INFO: Got endpoints: latency-svc-jpgsf [751.22218ms]
Feb 13 22:41:12.574: INFO: Created: latency-svc-xcs47
Feb 13 22:41:12.618: INFO: Got endpoints: latency-svc-swc6k [756.212345ms]
Feb 13 22:41:12.631: INFO: Created: latency-svc-9jcw5
Feb 13 22:41:12.661: INFO: Got endpoints: latency-svc-g8mkb [750.548837ms]
Feb 13 22:41:12.674: INFO: Created: latency-svc-v6rg9
Feb 13 22:41:12.717: INFO: Got endpoints: latency-svc-pxjhl [755.999251ms]
Feb 13 22:41:12.727: INFO: Created: latency-svc-sfs8t
Feb 13 22:41:12.763: INFO: Got endpoints: latency-svc-8w6wl [751.008431ms]
Feb 13 22:41:12.777: INFO: Created: latency-svc-zlcjw
Feb 13 22:41:12.811: INFO: Got endpoints: latency-svc-pdd4h [742.820018ms]
Feb 13 22:41:12.830: INFO: Created: latency-svc-72znh
Feb 13 22:41:12.860: INFO: Got endpoints: latency-svc-88tt8 [748.116532ms]
Feb 13 22:41:12.871: INFO: Created: latency-svc-zv4zx
Feb 13 22:41:12.914: INFO: Got endpoints: latency-svc-xckst [753.396022ms]
Feb 13 22:41:12.931: INFO: Created: latency-svc-nm84q
Feb 13 22:41:12.962: INFO: Got endpoints: latency-svc-2l77p [751.680686ms]
Feb 13 22:41:12.976: INFO: Created: latency-svc-vlsxh
Feb 13 22:41:13.010: INFO: Got endpoints: latency-svc-bwgc8 [748.29976ms]
Feb 13 22:41:13.022: INFO: Created: latency-svc-2r5bz
Feb 13 22:41:13.062: INFO: Got endpoints: latency-svc-hpqh2 [748.414314ms]
Feb 13 22:41:13.079: INFO: Created: latency-svc-gx8gf
Feb 13 22:41:13.111: INFO: Got endpoints: latency-svc-8s4xw [751.20683ms]
Feb 13 22:41:13.124: INFO: Created: latency-svc-74hqn
Feb 13 22:41:13.162: INFO: Got endpoints: latency-svc-h6blk [750.09706ms]
Feb 13 22:41:13.179: INFO: Created: latency-svc-qj4gd
Feb 13 22:41:13.211: INFO: Got endpoints: latency-svc-2784k [748.668298ms]
Feb 13 22:41:13.223: INFO: Created: latency-svc-8v8zp
Feb 13 22:41:13.261: INFO: Got endpoints: latency-svc-rwtg7 [744.09602ms]
Feb 13 22:41:13.273: INFO: Created: latency-svc-h8949
Feb 13 22:41:13.311: INFO: Got endpoints: latency-svc-xcs47 [750.056355ms]
Feb 13 22:41:13.324: INFO: Created: latency-svc-s9662
Feb 13 22:41:13.363: INFO: Got endpoints: latency-svc-9jcw5 [744.816264ms]
Feb 13 22:41:13.376: INFO: Created: latency-svc-qsht4
Feb 13 22:41:13.411: INFO: Got endpoints: latency-svc-v6rg9 [749.652725ms]
Feb 13 22:41:13.425: INFO: Created: latency-svc-m4lcd
Feb 13 22:41:13.471: INFO: Got endpoints: latency-svc-sfs8t [753.389636ms]
Feb 13 22:41:13.483: INFO: Created: latency-svc-t4rgk
Feb 13 22:41:13.510: INFO: Got endpoints: latency-svc-zlcjw [747.490773ms]
Feb 13 22:41:13.523: INFO: Created: latency-svc-zjfkd
Feb 13 22:41:13.563: INFO: Got endpoints: latency-svc-72znh [752.333778ms]
Feb 13 22:41:13.578: INFO: Created: latency-svc-mgxs7
Feb 13 22:41:13.611: INFO: Got endpoints: latency-svc-zv4zx [750.560041ms]
Feb 13 22:41:13.623: INFO: Created: latency-svc-wq9h9
Feb 13 22:41:13.661: INFO: Got endpoints: latency-svc-nm84q [747.291925ms]
Feb 13 22:41:13.675: INFO: Created: latency-svc-mmqrm
Feb 13 22:41:13.711: INFO: Got endpoints: latency-svc-vlsxh [748.891077ms]
Feb 13 22:41:13.735: INFO: Created: latency-svc-lrh5z
Feb 13 22:41:13.761: INFO: Got endpoints: latency-svc-2r5bz [750.842422ms]
Feb 13 22:41:13.789: INFO: Created: latency-svc-mtn8k
Feb 13 22:41:13.814: INFO: Got endpoints: latency-svc-gx8gf [751.869655ms]
Feb 13 22:41:13.825: INFO: Created: latency-svc-z5wds
Feb 13 22:41:13.861: INFO: Got endpoints: latency-svc-74hqn [749.993073ms]
Feb 13 22:41:13.876: INFO: Created: latency-svc-gbgm7
Feb 13 22:41:13.914: INFO: Got endpoints: latency-svc-qj4gd [751.333181ms]
Feb 13 22:41:13.926: INFO: Created: latency-svc-4826r
Feb 13 22:41:13.960: INFO: Got endpoints: latency-svc-8v8zp [749.276433ms]
Feb 13 22:41:13.975: INFO: Created: latency-svc-cj29q
Feb 13 22:41:14.014: INFO: Got endpoints: latency-svc-h8949 [752.760649ms]
Feb 13 22:41:14.027: INFO: Created: latency-svc-vwh8b
Feb 13 22:41:14.060: INFO: Got endpoints: latency-svc-s9662 [748.373547ms]
Feb 13 22:41:14.070: INFO: Created: latency-svc-jp4qx
Feb 13 22:41:14.112: INFO: Got endpoints: latency-svc-qsht4 [748.809568ms]
Feb 13 22:41:14.129: INFO: Created: latency-svc-9w4cb
Feb 13 22:41:14.162: INFO: Got endpoints: latency-svc-m4lcd [751.402844ms]
Feb 13 22:41:14.175: INFO: Created: latency-svc-96x4z
Feb 13 22:41:14.211: INFO: Got endpoints: latency-svc-t4rgk [739.954063ms]
Feb 13 22:41:14.229: INFO: Created: latency-svc-ldrwn
Feb 13 22:41:14.261: INFO: Got endpoints: latency-svc-zjfkd [750.995041ms]
Feb 13 22:41:14.273: INFO: Created: latency-svc-qjpr8
Feb 13 22:41:14.311: INFO: Got endpoints: latency-svc-mgxs7 [747.382413ms]
Feb 13 22:41:14.323: INFO: Created: latency-svc-ngwdf
Feb 13 22:41:14.361: INFO: Got endpoints: latency-svc-wq9h9 [749.618067ms]
Feb 13 22:41:14.372: INFO: Created: latency-svc-d5bmn
Feb 13 22:41:14.410: INFO: Got endpoints: latency-svc-mmqrm [748.876935ms]
Feb 13 22:41:14.424: INFO: Created: latency-svc-9wvdb
Feb 13 22:41:14.462: INFO: Got endpoints: latency-svc-lrh5z [750.624899ms]
Feb 13 22:41:14.476: INFO: Created: latency-svc-7rplc
Feb 13 22:41:14.516: INFO: Got endpoints: latency-svc-mtn8k [755.04531ms]
Feb 13 22:41:14.530: INFO: Created: latency-svc-s5fkj
Feb 13 22:41:14.561: INFO: Got endpoints: latency-svc-z5wds [746.846396ms]
Feb 13 22:41:14.575: INFO: Created: latency-svc-mkhr2
Feb 13 22:41:14.613: INFO: Got endpoints: latency-svc-gbgm7 [751.885853ms]
Feb 13 22:41:14.628: INFO: Created: latency-svc-9qrg6
Feb 13 22:41:14.667: INFO: Got endpoints: latency-svc-4826r [752.598267ms]
Feb 13 22:41:14.678: INFO: Created: latency-svc-drbvg
Feb 13 22:41:14.714: INFO: Got endpoints: latency-svc-cj29q [752.90503ms]
Feb 13 22:41:14.727: INFO: Created: latency-svc-2fm4v
Feb 13 22:41:14.762: INFO: Got endpoints: latency-svc-vwh8b [747.321041ms]
Feb 13 22:41:14.778: INFO: Created: latency-svc-6k5kw
Feb 13 22:41:14.811: INFO: Got endpoints: latency-svc-jp4qx [750.57903ms]
Feb 13 22:41:14.828: INFO: Created: latency-svc-tpwn8
Feb 13 22:41:14.865: INFO: Got endpoints: latency-svc-9w4cb [752.703307ms]
Feb 13 22:41:14.886: INFO: Created: latency-svc-krfpl
Feb 13 22:41:14.912: INFO: Got endpoints: latency-svc-96x4z [749.486153ms]
Feb 13 22:41:15.005: INFO: Got endpoints: latency-svc-ldrwn [793.66937ms]
Feb 13 22:41:15.022: INFO: Created: latency-svc-xwmnx
Feb 13 22:41:15.022: INFO: Got endpoints: latency-svc-qjpr8 [760.55386ms]
Feb 13 22:41:15.035: INFO: Created: latency-svc-jqc47
Feb 13 22:41:15.043: INFO: Created: latency-svc-vbh2v
Feb 13 22:41:15.060: INFO: Got endpoints: latency-svc-ngwdf [749.557544ms]
Feb 13 22:41:15.071: INFO: Created: latency-svc-5lm2q
Feb 13 22:41:15.112: INFO: Got endpoints: latency-svc-d5bmn [751.128352ms]
Feb 13 22:41:15.129: INFO: Created: latency-svc-dz2nw
Feb 13 22:41:15.164: INFO: Got endpoints: latency-svc-9wvdb [753.625791ms]
Feb 13 22:41:15.177: INFO: Created: latency-svc-q8mb4
Feb 13 22:41:15.210: INFO: Got endpoints: latency-svc-7rplc [747.786237ms]
Feb 13 22:41:15.226: INFO: Created: latency-svc-6d7l5
Feb 13 22:41:15.261: INFO: Got endpoints: latency-svc-s5fkj [744.929541ms]
Feb 13 22:41:15.277: INFO: Created: latency-svc-x7bmq
Feb 13 22:41:15.311: INFO: Got endpoints: latency-svc-mkhr2 [749.482937ms]
Feb 13 22:41:15.356: INFO: Created: latency-svc-xq5jp
Feb 13 22:41:15.360: INFO: Got endpoints: latency-svc-9qrg6 [747.158767ms]
Feb 13 22:41:15.372: INFO: Created: latency-svc-whkk6
Feb 13 22:41:15.411: INFO: Got endpoints: latency-svc-drbvg [744.195663ms]
Feb 13 22:41:15.422: INFO: Created: latency-svc-cxx8z
Feb 13 22:41:15.462: INFO: Got endpoints: latency-svc-2fm4v [747.906288ms]
Feb 13 22:41:15.475: INFO: Created: latency-svc-t2frb
Feb 13 22:41:15.510: INFO: Got endpoints: latency-svc-6k5kw [748.077702ms]
Feb 13 22:41:15.523: INFO: Created: latency-svc-7n8q5
Feb 13 22:41:15.560: INFO: Got endpoints: latency-svc-tpwn8 [749.473784ms]
Feb 13 22:41:15.576: INFO: Created: latency-svc-95zsr
Feb 13 22:41:15.610: INFO: Got endpoints: latency-svc-krfpl [745.441655ms]
Feb 13 22:41:15.620: INFO: Created: latency-svc-8mj46
Feb 13 22:41:15.661: INFO: Got endpoints: latency-svc-xwmnx [748.860155ms]
Feb 13 22:41:15.677: INFO: Created: latency-svc-6zdwt
Feb 13 22:41:15.712: INFO: Got endpoints: latency-svc-jqc47 [707.31036ms]
Feb 13 22:41:15.725: INFO: Created: latency-svc-j8tvp
Feb 13 22:41:15.761: INFO: Got endpoints: latency-svc-vbh2v [738.714564ms]
Feb 13 22:41:15.770: INFO: Created: latency-svc-dgmj2
Feb 13 22:41:15.811: INFO: Got endpoints: latency-svc-5lm2q [750.712111ms]
Feb 13 22:41:15.823: INFO: Created: latency-svc-22vd9
Feb 13 22:41:15.862: INFO: Got endpoints: latency-svc-dz2nw [749.460957ms]
Feb 13 22:41:15.876: INFO: Created: latency-svc-9d5nd
Feb 13 22:41:15.911: INFO: Got endpoints: latency-svc-q8mb4 [746.388316ms]
Feb 13 22:41:15.920: INFO: Created: latency-svc-b5l75
Feb 13 22:41:15.961: INFO: Got endpoints: latency-svc-6d7l5 [751.541985ms]
Feb 13 22:41:15.971: INFO: Created: latency-svc-b7n5w
Feb 13 22:41:16.012: INFO: Got endpoints: latency-svc-x7bmq [750.373382ms]
Feb 13 22:41:16.024: INFO: Created: latency-svc-6hnzl
Feb 13 22:41:16.063: INFO: Got endpoints: latency-svc-xq5jp [752.031216ms]
Feb 13 22:41:16.074: INFO: Created: latency-svc-jqsh6
Feb 13 22:41:16.111: INFO: Got endpoints: latency-svc-whkk6 [750.452314ms]
Feb 13 22:41:16.123: INFO: Created: latency-svc-97rl4
Feb 13 22:41:16.161: INFO: Got endpoints: latency-svc-cxx8z [750.258575ms]
Feb 13 22:41:16.174: INFO: Created: latency-svc-lcqd5
Feb 13 22:41:16.212: INFO: Got endpoints: latency-svc-t2frb [750.500343ms]
Feb 13 22:41:16.223: INFO: Created: latency-svc-gqdbd
Feb 13 22:41:16.260: INFO: Got endpoints: latency-svc-7n8q5 [750.184143ms]
Feb 13 22:41:16.272: INFO: Created: latency-svc-lljhh
Feb 13 22:41:16.312: INFO: Got endpoints: latency-svc-95zsr [751.00484ms]
Feb 13 22:41:16.329: INFO: Created: latency-svc-lswqf
Feb 13 22:41:16.361: INFO: Got endpoints: latency-svc-8mj46 [750.91558ms]
Feb 13 22:41:16.376: INFO: Created: latency-svc-bjls9
Feb 13 22:41:16.412: INFO: Got endpoints: latency-svc-6zdwt [750.280531ms]
Feb 13 22:41:16.429: INFO: Created: latency-svc-64jrh
Feb 13 22:41:16.461: INFO: Got endpoints: latency-svc-j8tvp [749.148183ms]
Feb 13 22:41:16.471: INFO: Created: latency-svc-twfbd
Feb 13 22:41:16.511: INFO: Got endpoints: latency-svc-dgmj2 [749.726058ms]
Feb 13 22:41:16.521: INFO: Created: latency-svc-b2trx
Feb 13 22:41:16.561: INFO: Got endpoints: latency-svc-22vd9 [749.9823ms]
Feb 13 22:41:16.579: INFO: Created: latency-svc-78wpb
Feb 13 22:41:16.614: INFO: Got endpoints: latency-svc-9d5nd [751.557307ms]
Feb 13 22:41:16.625: INFO: Created: latency-svc-dvggp
Feb 13 22:41:16.660: INFO: Got endpoints: latency-svc-b5l75 [749.512944ms]
Feb 13 22:41:16.672: INFO: Created: latency-svc-2szkv
Feb 13 22:41:16.710: INFO: Got endpoints: latency-svc-b7n5w [748.565094ms]
Feb 13 22:41:16.722: INFO: Created: latency-svc-5c8rk
Feb 13 22:41:16.761: INFO: Got endpoints: latency-svc-6hnzl [749.35732ms]
Feb 13 22:41:16.775: INFO: Created: latency-svc-bjr45
Feb 13 22:41:16.811: INFO: Got endpoints: latency-svc-jqsh6 [747.711186ms]
Feb 13 22:41:16.824: INFO: Created: latency-svc-b4ctn
Feb 13 22:41:16.861: INFO: Got endpoints: latency-svc-97rl4 [749.610275ms]
Feb 13 22:41:16.875: INFO: Created: latency-svc-n4tb5
Feb 13 22:41:16.910: INFO: Got endpoints: latency-svc-lcqd5 [748.758392ms]
Feb 13 22:41:16.919: INFO: Created: latency-svc-vcxwv
Feb 13 22:41:16.961: INFO: Got endpoints: latency-svc-gqdbd [748.551842ms]
Feb 13 22:41:16.983: INFO: Created: latency-svc-cd5nx
Feb 13 22:41:17.010: INFO: Got endpoints: latency-svc-lljhh [749.526837ms]
Feb 13 22:41:17.025: INFO: Created: latency-svc-tl4mx
Feb 13 22:41:17.064: INFO: Got endpoints: latency-svc-lswqf [751.937756ms]
Feb 13 22:41:17.076: INFO: Created: latency-svc-cjwc9
Feb 13 22:41:17.111: INFO: Got endpoints: latency-svc-bjls9 [749.432979ms]
Feb 13 22:41:17.124: INFO: Created: latency-svc-fskpw
Feb 13 22:41:17.161: INFO: Got endpoints: latency-svc-64jrh [749.023416ms]
Feb 13 22:41:17.178: INFO: Created: latency-svc-rhk8v
Feb 13 22:41:17.211: INFO: Got endpoints: latency-svc-twfbd [749.831003ms]
Feb 13 22:41:17.224: INFO: Created: latency-svc-2l9vp
Feb 13 22:41:17.262: INFO: Got endpoints: latency-svc-b2trx [751.26361ms]
Feb 13 22:41:17.281: INFO: Created: latency-svc-sd8zk
Feb 13 22:41:17.315: INFO: Got endpoints: latency-svc-78wpb [753.691982ms]
Feb 13 22:41:17.333: INFO: Created: latency-svc-48b4l
Feb 13 22:41:17.361: INFO: Got endpoints: latency-svc-dvggp [747.291362ms]
Feb 13 22:41:17.371: INFO: Created: latency-svc-gbwr9
Feb 13 22:41:17.411: INFO: Got endpoints: latency-svc-2szkv [750.970753ms]
Feb 13 22:41:17.421: INFO: Created: latency-svc-6rc2p
Feb 13 22:41:17.463: INFO: Got endpoints: latency-svc-5c8rk [752.34861ms]
Feb 13 22:41:17.480: INFO: Created: latency-svc-xkh4p
Feb 13 22:41:17.513: INFO: Got endpoints: latency-svc-bjr45 [751.563476ms]
Feb 13 22:41:17.532: INFO: Created: latency-svc-nm62l
Feb 13 22:41:17.560: INFO: Got endpoints: latency-svc-b4ctn [749.176048ms]
Feb 13 22:41:17.573: INFO: Created: latency-svc-4v4xq
Feb 13 22:41:17.611: INFO: Got endpoints: latency-svc-n4tb5 [750.140516ms]
Feb 13 22:41:17.621: INFO: Created: latency-svc-z85xx
Feb 13 22:41:17.660: INFO: Got endpoints: latency-svc-vcxwv [750.377249ms]
Feb 13 22:41:17.670: INFO: Created: latency-svc-8htl6
Feb 13 22:41:17.710: INFO: Got endpoints: latency-svc-cd5nx [749.210354ms]
Feb 13 22:41:17.722: INFO: Created: latency-svc-8j957
Feb 13 22:41:17.765: INFO: Got endpoints: latency-svc-tl4mx [754.316457ms]
Feb 13 22:41:17.780: INFO: Created: latency-svc-g4zdb
Feb 13 22:41:17.812: INFO: Got endpoints: latency-svc-cjwc9 [747.541487ms]
Feb 13 22:41:17.824: INFO: Created: latency-svc-49wjm
Feb 13 22:41:17.860: INFO: Got endpoints: latency-svc-fskpw [749.157303ms]
Feb 13 22:41:17.876: INFO: Created: latency-svc-z5r7g
Feb 13 22:41:17.911: INFO: Got endpoints: latency-svc-rhk8v [750.157949ms]
Feb 13 22:41:17.925: INFO: Created: latency-svc-b68rw
Feb 13 22:41:17.960: INFO: Got endpoints: latency-svc-2l9vp [748.261605ms]
Feb 13 22:41:17.972: INFO: Created: latency-svc-7mdhm
Feb 13 22:41:18.011: INFO: Got endpoints: latency-svc-sd8zk [748.941226ms]
Feb 13 22:41:18.027: INFO: Created: latency-svc-gzk9g
Feb 13 22:41:18.060: INFO: Got endpoints: latency-svc-48b4l [744.681969ms]
Feb 13 22:41:18.074: INFO: Created: latency-svc-72k8s
Feb 13 22:41:18.111: INFO: Got endpoints: latency-svc-gbwr9 [749.529218ms]
Feb 13 22:41:18.121: INFO: Created: latency-svc-9ddbn
Feb 13 22:41:18.162: INFO: Got endpoints: latency-svc-6rc2p [750.28573ms]
Feb 13 22:41:18.174: INFO: Created: latency-svc-t2j5d
Feb 13 22:41:18.211: INFO: Got endpoints: latency-svc-xkh4p [748.348211ms]
Feb 13 22:41:18.261: INFO: Got endpoints: latency-svc-nm62l [747.458018ms]
Feb 13 22:41:18.311: INFO: Got endpoints: latency-svc-4v4xq [750.212846ms]
Feb 13 22:41:18.361: INFO: Got endpoints: latency-svc-z85xx [749.455542ms]
Feb 13 22:41:18.410: INFO: Got endpoints: latency-svc-8htl6 [749.880461ms]
Feb 13 22:41:18.461: INFO: Got endpoints: latency-svc-8j957 [750.172262ms]
Feb 13 22:41:18.511: INFO: Got endpoints: latency-svc-g4zdb [746.095427ms]
Feb 13 22:41:18.561: INFO: Got endpoints: latency-svc-49wjm [748.928272ms]
Feb 13 22:41:18.611: INFO: Got endpoints: latency-svc-z5r7g [750.891298ms]
Feb 13 22:41:18.660: INFO: Got endpoints: latency-svc-b68rw [749.096858ms]
Feb 13 22:41:18.711: INFO: Got endpoints: latency-svc-7mdhm [751.256027ms]
Feb 13 22:41:18.760: INFO: Got endpoints: latency-svc-gzk9g [749.451949ms]
Feb 13 22:41:18.811: INFO: Got endpoints: latency-svc-72k8s [750.941138ms]
Feb 13 22:41:18.860: INFO: Got endpoints: latency-svc-9ddbn [748.944531ms]
Feb 13 22:41:18.911: INFO: Got endpoints: latency-svc-t2j5d [749.17736ms]
Feb 13 22:41:18.911: INFO: Latencies: [17.324806ms 37.652021ms 38.701642ms 47.954649ms 62.576578ms 80.149701ms 87.186629ms 118.08023ms 133.42022ms 142.560932ms 155.939704ms 176.046994ms 181.346625ms 190.572668ms 191.338232ms 202.177037ms 203.055822ms 206.64662ms 213.133211ms 222.36264ms 222.824775ms 225.277427ms 225.339624ms 225.589785ms 228.268735ms 231.707502ms 241.642886ms 242.297808ms 243.800411ms 244.074579ms 245.102671ms 246.837366ms 246.857504ms 250.440123ms 250.559901ms 250.594417ms 250.730572ms 251.54752ms 251.788718ms 254.460444ms 261.662909ms 261.975318ms 274.207575ms 295.302519ms 331.187122ms 359.00579ms 400.533983ms 437.837113ms 469.07588ms 508.277254ms 545.895983ms 586.295819ms 618.977954ms 666.63318ms 702.901686ms 707.31036ms 712.046164ms 727.866795ms 738.714564ms 739.954063ms 742.820018ms 744.09602ms 744.195663ms 744.681969ms 744.816264ms 744.929541ms 745.441655ms 746.095427ms 746.388316ms 746.846396ms 746.905854ms 747.158767ms 747.291362ms 747.291925ms 747.321041ms 747.382413ms 747.458018ms 747.490773ms 747.541487ms 747.711186ms 747.786237ms 747.860258ms 747.906288ms 748.077702ms 748.116532ms 748.261605ms 748.29976ms 748.348211ms 748.373547ms 748.414314ms 748.551842ms 748.565094ms 748.668298ms 748.758392ms 748.774951ms 748.77783ms 748.809568ms 748.860155ms 748.876935ms 748.891077ms 748.928272ms 748.941226ms 748.944531ms 749.023416ms 749.096858ms 749.148183ms 749.157303ms 749.176048ms 749.17736ms 749.210354ms 749.276433ms 749.35732ms 749.432979ms 749.451949ms 749.455542ms 749.460957ms 749.473784ms 749.482937ms 749.486153ms 749.512944ms 749.526837ms 749.529218ms 749.557544ms 749.595358ms 749.610275ms 749.618067ms 749.652725ms 749.726058ms 749.799816ms 749.831003ms 749.880461ms 749.9823ms 749.993073ms 750.056355ms 750.09706ms 750.128669ms 750.140516ms 750.157949ms 750.172262ms 750.184143ms 750.212201ms 750.212846ms 750.258575ms 750.280531ms 750.28573ms 750.373382ms 750.377249ms 750.452314ms 750.500343ms 750.548837ms 750.560041ms 750.57903ms 750.624899ms 750.712111ms 750.842422ms 750.891298ms 750.91558ms 750.941138ms 750.970753ms 750.995041ms 751.00484ms 751.008431ms 751.128352ms 751.20683ms 751.22218ms 751.256027ms 751.26361ms 751.333181ms 751.336531ms 751.350825ms 751.402844ms 751.435191ms 751.541985ms 751.557307ms 751.563476ms 751.680686ms 751.869655ms 751.885853ms 751.937756ms 752.031216ms 752.093856ms 752.333778ms 752.34861ms 752.598267ms 752.703307ms 752.760649ms 752.90503ms 753.111366ms 753.389636ms 753.396022ms 753.625791ms 753.691982ms 754.316457ms 755.04531ms 755.999251ms 756.212345ms 757.310183ms 757.942646ms 760.55386ms 793.66937ms]
Feb 13 22:41:18.912: INFO: 50 %ile: 748.928272ms
Feb 13 22:41:18.912: INFO: 90 %ile: 752.093856ms
Feb 13 22:41:18.912: INFO: 99 %ile: 760.55386ms
Feb 13 22:41:18.912: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:41:18.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-85mm8" for this suite.
Feb 13 22:41:30.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:41:30.961: INFO: namespace: e2e-tests-svc-latency-85mm8, resource: bindings, ignored listing per whitelist
Feb 13 22:41:30.965: INFO: namespace e2e-tests-svc-latency-85mm8 deletion completed in 12.048194353s

• [SLOW TEST:22.904 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:41:30.966: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-cwhlv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-cwhlv
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-cwhlv
STEP: Deleting pre-stop pod
Feb 13 22:41:44.125: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:41:44.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-cwhlv" for this suite.
Feb 13 22:42:22.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:42:22.176: INFO: namespace: e2e-tests-prestop-cwhlv, resource: bindings, ignored listing per whitelist
Feb 13 22:42:22.178: INFO: namespace e2e-tests-prestop-cwhlv deletion completed in 38.045732675s

• [SLOW TEST:51.212 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:42:22.178: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tjc5x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-a07b0bcd-2fe0-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:42:22.317: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-tjc5x" to be "success or failure"
Feb 13 22:42:22.320: INFO: Pod "pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.542533ms
Feb 13 22:42:24.322: INFO: Pod "pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004487158s
STEP: Saw pod success
Feb 13 22:42:24.322: INFO: Pod "pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:42:24.323: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:42:24.335: INFO: Waiting for pod pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:42:24.336: INFO: Pod pod-projected-configmaps-a07b5608-2fe0-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:42:24.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tjc5x" for this suite.
Feb 13 22:42:30.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:42:30.374: INFO: namespace: e2e-tests-projected-tjc5x, resource: bindings, ignored listing per whitelist
Feb 13 22:42:30.389: INFO: namespace e2e-tests-projected-tjc5x deletion completed in 6.051074729s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:42:30.390: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4cszj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4cszj
Feb 13 22:42:32.535: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4cszj
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:42:32.536: INFO: Initial restart count of pod liveness-http is 0
Feb 13 22:42:52.556: INFO: Restart count of pod e2e-tests-container-probe-4cszj/liveness-http is now 1 (20.020138567s elapsed)
Feb 13 22:43:12.574: INFO: Restart count of pod e2e-tests-container-probe-4cszj/liveness-http is now 2 (40.038494377s elapsed)
Feb 13 22:43:32.595: INFO: Restart count of pod e2e-tests-container-probe-4cszj/liveness-http is now 3 (1m0.058710135s elapsed)
Feb 13 22:43:52.613: INFO: Restart count of pod e2e-tests-container-probe-4cszj/liveness-http is now 4 (1m20.07689094s elapsed)
Feb 13 22:44:54.671: INFO: Restart count of pod e2e-tests-container-probe-4cszj/liveness-http is now 5 (2m22.134800051s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:44:54.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4cszj" for this suite.
Feb 13 22:45:00.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:45:00.711: INFO: namespace: e2e-tests-container-probe-4cszj, resource: bindings, ignored listing per whitelist
Feb 13 22:45:00.726: INFO: namespace e2e-tests-container-probe-4cszj deletion completed in 6.043504086s

• [SLOW TEST:150.336 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:45:00.726: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pgp8x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 13 22:45:00.865: INFO: Waiting up to 5m0s for pod "pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-pgp8x" to be "success or failure"
Feb 13 22:45:00.871: INFO: Pod "pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.722975ms
Feb 13 22:45:02.873: INFO: Pod "pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007717892s
STEP: Saw pod success
Feb 13 22:45:02.873: INFO: Pod "pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:45:02.874: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:45:02.887: INFO: Waiting for pod pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:45:02.888: INFO: Pod pod-fefbb39c-2fe0-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:45:02.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pgp8x" for this suite.
Feb 13 22:45:08.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:45:08.927: INFO: namespace: e2e-tests-emptydir-pgp8x, resource: bindings, ignored listing per whitelist
Feb 13 22:45:08.941: INFO: namespace e2e-tests-emptydir-pgp8x deletion completed in 6.05028637s

• [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:45:08.941: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ss2fj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 13 22:45:09.088: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ss2fj,SelfLink:/api/v1/namespaces/e2e-tests-watch-ss2fj/configmaps/e2e-watch-test-resource-version,UID:03e189ea-2fe1-11e9-80e0-0050569e5ced,ResourceVersion:25033,Generation:0,CreationTimestamp:2019-02-13 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 22:45:09.088: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ss2fj,SelfLink:/api/v1/namespaces/e2e-tests-watch-ss2fj/configmaps/e2e-watch-test-resource-version,UID:03e189ea-2fe1-11e9-80e0-0050569e5ced,ResourceVersion:25034,Generation:0,CreationTimestamp:2019-02-13 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:45:09.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ss2fj" for this suite.
Feb 13 22:45:15.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:45:15.128: INFO: namespace: e2e-tests-watch-ss2fj, resource: bindings, ignored listing per whitelist
Feb 13 22:45:15.136: INFO: namespace e2e-tests-watch-ss2fj deletion completed in 6.043870711s

• [SLOW TEST:6.195 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:45:15.137: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ltqbw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Feb 13 22:45:15.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-ltqbw'
Feb 13 22:45:15.576: INFO: stderr: ""
Feb 13 22:45:15.576: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
Feb 13 22:45:17.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-208905800 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-ltqbw'
Feb 13 22:45:17.660: INFO: stderr: ""
Feb 13 22:45:17.660: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:45:17.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ltqbw" for this suite.
Feb 13 22:45:23.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:45:23.742: INFO: namespace: e2e-tests-kubectl-ltqbw, resource: bindings, ignored listing per whitelist
Feb 13 22:45:23.753: INFO: namespace e2e-tests-kubectl-ltqbw deletion completed in 6.088054545s

• [SLOW TEST:8.616 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:45:23.753: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nvbth
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:45:23.912: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-downward-api-nvbth" to be "success or failure"
Feb 13 22:45:23.916: INFO: Pod "downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.842768ms
Feb 13 22:45:25.918: INFO: Pod "downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005409152s
STEP: Saw pod success
Feb 13 22:45:25.918: INFO: Pod "downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:45:25.919: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:45:25.933: INFO: Waiting for pod downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:45:25.934: INFO: Pod downwardapi-volume-0cb89f6a-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:45:25.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nvbth" for this suite.
Feb 13 22:45:31.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:45:31.950: INFO: namespace: e2e-tests-downward-api-nvbth, resource: bindings, ignored listing per whitelist
Feb 13 22:45:31.984: INFO: namespace e2e-tests-downward-api-nvbth deletion completed in 6.047977308s

• [SLOW TEST:8.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:45:31.985: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-p9n26
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 13 22:45:36.138: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.138: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.184: INFO: Exec stderr: ""
Feb 13 22:45:36.184: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.184: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.227: INFO: Exec stderr: ""
Feb 13 22:45:36.227: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.227: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.279: INFO: Exec stderr: ""
Feb 13 22:45:36.279: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.279: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.328: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 13 22:45:36.328: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.328: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.373: INFO: Exec stderr: ""
Feb 13 22:45:36.373: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.373: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.431: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 13 22:45:36.431: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.431: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.468: INFO: Exec stderr: ""
Feb 13 22:45:36.468: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.468: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.527: INFO: Exec stderr: ""
Feb 13 22:45:36.527: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.527: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.563: INFO: Exec stderr: ""
Feb 13 22:45:36.563: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p9n26 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:45:36.563: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
Feb 13 22:45:36.599: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:45:36.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-p9n26" for this suite.
Feb 13 22:46:20.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:46:20.633: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-p9n26, resource: bindings, ignored listing per whitelist
Feb 13 22:46:20.645: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-p9n26 deletion completed in 44.042766964s

• [SLOW TEST:48.660 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:46:20.646: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-f2krp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 13 22:46:20.784: INFO: Waiting up to 5m0s for pod "pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-f2krp" to be "success or failure"
Feb 13 22:46:20.788: INFO: Pod "pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.882141ms
Feb 13 22:46:22.790: INFO: Pod "pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005638244s
STEP: Saw pod success
Feb 13 22:46:22.790: INFO: Pod "pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:46:22.791: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:46:22.803: INFO: Waiting for pod pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:46:22.805: INFO: Pod pod-2e9e8135-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:46:22.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f2krp" for this suite.
Feb 13 22:46:28.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:46:28.845: INFO: namespace: e2e-tests-emptydir-f2krp, resource: bindings, ignored listing per whitelist
Feb 13 22:46:28.851: INFO: namespace e2e-tests-emptydir-f2krp deletion completed in 6.044496715s

• [SLOW TEST:8.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:46:28.851: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-hskqw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-33825ce1-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: Creating secret with name s-test-opt-upd-33825d08-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-33825ce1-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: Updating secret s-test-opt-upd-33825d08-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: Creating secret with name s-test-opt-create-33825d1a-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:46:35.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hskqw" for this suite.
Feb 13 22:46:57.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:46:57.072: INFO: namespace: e2e-tests-secrets-hskqw, resource: bindings, ignored listing per whitelist
Feb 13 22:46:57.075: INFO: namespace e2e-tests-secrets-hskqw deletion completed in 22.040122119s

• [SLOW TEST:28.224 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:46:57.076: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nvpft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-4455b8a9-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume secrets
Feb 13 22:46:57.220: INFO: Waiting up to 5m0s for pod "pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-secrets-nvpft" to be "success or failure"
Feb 13 22:46:57.225: INFO: Pod "pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.515054ms
Feb 13 22:46:59.226: INFO: Pod "pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006225756s
Feb 13 22:47:01.228: INFO: Pod "pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007737793s
STEP: Saw pod success
Feb 13 22:47:01.228: INFO: Pod "pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:47:01.229: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc container secret-env-test: <nil>
STEP: delete the pod
Feb 13 22:47:01.247: INFO: Waiting for pod pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:47:01.248: INFO: Pod pod-secrets-445630a4-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:47:01.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nvpft" for this suite.
Feb 13 22:47:07.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:47:07.281: INFO: namespace: e2e-tests-secrets-nvpft, resource: bindings, ignored listing per whitelist
Feb 13 22:47:07.299: INFO: namespace e2e-tests-secrets-nvpft deletion completed in 6.048435558s

• [SLOW TEST:10.223 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:47:07.304: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2w8vc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:47:07.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-2w8vc" to be "success or failure"
Feb 13 22:47:07.453: INFO: Pod "downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02888ms
Feb 13 22:47:09.455: INFO: Pod "downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005511692s
STEP: Saw pod success
Feb 13 22:47:09.455: INFO: Pod "downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:47:09.457: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:47:09.472: INFO: Waiting for pod downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:47:09.474: INFO: Pod downwardapi-volume-4a6f1da5-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:47:09.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2w8vc" for this suite.
Feb 13 22:47:15.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:47:15.487: INFO: namespace: e2e-tests-projected-2w8vc, resource: bindings, ignored listing per whitelist
Feb 13 22:47:15.519: INFO: namespace e2e-tests-projected-2w8vc deletion completed in 6.042779273s

• [SLOW TEST:8.215 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:47:15.520: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vqfmv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:47:15.653: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-projected-vqfmv" to be "success or failure"
Feb 13 22:47:15.654: INFO: Pod "downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.07023ms
Feb 13 22:47:17.656: INFO: Pod "downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002999207s
STEP: Saw pod success
Feb 13 22:47:17.656: INFO: Pod "downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:47:17.657: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerd2381a81c9 pod downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc container client-container: <nil>
STEP: delete the pod
Feb 13 22:47:17.673: INFO: Waiting for pod downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:47:17.674: INFO: Pod downwardapi-volume-4f52dc15-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:47:17.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vqfmv" for this suite.
Feb 13 22:47:23.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:47:23.736: INFO: namespace: e2e-tests-projected-vqfmv, resource: bindings, ignored listing per whitelist
Feb 13 22:47:23.770: INFO: namespace e2e-tests-projected-vqfmv deletion completed in 6.093488614s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:47:23.770: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-p9ssd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Feb 13 22:47:49.937: INFO: Container started at 2019-02-13 22:47:24 +0000 UTC, pod became ready at 2019-02-13 22:47:48 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:47:49.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p9ssd" for this suite.
Feb 13 22:48:11.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:48:11.952: INFO: namespace: e2e-tests-container-probe-p9ssd, resource: bindings, ignored listing per whitelist
Feb 13 22:48:11.984: INFO: namespace e2e-tests-container-probe-p9ssd deletion completed in 22.044814106s

• [SLOW TEST:48.214 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:48:11.986: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s2lhj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 13 22:48:12.123: INFO: Waiting up to 5m0s for pod "pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-emptydir-s2lhj" to be "success or failure"
Feb 13 22:48:12.127: INFO: Pod "pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.640729ms
Feb 13 22:48:14.129: INFO: Pod "pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005378344s
STEP: Saw pod success
Feb 13 22:48:14.129: INFO: Pod "pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:48:14.130: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc container test-container: <nil>
STEP: delete the pod
Feb 13 22:48:14.145: INFO: Waiting for pod pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:48:14.146: INFO: Pod pod-70fb72c9-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:48:14.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s2lhj" for this suite.
Feb 13 22:48:20.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:48:20.187: INFO: namespace: e2e-tests-emptydir-s2lhj, resource: bindings, ignored listing per whitelist
Feb 13 22:48:20.190: INFO: namespace e2e-tests-emptydir-s2lhj deletion completed in 6.04119538s

• [SLOW TEST:8.204 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Feb 13 22:48:20.190: INFO: >>> kubeConfig: /tmp/kubeconfig-208905800
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mqjvg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-mqjvg/configmap-test-75e6cdd7-2fe1-11e9-aeb1-a6e9e8347cdc
STEP: Creating a pod to test consume configMaps
Feb 13 22:48:20.378: INFO: Waiting up to 5m0s for pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc" in namespace "e2e-tests-configmap-mqjvg" to be "success or failure"
Feb 13 22:48:20.379: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.711788ms
Feb 13 22:48:22.381: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003627639s
Feb 13 22:48:24.383: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005660199s
Feb 13 22:48:26.385: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007554813s
Feb 13 22:48:28.387: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009402638s
Feb 13 22:48:30.390: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.011808496s
STEP: Saw pod success
Feb 13 22:48:30.390: INFO: Pod "pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc" satisfied condition "success or failure"
Feb 13 22:48:30.391: INFO: Trying to get logs from node alex-300-cp1-vsp2-workerbe2ca38349 pod pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc container env-test: <nil>
STEP: delete the pod
Feb 13 22:48:30.405: INFO: Waiting for pod pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc to disappear
Feb 13 22:48:30.406: INFO: Pod pod-configmaps-75e7179e-2fe1-11e9-aeb1-a6e9e8347cdc no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Feb 13 22:48:30.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mqjvg" for this suite.
Feb 13 22:48:36.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:48:36.439: INFO: namespace: e2e-tests-configmap-mqjvg, resource: bindings, ignored listing per whitelist
Feb 13 22:48:36.461: INFO: namespace e2e-tests-configmap-mqjvg deletion completed in 6.051955775s

• [SLOW TEST:16.271 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSFeb 13 22:48:36.462: INFO: Running AfterSuite actions on all node
Feb 13 22:48:36.462: INFO: Running AfterSuite actions on node 1
Feb 13 22:48:36.462: INFO: Skipping dumping logs from cluster

Ran 165 of 996 Specs in 4391.368 seconds
SUCCESS! -- 165 Passed | 0 Failed | 0 Pending | 831 Skipped PASS

Ginkgo ran 1 suite in 1h13m11.68520889s
Test Suite Passed
