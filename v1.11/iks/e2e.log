Jan 22 00:39:24.341: INFO: Overriding default scale value of zero to 1
Jan 22 00:39:24.341: INFO: Overriding default milliseconds value of zero to 5000
I0122 00:39:24.592712      15 test_context.go:382] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-059299132
I0122 00:39:24.593011      15 e2e.go:333] Starting e2e run "2a6595ff-1dde-11e9-8691-1e7d95aa6bfc" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1548117564 - Will randomize all specs
Will run 166 of 996 specs

Jan 22 00:39:24.690: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:39:24.693: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 22 00:39:24.734: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 22 00:39:24.787: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 22 00:39:24.787: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jan 22 00:39:24.794: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jan 22 00:39:24.794: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt
Jan 22 00:39:24.802: INFO: e2e test version: v1.11.3
Jan 22 00:39:24.804: INFO: kube-apiserver version: v1.11.6+IKS
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:39:24.804: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
Jan 22 00:39:24.969: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jan 22 00:39:24.994: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-prttc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 00:39:25.141: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
Jan 22 00:39:25.159: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-prttc/daemonsets","resourceVersion":"62014"},"items":null}

Jan 22 00:39:25.165: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-prttc/pods","resourceVersion":"62014"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:39:25.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-prttc" for this suite.
Jan 22 00:39:31.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:39:31.371: INFO: namespace: e2e-tests-daemonsets-prttc, resource: bindings, ignored listing per whitelist
Jan 22 00:39:31.532: INFO: namespace e2e-tests-daemonsets-prttc deletion completed in 6.323439375s

S [SKIPPING] [6.729 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

  Jan 22 00:39:25.141: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:39:31.533: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p6gvx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 00:39:31.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-p6gvx'
Jan 22 00:39:32.070: INFO: stderr: ""
Jan 22 00:39:32.070: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
Jan 22 00:39:36.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-p6gvx'
Jan 22 00:39:36.255: INFO: stderr: ""
Jan 22 00:39:36.255: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:39:36.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p6gvx" for this suite.
Jan 22 00:40:00.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:40:00.412: INFO: namespace: e2e-tests-kubectl-p6gvx, resource: bindings, ignored listing per whitelist
Jan 22 00:40:00.524: INFO: namespace e2e-tests-kubectl-p6gvx deletion completed in 24.255432005s

â€¢ [SLOW TEST:28.991 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:40:00.525: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c8jwt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jan 22 00:40:00.796: INFO: Waiting up to 5m0s for pod "downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-c8jwt" to be "success or failure"
Jan 22 00:40:00.804: INFO: Pod "downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.567436ms
Jan 22 00:40:02.810: INFO: Pod "downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013352133s
Jan 22 00:40:04.816: INFO: Pod "downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019308112s
STEP: Saw pod success
Jan 22 00:40:04.816: INFO: Pod "downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:40:04.821: INFO: Trying to get logs from node 10.191.28.14 pod downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 00:40:04.872: INFO: Waiting for pod downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:40:04.877: INFO: Pod downward-api-402826b8-1dde-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:40:04.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c8jwt" for this suite.
Jan 22 00:40:10.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:40:11.223: INFO: namespace: e2e-tests-downward-api-c8jwt, resource: bindings, ignored listing per whitelist
Jan 22 00:40:11.223: INFO: namespace e2e-tests-downward-api-c8jwt deletion completed in 6.335829503s

â€¢ [SLOW TEST:10.698 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:40:11.225: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-bkgn9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 22 00:40:12.022: INFO: Waiting up to 5m0s for pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs" in namespace "e2e-tests-svcaccounts-bkgn9" to be "success or failure"
Jan 22 00:40:12.031: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs": Phase="Pending", Reason="", readiness=false. Elapsed: 8.630208ms
Jan 22 00:40:14.038: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016035447s
STEP: Saw pod success
Jan 22 00:40:14.038: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs" satisfied condition "success or failure"
Jan 22 00:40:14.043: INFO: Trying to get logs from node 10.191.28.14 pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs container token-test: <nil>
STEP: delete the pod
Jan 22 00:40:14.144: INFO: Waiting for pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs to disappear
Jan 22 00:40:14.150: INFO: Pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-mlqfs no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 22 00:40:14.162: INFO: Waiting up to 5m0s for pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql" in namespace "e2e-tests-svcaccounts-bkgn9" to be "success or failure"
Jan 22 00:40:14.169: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql": Phase="Pending", Reason="", readiness=false. Elapsed: 7.376135ms
Jan 22 00:40:16.175: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013598244s
STEP: Saw pod success
Jan 22 00:40:16.175: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql" satisfied condition "success or failure"
Jan 22 00:40:16.181: INFO: Trying to get logs from node 10.191.28.14 pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql container root-ca-test: <nil>
STEP: delete the pod
Jan 22 00:40:16.238: INFO: Waiting for pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql to disappear
Jan 22 00:40:16.243: INFO: Pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-npnql no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 22 00:40:16.250: INFO: Waiting up to 5m0s for pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j" in namespace "e2e-tests-svcaccounts-bkgn9" to be "success or failure"
Jan 22 00:40:16.259: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j": Phase="Pending", Reason="", readiness=false. Elapsed: 9.334815ms
Jan 22 00:40:18.265: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015305476s
STEP: Saw pod success
Jan 22 00:40:18.265: INFO: Pod "pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j" satisfied condition "success or failure"
Jan 22 00:40:18.270: INFO: Trying to get logs from node 10.191.28.14 pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j container namespace-test: <nil>
STEP: delete the pod
Jan 22 00:40:18.309: INFO: Waiting for pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j to disappear
Jan 22 00:40:18.320: INFO: Pod pod-service-account-46d96674-1dde-11e9-8691-1e7d95aa6bfc-nct5j no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:40:18.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bkgn9" for this suite.
Jan 22 00:40:24.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:40:24.428: INFO: namespace: e2e-tests-svcaccounts-bkgn9, resource: bindings, ignored listing per whitelist
Jan 22 00:40:24.640: INFO: namespace e2e-tests-svcaccounts-bkgn9 deletion completed in 6.310096444s

â€¢ [SLOW TEST:13.416 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:40:24.642: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-v6dcd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-4e8a78bb-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 00:40:24.940: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-v6dcd" to be "success or failure"
Jan 22 00:40:24.947: INFO: Pod "pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.246344ms
Jan 22 00:40:26.953: INFO: Pod "pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01341723s
STEP: Saw pod success
Jan 22 00:40:26.953: INFO: Pod "pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:40:26.959: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 00:40:26.992: INFO: Waiting for pod pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:40:26.997: INFO: Pod pod-projected-secrets-4e8c3e45-1dde-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:40:26.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v6dcd" for this suite.
Jan 22 00:40:33.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:40:33.321: INFO: namespace: e2e-tests-projected-v6dcd, resource: bindings, ignored listing per whitelist
Jan 22 00:40:33.349: INFO: namespace e2e-tests-projected-v6dcd deletion completed in 6.339273836s

â€¢ [SLOW TEST:8.708 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:40:33.349: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mvsq4
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-53b91075-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating configMap with name cm-test-opt-upd-53b910b2-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-53b91075-1dde-11e9-8691-1e7d95aa6bfc
STEP: Updating configmap cm-test-opt-upd-53b910b2-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating configMap with name cm-test-opt-create-53b910ce-1dde-11e9-8691-1e7d95aa6bfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:40:37.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mvsq4" for this suite.
Jan 22 00:41:01.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:41:02.155: INFO: namespace: e2e-tests-configmap-mvsq4, resource: bindings, ignored listing per whitelist
Jan 22 00:41:02.243: INFO: namespace e2e-tests-configmap-mvsq4 deletion completed in 24.408835461s

â€¢ [SLOW TEST:28.893 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:41:02.244: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-5ljgg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 22 00:41:02.531: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5ljgg,SelfLink:/api/v1/namespaces/e2e-tests-watch-5ljgg/configmaps/e2e-watch-test-watch-closed,UID:64f3aba2-1dde-11e9-b13b-16990c636477,ResourceVersion:62523,Generation:0,CreationTimestamp:2019-01-22 00:41:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 00:41:02.531: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5ljgg,SelfLink:/api/v1/namespaces/e2e-tests-watch-5ljgg/configmaps/e2e-watch-test-watch-closed,UID:64f3aba2-1dde-11e9-b13b-16990c636477,ResourceVersion:62524,Generation:0,CreationTimestamp:2019-01-22 00:41:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 22 00:41:02.556: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5ljgg,SelfLink:/api/v1/namespaces/e2e-tests-watch-5ljgg/configmaps/e2e-watch-test-watch-closed,UID:64f3aba2-1dde-11e9-b13b-16990c636477,ResourceVersion:62525,Generation:0,CreationTimestamp:2019-01-22 00:41:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 00:41:02.556: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5ljgg,SelfLink:/api/v1/namespaces/e2e-tests-watch-5ljgg/configmaps/e2e-watch-test-watch-closed,UID:64f3aba2-1dde-11e9-b13b-16990c636477,ResourceVersion:62526,Generation:0,CreationTimestamp:2019-01-22 00:41:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:41:02.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5ljgg" for this suite.
Jan 22 00:41:08.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:41:08.703: INFO: namespace: e2e-tests-watch-5ljgg, resource: bindings, ignored listing per whitelist
Jan 22 00:41:08.816: INFO: namespace e2e-tests-watch-5ljgg deletion completed in 6.249773624s

â€¢ [SLOW TEST:6.573 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:41:08.819: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l5rn7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-68de049f-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 00:41:09.107: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-l5rn7" to be "success or failure"
Jan 22 00:41:09.113: INFO: Pod "pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.790419ms
Jan 22 00:41:11.119: INFO: Pod "pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.011572463s
Jan 22 00:41:13.126: INFO: Pod "pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018264787s
STEP: Saw pod success
Jan 22 00:41:13.126: INFO: Pod "pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:41:13.131: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 00:41:13.173: INFO: Waiting for pod pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:41:13.177: INFO: Pod pod-projected-secrets-68df6449-1dde-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:41:13.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l5rn7" for this suite.
Jan 22 00:41:19.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:41:19.421: INFO: namespace: e2e-tests-projected-l5rn7, resource: bindings, ignored listing per whitelist
Jan 22 00:41:19.531: INFO: namespace e2e-tests-projected-l5rn7 deletion completed in 6.309797681s

â€¢ [SLOW TEST:10.712 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:41:19.532: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5xxt5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 00:41:19.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:19.939: INFO: stderr: ""
Jan 22 00:41:19.939: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 22 00:41:19.949: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 22 00:41:20.020: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 22 00:41:20.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:35.992: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 22 00:41:35.992: INFO: stdout: "Created e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c\nScaling up e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 22 00:41:35.992: INFO: stdout: "Created e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c\nScaling up e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 22 00:41:35.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:36.128: INFO: stderr: ""
Jan 22 00:41:36.128: INFO: stdout: "e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c-s9s4x e2e-test-nginx-rc-9fms9 "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jan 22 00:41:41.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:41.324: INFO: stderr: ""
Jan 22 00:41:41.324: INFO: stdout: "e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c-s9s4x "
Jan 22 00:41:41.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c-s9s4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:41.441: INFO: stderr: ""
Jan 22 00:41:41.441: INFO: stdout: "true"
Jan 22 00:41:41.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c-s9s4x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:41.563: INFO: stderr: ""
Jan 22 00:41:41.563: INFO: stdout: "k8s.gcr.io/nginx-slim-amd64:0.20"
Jan 22 00:41:41.563: INFO: e2e-test-nginx-rc-16c45978c88505ff4d3879571836477c-s9s4x is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
Jan 22 00:41:41.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5xxt5'
Jan 22 00:41:41.747: INFO: stderr: ""
Jan 22 00:41:41.747: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:41:41.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5xxt5" for this suite.
Jan 22 00:42:05.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:42:06.556: INFO: namespace: e2e-tests-kubectl-5xxt5, resource: bindings, ignored listing per whitelist
Jan 22 00:42:06.578: INFO: namespace e2e-tests-kubectl-5xxt5 deletion completed in 24.821221714s

â€¢ [SLOW TEST:47.047 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:42:06.580: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-srcc9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 22 00:42:06.854: INFO: Waiting up to 5m0s for pod "pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-srcc9" to be "success or failure"
Jan 22 00:42:06.859: INFO: Pod "pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.914911ms
Jan 22 00:42:08.867: INFO: Pod "pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013081171s
STEP: Saw pod success
Jan 22 00:42:08.867: INFO: Pod "pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:42:08.872: INFO: Trying to get logs from node 10.191.28.14 pod pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 00:42:08.908: INFO: Waiting for pod pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:42:08.912: INFO: Pod pod-8b4b74be-1dde-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:42:08.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-srcc9" for this suite.
Jan 22 00:42:14.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:42:15.124: INFO: namespace: e2e-tests-emptydir-srcc9, resource: bindings, ignored listing per whitelist
Jan 22 00:42:15.220: INFO: namespace e2e-tests-emptydir-srcc9 deletion completed in 6.297592783s

â€¢ [SLOW TEST:8.640 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:42:15.220: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2tfpc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-906f12ef-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 00:42:15.487: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-2tfpc" to be "success or failure"
Jan 22 00:42:15.496: INFO: Pod "pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.890181ms
Jan 22 00:42:17.504: INFO: Pod "pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01639331s
STEP: Saw pod success
Jan 22 00:42:17.504: INFO: Pod "pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:42:17.509: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 00:42:17.540: INFO: Waiting for pod pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:42:17.620: INFO: Pod pod-projected-secrets-90707e70-1dde-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:42:17.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2tfpc" for this suite.
Jan 22 00:42:23.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:42:23.811: INFO: namespace: e2e-tests-projected-2tfpc, resource: bindings, ignored listing per whitelist
Jan 22 00:42:23.918: INFO: namespace e2e-tests-projected-2tfpc deletion completed in 6.287225563s

â€¢ [SLOW TEST:8.698 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:42:23.919: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-lsksl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0122 00:43:04.246172      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 00:43:04.246: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:43:04.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lsksl" for this suite.
Jan 22 00:43:12.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:43:12.426: INFO: namespace: e2e-tests-gc-lsksl, resource: bindings, ignored listing per whitelist
Jan 22 00:43:12.561: INFO: namespace e2e-tests-gc-lsksl deletion completed in 8.240013895s

â€¢ [SLOW TEST:48.642 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:43:12.561: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-r6hgp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating all guestbook components
Jan 22 00:43:12.824: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 22 00:43:12.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:13.155: INFO: stderr: ""
Jan 22 00:43:13.155: INFO: stdout: "service/redis-slave created\n"
Jan 22 00:43:13.155: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 22 00:43:13.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:14.174: INFO: stderr: ""
Jan 22 00:43:14.174: INFO: stdout: "service/redis-master created\n"
Jan 22 00:43:14.174: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 22 00:43:14.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:14.411: INFO: stderr: ""
Jan 22 00:43:14.411: INFO: stdout: "service/frontend created\n"
Jan 22 00:43:14.411: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 22 00:43:14.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:14.618: INFO: stderr: ""
Jan 22 00:43:14.618: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 22 00:43:14.618: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 22 00:43:14.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:14.870: INFO: stderr: ""
Jan 22 00:43:14.870: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 22 00:43:14.870: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 22 00:43:14.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:15.085: INFO: stderr: ""
Jan 22 00:43:15.085: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 22 00:43:15.085: INFO: Waiting for all frontend pods to be Running.
Jan 22 00:43:20.135: INFO: Waiting for frontend to serve content.
Jan 22 00:43:20.166: INFO: Trying to add a new entry to the guestbook.
Jan 22 00:43:20.196: INFO: Verifying that added entry can be retrieved.
Jan 22 00:43:20.221: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Jan 22 00:43:25.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:25.442: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 00:43:25.442: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 00:43:25.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:25.661: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 00:43:25.661: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 00:43:25.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:25.829: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 00:43:25.829: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 00:43:25.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:25.994: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 00:43:25.994: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 00:43:25.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:26.220: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 00:43:26.220: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 00:43:26.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r6hgp'
Jan 22 00:43:26.477: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 00:43:26.477: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:43:26.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r6hgp" for this suite.
Jan 22 00:44:12.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:44:12.824: INFO: namespace: e2e-tests-kubectl-r6hgp, resource: bindings, ignored listing per whitelist
Jan 22 00:44:12.824: INFO: namespace e2e-tests-kubectl-r6hgp deletion completed in 46.333908711s

â€¢ [SLOW TEST:60.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:44:12.825: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-pk8mz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0122 00:44:19.246683      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 00:44:19.246: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:44:19.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pk8mz" for this suite.
Jan 22 00:44:27.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:44:27.480: INFO: namespace: e2e-tests-gc-pk8mz, resource: bindings, ignored listing per whitelist
Jan 22 00:44:27.558: INFO: namespace e2e-tests-gc-pk8mz deletion completed in 8.227468059s

â€¢ [SLOW TEST:14.733 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:44:27.559: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-bp26m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bp26m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 00:44:27.810: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 00:44:50.045: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.118.154:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bp26m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 00:44:50.045: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:44:50.280: INFO: Found all expected endpoints: [netserver-0]
Jan 22 00:44:50.286: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.171.253:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bp26m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 00:44:50.286: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:44:50.452: INFO: Found all expected endpoints: [netserver-1]
Jan 22 00:44:50.458: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.27.253:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bp26m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 00:44:50.458: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:44:50.681: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:44:50.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bp26m" for this suite.
Jan 22 00:45:14.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:45:14.985: INFO: namespace: e2e-tests-pod-network-test-bp26m, resource: bindings, ignored listing per whitelist
Jan 22 00:45:15.026: INFO: namespace e2e-tests-pod-network-test-bp26m deletion completed in 24.295428776s

â€¢ [SLOW TEST:47.467 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:45:15.026: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9brnx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-fba23ddb-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating secret with name s-test-opt-upd-fba23e24-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fba23ddb-1dde-11e9-8691-1e7d95aa6bfc
STEP: Updating secret s-test-opt-upd-fba23e24-1dde-11e9-8691-1e7d95aa6bfc
STEP: Creating secret with name s-test-opt-create-fba23e47-1dde-11e9-8691-1e7d95aa6bfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:46:32.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9brnx" for this suite.
Jan 22 00:46:56.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:46:57.013: INFO: namespace: e2e-tests-projected-9brnx, resource: bindings, ignored listing per whitelist
Jan 22 00:46:57.077: INFO: namespace e2e-tests-projected-9brnx deletion completed in 24.739433552s

â€¢ [SLOW TEST:102.051 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:46:57.077: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g96mb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 00:46:57.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-g96mb'
Jan 22 00:46:57.494: INFO: stderr: ""
Jan 22 00:46:57.494: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
Jan 22 00:46:57.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-g96mb'
Jan 22 00:47:07.222: INFO: stderr: ""
Jan 22 00:47:07.222: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:47:07.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g96mb" for this suite.
Jan 22 00:47:13.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:47:13.687: INFO: namespace: e2e-tests-kubectl-g96mb, resource: bindings, ignored listing per whitelist
Jan 22 00:47:13.847: INFO: namespace e2e-tests-kubectl-g96mb deletion completed in 6.609228313s

â€¢ [SLOW TEST:16.770 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:47:13.849: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-jvpb5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Jan 22 00:47:14.108: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 22 00:48:14.243: INFO: Waiting for terminating namespaces to be deleted...
Jan 22 00:48:14.257: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 22 00:48:14.286: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 22 00:48:14.286: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jan 22 00:48:14.294: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jan 22 00:48:14.294: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.14 before test
Jan 22 00:48:14.319: INFO: calico-kube-controllers-5d496bb754-hxbr6 from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 22 00:48:14.319: INFO: ibm-kube-fluentd-s6x85 from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 00:48:14.319: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-229zh from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 00:48:14.319: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:48:14.319: INFO: calico-node-knwhb from kube-system started at 2019-01-21 19:04:23 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 00:48:14.319: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 00:48:14.319: INFO: ibm-keepalived-watcher-c6qjp from kube-system started at 2019-01-21 19:04:23 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 00:48:14.319: INFO: vpn-6bff56d46f-p84d6 from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container vpn ready: true, restart count 0
Jan 22 00:48:14.319: INFO: ibm-file-plugin-5f6f89cc66-wm2bv from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jan 22 00:48:14.319: INFO: kube-dns-amd64-74d5cf9648-srzhn from kube-system started at 2019-01-21 19:04:43 +0000 UTC (3 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 22 00:48:14.319: INFO: 	Container kubedns ready: true, restart count 0
Jan 22 00:48:14.319: INFO: 	Container sidecar ready: true, restart count 0
Jan 22 00:48:14.319: INFO: ibm-master-proxy-static-10.191.28.14 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 00:48:14.319: INFO: kube-dns-autoscaler-7d4745b6b-kpbmp from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container autoscaler ready: true, restart count 0
Jan 22 00:48:14.319: INFO: kubernetes-dashboard-7b545fbb4d-jtwpf from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Jan 22 00:48:14.319: INFO: ibm-storage-watcher-785496b956-24q6x from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.319: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jan 22 00:48:14.319: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.15 before test
Jan 22 00:48:14.351: INFO: public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-z9cwc from kube-system started at 2019-01-21 19:08:31 +0000 UTC (4 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 22 00:48:14.351: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-r65s6 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:48:14.351: INFO: kube-dns-amd64-74d5cf9648-mvp57 from kube-system started at 2019-01-21 19:05:11 +0000 UTC (3 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container kubedns ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container sidecar ready: true, restart count 0
Jan 22 00:48:14.351: INFO: ibm-keepalived-watcher-z9r9c from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 00:48:14.351: INFO: ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-hzrnk from ibm-system started at 2019-01-21 19:06:40 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container ibm-cloud-provider-ip-169-62-31-30 ready: true, restart count 0
Jan 22 00:48:14.351: INFO: ibm-kube-fluentd-mznzk from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 00:48:14.351: INFO: sonobuoy-e2e-job-a35b9383deaf4877 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container e2e ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:48:14.351: INFO: ibm-master-proxy-static-10.191.28.15 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 00:48:14.351: INFO: calico-node-47d7w from kube-system started at 2019-01-21 19:04:43 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.351: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 00:48:14.351: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.26 before test
Jan 22 00:48:14.386: INFO: calico-node-wr99s from kube-system started at 2019-01-21 19:04:55 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.386: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 00:48:14.386: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 00:48:14.386: INFO: ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-gpk7h from ibm-system started at 2019-01-21 19:06:40 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.386: INFO: 	Container ibm-cloud-provider-ip-169-62-31-30 ready: true, restart count 0
Jan 22 00:48:14.386: INFO: public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-pbwvk from kube-system started at 2019-01-21 19:08:31 +0000 UTC (4 container statuses recorded)
Jan 22 00:48:14.386: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 22 00:48:14.386: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 22 00:48:14.386: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 22 00:48:14.387: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 22 00:48:14.387: INFO: ibm-keepalived-watcher-p7vbr from kube-system started at 2019-01-21 19:04:55 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.387: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 00:48:14.387: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-22 00:39:06 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.387: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 22 00:48:14.387: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-2dcr2 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.387: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 00:48:14.387: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:48:14.387: INFO: ibm-master-proxy-static-10.191.28.26 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 00:48:14.387: INFO: heapster-b7b7c7876-5hmkp from kube-system started at 2019-01-21 19:05:16 +0000 UTC (2 container statuses recorded)
Jan 22 00:48:14.387: INFO: 	Container heapster ready: true, restart count 0
Jan 22 00:48:14.387: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 22 00:48:14.387: INFO: ibm-kube-fluentd-z5f6d from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.387: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 00:48:14.388: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-01-22 00:38:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:48:14.388: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157c053460a259be], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:48:15.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jvpb5" for this suite.
Jan 22 00:48:21.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:48:21.701: INFO: namespace: e2e-tests-sched-pred-jvpb5, resource: bindings, ignored listing per whitelist
Jan 22 00:48:21.833: INFO: namespace e2e-tests-sched-pred-jvpb5 deletion completed in 6.387495019s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

â€¢ [SLOW TEST:67.985 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:48:21.834: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-47tt9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 22 00:48:22.109: INFO: Waiting up to 5m0s for pod "pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-47tt9" to be "success or failure"
Jan 22 00:48:22.114: INFO: Pod "pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.366812ms
Jan 22 00:48:24.120: INFO: Pod "pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010958294s
STEP: Saw pod success
Jan 22 00:48:24.120: INFO: Pod "pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:48:24.125: INFO: Trying to get logs from node 10.191.28.14 pod pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 00:48:24.221: INFO: Waiting for pod pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:48:24.226: INFO: Pod pod-6af6a575-1ddf-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:48:24.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-47tt9" for this suite.
Jan 22 00:48:30.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:48:30.510: INFO: namespace: e2e-tests-emptydir-47tt9, resource: bindings, ignored listing per whitelist
Jan 22 00:48:30.570: INFO: namespace e2e-tests-emptydir-47tt9 deletion completed in 6.333026393s

â€¢ [SLOW TEST:8.736 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:48:30.570: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-58pzn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-7028dee7-1ddf-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 00:48:30.832: INFO: Waiting up to 5m0s for pod "pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-58pzn" to be "success or failure"
Jan 22 00:48:30.837: INFO: Pod "pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828374ms
Jan 22 00:48:32.844: INFO: Pod "pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012269308s
STEP: Saw pod success
Jan 22 00:48:32.844: INFO: Pod "pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:48:32.849: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 00:48:32.920: INFO: Waiting for pod pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:48:32.926: INFO: Pod pod-configmaps-7029d365-1ddf-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:48:32.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-58pzn" for this suite.
Jan 22 00:48:38.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:48:39.172: INFO: namespace: e2e-tests-configmap-58pzn, resource: bindings, ignored listing per whitelist
Jan 22 00:48:39.244: INFO: namespace e2e-tests-configmap-58pzn deletion completed in 6.302824881s

â€¢ [SLOW TEST:8.674 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:48:39.244: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-79zdg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Starting the proxy
Jan 22 00:48:39.506: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059299132 proxy --unix-socket=/tmp/kubectl-proxy-unix258167147/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:48:39.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-79zdg" for this suite.
Jan 22 00:48:45.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:48:45.760: INFO: namespace: e2e-tests-kubectl-79zdg, resource: bindings, ignored listing per whitelist
Jan 22 00:48:45.832: INFO: namespace e2e-tests-kubectl-79zdg deletion completed in 6.24754627s

â€¢ [SLOW TEST:6.588 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:48:45.833: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-hkjkx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hkjkx.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hkjkx.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hkjkx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hkjkx.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hkjkx.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hkjkx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 22 00:49:08.364: INFO: DNS probes using dns-test-79438f4c-1ddf-11e9-8691-1e7d95aa6bfc succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:49:08.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hkjkx" for this suite.
Jan 22 00:49:14.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:49:14.733: INFO: namespace: e2e-tests-dns-hkjkx, resource: bindings, ignored listing per whitelist
Jan 22 00:49:14.733: INFO: namespace e2e-tests-dns-hkjkx deletion completed in 6.333006415s

â€¢ [SLOW TEST:28.901 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:49:14.734: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-4zcln
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Jan 22 00:49:14.999: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 22 00:50:15.040: INFO: Waiting for terminating namespaces to be deleted...
Jan 22 00:50:15.055: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 22 00:50:15.085: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 22 00:50:15.085: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jan 22 00:50:15.092: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jan 22 00:50:15.092: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.14 before test
Jan 22 00:50:15.117: INFO: calico-kube-controllers-5d496bb754-hxbr6 from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 22 00:50:15.117: INFO: ibm-kube-fluentd-s6x85 from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 00:50:15.117: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-229zh from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 00:50:15.117: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:50:15.117: INFO: calico-node-knwhb from kube-system started at 2019-01-21 19:04:23 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 00:50:15.117: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 00:50:15.117: INFO: ibm-keepalived-watcher-c6qjp from kube-system started at 2019-01-21 19:04:23 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 00:50:15.117: INFO: vpn-6bff56d46f-p84d6 from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container vpn ready: true, restart count 0
Jan 22 00:50:15.117: INFO: ibm-file-plugin-5f6f89cc66-wm2bv from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jan 22 00:50:15.117: INFO: kube-dns-amd64-74d5cf9648-srzhn from kube-system started at 2019-01-21 19:04:43 +0000 UTC (3 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 22 00:50:15.117: INFO: 	Container kubedns ready: true, restart count 0
Jan 22 00:50:15.117: INFO: 	Container sidecar ready: true, restart count 0
Jan 22 00:50:15.117: INFO: ibm-master-proxy-static-10.191.28.14 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 00:50:15.117: INFO: kube-dns-autoscaler-7d4745b6b-kpbmp from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.117: INFO: 	Container autoscaler ready: true, restart count 0
Jan 22 00:50:15.118: INFO: kubernetes-dashboard-7b545fbb4d-jtwpf from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.118: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Jan 22 00:50:15.118: INFO: ibm-storage-watcher-785496b956-24q6x from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.118: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jan 22 00:50:15.118: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.15 before test
Jan 22 00:50:15.143: INFO: public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-z9cwc from kube-system started at 2019-01-21 19:08:31 +0000 UTC (4 container statuses recorded)
Jan 22 00:50:15.143: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 22 00:50:15.144: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-r65s6 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:50:15.144: INFO: kube-dns-amd64-74d5cf9648-mvp57 from kube-system started at 2019-01-21 19:05:11 +0000 UTC (3 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container kubedns ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container sidecar ready: true, restart count 0
Jan 22 00:50:15.144: INFO: ibm-keepalived-watcher-z9r9c from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 00:50:15.144: INFO: ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-hzrnk from ibm-system started at 2019-01-21 19:06:40 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container ibm-cloud-provider-ip-169-62-31-30 ready: true, restart count 0
Jan 22 00:50:15.144: INFO: ibm-kube-fluentd-mznzk from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 00:50:15.144: INFO: sonobuoy-e2e-job-a35b9383deaf4877 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container e2e ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:50:15.144: INFO: ibm-master-proxy-static-10.191.28.15 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 00:50:15.144: INFO: calico-node-47d7w from kube-system started at 2019-01-21 19:04:43 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.144: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 00:50:15.144: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.26 before test
Jan 22 00:50:15.171: INFO: ibm-keepalived-watcher-p7vbr from kube-system started at 2019-01-21 19:04:55 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.171: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 00:50:15.171: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-22 00:39:06 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.171: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 22 00:50:15.171: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-2dcr2 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.171: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 00:50:15.171: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 00:50:15.171: INFO: ibm-master-proxy-static-10.191.28.26 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 00:50:15.171: INFO: heapster-b7b7c7876-5hmkp from kube-system started at 2019-01-21 19:05:16 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.171: INFO: 	Container heapster ready: true, restart count 0
Jan 22 00:50:15.171: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 22 00:50:15.172: INFO: ibm-kube-fluentd-z5f6d from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.172: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 00:50:15.172: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-01-22 00:38:43 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.172: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jan 22 00:50:15.172: INFO: calico-node-wr99s from kube-system started at 2019-01-21 19:04:55 +0000 UTC (2 container statuses recorded)
Jan 22 00:50:15.172: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 00:50:15.173: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 00:50:15.173: INFO: ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-gpk7h from ibm-system started at 2019-01-21 19:06:40 +0000 UTC (1 container statuses recorded)
Jan 22 00:50:15.173: INFO: 	Container ibm-cloud-provider-ip-169-62-31-30 ready: true, restart count 0
Jan 22 00:50:15.173: INFO: public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-pbwvk from kube-system started at 2019-01-21 19:08:31 +0000 UTC (4 container statuses recorded)
Jan 22 00:50:15.173: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 22 00:50:15.173: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 22 00:50:15.173: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 22 00:50:15.173: INFO: 	Container nginx-ingress ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node 10.191.28.14
STEP: verifying the node has the label node 10.191.28.15
STEP: verifying the node has the label node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod sonobuoy-e2e-job-a35b9383deaf4877 requesting resource cpu=0m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-229zh requesting resource cpu=0m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-2dcr2 requesting resource cpu=0m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-r65s6 requesting resource cpu=0m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-gpk7h requesting resource cpu=0m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-hzrnk requesting resource cpu=0m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod calico-kube-controllers-5d496bb754-hxbr6 requesting resource cpu=0m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod calico-node-47d7w requesting resource cpu=250m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod calico-node-knwhb requesting resource cpu=250m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod calico-node-wr99s requesting resource cpu=250m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod heapster-b7b7c7876-5hmkp requesting resource cpu=138m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod ibm-file-plugin-5f6f89cc66-wm2bv requesting resource cpu=50m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod ibm-keepalived-watcher-c6qjp requesting resource cpu=0m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod ibm-keepalived-watcher-p7vbr requesting resource cpu=0m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod ibm-keepalived-watcher-z9r9c requesting resource cpu=0m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod ibm-kube-fluentd-mznzk requesting resource cpu=25m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod ibm-kube-fluentd-s6x85 requesting resource cpu=25m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod ibm-kube-fluentd-z5f6d requesting resource cpu=25m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod ibm-master-proxy-static-10.191.28.14 requesting resource cpu=25m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod ibm-master-proxy-static-10.191.28.15 requesting resource cpu=25m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod ibm-master-proxy-static-10.191.28.26 requesting resource cpu=25m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod ibm-storage-watcher-785496b956-24q6x requesting resource cpu=50m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod kube-dns-amd64-74d5cf9648-mvp57 requesting resource cpu=260m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod kube-dns-amd64-74d5cf9648-srzhn requesting resource cpu=260m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod kube-dns-autoscaler-7d4745b6b-kpbmp requesting resource cpu=20m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod kubernetes-dashboard-7b545fbb4d-jtwpf requesting resource cpu=0m on Node 10.191.28.14
Jan 22 00:50:15.282: INFO: Pod public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-pbwvk requesting resource cpu=0m on Node 10.191.28.26
Jan 22 00:50:15.282: INFO: Pod public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-z9cwc requesting resource cpu=0m on Node 10.191.28.15
Jan 22 00:50:15.282: INFO: Pod vpn-6bff56d46f-p84d6 requesting resource cpu=0m on Node 10.191.28.14
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae6d6a4f-1ddf-11e9-8691-1e7d95aa6bfc.157c055085f12e94], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4zcln/filler-pod-ae6d6a4f-1ddf-11e9-8691-1e7d95aa6bfc to 10.191.28.26]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae6d6a4f-1ddf-11e9-8691-1e7d95aa6bfc.157c0550bd804e6c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae6d6a4f-1ddf-11e9-8691-1e7d95aa6bfc.157c0550c183d891], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae6d6a4f-1ddf-11e9-8691-1e7d95aa6bfc.157c0550ca747726], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae709c8d-1ddf-11e9-8691-1e7d95aa6bfc.157c055086a22f2d], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4zcln/filler-pod-ae709c8d-1ddf-11e9-8691-1e7d95aa6bfc to 10.191.28.14]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae709c8d-1ddf-11e9-8691-1e7d95aa6bfc.157c0550b62d9c20], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae709c8d-1ddf-11e9-8691-1e7d95aa6bfc.157c0550b86f50c0], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae709c8d-1ddf-11e9-8691-1e7d95aa6bfc.157c0550c0dbc40e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae725d14-1ddf-11e9-8691-1e7d95aa6bfc.157c055087062d8e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4zcln/filler-pod-ae725d14-1ddf-11e9-8691-1e7d95aa6bfc to 10.191.28.15]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae725d14-1ddf-11e9-8691-1e7d95aa6bfc.157c0550b4d41f84], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae725d14-1ddf-11e9-8691-1e7d95aa6bfc.157c0550b7a03fe9], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae725d14-1ddf-11e9-8691-1e7d95aa6bfc.157c0550bf0bfa17], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157c0551045d7f86], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.191.28.26
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.191.28.14
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.191.28.15
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:50:18.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4zcln" for this suite.
Jan 22 00:50:24.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:50:24.714: INFO: namespace: e2e-tests-sched-pred-4zcln, resource: bindings, ignored listing per whitelist
Jan 22 00:50:24.862: INFO: namespace e2e-tests-sched-pred-4zcln deletion completed in 6.260517223s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

â€¢ [SLOW TEST:70.129 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:50:24.862: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-dgz5n
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 00:50:25.124: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:50:26.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-dgz5n" for this suite.
Jan 22 00:50:32.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:50:32.483: INFO: namespace: e2e-tests-custom-resource-definition-dgz5n, resource: bindings, ignored listing per whitelist
Jan 22 00:50:32.552: INFO: namespace e2e-tests-custom-resource-definition-dgz5n deletion completed in 6.248178523s

â€¢ [SLOW TEST:7.689 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:50:32.554: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-5mgjr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 22 00:50:32.852: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5mgjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5mgjr/configmaps/e2e-watch-test-label-changed,UID:b8e1c621-1ddf-11e9-b13b-16990c636477,ResourceVersion:65034,Generation:0,CreationTimestamp:2019-01-22 00:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 00:50:32.852: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5mgjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5mgjr/configmaps/e2e-watch-test-label-changed,UID:b8e1c621-1ddf-11e9-b13b-16990c636477,ResourceVersion:65035,Generation:0,CreationTimestamp:2019-01-22 00:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 22 00:50:32.852: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5mgjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5mgjr/configmaps/e2e-watch-test-label-changed,UID:b8e1c621-1ddf-11e9-b13b-16990c636477,ResourceVersion:65036,Generation:0,CreationTimestamp:2019-01-22 00:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 22 00:50:42.939: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5mgjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5mgjr/configmaps/e2e-watch-test-label-changed,UID:b8e1c621-1ddf-11e9-b13b-16990c636477,ResourceVersion:65054,Generation:0,CreationTimestamp:2019-01-22 00:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 00:50:42.939: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5mgjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5mgjr/configmaps/e2e-watch-test-label-changed,UID:b8e1c621-1ddf-11e9-b13b-16990c636477,ResourceVersion:65055,Generation:0,CreationTimestamp:2019-01-22 00:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 22 00:50:42.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5mgjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5mgjr/configmaps/e2e-watch-test-label-changed,UID:b8e1c621-1ddf-11e9-b13b-16990c636477,ResourceVersion:65056,Generation:0,CreationTimestamp:2019-01-22 00:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:50:42.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5mgjr" for this suite.
Jan 22 00:50:48.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:50:49.157: INFO: namespace: e2e-tests-watch-5mgjr, resource: bindings, ignored listing per whitelist
Jan 22 00:50:49.228: INFO: namespace e2e-tests-watch-5mgjr deletion completed in 6.276703766s

â€¢ [SLOW TEST:16.674 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:50:49.229: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-r6975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:50:49.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r6975" for this suite.
Jan 22 00:51:11.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:51:11.820: INFO: namespace: e2e-tests-pods-r6975, resource: bindings, ignored listing per whitelist
Jan 22 00:51:11.942: INFO: namespace e2e-tests-pods-r6975 deletion completed in 22.419344114s

â€¢ [SLOW TEST:22.713 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:51:11.942: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-sdf67
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 22 00:51:18.754: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d05a7e8a-1ddf-11e9-8691-1e7d95aa6bfc"
Jan 22 00:51:18.754: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d05a7e8a-1ddf-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-pods-sdf67" to be "terminated due to deadline exceeded"
Jan 22 00:51:18.827: INFO: Pod "pod-update-activedeadlineseconds-d05a7e8a-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 73.43814ms
Jan 22 00:51:18.827: INFO: Pod "pod-update-activedeadlineseconds-d05a7e8a-1ddf-11e9-8691-1e7d95aa6bfc" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:51:18.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sdf67" for this suite.
Jan 22 00:51:24.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:51:24.920: INFO: namespace: e2e-tests-pods-sdf67, resource: bindings, ignored listing per whitelist
Jan 22 00:51:25.100: INFO: namespace e2e-tests-pods-sdf67 deletion completed in 6.262009374s

â€¢ [SLOW TEST:13.158 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:51:25.101: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zdbx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jan 22 00:51:28.020: INFO: Successfully updated pod "annotationupdated836b629-1ddf-11e9-8691-1e7d95aa6bfc"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:51:32.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zdbx7" for this suite.
Jan 22 00:51:54.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:51:54.350: INFO: namespace: e2e-tests-projected-zdbx7, resource: bindings, ignored listing per whitelist
Jan 22 00:51:54.427: INFO: namespace e2e-tests-projected-zdbx7 deletion completed in 22.305520042s

â€¢ [SLOW TEST:29.326 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:51:54.428: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-rbj7l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e9acc7e4-1ddf-11e9-8691-1e7d95aa6bfc,GenerateName:,Namespace:e2e-tests-events-rbj7l,SelfLink:/api/v1/namespaces/e2e-tests-events-rbj7l/pods/send-events-e9acc7e4-1ddf-11e9-8691-1e7d95aa6bfc,UID:e9adcec1-1ddf-11e9-b13b-16990c636477,ResourceVersion:65309,Generation:0,CreationTimestamp:2019-01-22 00:51:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 683804301,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-p5xbf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p5xbf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-p5xbf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.14,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214cc660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214cc680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 00:51:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 00:51:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 00:51:54 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.14,PodIP:172.30.27.200,StartTime:2019-01-22 00:51:54 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-22 00:51:55 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 containerd://12abebcd18a03f2bece7e1f918c40d38554e3c73cbc0ab0296d8a99c0fbea3f7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:52:00.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-rbj7l" for this suite.
Jan 22 00:52:22.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:52:23.022: INFO: namespace: e2e-tests-events-rbj7l, resource: bindings, ignored listing per whitelist
Jan 22 00:52:23.142: INFO: namespace e2e-tests-events-rbj7l deletion completed in 22.320925909s

â€¢ [SLOW TEST:28.714 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:52:23.143: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6dnxs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-facdb2c2-1ddf-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 00:52:23.440: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-6dnxs" to be "success or failure"
Jan 22 00:52:23.444: INFO: Pod "pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.486291ms
Jan 22 00:52:25.453: INFO: Pod "pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01317136s
STEP: Saw pod success
Jan 22 00:52:25.453: INFO: Pod "pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:52:25.459: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 00:52:25.494: INFO: Waiting for pod pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:52:25.499: INFO: Pod pod-projected-secrets-facf0b5c-1ddf-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:52:25.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6dnxs" for this suite.
Jan 22 00:52:31.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:52:31.735: INFO: namespace: e2e-tests-projected-6dnxs, resource: bindings, ignored listing per whitelist
Jan 22 00:52:31.845: INFO: namespace e2e-tests-projected-6dnxs deletion completed in 6.334770104s

â€¢ [SLOW TEST:8.702 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:52:31.846: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-6qf8r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 00:52:34.221: INFO: Waiting up to 5m0s for pod "client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-pods-6qf8r" to be "success or failure"
Jan 22 00:52:34.228: INFO: Pod "client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.177456ms
Jan 22 00:52:36.235: INFO: Pod "client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014424331s
STEP: Saw pod success
Jan 22 00:52:36.235: INFO: Pod "client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:52:36.240: INFO: Trying to get logs from node 10.191.28.14 pod client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc container env3cont: <nil>
STEP: delete the pod
Jan 22 00:52:36.282: INFO: Waiting for pod client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:52:36.320: INFO: Pod client-envvars-013150a0-1de0-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:52:36.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6qf8r" for this suite.
Jan 22 00:53:00.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:53:00.617: INFO: namespace: e2e-tests-pods-6qf8r, resource: bindings, ignored listing per whitelist
Jan 22 00:53:00.639: INFO: namespace e2e-tests-pods-6qf8r deletion completed in 24.301363281s

â€¢ [SLOW TEST:28.793 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:53:00.639: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fr4j5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fr4j5
Jan 22 00:53:05.136: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fr4j5
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 00:53:05.144: INFO: Initial restart count of pod liveness-http is 0
Jan 22 00:53:15.179: INFO: Restart count of pod e2e-tests-container-probe-fr4j5/liveness-http is now 1 (10.035693624s elapsed)
Jan 22 00:53:35.239: INFO: Restart count of pod e2e-tests-container-probe-fr4j5/liveness-http is now 2 (30.095662509s elapsed)
Jan 22 00:53:55.379: INFO: Restart count of pod e2e-tests-container-probe-fr4j5/liveness-http is now 3 (50.234969619s elapsed)
Jan 22 00:54:15.445: INFO: Restart count of pod e2e-tests-container-probe-fr4j5/liveness-http is now 4 (1m10.30180249s elapsed)
Jan 22 00:55:27.671: INFO: Restart count of pod e2e-tests-container-probe-fr4j5/liveness-http is now 5 (2m22.527603872s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:55:27.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fr4j5" for this suite.
Jan 22 00:55:33.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:55:33.989: INFO: namespace: e2e-tests-container-probe-fr4j5, resource: bindings, ignored listing per whitelist
Jan 22 00:55:34.025: INFO: namespace e2e-tests-container-probe-fr4j5 deletion completed in 6.303626605s

â€¢ [SLOW TEST:153.386 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:55:34.026: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-pmccl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pmccl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 00:55:34.292: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 00:55:52.467: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.27.214:8080/dial?request=hostName&protocol=udp&host=172.30.27.211&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pmccl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 00:55:52.467: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:55:52.807: INFO: Waiting for endpoints: map[]
Jan 22 00:55:52.813: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.27.214:8080/dial?request=hostName&protocol=udp&host=172.30.171.255&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pmccl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 00:55:52.813: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:55:53.064: INFO: Waiting for endpoints: map[]
Jan 22 00:55:53.069: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.27.214:8080/dial?request=hostName&protocol=udp&host=172.30.118.157&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-pmccl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 00:55:53.069: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 00:55:53.307: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:55:53.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pmccl" for this suite.
Jan 22 00:56:17.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:56:17.642: INFO: namespace: e2e-tests-pod-network-test-pmccl, resource: bindings, ignored listing per whitelist
Jan 22 00:56:17.642: INFO: namespace e2e-tests-pod-network-test-pmccl deletion completed in 24.324515177s

â€¢ [SLOW TEST:43.617 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:56:17.643: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5n98k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 00:56:17.935: INFO: Waiting up to 5m0s for pod "downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-5n98k" to be "success or failure"
Jan 22 00:56:17.940: INFO: Pod "downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.047578ms
Jan 22 00:56:19.946: INFO: Pod "downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011313754s
STEP: Saw pod success
Jan 22 00:56:19.946: INFO: Pod "downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 00:56:19.951: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 00:56:19.987: INFO: Waiting for pod downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 00:56:20.020: INFO: Pod downwardapi-volume-869394cc-1de0-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 00:56:20.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5n98k" for this suite.
Jan 22 00:56:26.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 00:56:26.318: INFO: namespace: e2e-tests-downward-api-5n98k, resource: bindings, ignored listing per whitelist
Jan 22 00:56:26.325: INFO: namespace e2e-tests-downward-api-5n98k deletion completed in 6.294777044s

â€¢ [SLOW TEST:8.683 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 00:56:26.327: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-7gvlm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-7gvlm
Jan 22 00:56:28.593: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-7gvlm
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 00:56:28.598: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:00:30.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7gvlm" for this suite.
Jan 22 01:00:36.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:00:36.704: INFO: namespace: e2e-tests-container-probe-7gvlm, resource: bindings, ignored listing per whitelist
Jan 22 01:00:36.822: INFO: namespace e2e-tests-container-probe-7gvlm deletion completed in 6.308453472s

â€¢ [SLOW TEST:250.496 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:00:36.823: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p7b52
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:00:37.133: INFO: Waiting up to 5m0s for pod "downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-p7b52" to be "success or failure"
Jan 22 01:00:37.140: INFO: Pod "downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.438395ms
Jan 22 01:00:39.146: INFO: Pod "downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013758803s
STEP: Saw pod success
Jan 22 01:00:39.146: INFO: Pod "downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:00:39.152: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:00:39.237: INFO: Waiting for pod downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:00:39.242: INFO: Pod downwardapi-volume-210e1038-1de1-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:00:39.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p7b52" for this suite.
Jan 22 01:00:45.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:00:45.373: INFO: namespace: e2e-tests-projected-p7b52, resource: bindings, ignored listing per whitelist
Jan 22 01:00:45.543: INFO: namespace e2e-tests-projected-p7b52 deletion completed in 6.291521413s

â€¢ [SLOW TEST:8.720 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:00:45.543: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kj85q
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-upd-263f4a95-1de1-11e9-8691-1e7d95aa6bfc
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-263f4a95-1de1-11e9-8691-1e7d95aa6bfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:00:49.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kj85q" for this suite.
Jan 22 01:01:12.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:01:12.171: INFO: namespace: e2e-tests-configmap-kj85q, resource: bindings, ignored listing per whitelist
Jan 22 01:01:12.220: INFO: namespace e2e-tests-configmap-kj85q deletion completed in 22.253640777s

â€¢ [SLOW TEST:26.677 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:01:12.222: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-89zhg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-89zhg/configmap-test-36262aae-1de1-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:01:12.503: INFO: Waiting up to 5m0s for pod "pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-89zhg" to be "success or failure"
Jan 22 01:01:12.508: INFO: Pod "pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.948688ms
Jan 22 01:01:14.515: INFO: Pod "pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011315756s
STEP: Saw pod success
Jan 22 01:01:14.515: INFO: Pod "pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:01:14.520: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc container env-test: <nil>
STEP: delete the pod
Jan 22 01:01:14.553: INFO: Waiting for pod pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:01:14.558: INFO: Pod pod-configmaps-36278146-1de1-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:01:14.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-89zhg" for this suite.
Jan 22 01:01:20.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:01:20.683: INFO: namespace: e2e-tests-configmap-89zhg, resource: bindings, ignored listing per whitelist
Jan 22 01:01:20.822: INFO: namespace e2e-tests-configmap-89zhg deletion completed in 6.252992872s

â€¢ [SLOW TEST:8.600 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:01:20.822: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kt9sk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-kt9sk/configmap-test-3b445177-1de1-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:01:21.133: INFO: Waiting up to 5m0s for pod "pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-kt9sk" to be "success or failure"
Jan 22 01:01:21.141: INFO: Pod "pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.454827ms
Jan 22 01:01:23.146: INFO: Pod "pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013087233s
STEP: Saw pod success
Jan 22 01:01:23.146: INFO: Pod "pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:01:23.151: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc container env-test: <nil>
STEP: delete the pod
Jan 22 01:01:23.239: INFO: Waiting for pod pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:01:23.243: INFO: Pod pod-configmaps-3b4c2710-1de1-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:01:23.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kt9sk" for this suite.
Jan 22 01:01:29.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:01:29.413: INFO: namespace: e2e-tests-configmap-kt9sk, resource: bindings, ignored listing per whitelist
Jan 22 01:01:29.520: INFO: namespace e2e-tests-configmap-kt9sk deletion completed in 6.262402991s

â€¢ [SLOW TEST:8.698 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:01:29.521: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-58zm5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
Jan 22 01:01:29.791: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-58zm5" to be "success or failure"
Jan 22 01:01:29.796: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.986389ms
Jan 22 01:01:31.803: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011470823s
Jan 22 01:01:33.812: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020532591s
STEP: Saw pod success
Jan 22 01:01:33.812: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 22 01:01:33.817: INFO: Trying to get logs from node 10.191.28.14 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 22 01:01:33.852: INFO: Waiting for pod pod-host-path-test to disappear
Jan 22 01:01:33.857: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:01:33.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-58zm5" for this suite.
Jan 22 01:01:39.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:01:39.999: INFO: namespace: e2e-tests-hostpath-58zm5, resource: bindings, ignored listing per whitelist
Jan 22 01:01:40.122: INFO: namespace e2e-tests-hostpath-58zm5 deletion completed in 6.254455525s

â€¢ [SLOW TEST:10.601 seconds]
[sig-storage] HostPath
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:01:40.124: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-452fr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with configMap that has name projected-configmap-test-upd-46c9b9f8-1de1-11e9-8691-1e7d95aa6bfc
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-46c9b9f8-1de1-11e9-8691-1e7d95aa6bfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:01:44.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-452fr" for this suite.
Jan 22 01:02:06.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:02:06.783: INFO: namespace: e2e-tests-projected-452fr, resource: bindings, ignored listing per whitelist
Jan 22 01:02:06.819: INFO: namespace e2e-tests-projected-452fr deletion completed in 22.251211721s

â€¢ [SLOW TEST:26.696 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:02:06.820: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8v8pf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the initial replication controller
Jan 22 01:02:07.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:07.424: INFO: stderr: ""
Jan 22 01:02:07.424: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 01:02:07.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:07.574: INFO: stderr: ""
Jan 22 01:02:07.574: INFO: stdout: "update-demo-nautilus-nhtnl update-demo-nautilus-qbc7j "
Jan 22 01:02:07.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-nhtnl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:07.731: INFO: stderr: ""
Jan 22 01:02:07.731: INFO: stdout: ""
Jan 22 01:02:07.731: INFO: update-demo-nautilus-nhtnl is created but not running
Jan 22 01:02:12.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:12.870: INFO: stderr: ""
Jan 22 01:02:12.870: INFO: stdout: "update-demo-nautilus-nhtnl update-demo-nautilus-qbc7j "
Jan 22 01:02:12.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-nhtnl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:13.030: INFO: stderr: ""
Jan 22 01:02:13.030: INFO: stdout: "true"
Jan 22 01:02:13.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-nhtnl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:13.154: INFO: stderr: ""
Jan 22 01:02:13.154: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:02:13.154: INFO: validating pod update-demo-nautilus-nhtnl
Jan 22 01:02:13.169: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:02:13.169: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:02:13.169: INFO: update-demo-nautilus-nhtnl is verified up and running
Jan 22 01:02:13.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-qbc7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:13.334: INFO: stderr: ""
Jan 22 01:02:13.334: INFO: stdout: "true"
Jan 22 01:02:13.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-qbc7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:13.466: INFO: stderr: ""
Jan 22 01:02:13.466: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:02:13.466: INFO: validating pod update-demo-nautilus-qbc7j
Jan 22 01:02:13.482: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:02:13.482: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:02:13.482: INFO: update-demo-nautilus-qbc7j is verified up and running
STEP: rolling-update to new replication controller
Jan 22 01:02:13.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:33.272: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 22 01:02:33.272: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 01:02:33.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:33.425: INFO: stderr: ""
Jan 22 01:02:33.425: INFO: stdout: "update-demo-kitten-d97kr update-demo-kitten-hr99x "
Jan 22 01:02:33.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-kitten-d97kr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:33.581: INFO: stderr: ""
Jan 22 01:02:33.581: INFO: stdout: "true"
Jan 22 01:02:33.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-kitten-d97kr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:33.702: INFO: stderr: ""
Jan 22 01:02:33.702: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Jan 22 01:02:33.702: INFO: validating pod update-demo-kitten-d97kr
Jan 22 01:02:33.717: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 22 01:02:33.717: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 22 01:02:33.717: INFO: update-demo-kitten-d97kr is verified up and running
Jan 22 01:02:33.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-kitten-hr99x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:33.840: INFO: stderr: ""
Jan 22 01:02:33.840: INFO: stdout: "true"
Jan 22 01:02:33.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-kitten-hr99x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8v8pf'
Jan 22 01:02:33.987: INFO: stderr: ""
Jan 22 01:02:33.987: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Jan 22 01:02:33.987: INFO: validating pod update-demo-kitten-hr99x
Jan 22 01:02:34.003: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 22 01:02:34.003: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 22 01:02:34.003: INFO: update-demo-kitten-hr99x is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:02:34.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8v8pf" for this suite.
Jan 22 01:02:58.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:02:58.123: INFO: namespace: e2e-tests-kubectl-8v8pf, resource: bindings, ignored listing per whitelist
Jan 22 01:02:58.339: INFO: namespace e2e-tests-kubectl-8v8pf deletion completed in 24.324490028s

â€¢ [SLOW TEST:51.519 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:02:58.342: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bw967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-7567aff5-1de1-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:02:58.630: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-bw967" to be "success or failure"
Jan 22 01:02:58.635: INFO: Pod "pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.669101ms
Jan 22 01:03:00.641: INFO: Pod "pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010656796s
STEP: Saw pod success
Jan 22 01:03:00.641: INFO: Pod "pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:03:00.647: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:03:00.721: INFO: Waiting for pod pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:03:00.729: INFO: Pod pod-projected-configmaps-7568c666-1de1-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:03:00.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bw967" for this suite.
Jan 22 01:03:06.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:03:06.967: INFO: namespace: e2e-tests-projected-bw967, resource: bindings, ignored listing per whitelist
Jan 22 01:03:07.024: INFO: namespace e2e-tests-projected-bw967 deletion completed in 6.282524372s

â€¢ [SLOW TEST:8.683 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:03:07.024: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bh869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-7a90c9b4-1de1-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:03:07.333: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-bh869" to be "success or failure"
Jan 22 01:03:07.344: INFO: Pod "pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.198022ms
Jan 22 01:03:09.350: INFO: Pod "pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017501323s
STEP: Saw pod success
Jan 22 01:03:09.351: INFO: Pod "pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:03:09.356: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:03:09.388: INFO: Waiting for pod pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:03:09.393: INFO: Pod pod-projected-configmaps-7a98f9bf-1de1-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:03:09.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bh869" for this suite.
Jan 22 01:03:15.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:03:15.645: INFO: namespace: e2e-tests-projected-bh869, resource: bindings, ignored listing per whitelist
Jan 22 01:03:15.741: INFO: namespace e2e-tests-projected-bh869 deletion completed in 6.319547717s

â€¢ [SLOW TEST:8.717 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:03:15.743: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8pr2x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Jan 22 01:03:16.006: INFO: namespace e2e-tests-kubectl-8pr2x
Jan 22 01:03:16.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-8pr2x'
Jan 22 01:03:16.203: INFO: stderr: ""
Jan 22 01:03:16.203: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 22 01:03:17.209: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:03:17.209: INFO: Found 0 / 1
Jan 22 01:03:18.209: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:03:18.209: INFO: Found 1 / 1
Jan 22 01:03:18.209: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 22 01:03:18.214: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:03:18.214: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 22 01:03:18.214: INFO: wait on redis-master startup in e2e-tests-kubectl-8pr2x 
Jan 22 01:03:18.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 logs redis-master-hz24h redis-master --namespace=e2e-tests-kubectl-8pr2x'
Jan 22 01:03:18.375: INFO: stderr: ""
Jan 22 01:03:18.375: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Jan 01:03:17.493 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Jan 01:03:17.493 # Server started, Redis version 3.2.12\n1:M 22 Jan 01:03:17.493 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Jan 01:03:17.493 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 22 01:03:18.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-8pr2x'
Jan 22 01:03:18.537: INFO: stderr: ""
Jan 22 01:03:18.537: INFO: stdout: "service/rm2 exposed\n"
Jan 22 01:03:18.546: INFO: Service rm2 in namespace e2e-tests-kubectl-8pr2x found.
STEP: exposing service
Jan 22 01:03:20.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-8pr2x'
Jan 22 01:03:20.731: INFO: stderr: ""
Jan 22 01:03:20.731: INFO: stdout: "service/rm3 exposed\n"
Jan 22 01:03:20.740: INFO: Service rm3 in namespace e2e-tests-kubectl-8pr2x found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:03:22.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8pr2x" for this suite.
Jan 22 01:03:46.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:03:46.949: INFO: namespace: e2e-tests-kubectl-8pr2x, resource: bindings, ignored listing per whitelist
Jan 22 01:03:47.130: INFO: namespace e2e-tests-kubectl-8pr2x deletion completed in 24.346506286s

â€¢ [SLOW TEST:31.387 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create services for rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:03:47.131: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-n4mp6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jan 22 01:03:47.432: INFO: Waiting up to 5m0s for pod "downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-n4mp6" to be "success or failure"
Jan 22 01:03:47.437: INFO: Pod "downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.7061ms
Jan 22 01:03:49.444: INFO: Pod "downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011625088s
Jan 22 01:03:51.450: INFO: Pod "downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017853937s
STEP: Saw pod success
Jan 22 01:03:51.450: INFO: Pod "downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:03:51.455: INFO: Trying to get logs from node 10.191.28.26 pod downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:03:51.492: INFO: Waiting for pod downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:03:51.520: INFO: Pod downward-api-927c111a-1de1-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:03:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n4mp6" for this suite.
Jan 22 01:03:57.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:03:57.717: INFO: namespace: e2e-tests-downward-api-n4mp6, resource: bindings, ignored listing per whitelist
Jan 22 01:03:57.841: INFO: namespace e2e-tests-downward-api-n4mp6 deletion completed in 6.310481661s

â€¢ [SLOW TEST:10.710 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:03:57.843: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2kdkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-2kdkp
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
Jan 22 01:03:58.130: INFO: Found 0 stateful pods, waiting for 3
Jan 22 01:04:08.138: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:04:08.138: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:04:08.138: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:04:08.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-2kdkp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:04:08.633: INFO: stderr: ""
Jan 22 01:04:08.633: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:04:08.633: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Jan 22 01:04:18.770: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 22 01:04:18.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-2kdkp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:04:19.242: INFO: stderr: ""
Jan 22 01:04:19.242: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 01:04:19.242: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Jan 22 01:04:49.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-2kdkp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:04:49.669: INFO: stderr: ""
Jan 22 01:04:49.669: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:04:49.669: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:04:59.728: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 22 01:05:09.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-2kdkp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:05:10.708: INFO: stderr: ""
Jan 22 01:05:10.709: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 01:05:10.709: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jan 22 01:05:40.751: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2kdkp
Jan 22 01:05:40.759: INFO: Scaling statefulset ss2 to 0
Jan 22 01:06:10.842: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:06:10.850: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:06:10.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2kdkp" for this suite.
Jan 22 01:06:18.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:06:19.040: INFO: namespace: e2e-tests-statefulset-2kdkp, resource: bindings, ignored listing per whitelist
Jan 22 01:06:19.227: INFO: namespace e2e-tests-statefulset-2kdkp deletion completed in 8.306606504s

â€¢ [SLOW TEST:141.384 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:06:19.229: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-z9fph
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:06:19.554: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 22 01:06:19.582: INFO: Number of nodes with available pods: 0
Jan 22 01:06:19.582: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:06:20.626: INFO: Number of nodes with available pods: 0
Jan 22 01:06:20.626: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:06:21.602: INFO: Number of nodes with available pods: 3
Jan 22 01:06:21.602: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 22 01:06:21.649: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:21.649: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:21.649: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:22.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:22.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:22.664: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:23.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:23.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:23.664: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:23.664: INFO: Pod daemon-set-zg74t is not available
Jan 22 01:06:24.663: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:24.663: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:24.663: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:24.663: INFO: Pod daemon-set-zg74t is not available
Jan 22 01:06:25.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:25.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:25.664: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:25.664: INFO: Pod daemon-set-zg74t is not available
Jan 22 01:06:26.663: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:26.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:26.664: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:26.664: INFO: Pod daemon-set-zg74t is not available
Jan 22 01:06:27.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:27.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:27.664: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:27.664: INFO: Pod daemon-set-zg74t is not available
Jan 22 01:06:28.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:28.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:28.664: INFO: Wrong image for pod: daemon-set-zg74t. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:28.664: INFO: Pod daemon-set-zg74t is not available
Jan 22 01:06:29.663: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:29.663: INFO: Pod daemon-set-d6lz6 is not available
Jan 22 01:06:29.663: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:30.666: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:30.666: INFO: Pod daemon-set-d6lz6 is not available
Jan 22 01:06:30.666: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:31.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:31.664: INFO: Pod daemon-set-d6lz6 is not available
Jan 22 01:06:31.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:32.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:32.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:33.664: INFO: Wrong image for pod: daemon-set-7qj7n. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:33.664: INFO: Pod daemon-set-7qj7n is not available
Jan 22 01:06:33.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:34.664: INFO: Pod daemon-set-7lwh7 is not available
Jan 22 01:06:34.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:35.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:36.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:36.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:37.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:37.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:38.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:38.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:39.663: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:39.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:40.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:40.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:41.667: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:41.668: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:42.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:42.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:43.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:43.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:44.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:44.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:45.664: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:45.664: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:46.666: INFO: Wrong image for pod: daemon-set-w8vvr. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Jan 22 01:06:46.666: INFO: Pod daemon-set-w8vvr is not available
Jan 22 01:06:47.664: INFO: Pod daemon-set-5mxf4 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 22 01:06:47.726: INFO: Number of nodes with available pods: 2
Jan 22 01:06:47.726: INFO: Node 10.191.28.15 is running more than one daemon pod
Jan 22 01:06:48.745: INFO: Number of nodes with available pods: 3
Jan 22 01:06:48.745: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-z9fph, will wait for the garbage collector to delete the pods
Jan 22 01:06:48.910: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.266913ms
Jan 22 01:06:49.010: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.26488ms
Jan 22 01:06:59.625: INFO: Number of nodes with available pods: 0
Jan 22 01:06:59.625: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 01:06:59.637: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-z9fph/daemonsets","resourceVersion":"68346"},"items":null}

Jan 22 01:06:59.643: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-z9fph/pods","resourceVersion":"68346"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:06:59.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-z9fph" for this suite.
Jan 22 01:07:07.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:07:07.823: INFO: namespace: e2e-tests-daemonsets-z9fph, resource: bindings, ignored listing per whitelist
Jan 22 01:07:08.021: INFO: namespace e2e-tests-daemonsets-z9fph deletion completed in 8.328633564s

â€¢ [SLOW TEST:48.793 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:07:08.023: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gjwkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-0a3b11c6-1de2-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:07:08.343: INFO: Waiting up to 5m0s for pod "pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-gjwkh" to be "success or failure"
Jan 22 01:07:08.349: INFO: Pod "pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.710222ms
Jan 22 01:07:10.355: INFO: Pod "pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012030045s
STEP: Saw pod success
Jan 22 01:07:10.355: INFO: Pod "pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:07:10.361: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:07:10.404: INFO: Waiting for pod pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:07:10.409: INFO: Pod pod-secrets-0a4047ae-1de2-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:07:10.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gjwkh" for this suite.
Jan 22 01:07:16.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:07:16.595: INFO: namespace: e2e-tests-secrets-gjwkh, resource: bindings, ignored listing per whitelist
Jan 22 01:07:16.744: INFO: namespace e2e-tests-secrets-gjwkh deletion completed in 6.322198379s

â€¢ [SLOW TEST:8.720 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:07:16.744: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-7h7hd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-0f68abcc-1de2-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:07:17.005: INFO: Waiting up to 5m0s for pod "pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-7h7hd" to be "success or failure"
Jan 22 01:07:17.010: INFO: Pod "pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.015086ms
Jan 22 01:07:19.016: INFO: Pod "pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011148165s
STEP: Saw pod success
Jan 22 01:07:19.016: INFO: Pod "pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:07:19.021: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:07:19.072: INFO: Waiting for pod pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:07:19.079: INFO: Pod pod-secrets-0f6a0ab8-1de2-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:07:19.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7h7hd" for this suite.
Jan 22 01:07:25.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:07:25.207: INFO: namespace: e2e-tests-secrets-7h7hd, resource: bindings, ignored listing per whitelist
Jan 22 01:07:25.335: INFO: namespace e2e-tests-secrets-7h7hd deletion completed in 6.24334356s

â€¢ [SLOW TEST:8.591 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:07:25.335: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-gdrzn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
Jan 22 01:07:25.609: INFO: Waiting up to 5m0s for pod "var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-var-expansion-gdrzn" to be "success or failure"
Jan 22 01:07:25.613: INFO: Pod "var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.439658ms
Jan 22 01:07:27.619: INFO: Pod "var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010465965s
STEP: Saw pod success
Jan 22 01:07:27.619: INFO: Pod "var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:07:27.624: INFO: Trying to get logs from node 10.191.28.14 pod var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:07:27.658: INFO: Waiting for pod var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:07:27.663: INFO: Pod var-expansion-148a8cc0-1de2-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:07:27.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gdrzn" for this suite.
Jan 22 01:07:33.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:07:33.897: INFO: namespace: e2e-tests-var-expansion-gdrzn, resource: bindings, ignored listing per whitelist
Jan 22 01:07:33.917: INFO: namespace e2e-tests-var-expansion-gdrzn deletion completed in 6.241699458s

â€¢ [SLOW TEST:8.582 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:07:33.920: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-m4xs7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-19a9295e-1de2-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:07:34.205: INFO: Waiting up to 5m0s for pod "pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-m4xs7" to be "success or failure"
Jan 22 01:07:34.212: INFO: Pod "pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.829606ms
Jan 22 01:07:36.234: INFO: Pod "pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028795608s
STEP: Saw pod success
Jan 22 01:07:36.234: INFO: Pod "pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:07:36.239: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:07:36.284: INFO: Waiting for pod pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:07:36.291: INFO: Pod pod-secrets-19aa99be-1de2-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:07:36.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m4xs7" for this suite.
Jan 22 01:07:42.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:07:42.571: INFO: namespace: e2e-tests-secrets-m4xs7, resource: bindings, ignored listing per whitelist
Jan 22 01:07:42.633: INFO: namespace e2e-tests-secrets-m4xs7 deletion completed in 6.331508411s

â€¢ [SLOW TEST:8.713 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:07:42.634: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-g9gxx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-g9gxx
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-g9gxx
STEP: Deleting pre-stop pod
Jan 22 01:07:54.056: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:07:54.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-g9gxx" for this suite.
Jan 22 01:08:34.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:08:34.364: INFO: namespace: e2e-tests-prestop-g9gxx, resource: bindings, ignored listing per whitelist
Jan 22 01:08:34.422: INFO: namespace e2e-tests-prestop-g9gxx deletion completed in 40.301253249s

â€¢ [SLOW TEST:51.788 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:08:34.422: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wxjn4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Jan 22 01:08:34.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:34.923: INFO: stderr: ""
Jan 22 01:08:34.923: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 01:08:34.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:35.039: INFO: stderr: ""
Jan 22 01:08:35.039: INFO: stdout: "update-demo-nautilus-2mkkr update-demo-nautilus-gps69 "
Jan 22 01:08:35.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-2mkkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:35.172: INFO: stderr: ""
Jan 22 01:08:35.172: INFO: stdout: ""
Jan 22 01:08:35.172: INFO: update-demo-nautilus-2mkkr is created but not running
Jan 22 01:08:40.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:40.332: INFO: stderr: ""
Jan 22 01:08:40.332: INFO: stdout: "update-demo-nautilus-2mkkr update-demo-nautilus-gps69 "
Jan 22 01:08:40.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-2mkkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:40.456: INFO: stderr: ""
Jan 22 01:08:40.456: INFO: stdout: "true"
Jan 22 01:08:40.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-2mkkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:40.573: INFO: stderr: ""
Jan 22 01:08:40.573: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:08:40.573: INFO: validating pod update-demo-nautilus-2mkkr
Jan 22 01:08:40.585: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:08:40.586: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:08:40.586: INFO: update-demo-nautilus-2mkkr is verified up and running
Jan 22 01:08:40.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-gps69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:40.736: INFO: stderr: ""
Jan 22 01:08:40.736: INFO: stdout: "true"
Jan 22 01:08:40.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-gps69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:40.922: INFO: stderr: ""
Jan 22 01:08:40.922: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:08:40.922: INFO: validating pod update-demo-nautilus-gps69
Jan 22 01:08:40.938: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:08:40.938: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:08:40.938: INFO: update-demo-nautilus-gps69 is verified up and running
STEP: using delete to clean up resources
Jan 22 01:08:40.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:41.064: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 01:08:41.064: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 22 01:08:41.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-wxjn4'
Jan 22 01:08:41.223: INFO: stderr: "No resources found.\n"
Jan 22 01:08:41.223: INFO: stdout: ""
Jan 22 01:08:41.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -l name=update-demo --namespace=e2e-tests-kubectl-wxjn4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 01:08:41.336: INFO: stderr: ""
Jan 22 01:08:41.336: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:08:41.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wxjn4" for this suite.
Jan 22 01:09:05.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:09:05.563: INFO: namespace: e2e-tests-kubectl-wxjn4, resource: bindings, ignored listing per whitelist
Jan 22 01:09:05.632: INFO: namespace e2e-tests-kubectl-wxjn4 deletion completed in 24.28232471s

â€¢ [SLOW TEST:31.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:09:05.633: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wchtx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-wchtx
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wchtx
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wchtx
Jan 22 01:09:05.921: INFO: Found 0 stateful pods, waiting for 1
Jan 22 01:09:15.928: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 22 01:09:15.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:09:16.294: INFO: stderr: ""
Jan 22 01:09:16.294: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:09:16.294: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:09:16.301: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 22 01:09:26.307: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:09:26.307: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:09:26.335: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:26.335: INFO: ss-0  10.191.28.14  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:26.335: INFO: 
Jan 22 01:09:26.335: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 22 01:09:27.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994751984s
Jan 22 01:09:28.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988574311s
Jan 22 01:09:29.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.9807239s
Jan 22 01:09:30.362: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974562871s
Jan 22 01:09:31.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967959648s
Jan 22 01:09:32.375: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96189828s
Jan 22 01:09:33.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954857324s
Jan 22 01:09:34.388: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.948402231s
Jan 22 01:09:35.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 941.610789ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wchtx
Jan 22 01:09:36.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:09:36.713: INFO: stderr: ""
Jan 22 01:09:36.713: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 01:09:36.713: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 01:09:36.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:09:37.085: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Jan 22 01:09:37.085: INFO: stdout: ""
Jan 22 01:09:37.085: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Jan 22 01:09:37.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:09:37.546: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Jan 22 01:09:37.546: INFO: stdout: ""
Jan 22 01:09:37.546: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jan 22 01:09:37.553: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:09:37.553: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:09:37.553: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 22 01:09:37.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:09:37.903: INFO: stderr: ""
Jan 22 01:09:37.903: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:09:37.903: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:09:37.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:09:38.329: INFO: stderr: ""
Jan 22 01:09:38.329: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:09:38.329: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:09:38.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:09:38.693: INFO: stderr: ""
Jan 22 01:09:38.693: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:09:38.693: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:09:38.693: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:09:38.701: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 22 01:09:48.718: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:09:48.718: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:09:48.718: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:09:48.741: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:48.741: INFO: ss-0  10.191.28.14  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:48.741: INFO: ss-1  10.191.28.26  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:48.741: INFO: ss-2  10.191.28.15  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:48.741: INFO: 
Jan 22 01:09:48.741: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:49.748: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:49.748: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:49.748: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:49.748: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:49.748: INFO: 
Jan 22 01:09:49.748: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:50.754: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:50.754: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:50.754: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:50.754: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:50.754: INFO: 
Jan 22 01:09:50.754: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:51.760: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:51.760: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:51.760: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:51.760: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:51.760: INFO: 
Jan 22 01:09:51.760: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:52.767: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:52.767: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:52.767: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:52.767: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:52.767: INFO: 
Jan 22 01:09:52.767: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:53.773: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:53.773: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:53.773: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:53.773: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:53.773: INFO: 
Jan 22 01:09:53.773: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:54.826: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:54.826: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:54.826: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:54.826: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:54.827: INFO: 
Jan 22 01:09:54.827: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:55.834: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:55.834: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:55.834: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:55.834: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:55.834: INFO: 
Jan 22 01:09:55.834: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:56.840: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:56.840: INFO: ss-0  10.191.28.14  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:05 +0000 UTC  }]
Jan 22 01:09:56.840: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:56.840: INFO: ss-2  10.191.28.15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:56.840: INFO: 
Jan 22 01:09:56.840: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 01:09:57.846: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 22 01:09:57.846: INFO: ss-1  10.191.28.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 01:09:26 +0000 UTC  }]
Jan 22 01:09:57.846: INFO: 
Jan 22 01:09:57.846: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wchtx
Jan 22 01:09:58.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:09:59.125: INFO: rc: 1
Jan 22 01:09:59.126: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42147f350 exit status 1 <nil> <nil> true [0xc421bdaf90 0xc421bdafa8 0xc421bdafc0] [0xc421bdaf90 0xc421bdafa8 0xc421bdafc0] [0xc421bdafa0 0xc421bdafb8] [0x8f9b60 0x8f9b60] 0xc4218ac600 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jan 22 01:10:09.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:10:09.322: INFO: rc: 1
Jan 22 01:10:09.322: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420e17230 exit status 1 <nil> <nil> true [0xc4210490e8 0xc421049100 0xc421049118] [0xc4210490e8 0xc421049100 0xc421049118] [0xc4210490f8 0xc421049110] [0x8f9b60 0x8f9b60] 0xc421de1560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:10:19.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:10:19.430: INFO: rc: 1
Jan 22 01:10:19.430: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42147f830 exit status 1 <nil> <nil> true [0xc421bdafc8 0xc421bdaff8 0xc421bdb010] [0xc421bdafc8 0xc421bdaff8 0xc421bdb010] [0xc421bdafd8 0xc421bdb008] [0x8f9b60 0x8f9b60] 0xc4218ac720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:10:29.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:10:29.549: INFO: rc: 1
Jan 22 01:10:29.549: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420e175c0 exit status 1 <nil> <nil> true [0xc421049120 0xc421049138 0xc421049150] [0xc421049120 0xc421049138 0xc421049150] [0xc421049130 0xc421049148] [0x8f9b60 0x8f9b60] 0xc421de1680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:10:39.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:10:39.722: INFO: rc: 1
Jan 22 01:10:39.722: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc420e17c50 exit status 1 <nil> <nil> true [0xc421049158 0xc421049178 0xc421049190] [0xc421049158 0xc421049178 0xc421049190] [0xc421049170 0xc421049188] [0x8f9b60 0x8f9b60] 0xc421de17a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:10:49.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:10:49.857: INFO: rc: 1
Jan 22 01:10:49.857: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135e480 exit status 1 <nil> <nil> true [0xc421bda020 0xc421bda038 0xc421bda058] [0xc421bda020 0xc421bda038 0xc421bda058] [0xc421bda030 0xc421bda048] [0x8f9b60 0x8f9b60] 0xc421bf4960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:10:59.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:11:00.040: INFO: rc: 1
Jan 22 01:11:00.040: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215ce420 exit status 1 <nil> <nil> true [0xc421048000 0xc421048068 0xc421048098] [0xc421048000 0xc421048068 0xc421048098] [0xc421048038 0xc421048088] [0x8f9b60 0x8f9b60] 0xc421b1c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:11:10.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:11:10.176: INFO: rc: 1
Jan 22 01:11:10.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135e900 exit status 1 <nil> <nil> true [0xc421bda078 0xc421bda0a0 0xc421bda0b8] [0xc421bda078 0xc421bda0a0 0xc421bda0b8] [0xc421bda098 0xc421bda0b0] [0x8f9b60 0x8f9b60] 0xc421bf52c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:11:20.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:11:20.307: INFO: rc: 1
Jan 22 01:11:20.307: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135ecc0 exit status 1 <nil> <nil> true [0xc421bda0c0 0xc421bda0d8 0xc421bda0f0] [0xc421bda0c0 0xc421bda0d8 0xc421bda0f0] [0xc421bda0d0 0xc421bda0e8] [0x8f9b60 0x8f9b60] 0xc420f264e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:11:30.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:11:30.473: INFO: rc: 1
Jan 22 01:11:30.473: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135f1d0 exit status 1 <nil> <nil> true [0xc421bda0f8 0xc421bda110 0xc421bda128] [0xc421bda0f8 0xc421bda110 0xc421bda128] [0xc421bda108 0xc421bda120] [0x8f9b60 0x8f9b60] 0xc420f274a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:11:40.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:11:40.589: INFO: rc: 1
Jan 22 01:11:40.589: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215ce8a0 exit status 1 <nil> <nil> true [0xc4210480a8 0xc421048100 0xc421048140] [0xc4210480a8 0xc421048100 0xc421048140] [0xc4210480d8 0xc421048130] [0x8f9b60 0x8f9b60] 0xc421b1cde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:11:50.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:11:50.698: INFO: rc: 1
Jan 22 01:11:50.698: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cede0 exit status 1 <nil> <nil> true [0xc421048150 0xc421048188 0xc4210481b8] [0xc421048150 0xc421048188 0xc4210481b8] [0xc421048170 0xc4210481a8] [0x8f9b60 0x8f9b60] 0xc421b1dd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:12:00.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:12:01.260: INFO: rc: 1
Jan 22 01:12:01.260: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cf200 exit status 1 <nil> <nil> true [0xc4210481c8 0xc421048238 0xc421048268] [0xc4210481c8 0xc421048238 0xc421048268] [0xc421048210 0xc421048258] [0x8f9b60 0x8f9b60] 0xc420a53a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:12:11.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:12:11.363: INFO: rc: 1
Jan 22 01:12:11.364: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135f590 exit status 1 <nil> <nil> true [0xc421bda130 0xc421bda148 0xc421bda160] [0xc421bda130 0xc421bda148 0xc421bda160] [0xc421bda140 0xc421bda158] [0x8f9b60 0x8f9b60] 0xc4200c2300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:12:21.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:12:21.549: INFO: rc: 1
Jan 22 01:12:21.549: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135f9e0 exit status 1 <nil> <nil> true [0xc421bda168 0xc421bda180 0xc421bda1b0] [0xc421bda168 0xc421bda180 0xc421bda1b0] [0xc421bda178 0xc421bda1a8] [0x8f9b60 0x8f9b60] 0xc4200c3aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:12:31.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:12:31.743: INFO: rc: 1
Jan 22 01:12:31.744: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cf680 exit status 1 <nil> <nil> true [0xc421048288 0xc4210482d0 0xc421048310] [0xc421048288 0xc4210482d0 0xc421048310] [0xc4210482c0 0xc421048300] [0x8f9b60 0x8f9b60] 0xc421a8ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:12:41.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:12:41.849: INFO: rc: 1
Jan 22 01:12:41.849: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135fdd0 exit status 1 <nil> <nil> true [0xc421bda1b8 0xc421bda1d0 0xc421bda1e8] [0xc421bda1b8 0xc421bda1d0 0xc421bda1e8] [0xc421bda1c8 0xc421bda1e0] [0x8f9b60 0x8f9b60] 0xc42194d1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:12:51.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:12:51.955: INFO: rc: 1
Jan 22 01:12:51.955: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215ce450 exit status 1 <nil> <nil> true [0xc421048028 0xc421048078 0xc4210480a8] [0xc421048028 0xc421048078 0xc4210480a8] [0xc421048068 0xc421048098] [0x8f9b60 0x8f9b60] 0xc42194c600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:13:01.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:13:02.065: INFO: rc: 1
Jan 22 01:13:02.065: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215ce930 exit status 1 <nil> <nil> true [0xc4210480c8 0xc421048120 0xc421048150] [0xc4210480c8 0xc421048120 0xc421048150] [0xc421048100 0xc421048140] [0x8f9b60 0x8f9b60] 0xc4200c2300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:13:12.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:13:12.248: INFO: rc: 1
Jan 22 01:13:12.248: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135e450 exit status 1 <nil> <nil> true [0xc421bda000 0xc421bda030 0xc421bda048] [0xc421bda000 0xc421bda030 0xc421bda048] [0xc421bda028 0xc421bda040] [0x8f9b60 0x8f9b60] 0xc420a522a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:13:22.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:13:22.369: INFO: rc: 1
Jan 22 01:13:22.369: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135e8a0 exit status 1 <nil> <nil> true [0xc421bda058 0xc421bda098 0xc421bda0b0] [0xc421bda058 0xc421bda098 0xc421bda0b0] [0xc421bda080 0xc421bda0a8] [0x8f9b60 0x8f9b60] 0xc420f26000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:13:32.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:13:32.541: INFO: rc: 1
Jan 22 01:13:32.541: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135ec90 exit status 1 <nil> <nil> true [0xc421bda0b8 0xc421bda0d0 0xc421bda0e8] [0xc421bda0b8 0xc421bda0d0 0xc421bda0e8] [0xc421bda0c8 0xc421bda0e0] [0x8f9b60 0x8f9b60] 0xc420f270e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:13:42.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:13:42.670: INFO: rc: 1
Jan 22 01:13:42.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cee70 exit status 1 <nil> <nil> true [0xc421048160 0xc421048198 0xc4210481c8] [0xc421048160 0xc421048198 0xc4210481c8] [0xc421048188 0xc4210481b8] [0x8f9b60 0x8f9b60] 0xc4200c3aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:13:52.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:13:52.798: INFO: rc: 1
Jan 22 01:13:52.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135f200 exit status 1 <nil> <nil> true [0xc421bda0f0 0xc421bda108 0xc421bda120] [0xc421bda0f0 0xc421bda108 0xc421bda120] [0xc421bda100 0xc421bda118] [0x8f9b60 0x8f9b60] 0xc420f27aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:14:02.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:14:02.922: INFO: rc: 1
Jan 22 01:14:02.922: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cf290 exit status 1 <nil> <nil> true [0xc421048200 0xc421048248 0xc421048288] [0xc421048200 0xc421048248 0xc421048288] [0xc421048238 0xc421048268] [0x8f9b60 0x8f9b60] 0xc421b1c600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:14:12.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:14:13.122: INFO: rc: 1
Jan 22 01:14:13.122: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135f680 exit status 1 <nil> <nil> true [0xc421bda128 0xc421bda140 0xc421bda158] [0xc421bda128 0xc421bda140 0xc421bda158] [0xc421bda138 0xc421bda150] [0x8f9b60 0x8f9b60] 0xc421bf4cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:14:23.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:14:23.261: INFO: rc: 1
Jan 22 01:14:23.261: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135fb00 exit status 1 <nil> <nil> true [0xc421bda160 0xc421bda178 0xc421bda1a8] [0xc421bda160 0xc421bda178 0xc421bda1a8] [0xc421bda170 0xc421bda190] [0x8f9b60 0x8f9b60] 0xc421bf59e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:14:33.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:14:33.422: INFO: rc: 1
Jan 22 01:14:33.422: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cf7d0 exit status 1 <nil> <nil> true [0xc421048298 0xc4210482f0 0xc421048320] [0xc421048298 0xc4210482f0 0xc421048320] [0xc4210482d0 0xc421048310] [0x8f9b60 0x8f9b60] 0xc421b1d7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:14:43.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:14:43.541: INFO: rc: 1
Jan 22 01:14:43.541: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42135fef0 exit status 1 <nil> <nil> true [0xc421bda1b0 0xc421bda1c8 0xc421bda1e0] [0xc421bda1b0 0xc421bda1c8 0xc421bda1e0] [0xc421bda1c0 0xc421bda1d8] [0x8f9b60 0x8f9b60] 0xc421a8d560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:14:53.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:14:53.680: INFO: rc: 1
Jan 22 01:14:53.680: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215cfb90 exit status 1 <nil> <nil> true [0xc421048350 0xc421048390 0xc4210483d8] [0xc421048350 0xc421048390 0xc4210483d8] [0xc421048380 0xc4210483c8] [0x8f9b60 0x8f9b60] 0xc421b1dd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan 22 01:15:03.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-wchtx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:15:03.790: INFO: rc: 1
Jan 22 01:15:03.790: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Jan 22 01:15:03.790: INFO: Scaling statefulset ss to 0
Jan 22 01:15:03.843: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jan 22 01:15:03.850: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wchtx
Jan 22 01:15:03.857: INFO: Scaling statefulset ss to 0
Jan 22 01:15:03.877: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:15:03.884: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:15:03.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wchtx" for this suite.
Jan 22 01:15:09.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:15:10.088: INFO: namespace: e2e-tests-statefulset-wchtx, resource: bindings, ignored listing per whitelist
Jan 22 01:15:10.181: INFO: namespace e2e-tests-statefulset-wchtx deletion completed in 6.255812153s

â€¢ [SLOW TEST:364.547 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:15:10.181: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tt28l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 22 01:15:10.447: INFO: Waiting up to 5m0s for pod "pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-tt28l" to be "success or failure"
Jan 22 01:15:10.452: INFO: Pod "pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.957573ms
Jan 22 01:15:12.458: INFO: Pod "pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011002152s
Jan 22 01:15:14.464: INFO: Pod "pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016879601s
STEP: Saw pod success
Jan 22 01:15:14.464: INFO: Pod "pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:15:14.469: INFO: Trying to get logs from node 10.191.28.14 pod pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:15:14.537: INFO: Waiting for pod pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:15:14.542: INFO: Pod pod-299ba2d1-1de3-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:15:14.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tt28l" for this suite.
Jan 22 01:15:20.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:15:20.672: INFO: namespace: e2e-tests-emptydir-tt28l, resource: bindings, ignored listing per whitelist
Jan 22 01:15:20.825: INFO: namespace e2e-tests-emptydir-tt28l deletion completed in 6.272516212s

â€¢ [SLOW TEST:10.645 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:15:20.826: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-gl7r9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:15:21.146: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 22 01:15:21.164: INFO: Number of nodes with available pods: 0
Jan 22 01:15:21.164: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 22 01:15:21.203: INFO: Number of nodes with available pods: 0
Jan 22 01:15:21.204: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:22.210: INFO: Number of nodes with available pods: 0
Jan 22 01:15:22.210: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:23.209: INFO: Number of nodes with available pods: 1
Jan 22 01:15:23.210: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 22 01:15:23.326: INFO: Number of nodes with available pods: 0
Jan 22 01:15:23.326: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 22 01:15:23.341: INFO: Number of nodes with available pods: 0
Jan 22 01:15:23.341: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:24.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:24.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:25.351: INFO: Number of nodes with available pods: 0
Jan 22 01:15:25.351: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:26.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:26.347: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:27.348: INFO: Number of nodes with available pods: 0
Jan 22 01:15:27.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:28.348: INFO: Number of nodes with available pods: 0
Jan 22 01:15:28.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:29.348: INFO: Number of nodes with available pods: 0
Jan 22 01:15:29.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:30.349: INFO: Number of nodes with available pods: 0
Jan 22 01:15:30.349: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:31.348: INFO: Number of nodes with available pods: 0
Jan 22 01:15:31.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:32.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:32.347: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:33.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:33.347: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:34.348: INFO: Number of nodes with available pods: 0
Jan 22 01:15:34.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:35.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:35.347: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:36.348: INFO: Number of nodes with available pods: 0
Jan 22 01:15:36.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:37.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:37.348: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:38.347: INFO: Number of nodes with available pods: 0
Jan 22 01:15:38.347: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:15:39.347: INFO: Number of nodes with available pods: 1
Jan 22 01:15:39.347: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-gl7r9, will wait for the garbage collector to delete the pods
Jan 22 01:15:39.436: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.559335ms
Jan 22 01:15:39.536: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.352291ms
Jan 22 01:15:47.242: INFO: Number of nodes with available pods: 0
Jan 22 01:15:47.242: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 01:15:47.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gl7r9/daemonsets","resourceVersion":"69881"},"items":null}

Jan 22 01:15:47.255: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gl7r9/pods","resourceVersion":"69881"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:15:47.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gl7r9" for this suite.
Jan 22 01:15:53.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:15:53.816: INFO: namespace: e2e-tests-daemonsets-gl7r9, resource: bindings, ignored listing per whitelist
Jan 22 01:15:54.073: INFO: namespace e2e-tests-daemonsets-gl7r9 deletion completed in 6.754764414s

â€¢ [SLOW TEST:33.248 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:15:54.074: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-275d9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-43c6a4ee-1de3-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:15:54.420: INFO: Waiting up to 5m0s for pod "pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-275d9" to be "success or failure"
Jan 22 01:15:54.425: INFO: Pod "pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.366414ms
Jan 22 01:15:56.431: INFO: Pod "pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011111892s
STEP: Saw pod success
Jan 22 01:15:56.431: INFO: Pod "pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:15:56.436: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:15:56.469: INFO: Waiting for pod pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:15:56.474: INFO: Pod pod-configmaps-43c7a6e4-1de3-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:15:56.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-275d9" for this suite.
Jan 22 01:16:02.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:16:02.696: INFO: namespace: e2e-tests-configmap-275d9, resource: bindings, ignored listing per whitelist
Jan 22 01:16:02.721: INFO: namespace e2e-tests-configmap-275d9 deletion completed in 6.236716887s

â€¢ [SLOW TEST:8.647 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:16:02.722: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-46t92
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:16:02.984: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-46t92" to be "success or failure"
Jan 22 01:16:02.997: INFO: Pod "downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.855675ms
Jan 22 01:16:05.004: INFO: Pod "downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.01936502s
Jan 22 01:16:07.010: INFO: Pod "downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025290091s
STEP: Saw pod success
Jan 22 01:16:07.010: INFO: Pod "downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:16:07.014: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:16:07.120: INFO: Waiting for pod downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:16:07.127: INFO: Pod downwardapi-volume-48ebf252-1de3-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:16:07.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-46t92" for this suite.
Jan 22 01:16:13.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:16:13.308: INFO: namespace: e2e-tests-downward-api-46t92, resource: bindings, ignored listing per whitelist
Jan 22 01:16:13.442: INFO: namespace e2e-tests-downward-api-46t92 deletion completed in 6.302984526s

â€¢ [SLOW TEST:10.720 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:16:13.444: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g5gvt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Jan 22 01:16:13.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-g5gvt'
Jan 22 01:16:14.076: INFO: stderr: ""
Jan 22 01:16:14.076: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 22 01:16:15.083: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:16:15.083: INFO: Found 0 / 1
Jan 22 01:16:16.084: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:16:16.084: INFO: Found 1 / 1
Jan 22 01:16:16.084: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 22 01:16:16.090: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:16:16.090: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 22 01:16:16.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 patch pod redis-master-xwptf --namespace=e2e-tests-kubectl-g5gvt -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 22 01:16:16.249: INFO: stderr: ""
Jan 22 01:16:16.249: INFO: stdout: "pod/redis-master-xwptf patched\n"
STEP: checking annotations
Jan 22 01:16:16.255: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:16:16.255: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:16:16.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g5gvt" for this suite.
Jan 22 01:16:38.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:16:38.342: INFO: namespace: e2e-tests-kubectl-g5gvt, resource: bindings, ignored listing per whitelist
Jan 22 01:16:38.528: INFO: namespace e2e-tests-kubectl-g5gvt deletion completed in 22.258647714s

â€¢ [SLOW TEST:25.084 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:16:38.528: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-l7wpw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 22 01:16:38.835: INFO: Waiting up to 5m0s for pod "pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-l7wpw" to be "success or failure"
Jan 22 01:16:38.840: INFO: Pod "pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.68182ms
Jan 22 01:16:40.847: INFO: Pod "pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012232566s
STEP: Saw pod success
Jan 22 01:16:40.847: INFO: Pod "pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:16:40.852: INFO: Trying to get logs from node 10.191.28.14 pod pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:16:40.890: INFO: Waiting for pod pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:16:40.920: INFO: Pod pod-5e4a4083-1de3-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:16:40.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l7wpw" for this suite.
Jan 22 01:16:46.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:16:47.080: INFO: namespace: e2e-tests-emptydir-l7wpw, resource: bindings, ignored listing per whitelist
Jan 22 01:16:47.216: INFO: namespace e2e-tests-emptydir-l7wpw deletion completed in 6.281330973s

â€¢ [SLOW TEST:8.688 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:16:47.216: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2lsbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:16:47.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-2lsbn" to be "success or failure"
Jan 22 01:16:47.525: INFO: Pod "downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 56.57025ms
Jan 22 01:16:49.532: INFO: Pod "downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.063348903s
STEP: Saw pod success
Jan 22 01:16:49.532: INFO: Pod "downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:16:49.537: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:16:49.620: INFO: Waiting for pod downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:16:49.627: INFO: Pod downwardapi-volume-636faf65-1de3-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:16:49.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2lsbn" for this suite.
Jan 22 01:16:55.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:16:55.807: INFO: namespace: e2e-tests-projected-2lsbn, resource: bindings, ignored listing per whitelist
Jan 22 01:16:55.920: INFO: namespace e2e-tests-projected-2lsbn deletion completed in 6.280417142s

â€¢ [SLOW TEST:8.704 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:16:55.922: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-szpwb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-68a4b1be-1de3-11e9-8691-1e7d95aa6bfc
STEP: Creating secret with name secret-projected-all-test-volume-68a4b19a-1de3-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 22 01:16:56.221: INFO: Waiting up to 5m0s for pod "projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-szpwb" to be "success or failure"
Jan 22 01:16:56.227: INFO: Pod "projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.354248ms
Jan 22 01:16:58.233: INFO: Pod "projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011474026s
Jan 22 01:17:00.239: INFO: Pod "projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01773508s
STEP: Saw pod success
Jan 22 01:17:00.239: INFO: Pod "projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:17:00.245: INFO: Trying to get logs from node 10.191.28.14 pod projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 22 01:17:00.320: INFO: Waiting for pod projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:17:00.325: INFO: Pod projected-volume-68a4b15c-1de3-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:17:00.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-szpwb" for this suite.
Jan 22 01:17:06.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:17:06.484: INFO: namespace: e2e-tests-projected-szpwb, resource: bindings, ignored listing per whitelist
Jan 22 01:17:06.643: INFO: namespace e2e-tests-projected-szpwb deletion completed in 6.307097379s

â€¢ [SLOW TEST:10.721 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:17:06.646: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rssc2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 01:17:06.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rssc2'
Jan 22 01:17:07.065: INFO: stderr: ""
Jan 22 01:17:07.065: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 22 01:17:12.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rssc2 -o json'
Jan 22 01:17:12.322: INFO: stderr: ""
Jan 22 01:17:12.322: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-01-22T01:17:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-rssc2\",\n        \"resourceVersion\": \"70282\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-rssc2/pods/e2e-test-nginx-pod\",\n        \"uid\": \"6f1c0ace-1de3-11e9-9022-22547e9f3e72\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sl8vl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.191.28.14\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sl8vl\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sl8vl\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T01:17:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T01:17:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T01:17:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://fa449838bf3c4beeeb24f301ae887cd725660b5d0aebe53dc612a0de75101d6f\",\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imageID\": \"k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-22T01:17:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.191.28.14\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.27.247\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-22T01:17:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 22 01:17:12.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 replace -f - --namespace=e2e-tests-kubectl-rssc2'
Jan 22 01:17:12.536: INFO: stderr: ""
Jan 22 01:17:12.536: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
Jan 22 01:17:12.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rssc2'
Jan 22 01:17:15.328: INFO: stderr: ""
Jan 22 01:17:15.328: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:17:15.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rssc2" for this suite.
Jan 22 01:17:21.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:17:21.629: INFO: namespace: e2e-tests-kubectl-rssc2, resource: bindings, ignored listing per whitelist
Jan 22 01:17:21.638: INFO: namespace e2e-tests-kubectl-rssc2 deletion completed in 6.299758427s

â€¢ [SLOW TEST:14.992 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:17:21.639: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zxrb6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zxrb6
Jan 22 01:17:23.932: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zxrb6
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 01:17:23.937: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:21:25.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zxrb6" for this suite.
Jan 22 01:21:31.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:21:31.491: INFO: namespace: e2e-tests-container-probe-zxrb6, resource: bindings, ignored listing per whitelist
Jan 22 01:21:31.640: INFO: namespace e2e-tests-container-probe-zxrb6 deletion completed in 6.308713389s

â€¢ [SLOW TEST:250.001 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:21:31.641: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zd9r8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Jan 22 01:21:31.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:32.125: INFO: stderr: ""
Jan 22 01:21:32.125: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 01:21:32.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:32.262: INFO: stderr: ""
Jan 22 01:21:32.262: INFO: stdout: "update-demo-nautilus-2phmn update-demo-nautilus-b7fjv "
Jan 22 01:21:32.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-2phmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:32.397: INFO: stderr: ""
Jan 22 01:21:32.397: INFO: stdout: ""
Jan 22 01:21:32.397: INFO: update-demo-nautilus-2phmn is created but not running
Jan 22 01:21:37.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:37.547: INFO: stderr: ""
Jan 22 01:21:37.547: INFO: stdout: "update-demo-nautilus-2phmn update-demo-nautilus-b7fjv "
Jan 22 01:21:37.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-2phmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:37.698: INFO: stderr: ""
Jan 22 01:21:37.698: INFO: stdout: "true"
Jan 22 01:21:37.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-2phmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:37.894: INFO: stderr: ""
Jan 22 01:21:37.894: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:21:37.894: INFO: validating pod update-demo-nautilus-2phmn
Jan 22 01:21:37.909: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:21:37.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:21:37.909: INFO: update-demo-nautilus-2phmn is verified up and running
Jan 22 01:21:37.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-b7fjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:38.054: INFO: stderr: ""
Jan 22 01:21:38.054: INFO: stdout: "true"
Jan 22 01:21:38.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-b7fjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:38.195: INFO: stderr: ""
Jan 22 01:21:38.195: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:21:38.195: INFO: validating pod update-demo-nautilus-b7fjv
Jan 22 01:21:38.211: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:21:38.211: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:21:38.211: INFO: update-demo-nautilus-b7fjv is verified up and running
STEP: scaling down the replication controller
Jan 22 01:21:38.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:38.433: INFO: stderr: ""
Jan 22 01:21:38.433: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 01:21:38.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:38.567: INFO: stderr: ""
Jan 22 01:21:38.567: INFO: stdout: "update-demo-nautilus-2phmn update-demo-nautilus-b7fjv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 22 01:21:43.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:43.706: INFO: stderr: ""
Jan 22 01:21:43.706: INFO: stdout: "update-demo-nautilus-2phmn update-demo-nautilus-b7fjv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 22 01:21:48.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:48.859: INFO: stderr: ""
Jan 22 01:21:48.859: INFO: stdout: "update-demo-nautilus-b7fjv "
Jan 22 01:21:48.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-b7fjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:48.977: INFO: stderr: ""
Jan 22 01:21:48.977: INFO: stdout: "true"
Jan 22 01:21:48.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-b7fjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:49.138: INFO: stderr: ""
Jan 22 01:21:49.138: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:21:49.138: INFO: validating pod update-demo-nautilus-b7fjv
Jan 22 01:21:49.150: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:21:49.150: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:21:49.150: INFO: update-demo-nautilus-b7fjv is verified up and running
STEP: scaling up the replication controller
Jan 22 01:21:49.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:50.335: INFO: stderr: ""
Jan 22 01:21:50.336: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 01:21:50.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:50.485: INFO: stderr: ""
Jan 22 01:21:50.485: INFO: stdout: "update-demo-nautilus-b7fjv update-demo-nautilus-ffkj6 "
Jan 22 01:21:50.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-b7fjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:50.631: INFO: stderr: ""
Jan 22 01:21:50.631: INFO: stdout: "true"
Jan 22 01:21:50.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-b7fjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:50.754: INFO: stderr: ""
Jan 22 01:21:50.754: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:21:50.754: INFO: validating pod update-demo-nautilus-b7fjv
Jan 22 01:21:50.769: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:21:50.769: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:21:50.769: INFO: update-demo-nautilus-b7fjv is verified up and running
Jan 22 01:21:50.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-ffkj6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:50.956: INFO: stderr: ""
Jan 22 01:21:50.956: INFO: stdout: "true"
Jan 22 01:21:50.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods update-demo-nautilus-ffkj6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:51.101: INFO: stderr: ""
Jan 22 01:21:51.101: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Jan 22 01:21:51.101: INFO: validating pod update-demo-nautilus-ffkj6
Jan 22 01:21:51.115: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 01:21:51.115: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 01:21:51.115: INFO: update-demo-nautilus-ffkj6 is verified up and running
STEP: using delete to clean up resources
Jan 22 01:21:51.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:51.253: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 01:21:51.253: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 22 01:21:51.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zd9r8'
Jan 22 01:21:51.398: INFO: stderr: "No resources found.\n"
Jan 22 01:21:51.398: INFO: stdout: ""
Jan 22 01:21:51.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zd9r8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 01:21:51.522: INFO: stderr: ""
Jan 22 01:21:51.522: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:21:51.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zd9r8" for this suite.
Jan 22 01:21:57.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:21:57.870: INFO: namespace: e2e-tests-kubectl-zd9r8, resource: bindings, ignored listing per whitelist
Jan 22 01:21:57.900: INFO: namespace e2e-tests-kubectl-zd9r8 deletion completed in 6.366266736s

â€¢ [SLOW TEST:26.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:21:57.901: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h6qfq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-1ca1585e-1de4-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:21:58.245: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-h6qfq" to be "success or failure"
Jan 22 01:21:58.251: INFO: Pod "pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.555809ms
Jan 22 01:22:00.257: INFO: Pod "pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011652354s
STEP: Saw pod success
Jan 22 01:22:00.257: INFO: Pod "pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:22:00.263: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:22:00.308: INFO: Waiting for pod pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:22:00.320: INFO: Pod pod-projected-secrets-1cac9b99-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:22:00.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h6qfq" for this suite.
Jan 22 01:22:06.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:22:06.548: INFO: namespace: e2e-tests-projected-h6qfq, resource: bindings, ignored listing per whitelist
Jan 22 01:22:06.619: INFO: namespace e2e-tests-projected-h6qfq deletion completed in 6.287842548s

â€¢ [SLOW TEST:8.718 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:22:06.620: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qbs7g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-qbs7g/secret-test-21d17fe0-1de4-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:22:06.940: INFO: Waiting up to 5m0s for pod "pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-qbs7g" to be "success or failure"
Jan 22 01:22:06.945: INFO: Pod "pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.155332ms
Jan 22 01:22:08.951: INFO: Pod "pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010876744s
STEP: Saw pod success
Jan 22 01:22:08.951: INFO: Pod "pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:22:08.957: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc container env-test: <nil>
STEP: delete the pod
Jan 22 01:22:09.009: INFO: Waiting for pod pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:22:09.014: INFO: Pod pod-configmaps-21db7c46-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:22:09.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qbs7g" for this suite.
Jan 22 01:22:15.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:22:15.093: INFO: namespace: e2e-tests-secrets-qbs7g, resource: bindings, ignored listing per whitelist
Jan 22 01:22:15.284: INFO: namespace e2e-tests-secrets-qbs7g deletion completed in 6.260083308s

â€¢ [SLOW TEST:8.664 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:22:15.285: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4f988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0122 01:22:25.747619      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 01:22:25.747: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:22:25.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4f988" for this suite.
Jan 22 01:22:33.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:22:34.110: INFO: namespace: e2e-tests-gc-4f988, resource: bindings, ignored listing per whitelist
Jan 22 01:22:34.117: INFO: namespace e2e-tests-gc-4f988 deletion completed in 8.29677036s

â€¢ [SLOW TEST:18.832 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:22:34.118: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-f49s2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jan 22 01:22:34.434: INFO: Waiting up to 5m0s for pod "downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-f49s2" to be "success or failure"
Jan 22 01:22:34.439: INFO: Pod "downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.102691ms
Jan 22 01:22:36.446: INFO: Pod "downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012016913s
STEP: Saw pod success
Jan 22 01:22:36.446: INFO: Pod "downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:22:36.453: INFO: Trying to get logs from node 10.191.28.14 pod downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:22:36.488: INFO: Waiting for pod downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:22:36.493: INFO: Pod downward-api-323e9917-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:22:36.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f49s2" for this suite.
Jan 22 01:22:42.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:22:42.767: INFO: namespace: e2e-tests-downward-api-f49s2, resource: bindings, ignored listing per whitelist
Jan 22 01:22:42.832: INFO: namespace e2e-tests-downward-api-f49s2 deletion completed in 6.328860558s

â€¢ [SLOW TEST:8.714 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:22:42.832: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xvhvh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-3766d0ba-1de4-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:22:43.092: INFO: Waiting up to 5m0s for pod "pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-xvhvh" to be "success or failure"
Jan 22 01:22:43.098: INFO: Pod "pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.774841ms
Jan 22 01:22:45.107: INFO: Pod "pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.015074686s
Jan 22 01:22:47.113: INFO: Pod "pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020942206s
STEP: Saw pod success
Jan 22 01:22:47.113: INFO: Pod "pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:22:47.118: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:22:47.163: INFO: Waiting for pod pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:22:47.220: INFO: Pod pod-configmaps-3767e58b-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:22:47.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xvhvh" for this suite.
Jan 22 01:22:53.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:22:53.397: INFO: namespace: e2e-tests-configmap-xvhvh, resource: bindings, ignored listing per whitelist
Jan 22 01:22:53.522: INFO: namespace e2e-tests-configmap-xvhvh deletion completed in 6.287498615s

â€¢ [SLOW TEST:10.690 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:22:53.522: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l767d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:22:53.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-l767d" to be "success or failure"
Jan 22 01:22:53.801: INFO: Pod "downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.998502ms
Jan 22 01:22:55.807: INFO: Pod "downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010692663s
STEP: Saw pod success
Jan 22 01:22:55.807: INFO: Pod "downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:22:55.813: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:22:55.849: INFO: Waiting for pod downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:22:55.853: INFO: Pod downwardapi-volume-3dc8cfc5-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:22:55.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l767d" for this suite.
Jan 22 01:23:01.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:23:02.052: INFO: namespace: e2e-tests-projected-l767d, resource: bindings, ignored listing per whitelist
Jan 22 01:23:02.123: INFO: namespace e2e-tests-projected-l767d deletion completed in 6.258901292s

â€¢ [SLOW TEST:8.601 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:23:02.124: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wvzwh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 22 01:23:02.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wvzwh,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvzwh/configmaps/e2e-watch-test-resource-version,UID:42e73e93-1de4-11e9-b13b-16990c636477,ResourceVersion:71542,Generation:0,CreationTimestamp:2019-01-22 01:23:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 01:23:02.423: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wvzwh,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvzwh/configmaps/e2e-watch-test-resource-version,UID:42e73e93-1de4-11e9-b13b-16990c636477,ResourceVersion:71543,Generation:0,CreationTimestamp:2019-01-22 01:23:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:23:02.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wvzwh" for this suite.
Jan 22 01:23:08.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:23:08.522: INFO: namespace: e2e-tests-watch-wvzwh, resource: bindings, ignored listing per whitelist
Jan 22 01:23:08.720: INFO: namespace e2e-tests-watch-wvzwh deletion completed in 6.28797771s

â€¢ [SLOW TEST:6.596 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:23:08.721: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-bqgpb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bqgpb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 01:23:08.997: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 01:23:29.163: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.27.205 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bqgpb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:23:29.163: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:23:30.389: INFO: Found all expected endpoints: [netserver-0]
Jan 22 01:23:30.395: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.118.174 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bqgpb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:23:30.395: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:23:31.569: INFO: Found all expected endpoints: [netserver-1]
Jan 22 01:23:31.626: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.171.202 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bqgpb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:23:31.627: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:23:32.855: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:23:32.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bqgpb" for this suite.
Jan 22 01:23:56.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:23:57.048: INFO: namespace: e2e-tests-pod-network-test-bqgpb, resource: bindings, ignored listing per whitelist
Jan 22 01:23:57.260: INFO: namespace e2e-tests-pod-network-test-bqgpb deletion completed in 24.3388826s

â€¢ [SLOW TEST:48.539 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:23:57.261: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-hckx7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
Jan 22 01:23:58.120: INFO: created pod pod-service-account-defaultsa
Jan 22 01:23:58.120: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 22 01:23:58.130: INFO: created pod pod-service-account-mountsa
Jan 22 01:23:58.130: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 22 01:23:58.138: INFO: created pod pod-service-account-nomountsa
Jan 22 01:23:58.138: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 22 01:23:58.148: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 22 01:23:58.148: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 22 01:23:58.157: INFO: created pod pod-service-account-mountsa-mountspec
Jan 22 01:23:58.157: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 22 01:23:58.166: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 22 01:23:58.166: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 22 01:23:58.173: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 22 01:23:58.174: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 22 01:23:58.187: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 22 01:23:58.187: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 22 01:23:58.200: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 22 01:23:58.200: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:23:58.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hckx7" for this suite.
Jan 22 01:24:04.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:24:04.332: INFO: namespace: e2e-tests-svcaccounts-hckx7, resource: bindings, ignored listing per whitelist
Jan 22 01:24:04.528: INFO: namespace e2e-tests-svcaccounts-hckx7 deletion completed in 6.308031712s

â€¢ [SLOW TEST:7.267 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:24:04.529: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-jlln6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 22 01:24:08.871: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:08.871: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:09.046: INFO: Exec stderr: ""
Jan 22 01:24:09.046: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:09.046: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:09.278: INFO: Exec stderr: ""
Jan 22 01:24:09.278: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:09.278: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:09.501: INFO: Exec stderr: ""
Jan 22 01:24:09.501: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:09.501: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:09.697: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 22 01:24:09.697: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:09.697: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:10.640: INFO: Exec stderr: ""
Jan 22 01:24:10.640: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:10.640: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:10.906: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 22 01:24:10.906: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:10.906: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:11.237: INFO: Exec stderr: ""
Jan 22 01:24:11.237: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:11.237: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:11.497: INFO: Exec stderr: ""
Jan 22 01:24:11.497: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:11.497: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:11.705: INFO: Exec stderr: ""
Jan 22 01:24:11.705: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jlln6 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:24:11.705: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:24:11.953: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:24:11.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-jlln6" for this suite.
Jan 22 01:24:59.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:25:00.037: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-jlln6, resource: bindings, ignored listing per whitelist
Jan 22 01:25:00.205: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-jlln6 deletion completed in 48.240158567s

â€¢ [SLOW TEST:55.676 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:25:00.206: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4dxv7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:25:22.495: INFO: Container started at 2019-01-22 01:25:01 +0000 UTC, pod became ready at 2019-01-22 01:25:21 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:25:22.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4dxv7" for this suite.
Jan 22 01:25:44.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:25:44.649: INFO: namespace: e2e-tests-container-probe-4dxv7, resource: bindings, ignored listing per whitelist
Jan 22 01:25:44.836: INFO: namespace e2e-tests-container-probe-4dxv7 deletion completed in 22.330128405s

â€¢ [SLOW TEST:44.630 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:25:44.837: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x55bh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating api versions
Jan 22 01:25:45.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 api-versions'
Jan 22 01:25:45.214: INFO: stderr: ""
Jan 22 01:25:45.214: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:25:45.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x55bh" for this suite.
Jan 22 01:25:51.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:25:51.373: INFO: namespace: e2e-tests-kubectl-x55bh, resource: bindings, ignored listing per whitelist
Jan 22 01:25:51.475: INFO: namespace e2e-tests-kubectl-x55bh deletion completed in 6.250568763s

â€¢ [SLOW TEST:6.638 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:25:51.476: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-94vfc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 22 01:25:51.746: INFO: Waiting up to 5m0s for pod "pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-94vfc" to be "success or failure"
Jan 22 01:25:51.751: INFO: Pod "pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.760929ms
Jan 22 01:25:53.758: INFO: Pod "pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011809626s
STEP: Saw pod success
Jan 22 01:25:53.758: INFO: Pod "pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:25:53.763: INFO: Trying to get logs from node 10.191.28.14 pod pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:25:53.814: INFO: Waiting for pod pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:25:53.820: INFO: Pod pod-a7d9b351-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:25:53.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-94vfc" for this suite.
Jan 22 01:25:59.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:26:00.076: INFO: namespace: e2e-tests-emptydir-94vfc, resource: bindings, ignored listing per whitelist
Jan 22 01:26:00.127: INFO: namespace e2e-tests-emptydir-94vfc deletion completed in 6.29718159s

â€¢ [SLOW TEST:8.651 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:26:00.127: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x227v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 22 01:26:00.400: INFO: Waiting up to 5m0s for pod "pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-x227v" to be "success or failure"
Jan 22 01:26:00.411: INFO: Pod "pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.622442ms
Jan 22 01:26:02.417: INFO: Pod "pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016549007s
STEP: Saw pod success
Jan 22 01:26:02.417: INFO: Pod "pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:26:02.422: INFO: Trying to get logs from node 10.191.28.14 pod pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:26:02.456: INFO: Waiting for pod pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:26:02.521: INFO: Pod pod-ad02a137-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:26:02.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x227v" for this suite.
Jan 22 01:26:08.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:26:08.777: INFO: namespace: e2e-tests-emptydir-x227v, resource: bindings, ignored listing per whitelist
Jan 22 01:26:08.834: INFO: namespace e2e-tests-emptydir-x227v deletion completed in 6.302553957s

â€¢ [SLOW TEST:8.707 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:26:08.834: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7bvwh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting the proxy server
Jan 22 01:26:09.086: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059299132 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:26:09.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7bvwh" for this suite.
Jan 22 01:26:15.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:26:15.376: INFO: namespace: e2e-tests-kubectl-7bvwh, resource: bindings, ignored listing per whitelist
Jan 22 01:26:15.535: INFO: namespace e2e-tests-kubectl-7bvwh deletion completed in 6.302834261s

â€¢ [SLOW TEST:6.701 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:26:15.535: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4fhgn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-b632b2a1-1de4-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:26:15.825: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-4fhgn" to be "success or failure"
Jan 22 01:26:15.830: INFO: Pod "pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.945117ms
Jan 22 01:26:17.836: INFO: Pod "pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010681779s
STEP: Saw pod success
Jan 22 01:26:17.836: INFO: Pod "pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:26:17.843: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:26:17.936: INFO: Waiting for pod pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:26:17.941: INFO: Pod pod-projected-configmaps-b6344247-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:26:17.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4fhgn" for this suite.
Jan 22 01:26:23.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:26:24.190: INFO: namespace: e2e-tests-projected-4fhgn, resource: bindings, ignored listing per whitelist
Jan 22 01:26:24.216: INFO: namespace e2e-tests-projected-4fhgn deletion completed in 6.264199339s

â€¢ [SLOW TEST:8.680 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:26:24.216: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-rh22l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-rh22l
I0122 01:26:24.474977      15 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-rh22l, replica count: 1
I0122 01:26:25.525463      15 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 01:26:26.525763      15 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 22 01:26:26.650: INFO: Created: latency-svc-6t86x
Jan 22 01:26:26.672: INFO: Got endpoints: latency-svc-6t86x [46.377722ms]
Jan 22 01:26:26.721: INFO: Created: latency-svc-kkcfq
Jan 22 01:26:26.721: INFO: Got endpoints: latency-svc-kkcfq [48.477397ms]
Jan 22 01:26:26.743: INFO: Created: latency-svc-gcn87
Jan 22 01:26:26.753: INFO: Got endpoints: latency-svc-gcn87 [81.104938ms]
Jan 22 01:26:26.762: INFO: Created: latency-svc-dcz9c
Jan 22 01:26:26.771: INFO: Got endpoints: latency-svc-dcz9c [98.17877ms]
Jan 22 01:26:26.771: INFO: Created: latency-svc-t2h4q
Jan 22 01:26:26.779: INFO: Got endpoints: latency-svc-t2h4q [106.441284ms]
Jan 22 01:26:26.793: INFO: Created: latency-svc-sngg4
Jan 22 01:26:26.801: INFO: Created: latency-svc-qttt7
Jan 22 01:26:26.803: INFO: Got endpoints: latency-svc-sngg4 [130.790721ms]
Jan 22 01:26:26.809: INFO: Got endpoints: latency-svc-qttt7 [136.027033ms]
Jan 22 01:26:26.816: INFO: Created: latency-svc-zg6v4
Jan 22 01:26:26.825: INFO: Got endpoints: latency-svc-zg6v4 [152.256954ms]
Jan 22 01:26:26.831: INFO: Created: latency-svc-7gkhc
Jan 22 01:26:26.840: INFO: Got endpoints: latency-svc-7gkhc [166.975359ms]
Jan 22 01:26:26.845: INFO: Created: latency-svc-7ffsl
Jan 22 01:26:26.854: INFO: Got endpoints: latency-svc-7ffsl [133.101417ms]
Jan 22 01:26:26.859: INFO: Created: latency-svc-dlmmb
Jan 22 01:26:26.866: INFO: Got endpoints: latency-svc-dlmmb [193.824658ms]
Jan 22 01:26:26.873: INFO: Created: latency-svc-78m88
Jan 22 01:26:26.881: INFO: Got endpoints: latency-svc-78m88 [208.105579ms]
Jan 22 01:26:26.884: INFO: Created: latency-svc-f2gbj
Jan 22 01:26:26.892: INFO: Got endpoints: latency-svc-f2gbj [219.242707ms]
Jan 22 01:26:26.897: INFO: Created: latency-svc-hvklk
Jan 22 01:26:26.906: INFO: Got endpoints: latency-svc-hvklk [232.933447ms]
Jan 22 01:26:26.910: INFO: Created: latency-svc-7f9lm
Jan 22 01:26:26.918: INFO: Got endpoints: latency-svc-7f9lm [245.408661ms]
Jan 22 01:26:26.924: INFO: Created: latency-svc-nq2zh
Jan 22 01:26:26.933: INFO: Got endpoints: latency-svc-nq2zh [260.978262ms]
Jan 22 01:26:26.939: INFO: Created: latency-svc-rktsn
Jan 22 01:26:26.947: INFO: Got endpoints: latency-svc-rktsn [274.663143ms]
Jan 22 01:26:26.952: INFO: Created: latency-svc-nc2lw
Jan 22 01:26:26.960: INFO: Got endpoints: latency-svc-nc2lw [206.826485ms]
Jan 22 01:26:26.966: INFO: Created: latency-svc-z4zrc
Jan 22 01:26:26.974: INFO: Got endpoints: latency-svc-z4zrc [203.898292ms]
Jan 22 01:26:26.981: INFO: Created: latency-svc-z9xfp
Jan 22 01:26:26.989: INFO: Got endpoints: latency-svc-z9xfp [209.824153ms]
Jan 22 01:26:26.994: INFO: Created: latency-svc-rrghd
Jan 22 01:26:27.003: INFO: Got endpoints: latency-svc-rrghd [199.461029ms]
Jan 22 01:26:27.009: INFO: Created: latency-svc-mvlvp
Jan 22 01:26:27.017: INFO: Got endpoints: latency-svc-mvlvp [207.966796ms]
Jan 22 01:26:27.023: INFO: Created: latency-svc-km54w
Jan 22 01:26:27.031: INFO: Got endpoints: latency-svc-km54w [205.903445ms]
Jan 22 01:26:27.038: INFO: Created: latency-svc-dpz4f
Jan 22 01:26:27.048: INFO: Got endpoints: latency-svc-dpz4f [208.570592ms]
Jan 22 01:26:27.054: INFO: Created: latency-svc-jp6r7
Jan 22 01:26:27.063: INFO: Got endpoints: latency-svc-jp6r7 [208.771573ms]
Jan 22 01:26:27.067: INFO: Created: latency-svc-fsdjr
Jan 22 01:26:27.075: INFO: Got endpoints: latency-svc-fsdjr [208.669ms]
Jan 22 01:26:27.082: INFO: Created: latency-svc-w4vj9
Jan 22 01:26:27.091: INFO: Got endpoints: latency-svc-w4vj9 [210.382505ms]
Jan 22 01:26:27.099: INFO: Created: latency-svc-4z8tr
Jan 22 01:26:27.107: INFO: Got endpoints: latency-svc-4z8tr [214.941645ms]
Jan 22 01:26:27.113: INFO: Created: latency-svc-9nlkp
Jan 22 01:26:27.121: INFO: Got endpoints: latency-svc-9nlkp [215.64431ms]
Jan 22 01:26:27.128: INFO: Created: latency-svc-xgwzw
Jan 22 01:26:27.144: INFO: Got endpoints: latency-svc-xgwzw [226.039915ms]
Jan 22 01:26:27.151: INFO: Created: latency-svc-shcfr
Jan 22 01:26:27.160: INFO: Got endpoints: latency-svc-shcfr [226.365058ms]
Jan 22 01:26:27.167: INFO: Created: latency-svc-kbckz
Jan 22 01:26:27.174: INFO: Got endpoints: latency-svc-kbckz [227.276845ms]
Jan 22 01:26:27.181: INFO: Created: latency-svc-j7f5r
Jan 22 01:26:27.189: INFO: Got endpoints: latency-svc-j7f5r [229.226967ms]
Jan 22 01:26:27.194: INFO: Created: latency-svc-thr46
Jan 22 01:26:27.201: INFO: Got endpoints: latency-svc-thr46 [226.783868ms]
Jan 22 01:26:27.208: INFO: Created: latency-svc-r2br4
Jan 22 01:26:27.221: INFO: Got endpoints: latency-svc-r2br4 [231.836941ms]
Jan 22 01:26:27.226: INFO: Created: latency-svc-6vrsn
Jan 22 01:26:27.236: INFO: Got endpoints: latency-svc-6vrsn [233.473624ms]
Jan 22 01:26:27.241: INFO: Created: latency-svc-gvdbk
Jan 22 01:26:27.249: INFO: Got endpoints: latency-svc-gvdbk [232.711688ms]
Jan 22 01:26:27.254: INFO: Created: latency-svc-b8n5f
Jan 22 01:26:27.263: INFO: Got endpoints: latency-svc-b8n5f [231.453237ms]
Jan 22 01:26:27.269: INFO: Created: latency-svc-d2pth
Jan 22 01:26:27.277: INFO: Got endpoints: latency-svc-d2pth [228.364727ms]
Jan 22 01:26:27.284: INFO: Created: latency-svc-vj2sk
Jan 22 01:26:27.292: INFO: Got endpoints: latency-svc-vj2sk [229.700724ms]
Jan 22 01:26:27.297: INFO: Created: latency-svc-m8628
Jan 22 01:26:27.304: INFO: Got endpoints: latency-svc-m8628 [228.87091ms]
Jan 22 01:26:27.311: INFO: Created: latency-svc-f8ls5
Jan 22 01:26:27.320: INFO: Got endpoints: latency-svc-f8ls5 [228.716528ms]
Jan 22 01:26:27.327: INFO: Created: latency-svc-flllb
Jan 22 01:26:27.336: INFO: Got endpoints: latency-svc-flllb [229.761145ms]
Jan 22 01:26:27.345: INFO: Created: latency-svc-vdcwp
Jan 22 01:26:27.359: INFO: Got endpoints: latency-svc-vdcwp [237.871076ms]
Jan 22 01:26:27.360: INFO: Created: latency-svc-rp2pk
Jan 22 01:26:27.376: INFO: Created: latency-svc-9bkrk
Jan 22 01:26:27.390: INFO: Created: latency-svc-ckmzh
Jan 22 01:26:27.405: INFO: Created: latency-svc-cxbxb
Jan 22 01:26:27.413: INFO: Got endpoints: latency-svc-rp2pk [268.960115ms]
Jan 22 01:26:27.422: INFO: Created: latency-svc-rj99z
Jan 22 01:26:27.437: INFO: Created: latency-svc-2twc2
Jan 22 01:26:27.458: INFO: Created: latency-svc-2r55m
Jan 22 01:26:27.460: INFO: Got endpoints: latency-svc-9bkrk [300.21741ms]
Jan 22 01:26:27.476: INFO: Created: latency-svc-pd4kr
Jan 22 01:26:27.495: INFO: Created: latency-svc-pbrrq
Jan 22 01:26:27.508: INFO: Got endpoints: latency-svc-ckmzh [333.836793ms]
Jan 22 01:26:27.510: INFO: Created: latency-svc-wrk6b
Jan 22 01:26:27.529: INFO: Created: latency-svc-jmr6h
Jan 22 01:26:27.545: INFO: Created: latency-svc-99qdd
Jan 22 01:26:27.558: INFO: Got endpoints: latency-svc-cxbxb [369.081195ms]
Jan 22 01:26:27.564: INFO: Created: latency-svc-zh945
Jan 22 01:26:27.577: INFO: Created: latency-svc-gkkrw
Jan 22 01:26:27.595: INFO: Created: latency-svc-mhscx
Jan 22 01:26:27.608: INFO: Got endpoints: latency-svc-rj99z [406.985805ms]
Jan 22 01:26:27.611: INFO: Created: latency-svc-7xwhf
Jan 22 01:26:27.626: INFO: Created: latency-svc-ndwfh
Jan 22 01:26:27.641: INFO: Created: latency-svc-6tm28
Jan 22 01:26:27.657: INFO: Created: latency-svc-gpkhw
Jan 22 01:26:27.659: INFO: Got endpoints: latency-svc-2twc2 [437.804213ms]
Jan 22 01:26:27.673: INFO: Created: latency-svc-6b2pp
Jan 22 01:26:27.690: INFO: Created: latency-svc-8wpmc
Jan 22 01:26:27.708: INFO: Got endpoints: latency-svc-2r55m [471.95483ms]
Jan 22 01:26:27.761: INFO: Created: latency-svc-9krhz
Jan 22 01:26:27.762: INFO: Got endpoints: latency-svc-pd4kr [512.922615ms]
Jan 22 01:26:27.793: INFO: Created: latency-svc-cnl2x
Jan 22 01:26:27.809: INFO: Got endpoints: latency-svc-pbrrq [546.075626ms]
Jan 22 01:26:27.832: INFO: Created: latency-svc-cjs5q
Jan 22 01:26:27.858: INFO: Got endpoints: latency-svc-wrk6b [581.346205ms]
Jan 22 01:26:27.887: INFO: Created: latency-svc-t62hq
Jan 22 01:26:27.909: INFO: Got endpoints: latency-svc-jmr6h [616.077553ms]
Jan 22 01:26:27.937: INFO: Created: latency-svc-vb78d
Jan 22 01:26:27.960: INFO: Got endpoints: latency-svc-99qdd [656.147516ms]
Jan 22 01:26:27.988: INFO: Created: latency-svc-pzd7v
Jan 22 01:26:28.009: INFO: Got endpoints: latency-svc-zh945 [688.716759ms]
Jan 22 01:26:28.039: INFO: Created: latency-svc-cnz5h
Jan 22 01:26:28.059: INFO: Got endpoints: latency-svc-gkkrw [722.542901ms]
Jan 22 01:26:28.085: INFO: Created: latency-svc-7hql7
Jan 22 01:26:28.109: INFO: Got endpoints: latency-svc-mhscx [749.324195ms]
Jan 22 01:26:28.137: INFO: Created: latency-svc-7gxx9
Jan 22 01:26:28.159: INFO: Got endpoints: latency-svc-7xwhf [745.750446ms]
Jan 22 01:26:28.186: INFO: Created: latency-svc-zb257
Jan 22 01:26:28.211: INFO: Got endpoints: latency-svc-ndwfh [751.165042ms]
Jan 22 01:26:28.239: INFO: Created: latency-svc-89hkn
Jan 22 01:26:28.259: INFO: Got endpoints: latency-svc-6tm28 [750.283159ms]
Jan 22 01:26:28.285: INFO: Created: latency-svc-cmpbn
Jan 22 01:26:28.309: INFO: Got endpoints: latency-svc-gpkhw [750.647876ms]
Jan 22 01:26:28.342: INFO: Created: latency-svc-9989r
Jan 22 01:26:28.361: INFO: Got endpoints: latency-svc-6b2pp [752.607248ms]
Jan 22 01:26:28.388: INFO: Created: latency-svc-q2xpx
Jan 22 01:26:28.409: INFO: Got endpoints: latency-svc-8wpmc [750.758709ms]
Jan 22 01:26:28.435: INFO: Created: latency-svc-766bx
Jan 22 01:26:28.464: INFO: Got endpoints: latency-svc-9krhz [756.119078ms]
Jan 22 01:26:28.489: INFO: Created: latency-svc-bsxsl
Jan 22 01:26:28.512: INFO: Got endpoints: latency-svc-cnl2x [747.064316ms]
Jan 22 01:26:28.540: INFO: Created: latency-svc-qbgsq
Jan 22 01:26:28.559: INFO: Got endpoints: latency-svc-cjs5q [750.381236ms]
Jan 22 01:26:28.588: INFO: Created: latency-svc-rfp2r
Jan 22 01:26:28.609: INFO: Got endpoints: latency-svc-t62hq [750.334402ms]
Jan 22 01:26:28.636: INFO: Created: latency-svc-drr8p
Jan 22 01:26:28.662: INFO: Got endpoints: latency-svc-vb78d [753.6188ms]
Jan 22 01:26:28.690: INFO: Created: latency-svc-zmqhk
Jan 22 01:26:28.709: INFO: Got endpoints: latency-svc-pzd7v [748.230285ms]
Jan 22 01:26:28.732: INFO: Created: latency-svc-4slq8
Jan 22 01:26:28.759: INFO: Got endpoints: latency-svc-cnz5h [749.770169ms]
Jan 22 01:26:28.783: INFO: Created: latency-svc-4f75v
Jan 22 01:26:28.811: INFO: Got endpoints: latency-svc-7hql7 [751.420946ms]
Jan 22 01:26:28.833: INFO: Created: latency-svc-gjgdp
Jan 22 01:26:28.859: INFO: Got endpoints: latency-svc-7gxx9 [750.187669ms]
Jan 22 01:26:28.883: INFO: Created: latency-svc-tnj4r
Jan 22 01:26:28.909: INFO: Got endpoints: latency-svc-zb257 [749.501774ms]
Jan 22 01:26:28.938: INFO: Created: latency-svc-mw6s4
Jan 22 01:26:28.959: INFO: Got endpoints: latency-svc-89hkn [747.314279ms]
Jan 22 01:26:28.985: INFO: Created: latency-svc-5j4sk
Jan 22 01:26:29.008: INFO: Got endpoints: latency-svc-cmpbn [749.538419ms]
Jan 22 01:26:29.034: INFO: Created: latency-svc-2mjzc
Jan 22 01:26:29.059: INFO: Got endpoints: latency-svc-9989r [749.447163ms]
Jan 22 01:26:29.091: INFO: Created: latency-svc-n68gz
Jan 22 01:26:29.115: INFO: Got endpoints: latency-svc-q2xpx [753.644334ms]
Jan 22 01:26:29.142: INFO: Created: latency-svc-jx9q9
Jan 22 01:26:29.162: INFO: Got endpoints: latency-svc-766bx [752.060907ms]
Jan 22 01:26:29.190: INFO: Created: latency-svc-btclp
Jan 22 01:26:29.209: INFO: Got endpoints: latency-svc-bsxsl [744.44823ms]
Jan 22 01:26:29.237: INFO: Created: latency-svc-tm6nd
Jan 22 01:26:29.259: INFO: Got endpoints: latency-svc-qbgsq [746.687841ms]
Jan 22 01:26:29.285: INFO: Created: latency-svc-b7gxs
Jan 22 01:26:29.308: INFO: Got endpoints: latency-svc-rfp2r [749.265337ms]
Jan 22 01:26:29.335: INFO: Created: latency-svc-tsnqx
Jan 22 01:26:29.360: INFO: Got endpoints: latency-svc-drr8p [751.267777ms]
Jan 22 01:26:29.383: INFO: Created: latency-svc-cg98f
Jan 22 01:26:29.410: INFO: Got endpoints: latency-svc-zmqhk [747.525784ms]
Jan 22 01:26:29.435: INFO: Created: latency-svc-kh5wv
Jan 22 01:26:29.459: INFO: Got endpoints: latency-svc-4slq8 [749.85343ms]
Jan 22 01:26:29.494: INFO: Created: latency-svc-hdzck
Jan 22 01:26:29.510: INFO: Got endpoints: latency-svc-4f75v [750.969619ms]
Jan 22 01:26:29.533: INFO: Created: latency-svc-5cq5l
Jan 22 01:26:29.559: INFO: Got endpoints: latency-svc-gjgdp [747.933737ms]
Jan 22 01:26:29.582: INFO: Created: latency-svc-jd5c4
Jan 22 01:26:29.609: INFO: Got endpoints: latency-svc-tnj4r [749.743279ms]
Jan 22 01:26:29.633: INFO: Created: latency-svc-wd5nj
Jan 22 01:26:29.661: INFO: Got endpoints: latency-svc-mw6s4 [751.670418ms]
Jan 22 01:26:29.692: INFO: Created: latency-svc-tx5sp
Jan 22 01:26:29.713: INFO: Got endpoints: latency-svc-5j4sk [753.886503ms]
Jan 22 01:26:29.752: INFO: Created: latency-svc-mm926
Jan 22 01:26:29.759: INFO: Got endpoints: latency-svc-2mjzc [750.22266ms]
Jan 22 01:26:29.789: INFO: Created: latency-svc-k59xl
Jan 22 01:26:29.812: INFO: Got endpoints: latency-svc-n68gz [752.807262ms]
Jan 22 01:26:29.849: INFO: Created: latency-svc-zdbvx
Jan 22 01:26:29.859: INFO: Got endpoints: latency-svc-jx9q9 [743.831678ms]
Jan 22 01:26:29.887: INFO: Created: latency-svc-5txmf
Jan 22 01:26:29.909: INFO: Got endpoints: latency-svc-btclp [747.57967ms]
Jan 22 01:26:29.937: INFO: Created: latency-svc-7tng9
Jan 22 01:26:29.961: INFO: Got endpoints: latency-svc-tm6nd [751.82315ms]
Jan 22 01:26:29.991: INFO: Created: latency-svc-2zwx8
Jan 22 01:26:30.009: INFO: Got endpoints: latency-svc-b7gxs [750.318127ms]
Jan 22 01:26:30.048: INFO: Created: latency-svc-qj52s
Jan 22 01:26:30.059: INFO: Got endpoints: latency-svc-tsnqx [750.203446ms]
Jan 22 01:26:30.097: INFO: Created: latency-svc-29zsl
Jan 22 01:26:30.113: INFO: Got endpoints: latency-svc-cg98f [753.064148ms]
Jan 22 01:26:30.152: INFO: Created: latency-svc-9btsp
Jan 22 01:26:30.160: INFO: Got endpoints: latency-svc-kh5wv [749.954199ms]
Jan 22 01:26:30.194: INFO: Created: latency-svc-dlbld
Jan 22 01:26:30.209: INFO: Got endpoints: latency-svc-hdzck [750.867318ms]
Jan 22 01:26:30.245: INFO: Created: latency-svc-n84lz
Jan 22 01:26:30.260: INFO: Got endpoints: latency-svc-5cq5l [750.489645ms]
Jan 22 01:26:30.297: INFO: Created: latency-svc-z5vv7
Jan 22 01:26:30.309: INFO: Got endpoints: latency-svc-jd5c4 [750.539935ms]
Jan 22 01:26:30.343: INFO: Created: latency-svc-4zf2h
Jan 22 01:26:30.359: INFO: Got endpoints: latency-svc-wd5nj [750.325163ms]
Jan 22 01:26:30.394: INFO: Created: latency-svc-bs5d2
Jan 22 01:26:30.408: INFO: Got endpoints: latency-svc-tx5sp [747.533149ms]
Jan 22 01:26:30.434: INFO: Created: latency-svc-4zql5
Jan 22 01:26:30.458: INFO: Got endpoints: latency-svc-mm926 [745.580143ms]
Jan 22 01:26:30.493: INFO: Created: latency-svc-dw76w
Jan 22 01:26:30.510: INFO: Got endpoints: latency-svc-k59xl [750.923345ms]
Jan 22 01:26:30.546: INFO: Created: latency-svc-lj27f
Jan 22 01:26:30.559: INFO: Got endpoints: latency-svc-zdbvx [746.689351ms]
Jan 22 01:26:30.587: INFO: Created: latency-svc-75qb2
Jan 22 01:26:30.609: INFO: Got endpoints: latency-svc-5txmf [749.755565ms]
Jan 22 01:26:30.647: INFO: Created: latency-svc-pllmz
Jan 22 01:26:30.659: INFO: Got endpoints: latency-svc-7tng9 [749.234471ms]
Jan 22 01:26:30.698: INFO: Created: latency-svc-q7jt2
Jan 22 01:26:30.709: INFO: Got endpoints: latency-svc-2zwx8 [747.967448ms]
Jan 22 01:26:30.749: INFO: Created: latency-svc-rj86d
Jan 22 01:26:30.758: INFO: Got endpoints: latency-svc-qj52s [748.955918ms]
Jan 22 01:26:30.797: INFO: Created: latency-svc-m8ppq
Jan 22 01:26:30.809: INFO: Got endpoints: latency-svc-29zsl [750.229875ms]
Jan 22 01:26:30.858: INFO: Created: latency-svc-2qjrb
Jan 22 01:26:30.859: INFO: Got endpoints: latency-svc-9btsp [746.17128ms]
Jan 22 01:26:30.901: INFO: Created: latency-svc-5ss9n
Jan 22 01:26:30.908: INFO: Got endpoints: latency-svc-dlbld [748.488493ms]
Jan 22 01:26:30.944: INFO: Created: latency-svc-62qh7
Jan 22 01:26:30.960: INFO: Got endpoints: latency-svc-n84lz [750.792329ms]
Jan 22 01:26:31.003: INFO: Created: latency-svc-fpjkk
Jan 22 01:26:31.008: INFO: Got endpoints: latency-svc-z5vv7 [747.413908ms]
Jan 22 01:26:31.053: INFO: Created: latency-svc-jc9zk
Jan 22 01:26:31.059: INFO: Got endpoints: latency-svc-4zf2h [749.84526ms]
Jan 22 01:26:31.085: INFO: Created: latency-svc-ccwxn
Jan 22 01:26:31.109: INFO: Got endpoints: latency-svc-bs5d2 [749.583327ms]
Jan 22 01:26:31.154: INFO: Created: latency-svc-vq8mj
Jan 22 01:26:31.158: INFO: Got endpoints: latency-svc-4zql5 [749.731986ms]
Jan 22 01:26:31.197: INFO: Created: latency-svc-5wd6r
Jan 22 01:26:31.208: INFO: Got endpoints: latency-svc-dw76w [749.904055ms]
Jan 22 01:26:31.234: INFO: Created: latency-svc-6mrqd
Jan 22 01:26:31.259: INFO: Got endpoints: latency-svc-lj27f [749.393338ms]
Jan 22 01:26:31.306: INFO: Created: latency-svc-8k9f2
Jan 22 01:26:31.308: INFO: Got endpoints: latency-svc-75qb2 [749.182967ms]
Jan 22 01:26:31.343: INFO: Created: latency-svc-d9f6f
Jan 22 01:26:31.362: INFO: Got endpoints: latency-svc-pllmz [753.615834ms]
Jan 22 01:26:31.396: INFO: Created: latency-svc-psdpf
Jan 22 01:26:31.414: INFO: Got endpoints: latency-svc-q7jt2 [755.112138ms]
Jan 22 01:26:31.452: INFO: Created: latency-svc-r4qrw
Jan 22 01:26:31.458: INFO: Got endpoints: latency-svc-rj86d [749.496648ms]
Jan 22 01:26:31.497: INFO: Created: latency-svc-7fmk2
Jan 22 01:26:31.512: INFO: Got endpoints: latency-svc-m8ppq [753.424401ms]
Jan 22 01:26:31.547: INFO: Created: latency-svc-gshx6
Jan 22 01:26:31.559: INFO: Got endpoints: latency-svc-2qjrb [750.185777ms]
Jan 22 01:26:31.598: INFO: Created: latency-svc-bhsqv
Jan 22 01:26:31.608: INFO: Got endpoints: latency-svc-5ss9n [748.360292ms]
Jan 22 01:26:31.644: INFO: Created: latency-svc-b857l
Jan 22 01:26:31.662: INFO: Got endpoints: latency-svc-62qh7 [753.82587ms]
Jan 22 01:26:31.698: INFO: Created: latency-svc-fxdxh
Jan 22 01:26:31.709: INFO: Got endpoints: latency-svc-fpjkk [748.087642ms]
Jan 22 01:26:31.733: INFO: Created: latency-svc-4rpmt
Jan 22 01:26:31.761: INFO: Got endpoints: latency-svc-jc9zk [753.368939ms]
Jan 22 01:26:31.788: INFO: Created: latency-svc-c5s6l
Jan 22 01:26:31.809: INFO: Got endpoints: latency-svc-ccwxn [749.47761ms]
Jan 22 01:26:31.837: INFO: Created: latency-svc-qdwr7
Jan 22 01:26:31.859: INFO: Got endpoints: latency-svc-vq8mj [750.467676ms]
Jan 22 01:26:31.893: INFO: Created: latency-svc-gwcsc
Jan 22 01:26:31.908: INFO: Got endpoints: latency-svc-5wd6r [750.322813ms]
Jan 22 01:26:31.935: INFO: Created: latency-svc-v9cjp
Jan 22 01:26:31.958: INFO: Got endpoints: latency-svc-6mrqd [749.692074ms]
Jan 22 01:26:31.986: INFO: Created: latency-svc-52jdj
Jan 22 01:26:32.008: INFO: Got endpoints: latency-svc-8k9f2 [749.080388ms]
Jan 22 01:26:32.041: INFO: Created: latency-svc-knwb2
Jan 22 01:26:32.058: INFO: Got endpoints: latency-svc-d9f6f [750.085632ms]
Jan 22 01:26:32.087: INFO: Created: latency-svc-77lvp
Jan 22 01:26:32.109: INFO: Got endpoints: latency-svc-psdpf [746.398445ms]
Jan 22 01:26:32.140: INFO: Created: latency-svc-tgzh6
Jan 22 01:26:32.163: INFO: Got endpoints: latency-svc-r4qrw [749.088178ms]
Jan 22 01:26:32.189: INFO: Created: latency-svc-wjw4r
Jan 22 01:26:32.211: INFO: Got endpoints: latency-svc-7fmk2 [752.428741ms]
Jan 22 01:26:32.234: INFO: Created: latency-svc-lxbx9
Jan 22 01:26:32.261: INFO: Got endpoints: latency-svc-gshx6 [749.638447ms]
Jan 22 01:26:32.289: INFO: Created: latency-svc-lckcf
Jan 22 01:26:32.309: INFO: Got endpoints: latency-svc-bhsqv [749.627307ms]
Jan 22 01:26:32.334: INFO: Created: latency-svc-2nmdm
Jan 22 01:26:32.358: INFO: Got endpoints: latency-svc-b857l [750.056291ms]
Jan 22 01:26:32.383: INFO: Created: latency-svc-2llqr
Jan 22 01:26:32.409: INFO: Got endpoints: latency-svc-fxdxh [746.675852ms]
Jan 22 01:26:32.434: INFO: Created: latency-svc-j9jhk
Jan 22 01:26:32.463: INFO: Got endpoints: latency-svc-4rpmt [753.987966ms]
Jan 22 01:26:32.489: INFO: Created: latency-svc-zwdrm
Jan 22 01:26:32.509: INFO: Got endpoints: latency-svc-c5s6l [747.41934ms]
Jan 22 01:26:32.536: INFO: Created: latency-svc-5p822
Jan 22 01:26:32.563: INFO: Got endpoints: latency-svc-qdwr7 [754.616514ms]
Jan 22 01:26:32.591: INFO: Created: latency-svc-czqrv
Jan 22 01:26:32.608: INFO: Got endpoints: latency-svc-gwcsc [748.959068ms]
Jan 22 01:26:32.636: INFO: Created: latency-svc-7vsx4
Jan 22 01:26:32.658: INFO: Got endpoints: latency-svc-v9cjp [749.687283ms]
Jan 22 01:26:32.684: INFO: Created: latency-svc-nbrc5
Jan 22 01:26:32.708: INFO: Got endpoints: latency-svc-52jdj [750.161863ms]
Jan 22 01:26:32.736: INFO: Created: latency-svc-v6vvq
Jan 22 01:26:32.759: INFO: Got endpoints: latency-svc-knwb2 [750.262438ms]
Jan 22 01:26:32.783: INFO: Created: latency-svc-vw44g
Jan 22 01:26:32.813: INFO: Got endpoints: latency-svc-77lvp [754.912632ms]
Jan 22 01:26:32.837: INFO: Created: latency-svc-bvh59
Jan 22 01:26:32.861: INFO: Got endpoints: latency-svc-tgzh6 [751.686061ms]
Jan 22 01:26:32.888: INFO: Created: latency-svc-8sk4b
Jan 22 01:26:32.909: INFO: Got endpoints: latency-svc-wjw4r [746.229844ms]
Jan 22 01:26:32.938: INFO: Created: latency-svc-2mbbf
Jan 22 01:26:32.958: INFO: Got endpoints: latency-svc-lxbx9 [747.54826ms]
Jan 22 01:26:32.987: INFO: Created: latency-svc-pwjvp
Jan 22 01:26:33.009: INFO: Got endpoints: latency-svc-lckcf [747.147737ms]
Jan 22 01:26:33.036: INFO: Created: latency-svc-swrz9
Jan 22 01:26:33.058: INFO: Got endpoints: latency-svc-2nmdm [749.265561ms]
Jan 22 01:26:33.087: INFO: Created: latency-svc-gw4q4
Jan 22 01:26:33.109: INFO: Got endpoints: latency-svc-2llqr [751.400327ms]
Jan 22 01:26:33.135: INFO: Created: latency-svc-gfj8n
Jan 22 01:26:33.159: INFO: Got endpoints: latency-svc-j9jhk [749.502245ms]
Jan 22 01:26:33.191: INFO: Created: latency-svc-gv6zj
Jan 22 01:26:33.208: INFO: Got endpoints: latency-svc-zwdrm [745.309368ms]
Jan 22 01:26:33.235: INFO: Created: latency-svc-q42ld
Jan 22 01:26:33.261: INFO: Got endpoints: latency-svc-5p822 [751.49716ms]
Jan 22 01:26:33.291: INFO: Created: latency-svc-dvrjm
Jan 22 01:26:33.309: INFO: Got endpoints: latency-svc-czqrv [745.299859ms]
Jan 22 01:26:33.338: INFO: Created: latency-svc-2j8s4
Jan 22 01:26:33.359: INFO: Got endpoints: latency-svc-7vsx4 [751.159257ms]
Jan 22 01:26:33.402: INFO: Created: latency-svc-7ddzr
Jan 22 01:26:33.408: INFO: Got endpoints: latency-svc-nbrc5 [750.27283ms]
Jan 22 01:26:33.436: INFO: Created: latency-svc-8h4vh
Jan 22 01:26:33.458: INFO: Got endpoints: latency-svc-v6vvq [749.817618ms]
Jan 22 01:26:33.499: INFO: Created: latency-svc-mjpl6
Jan 22 01:26:33.508: INFO: Got endpoints: latency-svc-vw44g [749.742323ms]
Jan 22 01:26:33.544: INFO: Created: latency-svc-vjjzd
Jan 22 01:26:33.565: INFO: Got endpoints: latency-svc-bvh59 [752.000726ms]
Jan 22 01:26:33.593: INFO: Created: latency-svc-bj2fw
Jan 22 01:26:33.611: INFO: Got endpoints: latency-svc-8sk4b [750.260004ms]
Jan 22 01:26:33.636: INFO: Created: latency-svc-8h5bm
Jan 22 01:26:33.659: INFO: Got endpoints: latency-svc-2mbbf [749.923373ms]
Jan 22 01:26:33.682: INFO: Created: latency-svc-wpw54
Jan 22 01:26:33.709: INFO: Got endpoints: latency-svc-pwjvp [750.93464ms]
Jan 22 01:26:33.733: INFO: Created: latency-svc-fv4pt
Jan 22 01:26:33.759: INFO: Got endpoints: latency-svc-swrz9 [750.247865ms]
Jan 22 01:26:33.782: INFO: Created: latency-svc-dh5cl
Jan 22 01:26:33.810: INFO: Got endpoints: latency-svc-gw4q4 [751.204285ms]
Jan 22 01:26:33.833: INFO: Created: latency-svc-g77bj
Jan 22 01:26:33.858: INFO: Got endpoints: latency-svc-gfj8n [749.047094ms]
Jan 22 01:26:33.883: INFO: Created: latency-svc-tkjtq
Jan 22 01:26:33.908: INFO: Got endpoints: latency-svc-gv6zj [749.206493ms]
Jan 22 01:26:33.933: INFO: Created: latency-svc-sclbm
Jan 22 01:26:33.962: INFO: Got endpoints: latency-svc-q42ld [753.917433ms]
Jan 22 01:26:33.990: INFO: Created: latency-svc-xnrd2
Jan 22 01:26:34.008: INFO: Got endpoints: latency-svc-dvrjm [747.887422ms]
Jan 22 01:26:34.033: INFO: Created: latency-svc-mj95c
Jan 22 01:26:34.058: INFO: Got endpoints: latency-svc-2j8s4 [749.490079ms]
Jan 22 01:26:34.085: INFO: Created: latency-svc-7qkw8
Jan 22 01:26:34.111: INFO: Got endpoints: latency-svc-7ddzr [751.918365ms]
Jan 22 01:26:34.143: INFO: Created: latency-svc-2w2mh
Jan 22 01:26:34.159: INFO: Got endpoints: latency-svc-8h4vh [750.210533ms]
Jan 22 01:26:34.186: INFO: Created: latency-svc-2nrmd
Jan 22 01:26:34.215: INFO: Got endpoints: latency-svc-mjpl6 [755.821317ms]
Jan 22 01:26:34.244: INFO: Created: latency-svc-t285t
Jan 22 01:26:34.262: INFO: Got endpoints: latency-svc-vjjzd [753.137081ms]
Jan 22 01:26:34.287: INFO: Created: latency-svc-m5467
Jan 22 01:26:34.309: INFO: Got endpoints: latency-svc-bj2fw [743.853066ms]
Jan 22 01:26:34.334: INFO: Created: latency-svc-d9krm
Jan 22 01:26:34.357: INFO: Got endpoints: latency-svc-8h5bm [746.284556ms]
Jan 22 01:26:34.382: INFO: Created: latency-svc-hcth9
Jan 22 01:26:34.412: INFO: Got endpoints: latency-svc-wpw54 [752.504052ms]
Jan 22 01:26:34.437: INFO: Created: latency-svc-2jl5l
Jan 22 01:26:34.461: INFO: Got endpoints: latency-svc-fv4pt [751.44929ms]
Jan 22 01:26:34.489: INFO: Created: latency-svc-49h27
Jan 22 01:26:34.510: INFO: Got endpoints: latency-svc-dh5cl [750.87772ms]
Jan 22 01:26:34.560: INFO: Got endpoints: latency-svc-g77bj [749.991562ms]
Jan 22 01:26:34.612: INFO: Got endpoints: latency-svc-tkjtq [753.323779ms]
Jan 22 01:26:34.659: INFO: Got endpoints: latency-svc-sclbm [751.277653ms]
Jan 22 01:26:34.709: INFO: Got endpoints: latency-svc-xnrd2 [747.010161ms]
Jan 22 01:26:34.759: INFO: Got endpoints: latency-svc-mj95c [750.498304ms]
Jan 22 01:26:34.809: INFO: Got endpoints: latency-svc-7qkw8 [750.071577ms]
Jan 22 01:26:34.859: INFO: Got endpoints: latency-svc-2w2mh [747.192372ms]
Jan 22 01:26:34.908: INFO: Got endpoints: latency-svc-2nrmd [749.434874ms]
Jan 22 01:26:34.959: INFO: Got endpoints: latency-svc-t285t [744.527439ms]
Jan 22 01:26:35.009: INFO: Got endpoints: latency-svc-m5467 [747.461418ms]
Jan 22 01:26:35.060: INFO: Got endpoints: latency-svc-d9krm [750.590088ms]
Jan 22 01:26:35.109: INFO: Got endpoints: latency-svc-hcth9 [751.177361ms]
Jan 22 01:26:35.159: INFO: Got endpoints: latency-svc-2jl5l [746.950943ms]
Jan 22 01:26:35.208: INFO: Got endpoints: latency-svc-49h27 [747.31857ms]
Jan 22 01:26:35.208: INFO: Latencies: [48.477397ms 81.104938ms 98.17877ms 106.441284ms 130.790721ms 133.101417ms 136.027033ms 152.256954ms 166.975359ms 193.824658ms 199.461029ms 203.898292ms 205.903445ms 206.826485ms 207.966796ms 208.105579ms 208.570592ms 208.669ms 208.771573ms 209.824153ms 210.382505ms 214.941645ms 215.64431ms 219.242707ms 226.039915ms 226.365058ms 226.783868ms 227.276845ms 228.364727ms 228.716528ms 228.87091ms 229.226967ms 229.700724ms 229.761145ms 231.453237ms 231.836941ms 232.711688ms 232.933447ms 233.473624ms 237.871076ms 245.408661ms 260.978262ms 268.960115ms 274.663143ms 300.21741ms 333.836793ms 369.081195ms 406.985805ms 437.804213ms 471.95483ms 512.922615ms 546.075626ms 581.346205ms 616.077553ms 656.147516ms 688.716759ms 722.542901ms 743.831678ms 743.853066ms 744.44823ms 744.527439ms 745.299859ms 745.309368ms 745.580143ms 745.750446ms 746.17128ms 746.229844ms 746.284556ms 746.398445ms 746.675852ms 746.687841ms 746.689351ms 746.950943ms 747.010161ms 747.064316ms 747.147737ms 747.192372ms 747.314279ms 747.31857ms 747.413908ms 747.41934ms 747.461418ms 747.525784ms 747.533149ms 747.54826ms 747.57967ms 747.887422ms 747.933737ms 747.967448ms 748.087642ms 748.230285ms 748.360292ms 748.488493ms 748.955918ms 748.959068ms 749.047094ms 749.080388ms 749.088178ms 749.182967ms 749.206493ms 749.234471ms 749.265337ms 749.265561ms 749.324195ms 749.393338ms 749.434874ms 749.447163ms 749.47761ms 749.490079ms 749.496648ms 749.501774ms 749.502245ms 749.538419ms 749.583327ms 749.627307ms 749.638447ms 749.687283ms 749.692074ms 749.731986ms 749.742323ms 749.743279ms 749.755565ms 749.770169ms 749.817618ms 749.84526ms 749.85343ms 749.904055ms 749.923373ms 749.954199ms 749.991562ms 750.056291ms 750.071577ms 750.085632ms 750.161863ms 750.185777ms 750.187669ms 750.203446ms 750.210533ms 750.22266ms 750.229875ms 750.247865ms 750.260004ms 750.262438ms 750.27283ms 750.283159ms 750.318127ms 750.322813ms 750.325163ms 750.334402ms 750.381236ms 750.467676ms 750.489645ms 750.498304ms 750.539935ms 750.590088ms 750.647876ms 750.758709ms 750.792329ms 750.867318ms 750.87772ms 750.923345ms 750.93464ms 750.969619ms 751.159257ms 751.165042ms 751.177361ms 751.204285ms 751.267777ms 751.277653ms 751.400327ms 751.420946ms 751.44929ms 751.49716ms 751.670418ms 751.686061ms 751.82315ms 751.918365ms 752.000726ms 752.060907ms 752.428741ms 752.504052ms 752.607248ms 752.807262ms 753.064148ms 753.137081ms 753.323779ms 753.368939ms 753.424401ms 753.615834ms 753.6188ms 753.644334ms 753.82587ms 753.886503ms 753.917433ms 753.987966ms 754.616514ms 754.912632ms 755.112138ms 755.821317ms 756.119078ms]
Jan 22 01:26:35.208: INFO: 50 %ile: 749.234471ms
Jan 22 01:26:35.208: INFO: 90 %ile: 752.504052ms
Jan 22 01:26:35.208: INFO: 99 %ile: 755.821317ms
Jan 22 01:26:35.208: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:26:35.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-rh22l" for this suite.
Jan 22 01:26:59.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:26:59.397: INFO: namespace: e2e-tests-svc-latency-rh22l, resource: bindings, ignored listing per whitelist
Jan 22 01:26:59.527: INFO: namespace e2e-tests-svc-latency-rh22l deletion completed in 24.296604463s

â€¢ [SLOW TEST:35.311 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:26:59.528: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-l8fd4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:26:59.860: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d072d87a-1de4-11e9-b13b-16990c636477", Controller:(*bool)(0xc4228b3c5e), BlockOwnerDeletion:(*bool)(0xc4228b3c5f)}}
Jan 22 01:26:59.866: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d06ff675-1de4-11e9-b13b-16990c636477", Controller:(*bool)(0xc4220912d6), BlockOwnerDeletion:(*bool)(0xc4220912d7)}}
Jan 22 01:26:59.880: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d0711670-1de4-11e9-b13b-16990c636477", Controller:(*bool)(0xc4228b3e36), BlockOwnerDeletion:(*bool)(0xc4228b3e37)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:27:04.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l8fd4" for this suite.
Jan 22 01:27:10.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:27:11.232: INFO: namespace: e2e-tests-gc-l8fd4, resource: bindings, ignored listing per whitelist
Jan 22 01:27:11.232: INFO: namespace e2e-tests-gc-l8fd4 deletion completed in 6.32406577s

â€¢ [SLOW TEST:11.705 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:27:11.232: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fjtkt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:27:11.524: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-fjtkt" to be "success or failure"
Jan 22 01:27:11.535: INFO: Pod "downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.659016ms
Jan 22 01:27:13.541: INFO: Pod "downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016518482s
STEP: Saw pod success
Jan 22 01:27:13.541: INFO: Pod "downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:27:13.545: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:27:13.587: INFO: Waiting for pod downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:27:13.620: INFO: Pod downwardapi-volume-d7671a39-1de4-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:27:13.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fjtkt" for this suite.
Jan 22 01:27:19.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:27:19.867: INFO: namespace: e2e-tests-downward-api-fjtkt, resource: bindings, ignored listing per whitelist
Jan 22 01:27:19.931: INFO: namespace e2e-tests-downward-api-fjtkt deletion completed in 6.299521733s

â€¢ [SLOW TEST:8.699 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:27:19.932: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pw79k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:27:20.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 version'
Jan 22 01:27:20.323: INFO: stderr: ""
Jan 22 01:27:20.323: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.6+IKS\", GitCommit:\"002d263ed027db260968616b951fb46f2bab9bb1\", GitTreeState:\"clean\", BuildDate:\"2019-01-09T08:07:22Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:27:20.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pw79k" for this suite.
Jan 22 01:27:26.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:27:26.543: INFO: namespace: e2e-tests-kubectl-pw79k, resource: bindings, ignored listing per whitelist
Jan 22 01:27:26.736: INFO: namespace e2e-tests-kubectl-pw79k deletion completed in 6.315755465s

â€¢ [SLOW TEST:6.804 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:27:26.736: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nnqkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:28:27.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nnqkm" for this suite.
Jan 22 01:28:51.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:28:51.251: INFO: namespace: e2e-tests-container-probe-nnqkm, resource: bindings, ignored listing per whitelist
Jan 22 01:28:51.440: INFO: namespace e2e-tests-container-probe-nnqkm deletion completed in 24.261359806s

â€¢ [SLOW TEST:84.704 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:28:51.441: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pkp8l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jan 22 01:28:54.320: INFO: Successfully updated pod "labelsupdate131ee3f8-1de5-11e9-8691-1e7d95aa6bfc"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:28:58.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pkp8l" for this suite.
Jan 22 01:29:20.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:29:20.598: INFO: namespace: e2e-tests-downward-api-pkp8l, resource: bindings, ignored listing per whitelist
Jan 22 01:29:20.743: INFO: namespace e2e-tests-downward-api-pkp8l deletion completed in 22.359556677s

â€¢ [SLOW TEST:29.302 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:29:20.744: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-zcgsd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:29:21.002: INFO: Creating ReplicaSet my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc
Jan 22 01:29:21.017: INFO: Pod name my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc: Found 0 pods out of 1
Jan 22 01:29:26.024: INFO: Pod name my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc: Found 1 pods out of 1
Jan 22 01:29:26.024: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc" is running
Jan 22 01:29:26.029: INFO: Pod "my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc-4whx8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 01:29:21 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 01:29:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 01:29:21 +0000 UTC Reason: Message:}])
Jan 22 01:29:26.029: INFO: Trying to dial the pod
Jan 22 01:29:31.057: INFO: Controller my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc: Got expected result from replica 1 [my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc-4whx8]: "my-hostname-basic-2495cdd1-1de5-11e9-8691-1e7d95aa6bfc-4whx8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:29:31.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-zcgsd" for this suite.
Jan 22 01:29:37.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:29:37.486: INFO: namespace: e2e-tests-replicaset-zcgsd, resource: bindings, ignored listing per whitelist
Jan 22 01:29:37.501: INFO: namespace e2e-tests-replicaset-zcgsd deletion completed in 6.432449314s

â€¢ [SLOW TEST:16.757 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:29:37.501: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-qtqcs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-qtqcs;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-qtqcs;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qtqcs.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 120.90.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.90.120_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 120.90.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.90.120_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-qtqcs;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-qtqcs;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qtqcs.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-qtqcs.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qtqcs.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 120.90.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.90.120_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 120.90.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.90.120_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 22 01:29:50.234: INFO: DNS probes using dns-test-2e9a8122-1de5-11e9-8691-1e7d95aa6bfc succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:29:50.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-qtqcs" for this suite.
Jan 22 01:29:56.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:29:56.447: INFO: namespace: e2e-tests-dns-qtqcs, resource: bindings, ignored listing per whitelist
Jan 22 01:29:56.626: INFO: namespace e2e-tests-dns-qtqcs deletion completed in 6.260607769s

â€¢ [SLOW TEST:19.125 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:29:56.626: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-855p5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 22 01:29:56.899: INFO: Waiting up to 5m0s for pod "pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-855p5" to be "success or failure"
Jan 22 01:29:56.906: INFO: Pod "pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.904421ms
Jan 22 01:29:58.912: INFO: Pod "pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012918963s
STEP: Saw pod success
Jan 22 01:29:58.912: INFO: Pod "pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:29:58.917: INFO: Trying to get logs from node 10.191.28.14 pod pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:29:58.951: INFO: Waiting for pod pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:29:59.020: INFO: Pod pod-39f8e0c9-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:29:59.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-855p5" for this suite.
Jan 22 01:30:05.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:30:05.318: INFO: namespace: e2e-tests-emptydir-855p5, resource: bindings, ignored listing per whitelist
Jan 22 01:30:05.324: INFO: namespace e2e-tests-emptydir-855p5 deletion completed in 6.282822829s

â€¢ [SLOW TEST:8.698 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:30:05.324: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-57rhp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc
Jan 22 01:30:05.625: INFO: Pod name my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc: Found 1 pods out of 1
Jan 22 01:30:05.625: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc" are running
Jan 22 01:30:15.635: INFO: Pod "my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc-pljsz" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 01:30:05 +0000 UTC Reason: Message:}])
Jan 22 01:30:15.635: INFO: Trying to dial the pod
Jan 22 01:30:20.661: INFO: Controller my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc: Got expected result from replica 1 [my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc-pljsz]: "my-hostname-basic-3f269208-1de5-11e9-8691-1e7d95aa6bfc-pljsz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:30:20.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-57rhp" for this suite.
Jan 22 01:30:26.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:30:26.854: INFO: namespace: e2e-tests-replication-controller-57rhp, resource: bindings, ignored listing per whitelist
Jan 22 01:30:26.919: INFO: namespace e2e-tests-replication-controller-57rhp deletion completed in 6.246519057s

â€¢ [SLOW TEST:21.595 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:30:26.919: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-sv6zp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jan 22 01:30:27.231: INFO: Waiting up to 5m0s for pod "downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-sv6zp" to be "success or failure"
Jan 22 01:30:27.242: INFO: Pod "downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.144537ms
Jan 22 01:30:29.248: INFO: Pod "downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.016582143s
Jan 22 01:30:31.253: INFO: Pod "downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021984112s
STEP: Saw pod success
Jan 22 01:30:31.253: INFO: Pod "downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:30:31.259: INFO: Trying to get logs from node 10.191.28.14 pod downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:30:31.291: INFO: Waiting for pod downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:30:31.320: INFO: Pod downward-api-4c083072-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:30:31.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sv6zp" for this suite.
Jan 22 01:30:37.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:30:37.576: INFO: namespace: e2e-tests-downward-api-sv6zp, resource: bindings, ignored listing per whitelist
Jan 22 01:30:37.645: INFO: namespace e2e-tests-downward-api-sv6zp deletion completed in 6.311124803s

â€¢ [SLOW TEST:10.726 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:30:37.646: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-htt6m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-5270cb67-1de5-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:30:37.971: INFO: Waiting up to 5m0s for pod "pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-htt6m" to be "success or failure"
Jan 22 01:30:37.976: INFO: Pod "pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.361725ms
Jan 22 01:30:39.982: INFO: Pod "pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011442661s
STEP: Saw pod success
Jan 22 01:30:39.982: INFO: Pod "pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:30:39.987: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:30:40.021: INFO: Waiting for pod pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:30:40.029: INFO: Pod pod-configmaps-5272a995-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:30:40.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-htt6m" for this suite.
Jan 22 01:30:46.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:30:46.252: INFO: namespace: e2e-tests-configmap-htt6m, resource: bindings, ignored listing per whitelist
Jan 22 01:30:46.322: INFO: namespace e2e-tests-configmap-htt6m deletion completed in 6.277923163s

â€¢ [SLOW TEST:8.676 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:30:46.325: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4zp8t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
STEP: creating the pod
Jan 22 01:30:46.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:46.968: INFO: stderr: ""
Jan 22 01:30:46.968: INFO: stdout: "pod/pause created\n"
Jan 22 01:30:46.968: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 22 01:30:46.968: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-4zp8t" to be "running and ready"
Jan 22 01:30:46.973: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.155543ms
Jan 22 01:30:48.979: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010846544s
Jan 22 01:30:48.979: INFO: Pod "pause" satisfied condition "running and ready"
Jan 22 01:30:48.979: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 22 01:30:48.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:49.140: INFO: stderr: ""
Jan 22 01:30:49.140: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 22 01:30:49.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:49.262: INFO: stderr: ""
Jan 22 01:30:49.262: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          3s        testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 22 01:30:49.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 label pods pause testing-label- --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:49.403: INFO: stderr: ""
Jan 22 01:30:49.403: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 22 01:30:49.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:49.525: INFO: stderr: ""
Jan 22 01:30:49.525: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          3s        \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
STEP: using delete to clean up resources
Jan 22 01:30:49.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:49.694: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 01:30:49.694: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 22 01:30:49.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-4zp8t'
Jan 22 01:30:49.868: INFO: stderr: "No resources found.\n"
Jan 22 01:30:49.868: INFO: stdout: ""
Jan 22 01:30:49.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -l name=pause --namespace=e2e-tests-kubectl-4zp8t -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 01:30:49.990: INFO: stderr: ""
Jan 22 01:30:49.990: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:30:49.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4zp8t" for this suite.
Jan 22 01:30:56.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:30:56.299: INFO: namespace: e2e-tests-kubectl-4zp8t, resource: bindings, ignored listing per whitelist
Jan 22 01:30:56.345: INFO: namespace e2e-tests-kubectl-4zp8t deletion completed in 6.343352464s

â€¢ [SLOW TEST:10.020 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:30:56.346: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xtb62
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Jan 22 01:30:56.620: INFO: Waiting up to 5m0s for pod "downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-xtb62" to be "success or failure"
Jan 22 01:30:56.630: INFO: Pod "downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.078717ms
Jan 22 01:30:58.637: INFO: Pod "downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016844968s
STEP: Saw pod success
Jan 22 01:30:58.637: INFO: Pod "downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:30:58.643: INFO: Trying to get logs from node 10.191.28.14 pod downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:30:58.742: INFO: Waiting for pod downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:30:58.747: INFO: Pod downward-api-5d920eb8-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:30:58.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xtb62" for this suite.
Jan 22 01:31:04.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:31:04.960: INFO: namespace: e2e-tests-downward-api-xtb62, resource: bindings, ignored listing per whitelist
Jan 22 01:31:05.045: INFO: namespace e2e-tests-downward-api-xtb62 deletion completed in 6.286198935s

â€¢ [SLOW TEST:8.699 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:31:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-5gv6n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:31:05.318: INFO: (0) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.877604ms)
Jan 22 01:31:05.329: INFO: (1) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.688639ms)
Jan 22 01:31:05.342: INFO: (2) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.716358ms)
Jan 22 01:31:05.355: INFO: (3) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.193899ms)
Jan 22 01:31:05.367: INFO: (4) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.545124ms)
Jan 22 01:31:05.381: INFO: (5) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.295639ms)
Jan 22 01:31:05.393: INFO: (6) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.9189ms)
Jan 22 01:31:05.405: INFO: (7) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.163237ms)
Jan 22 01:31:05.417: INFO: (8) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.323615ms)
Jan 22 01:31:05.430: INFO: (9) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.292702ms)
Jan 22 01:31:05.441: INFO: (10) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.472928ms)
Jan 22 01:31:05.455: INFO: (11) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.692959ms)
Jan 22 01:31:05.466: INFO: (12) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.058635ms)
Jan 22 01:31:05.478: INFO: (13) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.904947ms)
Jan 22 01:31:05.490: INFO: (14) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.995464ms)
Jan 22 01:31:05.502: INFO: (15) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.593547ms)
Jan 22 01:31:05.513: INFO: (16) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.285036ms)
Jan 22 01:31:05.526: INFO: (17) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.221046ms)
Jan 22 01:31:05.538: INFO: (18) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.774098ms)
Jan 22 01:31:05.551: INFO: (19) /api/v1/nodes/10.191.28.14/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.557093ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:31:05.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5gv6n" for this suite.
Jan 22 01:31:11.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:31:11.798: INFO: namespace: e2e-tests-proxy-5gv6n, resource: bindings, ignored listing per whitelist
Jan 22 01:31:11.882: INFO: namespace e2e-tests-proxy-5gv6n deletion completed in 6.253343241s

â€¢ [SLOW TEST:6.837 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:31:11.882: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vpmhr
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-66d6a0a1-1de5-11e9-8691-1e7d95aa6bfc
STEP: Creating secret with name s-test-opt-upd-66d6a0f0-1de5-11e9-8691-1e7d95aa6bfc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-66d6a0a1-1de5-11e9-8691-1e7d95aa6bfc
STEP: Updating secret s-test-opt-upd-66d6a0f0-1de5-11e9-8691-1e7d95aa6bfc
STEP: Creating secret with name s-test-opt-create-66d6a115-1de5-11e9-8691-1e7d95aa6bfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:32:29.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vpmhr" for this suite.
Jan 22 01:32:53.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:32:54.182: INFO: namespace: e2e-tests-secrets-vpmhr, resource: bindings, ignored listing per whitelist
Jan 22 01:32:54.218: INFO: namespace e2e-tests-secrets-vpmhr deletion completed in 24.302485194s

â€¢ [SLOW TEST:102.336 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:32:54.219: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xr4ws
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: executing a command with run --rm and attach with stdin
Jan 22 01:32:54.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 --namespace=e2e-tests-kubectl-xr4ws run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 22 01:32:55.972: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
Jan 22 01:32:55.972: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:32:57.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xr4ws" for this suite.
Jan 22 01:33:04.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:33:04.213: INFO: namespace: e2e-tests-kubectl-xr4ws, resource: bindings, ignored listing per whitelist
Jan 22 01:33:04.348: INFO: namespace e2e-tests-kubectl-xr4ws deletion completed in 6.349660102s

â€¢ [SLOW TEST:10.129 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:33:04.348: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-66mrl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:33:04.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-66mrl" to be "success or failure"
Jan 22 01:33:04.638: INFO: Pod "downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.913756ms
Jan 22 01:33:06.644: INFO: Pod "downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013066476s
Jan 22 01:33:08.650: INFO: Pod "downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018900739s
STEP: Saw pod success
Jan 22 01:33:08.650: INFO: Pod "downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:33:08.655: INFO: Trying to get logs from node 10.191.28.26 pod downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:33:08.720: INFO: Waiting for pod downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:33:08.725: INFO: Pod downwardapi-volume-a9def911-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:33:08.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-66mrl" for this suite.
Jan 22 01:33:14.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:33:14.825: INFO: namespace: e2e-tests-projected-66mrl, resource: bindings, ignored listing per whitelist
Jan 22 01:33:15.056: INFO: namespace e2e-tests-projected-66mrl deletion completed in 6.319778602s

â€¢ [SLOW TEST:10.707 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:33:15.056: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-z65nl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-b040d00f-1de5-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:33:15.350: INFO: Waiting up to 5m0s for pod "pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-z65nl" to be "success or failure"
Jan 22 01:33:15.355: INFO: Pod "pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.154866ms
Jan 22 01:33:17.361: INFO: Pod "pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011415436s
STEP: Saw pod success
Jan 22 01:33:17.362: INFO: Pod "pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:33:17.367: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:33:17.420: INFO: Waiting for pod pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:33:17.425: INFO: Pod pod-secrets-b0421e8a-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:33:17.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-z65nl" for this suite.
Jan 22 01:33:23.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:33:23.614: INFO: namespace: e2e-tests-secrets-z65nl, resource: bindings, ignored listing per whitelist
Jan 22 01:33:23.754: INFO: namespace e2e-tests-secrets-z65nl deletion completed in 6.317224149s

â€¢ [SLOW TEST:8.698 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:33:23.754: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-frl5k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:33:24.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-frl5k" to be "success or failure"
Jan 22 01:33:24.026: INFO: Pod "downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.366994ms
Jan 22 01:33:26.032: INFO: Pod "downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014726872s
STEP: Saw pod success
Jan 22 01:33:26.032: INFO: Pod "downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:33:26.037: INFO: Trying to get logs from node 10.191.28.26 pod downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:33:26.120: INFO: Waiting for pod downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:33:26.127: INFO: Pod downwardapi-volume-b56d2db9-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:33:26.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-frl5k" for this suite.
Jan 22 01:33:32.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:33:32.400: INFO: namespace: e2e-tests-projected-frl5k, resource: bindings, ignored listing per whitelist
Jan 22 01:33:32.450: INFO: namespace e2e-tests-projected-frl5k deletion completed in 6.313466286s

â€¢ [SLOW TEST:8.696 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:33:32.451: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2vl4w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:33:32.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-2vl4w" to be "success or failure"
Jan 22 01:33:32.739: INFO: Pod "downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.190722ms
Jan 22 01:33:34.745: INFO: Pod "downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016827798s
STEP: Saw pod success
Jan 22 01:33:34.745: INFO: Pod "downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:33:34.751: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:33:34.786: INFO: Waiting for pod downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:33:34.791: INFO: Pod downwardapi-volume-ba9e6812-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:33:34.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2vl4w" for this suite.
Jan 22 01:33:41.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:33:41.123: INFO: namespace: e2e-tests-downward-api-2vl4w, resource: bindings, ignored listing per whitelist
Jan 22 01:33:41.241: INFO: namespace e2e-tests-downward-api-2vl4w deletion completed in 6.409030896s

â€¢ [SLOW TEST:8.791 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:33:41.243: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vb28c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-bfda48c6-1de5-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:33:41.517: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-vb28c" to be "success or failure"
Jan 22 01:33:41.522: INFO: Pod "pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.109589ms
Jan 22 01:33:43.528: INFO: Pod "pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011421238s
STEP: Saw pod success
Jan 22 01:33:43.528: INFO: Pod "pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:33:43.534: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:33:43.576: INFO: Waiting for pod pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:33:43.581: INFO: Pod pod-configmaps-bfdb5013-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:33:43.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vb28c" for this suite.
Jan 22 01:33:49.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:33:49.752: INFO: namespace: e2e-tests-configmap-vb28c, resource: bindings, ignored listing per whitelist
Jan 22 01:33:49.924: INFO: namespace e2e-tests-configmap-vb28c deletion completed in 6.328938615s

â€¢ [SLOW TEST:8.682 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:33:49.925: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-df4bm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0122 01:34:20.830987      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 01:34:20.831: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:34:20.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-df4bm" for this suite.
Jan 22 01:34:26.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:34:27.014: INFO: namespace: e2e-tests-gc-df4bm, resource: bindings, ignored listing per whitelist
Jan 22 01:34:27.113: INFO: namespace e2e-tests-gc-df4bm deletion completed in 6.273194298s

â€¢ [SLOW TEST:37.188 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:34:27.113: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ftgqf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:34:27.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-ftgqf" to be "success or failure"
Jan 22 01:34:27.398: INFO: Pod "downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.144673ms
Jan 22 01:34:29.404: INFO: Pod "downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010720179s
STEP: Saw pod success
Jan 22 01:34:29.404: INFO: Pod "downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:34:29.409: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:34:29.442: INFO: Waiting for pod downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:34:29.446: INFO: Pod downwardapi-volume-db3305d5-1de5-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:34:29.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ftgqf" for this suite.
Jan 22 01:34:35.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:34:35.595: INFO: namespace: e2e-tests-projected-ftgqf, resource: bindings, ignored listing per whitelist
Jan 22 01:34:35.726: INFO: namespace e2e-tests-projected-ftgqf deletion completed in 6.267706595s

â€¢ [SLOW TEST:8.613 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:34:35.728: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8ww4w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-8ww4w
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
Jan 22 01:34:36.000: INFO: Found 0 stateful pods, waiting for 3
Jan 22 01:34:46.007: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:34:46.007: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:34:46.007: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Jan 22 01:34:46.129: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 22 01:34:56.184: INFO: Updating stateful set ss2
Jan 22 01:34:56.200: INFO: Waiting for Pod e2e-tests-statefulset-8ww4w/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Jan 22 01:35:06.214: INFO: Waiting for Pod e2e-tests-statefulset-8ww4w/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
Jan 22 01:35:16.364: INFO: Found 2 stateful pods, waiting for 3
Jan 22 01:35:26.371: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:35:26.371: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:35:26.371: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 22 01:35:26.412: INFO: Updating stateful set ss2
Jan 22 01:35:26.425: INFO: Waiting for Pod e2e-tests-statefulset-8ww4w/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Jan 22 01:35:36.469: INFO: Updating stateful set ss2
Jan 22 01:35:36.529: INFO: Waiting for StatefulSet e2e-tests-statefulset-8ww4w/ss2 to complete update
Jan 22 01:35:36.529: INFO: Waiting for Pod e2e-tests-statefulset-8ww4w/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Jan 22 01:35:46.553: INFO: Waiting for StatefulSet e2e-tests-statefulset-8ww4w/ss2 to complete update
Jan 22 01:35:46.553: INFO: Waiting for Pod e2e-tests-statefulset-8ww4w/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jan 22 01:35:56.543: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8ww4w
Jan 22 01:35:56.551: INFO: Scaling statefulset ss2 to 0
Jan 22 01:36:36.632: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:36:36.639: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:36:36.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8ww4w" for this suite.
Jan 22 01:36:42.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:36:42.901: INFO: namespace: e2e-tests-statefulset-8ww4w, resource: bindings, ignored listing per whitelist
Jan 22 01:36:42.957: INFO: namespace e2e-tests-statefulset-8ww4w deletion completed in 6.269498477s

â€¢ [SLOW TEST:127.229 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:36:42.958: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vxgq6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating cluster-info
Jan 22 01:36:43.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 cluster-info'
Jan 22 01:36:43.363: INFO: stderr: ""
Jan 22 01:36:43.363: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:36:43.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vxgq6" for this suite.
Jan 22 01:36:49.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:36:49.513: INFO: namespace: e2e-tests-kubectl-vxgq6, resource: bindings, ignored listing per whitelist
Jan 22 01:36:49.635: INFO: namespace e2e-tests-kubectl-vxgq6 deletion completed in 6.260346522s

â€¢ [SLOW TEST:6.676 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:36:49.638: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qbxt8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:36:49.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-qbxt8" to be "success or failure"
Jan 22 01:36:49.910: INFO: Pod "downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.044002ms
Jan 22 01:36:51.916: INFO: Pod "downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.011227036s
Jan 22 01:36:53.922: INFO: Pod "downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01731076s
STEP: Saw pod success
Jan 22 01:36:53.922: INFO: Pod "downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:36:53.927: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:36:54.041: INFO: Waiting for pod downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:36:54.046: INFO: Pod downwardapi-volume-30250d4b-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:36:54.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qbxt8" for this suite.
Jan 22 01:37:00.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:37:00.359: INFO: namespace: e2e-tests-projected-qbxt8, resource: bindings, ignored listing per whitelist
Jan 22 01:37:00.501: INFO: namespace e2e-tests-projected-qbxt8 deletion completed in 6.445828323s

â€¢ [SLOW TEST:10.864 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:37:00.503: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-nqdhp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:37:00.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nqdhp" for this suite.
Jan 22 01:37:06.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:37:06.893: INFO: namespace: e2e-tests-services-nqdhp, resource: bindings, ignored listing per whitelist
Jan 22 01:37:07.012: INFO: namespace e2e-tests-services-nqdhp deletion completed in 6.229988495s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:6.509 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:37:07.014: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-dsksv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-dsksv
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dsksv to expose endpoints map[]
Jan 22 01:37:07.327: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dsksv exposes endpoints map[] (7.469992ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-dsksv
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dsksv to expose endpoints map[pod1:[80]]
Jan 22 01:37:10.433: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dsksv exposes endpoints map[pod1:[80]] (3.094128671s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-dsksv
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dsksv to expose endpoints map[pod1:[80] pod2:[80]]
Jan 22 01:37:12.496: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dsksv exposes endpoints map[pod1:[80] pod2:[80]] (2.056013911s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-dsksv
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dsksv to expose endpoints map[pod2:[80]]
Jan 22 01:37:13.620: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dsksv exposes endpoints map[pod2:[80]] (1.112587069s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-dsksv
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-dsksv to expose endpoints map[]
Jan 22 01:37:14.647: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-dsksv exposes endpoints map[] (1.017134337s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:37:14.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-dsksv" for this suite.
Jan 22 01:37:20.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:37:20.869: INFO: namespace: e2e-tests-services-dsksv, resource: bindings, ignored listing per whitelist
Jan 22 01:37:21.037: INFO: namespace e2e-tests-services-dsksv deletion completed in 6.323395868s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:14.023 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:37:21.037: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-jrm9v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-42de51d6-1de6-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:37:21.330: INFO: Waiting up to 5m0s for pod "pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-jrm9v" to be "success or failure"
Jan 22 01:37:21.336: INFO: Pod "pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.897837ms
Jan 22 01:37:23.341: INFO: Pod "pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011287618s
STEP: Saw pod success
Jan 22 01:37:23.341: INFO: Pod "pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:37:23.346: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:37:23.387: INFO: Waiting for pod pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:37:23.420: INFO: Pod pod-secrets-42dfba63-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:37:23.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jrm9v" for this suite.
Jan 22 01:37:29.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:37:29.682: INFO: namespace: e2e-tests-secrets-jrm9v, resource: bindings, ignored listing per whitelist
Jan 22 01:37:29.729: INFO: namespace e2e-tests-secrets-jrm9v deletion completed in 6.294989051s

â€¢ [SLOW TEST:8.692 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:37:29.731: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-nx9zr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 22 01:37:32.541: INFO: Successfully updated pod "pod-update-480b14bc-1de6-11e9-8691-1e7d95aa6bfc"
STEP: verifying the updated pod is in kubernetes
Jan 22 01:37:33.083: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:37:33.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nx9zr" for this suite.
Jan 22 01:37:55.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:37:55.288: INFO: namespace: e2e-tests-pods-nx9zr, resource: bindings, ignored listing per whitelist
Jan 22 01:37:55.427: INFO: namespace e2e-tests-pods-nx9zr deletion completed in 22.327261812s

â€¢ [SLOW TEST:25.696 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:37:55.427: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-8c5sb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Jan 22 01:37:55.698: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 22 01:38:55.739: INFO: Waiting for terminating namespaces to be deleted...
Jan 22 01:38:55.751: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 22 01:38:55.782: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 22 01:38:55.782: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jan 22 01:38:55.790: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Jan 22 01:38:55.790: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.14 before test
Jan 22 01:38:55.815: INFO: ibm-master-proxy-static-10.191.28.14 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 01:38:55.815: INFO: kube-dns-autoscaler-7d4745b6b-kpbmp from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.815: INFO: 	Container autoscaler ready: true, restart count 0
Jan 22 01:38:55.815: INFO: kubernetes-dashboard-7b545fbb4d-jtwpf from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.815: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Jan 22 01:38:55.816: INFO: ibm-storage-watcher-785496b956-24q6x from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jan 22 01:38:55.816: INFO: calico-node-knwhb from kube-system started at 2019-01-21 19:04:23 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 01:38:55.816: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 01:38:55.816: INFO: ibm-keepalived-watcher-c6qjp from kube-system started at 2019-01-21 19:04:23 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 01:38:55.816: INFO: calico-kube-controllers-5d496bb754-hxbr6 from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 22 01:38:55.816: INFO: ibm-kube-fluentd-s6x85 from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 01:38:55.816: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-229zh from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 01:38:55.816: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 01:38:55.816: INFO: ibm-file-plugin-5f6f89cc66-wm2bv from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jan 22 01:38:55.816: INFO: kube-dns-amd64-74d5cf9648-srzhn from kube-system started at 2019-01-21 19:04:43 +0000 UTC (3 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 22 01:38:55.816: INFO: 	Container kubedns ready: true, restart count 0
Jan 22 01:38:55.816: INFO: 	Container sidecar ready: true, restart count 0
Jan 22 01:38:55.816: INFO: vpn-6bff56d46f-p84d6 from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.816: INFO: 	Container vpn ready: true, restart count 0
Jan 22 01:38:55.816: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.15 before test
Jan 22 01:38:55.845: INFO: ibm-master-proxy-static-10.191.28.15 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 01:38:55.854: INFO: calico-node-47d7w from kube-system started at 2019-01-21 19:04:43 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 01:38:55.854: INFO: ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-hzrnk from ibm-system started at 2019-01-21 19:06:40 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container ibm-cloud-provider-ip-169-62-31-30 ready: true, restart count 0
Jan 22 01:38:55.854: INFO: ibm-kube-fluentd-mznzk from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 01:38:55.854: INFO: sonobuoy-e2e-job-a35b9383deaf4877 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container e2e ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 01:38:55.854: INFO: kube-dns-amd64-74d5cf9648-mvp57 from kube-system started at 2019-01-21 19:05:11 +0000 UTC (3 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container kubedns ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container sidecar ready: true, restart count 0
Jan 22 01:38:55.854: INFO: ibm-keepalived-watcher-z9r9c from kube-system started at 2019-01-21 19:04:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 01:38:55.854: INFO: public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-z9cwc from kube-system started at 2019-01-21 19:08:31 +0000 UTC (4 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 22 01:38:55.854: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-r65s6 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.854: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 01:38:55.854: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.26 before test
Jan 22 01:38:55.891: INFO: ibm-master-proxy-static-10.191.28.26 from kube-system started at <nil> (0 container statuses recorded)
Jan 22 01:38:55.891: INFO: heapster-b7b7c7876-5hmkp from kube-system started at 2019-01-21 19:05:16 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container heapster ready: true, restart count 0
Jan 22 01:38:55.891: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 22 01:38:55.891: INFO: ibm-kube-fluentd-z5f6d from kube-system started at 2019-01-21 19:08:38 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container fluentd ready: true, restart count 0
Jan 22 01:38:55.891: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-01-22 00:38:43 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jan 22 01:38:55.891: INFO: sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-2dcr2 from heptio-sonobuoy started at 2019-01-22 00:39:08 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 01:38:55.891: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 01:38:55.891: INFO: calico-node-wr99s from kube-system started at 2019-01-21 19:04:55 +0000 UTC (2 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container calico-node ready: true, restart count 0
Jan 22 01:38:55.891: INFO: 	Container install-cni ready: true, restart count 0
Jan 22 01:38:55.891: INFO: ibm-cloud-provider-ip-169-62-31-30-5b8845bb69-gpk7h from ibm-system started at 2019-01-21 19:06:40 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container ibm-cloud-provider-ip-169-62-31-30 ready: true, restart count 0
Jan 22 01:38:55.891: INFO: public-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-alb1-88f6b6f47-pbwvk from kube-system started at 2019-01-21 19:08:31 +0000 UTC (4 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 22 01:38:55.891: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 22 01:38:55.891: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 22 01:38:55.891: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 22 01:38:55.891: INFO: ibm-keepalived-watcher-p7vbr from kube-system started at 2019-01-21 19:04:55 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 22 01:38:55.891: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-22 00:39:06 +0000 UTC (1 container statuses recorded)
Jan 22 01:38:55.891: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7c83c4ea-1de6-11e9-8691-1e7d95aa6bfc 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7c83c4ea-1de6-11e9-8691-1e7d95aa6bfc off the node 10.191.28.14
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7c83c4ea-1de6-11e9-8691-1e7d95aa6bfc
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:00.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8c5sb" for this suite.
Jan 22 01:39:10.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:39:10.224: INFO: namespace: e2e-tests-sched-pred-8c5sb, resource: bindings, ignored listing per whitelist
Jan 22 01:39:10.423: INFO: namespace e2e-tests-sched-pred-8c5sb deletion completed in 10.292902888s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

â€¢ [SLOW TEST:74.996 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:39:10.424: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cc8vr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-840faad1-1de6-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:39:10.698: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-cc8vr" to be "success or failure"
Jan 22 01:39:10.704: INFO: Pod "pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.052004ms
Jan 22 01:39:12.709: INFO: Pod "pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010704535s
Jan 22 01:39:14.715: INFO: Pod "pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016538038s
STEP: Saw pod success
Jan 22 01:39:14.715: INFO: Pod "pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:39:14.720: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:39:14.762: INFO: Waiting for pod pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:39:14.820: INFO: Pod pod-projected-configmaps-8410b000-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:14.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cc8vr" for this suite.
Jan 22 01:39:20.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:39:20.991: INFO: namespace: e2e-tests-projected-cc8vr, resource: bindings, ignored listing per whitelist
Jan 22 01:39:21.133: INFO: namespace e2e-tests-projected-cc8vr deletion completed in 6.301018111s

â€¢ [SLOW TEST:10.710 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:39:21.135: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wf6r5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0122 01:39:22.561713      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 01:39:22.561: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:22.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wf6r5" for this suite.
Jan 22 01:39:28.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:39:28.635: INFO: namespace: e2e-tests-gc-wf6r5, resource: bindings, ignored listing per whitelist
Jan 22 01:39:28.820: INFO: namespace e2e-tests-gc-wf6r5 deletion completed in 6.241932961s

â€¢ [SLOW TEST:7.685 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:39:28.820: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-dvwwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
Jan 22 01:39:29.086: INFO: Waiting up to 5m0s for pod "client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-containers-dvwwb" to be "success or failure"
Jan 22 01:39:29.091: INFO: Pod "client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.933511ms
Jan 22 01:39:31.097: INFO: Pod "client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011105281s
Jan 22 01:39:33.103: INFO: Pod "client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017285574s
STEP: Saw pod success
Jan 22 01:39:33.103: INFO: Pod "client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:39:33.108: INFO: Trying to get logs from node 10.191.28.14 pod client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:39:33.145: INFO: Waiting for pod client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:39:33.220: INFO: Pod client-containers-8f0664ac-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:33.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dvwwb" for this suite.
Jan 22 01:39:39.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:39:39.475: INFO: namespace: e2e-tests-containers-dvwwb, resource: bindings, ignored listing per whitelist
Jan 22 01:39:39.529: INFO: namespace e2e-tests-containers-dvwwb deletion completed in 6.29483822s

â€¢ [SLOW TEST:10.709 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:39:39.529: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s5dtm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-9568981f-1de6-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:39:39.804: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-s5dtm" to be "success or failure"
Jan 22 01:39:39.816: INFO: Pod "pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023204ms
Jan 22 01:39:41.823: INFO: Pod "pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018972709s
STEP: Saw pod success
Jan 22 01:39:41.823: INFO: Pod "pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:39:41.828: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:39:41.947: INFO: Waiting for pod pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:39:41.952: INFO: Pod pod-projected-configmaps-95699ffe-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:41.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s5dtm" for this suite.
Jan 22 01:39:47.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:39:48.039: INFO: namespace: e2e-tests-projected-s5dtm, resource: bindings, ignored listing per whitelist
Jan 22 01:39:48.222: INFO: namespace e2e-tests-projected-s5dtm deletion completed in 6.256925583s

â€¢ [SLOW TEST:8.693 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:39:48.223: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-bkj9c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
Jan 22 01:39:48.485: INFO: Waiting up to 5m0s for pod "client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-containers-bkj9c" to be "success or failure"
Jan 22 01:39:48.492: INFO: Pod "client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.429379ms
Jan 22 01:39:50.498: INFO: Pod "client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01319216s
STEP: Saw pod success
Jan 22 01:39:50.498: INFO: Pod "client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:39:50.504: INFO: Trying to get logs from node 10.191.28.14 pod client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:39:50.541: INFO: Waiting for pod client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:39:50.546: INFO: Pod client-containers-9a958822-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:50.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bkj9c" for this suite.
Jan 22 01:39:56.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:39:56.837: INFO: namespace: e2e-tests-containers-bkj9c, resource: bindings, ignored listing per whitelist
Jan 22 01:39:56.837: INFO: namespace e2e-tests-containers-bkj9c deletion completed in 6.279673045s

â€¢ [SLOW TEST:8.615 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:39:56.838: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6nd9w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:39:57.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-6nd9w" to be "success or failure"
Jan 22 01:39:57.120: INFO: Pod "downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.421902ms
Jan 22 01:39:59.126: INFO: Pod "downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013523876s
STEP: Saw pod success
Jan 22 01:39:59.126: INFO: Pod "downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:39:59.131: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:39:59.220: INFO: Waiting for pod downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:39:59.226: INFO: Pod downwardapi-volume-9fbadcbb-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:39:59.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6nd9w" for this suite.
Jan 22 01:40:05.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:40:05.463: INFO: namespace: e2e-tests-downward-api-6nd9w, resource: bindings, ignored listing per whitelist
Jan 22 01:40:05.545: INFO: namespace e2e-tests-downward-api-6nd9w deletion completed in 6.307749803s

â€¢ [SLOW TEST:8.707 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:40:05.547: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-jt896
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-6s7n2 in namespace e2e-tests-proxy-jt896
I0122 01:40:05.854765      15 runners.go:177] Created replication controller with name: proxy-service-6s7n2, namespace: e2e-tests-proxy-jt896, replica count: 1
I0122 01:40:06.905182      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 01:40:07.905472      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 01:40:08.905700      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:09.905940      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:10.906214      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:11.906425      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:12.906729      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:13.907089      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:14.907356      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 01:40:15.907594      15 runners.go:177] proxy-service-6s7n2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 22 01:40:15.916: INFO: setup took 10.129253744s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 22 01:40:15.929: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 12.608466ms)
Jan 22 01:40:15.933: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 16.780505ms)
Jan 22 01:40:15.933: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 16.81579ms)
Jan 22 01:40:15.933: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 16.529411ms)
Jan 22 01:40:15.934: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 16.963257ms)
Jan 22 01:40:15.938: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 21.614526ms)
Jan 22 01:40:15.938: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 21.246359ms)
Jan 22 01:40:15.938: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 21.533932ms)
Jan 22 01:40:15.939: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 21.612343ms)
Jan 22 01:40:15.939: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 22.317038ms)
Jan 22 01:40:15.940: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 22.694116ms)
Jan 22 01:40:15.947: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 30.247311ms)
Jan 22 01:40:15.948: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 31.172107ms)
Jan 22 01:40:15.948: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 31.390063ms)
Jan 22 01:40:15.954: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 36.214908ms)
Jan 22 01:40:15.959: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 41.599916ms)
Jan 22 01:40:15.967: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 7.711103ms)
Jan 22 01:40:15.969: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 9.587267ms)
Jan 22 01:40:15.969: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.269377ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 10.578328ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 9.567809ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 10.09034ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 9.851242ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 10.38044ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 9.847824ms)
Jan 22 01:40:15.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 9.77309ms)
Jan 22 01:40:15.973: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 13.315516ms)
Jan 22 01:40:15.977: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 17.634339ms)
Jan 22 01:40:15.979: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 19.569154ms)
Jan 22 01:40:15.979: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 19.014355ms)
Jan 22 01:40:15.979: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 19.799933ms)
Jan 22 01:40:15.979: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 19.205753ms)
Jan 22 01:40:15.987: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 7.801041ms)
Jan 22 01:40:15.989: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 8.744957ms)
Jan 22 01:40:15.990: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 9.944317ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 11.345093ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 11.139776ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.46202ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.489588ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.534063ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.900197ms)
Jan 22 01:40:15.991: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 11.958225ms)
Jan 22 01:40:15.993: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 13.171454ms)
Jan 22 01:40:15.995: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 15.852287ms)
Jan 22 01:40:15.997: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 17.930481ms)
Jan 22 01:40:15.997: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 17.565368ms)
Jan 22 01:40:15.997: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 17.714468ms)
Jan 22 01:40:15.998: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 18.185671ms)
Jan 22 01:40:16.006: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 8.625231ms)
Jan 22 01:40:16.008: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 9.436771ms)
Jan 22 01:40:16.008: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 10.24373ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 12.338991ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 12.701605ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 12.683924ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 13.326271ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 12.398499ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 13.144185ms)
Jan 22 01:40:16.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 12.792342ms)
Jan 22 01:40:16.014: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 15.889272ms)
Jan 22 01:40:16.015: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 15.905582ms)
Jan 22 01:40:16.019: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 20.431395ms)
Jan 22 01:40:16.019: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 20.912551ms)
Jan 22 01:40:16.019: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 20.553723ms)
Jan 22 01:40:16.019: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 20.153018ms)
Jan 22 01:40:16.030: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 10.642015ms)
Jan 22 01:40:16.031: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 12.144157ms)
Jan 22 01:40:16.033: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 13.597749ms)
Jan 22 01:40:16.033: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 13.629579ms)
Jan 22 01:40:16.034: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 14.706257ms)
Jan 22 01:40:16.034: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 14.517088ms)
Jan 22 01:40:16.034: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 14.695614ms)
Jan 22 01:40:16.034: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 15.014009ms)
Jan 22 01:40:16.035: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 14.915265ms)
Jan 22 01:40:16.035: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 15.119896ms)
Jan 22 01:40:16.036: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 16.634104ms)
Jan 22 01:40:16.040: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 19.821247ms)
Jan 22 01:40:16.041: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 21.845549ms)
Jan 22 01:40:16.041: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 21.650693ms)
Jan 22 01:40:16.042: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 21.854519ms)
Jan 22 01:40:16.042: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 22.17728ms)
Jan 22 01:40:16.059: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 16.634549ms)
Jan 22 01:40:16.059: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 17.56402ms)
Jan 22 01:40:16.059: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 16.977603ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 18.42182ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 18.829464ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 18.708784ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 18.711479ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 19.344502ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 19.056489ms)
Jan 22 01:40:16.061: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 18.656498ms)
Jan 22 01:40:16.064: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 22.644006ms)
Jan 22 01:40:16.066: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 23.969184ms)
Jan 22 01:40:16.067: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 24.38997ms)
Jan 22 01:40:16.067: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 24.625245ms)
Jan 22 01:40:16.067: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 24.966503ms)
Jan 22 01:40:16.067: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 24.663921ms)
Jan 22 01:40:16.077: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 9.794251ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 10.879649ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.031641ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.101372ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 10.883072ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.7836ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.941168ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.353848ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 12.450302ms)
Jan 22 01:40:16.079: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 11.489207ms)
Jan 22 01:40:16.080: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 13.325004ms)
Jan 22 01:40:16.085: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 16.774588ms)
Jan 22 01:40:16.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 18.912005ms)
Jan 22 01:40:16.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 19.439433ms)
Jan 22 01:40:16.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 19.261432ms)
Jan 22 01:40:16.087: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 19.291112ms)
Jan 22 01:40:16.095: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 7.97891ms)
Jan 22 01:40:16.098: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 10.738847ms)
Jan 22 01:40:16.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 10.91622ms)
Jan 22 01:40:16.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.987823ms)
Jan 22 01:40:16.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.466623ms)
Jan 22 01:40:16.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.591314ms)
Jan 22 01:40:16.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.714024ms)
Jan 22 01:40:16.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.555685ms)
Jan 22 01:40:16.100: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.639382ms)
Jan 22 01:40:16.100: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 11.809366ms)
Jan 22 01:40:16.101: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 13.746247ms)
Jan 22 01:40:16.105: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 17.494889ms)
Jan 22 01:40:16.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 19.453273ms)
Jan 22 01:40:16.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 19.151028ms)
Jan 22 01:40:16.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 19.538527ms)
Jan 22 01:40:16.107: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 19.900504ms)
Jan 22 01:40:16.116: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 8.041054ms)
Jan 22 01:40:16.118: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.565551ms)
Jan 22 01:40:16.118: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.65504ms)
Jan 22 01:40:16.119: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 10.548534ms)
Jan 22 01:40:16.119: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 10.807887ms)
Jan 22 01:40:16.119: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.276513ms)
Jan 22 01:40:16.121: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 12.536974ms)
Jan 22 01:40:16.121: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 12.740506ms)
Jan 22 01:40:16.121: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 12.360841ms)
Jan 22 01:40:16.121: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 12.451562ms)
Jan 22 01:40:16.122: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 14.060158ms)
Jan 22 01:40:16.127: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 17.992179ms)
Jan 22 01:40:16.129: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 20.608004ms)
Jan 22 01:40:16.129: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 20.867464ms)
Jan 22 01:40:16.129: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 20.798093ms)
Jan 22 01:40:16.129: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 20.422905ms)
Jan 22 01:40:16.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 17.189044ms)
Jan 22 01:40:16.147: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 17.276409ms)
Jan 22 01:40:16.147: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 17.0236ms)
Jan 22 01:40:16.148: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 18.105023ms)
Jan 22 01:40:16.148: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 18.593569ms)
Jan 22 01:40:16.148: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 18.616235ms)
Jan 22 01:40:16.148: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 18.628292ms)
Jan 22 01:40:16.148: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 18.648932ms)
Jan 22 01:40:16.149: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 19.441249ms)
Jan 22 01:40:16.149: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 19.430315ms)
Jan 22 01:40:16.150: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 20.743617ms)
Jan 22 01:40:16.150: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 20.745643ms)
Jan 22 01:40:16.152: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 22.980203ms)
Jan 22 01:40:16.153: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 23.277123ms)
Jan 22 01:40:16.153: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 23.295971ms)
Jan 22 01:40:16.153: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 23.678526ms)
Jan 22 01:40:16.161: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 8.392502ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 11.470053ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.585275ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 12.042216ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 11.883694ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.688573ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.742311ms)
Jan 22 01:40:16.165: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 12.142652ms)
Jan 22 01:40:16.166: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 12.242285ms)
Jan 22 01:40:16.166: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 12.586967ms)
Jan 22 01:40:16.167: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 13.951018ms)
Jan 22 01:40:16.171: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 17.067559ms)
Jan 22 01:40:16.173: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 19.495163ms)
Jan 22 01:40:16.173: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 19.674924ms)
Jan 22 01:40:16.173: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 19.402346ms)
Jan 22 01:40:16.173: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 19.713868ms)
Jan 22 01:40:16.182: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 9.008574ms)
Jan 22 01:40:16.183: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.138576ms)
Jan 22 01:40:16.184: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 10.565286ms)
Jan 22 01:40:16.184: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 10.051411ms)
Jan 22 01:40:16.184: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 10.883677ms)
Jan 22 01:40:16.184: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.537552ms)
Jan 22 01:40:16.185: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.146584ms)
Jan 22 01:40:16.185: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 11.40098ms)
Jan 22 01:40:16.186: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.780435ms)
Jan 22 01:40:16.186: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.86053ms)
Jan 22 01:40:16.187: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 13.423222ms)
Jan 22 01:40:16.190: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 15.816855ms)
Jan 22 01:40:16.192: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 17.602541ms)
Jan 22 01:40:16.192: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 18.207003ms)
Jan 22 01:40:16.192: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 18.313243ms)
Jan 22 01:40:16.192: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 18.594517ms)
Jan 22 01:40:16.201: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 8.360954ms)
Jan 22 01:40:16.203: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 10.367066ms)
Jan 22 01:40:16.203: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 10.796324ms)
Jan 22 01:40:16.204: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 11.185928ms)
Jan 22 01:40:16.204: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.155396ms)
Jan 22 01:40:16.204: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.58867ms)
Jan 22 01:40:16.204: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 11.872282ms)
Jan 22 01:40:16.204: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.527834ms)
Jan 22 01:40:16.205: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.826305ms)
Jan 22 01:40:16.205: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 12.266713ms)
Jan 22 01:40:16.206: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 12.706251ms)
Jan 22 01:40:16.210: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 17.237457ms)
Jan 22 01:40:16.212: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 19.022033ms)
Jan 22 01:40:16.212: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 19.411574ms)
Jan 22 01:40:16.212: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 19.483466ms)
Jan 22 01:40:16.212: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 19.815389ms)
Jan 22 01:40:16.228: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 15.365855ms)
Jan 22 01:40:16.228: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 15.271147ms)
Jan 22 01:40:16.231: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 18.087385ms)
Jan 22 01:40:16.231: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 18.585389ms)
Jan 22 01:40:16.231: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 18.723116ms)
Jan 22 01:40:16.232: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 18.871449ms)
Jan 22 01:40:16.232: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 18.903285ms)
Jan 22 01:40:16.232: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 19.231621ms)
Jan 22 01:40:16.232: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 19.352664ms)
Jan 22 01:40:16.232: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 19.418855ms)
Jan 22 01:40:16.233: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 20.008537ms)
Jan 22 01:40:16.237: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 24.352451ms)
Jan 22 01:40:16.239: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 26.570315ms)
Jan 22 01:40:16.240: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 27.175074ms)
Jan 22 01:40:16.240: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 26.971455ms)
Jan 22 01:40:16.240: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 27.031787ms)
Jan 22 01:40:16.248: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 8.404649ms)
Jan 22 01:40:16.250: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 8.437307ms)
Jan 22 01:40:16.250: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 10.046144ms)
Jan 22 01:40:16.250: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 9.334014ms)
Jan 22 01:40:16.250: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.148272ms)
Jan 22 01:40:16.251: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 9.895947ms)
Jan 22 01:40:16.251: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 9.475507ms)
Jan 22 01:40:16.251: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.235123ms)
Jan 22 01:40:16.251: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 9.54814ms)
Jan 22 01:40:16.252: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 10.381797ms)
Jan 22 01:40:16.258: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 17.60766ms)
Jan 22 01:40:16.261: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 20.096983ms)
Jan 22 01:40:16.263: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 21.816242ms)
Jan 22 01:40:16.264: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 22.839134ms)
Jan 22 01:40:16.264: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 23.284945ms)
Jan 22 01:40:16.264: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 22.502525ms)
Jan 22 01:40:16.272: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 7.925488ms)
Jan 22 01:40:16.274: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 9.309393ms)
Jan 22 01:40:16.274: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 9.765841ms)
Jan 22 01:40:16.275: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 10.348801ms)
Jan 22 01:40:16.275: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.688135ms)
Jan 22 01:40:16.276: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.159352ms)
Jan 22 01:40:16.277: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.939327ms)
Jan 22 01:40:16.277: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 12.375059ms)
Jan 22 01:40:16.277: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.893866ms)
Jan 22 01:40:16.277: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.92278ms)
Jan 22 01:40:16.278: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 14.117733ms)
Jan 22 01:40:16.283: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 18.941893ms)
Jan 22 01:40:16.287: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 22.229111ms)
Jan 22 01:40:16.287: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 22.212872ms)
Jan 22 01:40:16.287: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 22.369373ms)
Jan 22 01:40:16.287: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 22.622898ms)
Jan 22 01:40:16.296: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 9.096402ms)
Jan 22 01:40:16.298: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 9.153257ms)
Jan 22 01:40:16.298: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 10.624216ms)
Jan 22 01:40:16.299: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 10.789572ms)
Jan 22 01:40:16.299: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 10.463384ms)
Jan 22 01:40:16.300: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.887077ms)
Jan 22 01:40:16.300: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.811821ms)
Jan 22 01:40:16.300: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 12.14824ms)
Jan 22 01:40:16.300: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.734603ms)
Jan 22 01:40:16.300: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 11.637135ms)
Jan 22 01:40:16.302: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 14.675969ms)
Jan 22 01:40:16.305: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 17.7005ms)
Jan 22 01:40:16.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 18.54245ms)
Jan 22 01:40:16.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 18.001091ms)
Jan 22 01:40:16.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 18.799703ms)
Jan 22 01:40:16.307: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 17.988095ms)
Jan 22 01:40:16.316: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 8.665686ms)
Jan 22 01:40:16.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.556118ms)
Jan 22 01:40:16.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.515316ms)
Jan 22 01:40:16.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 12.251327ms)
Jan 22 01:40:16.320: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 12.058431ms)
Jan 22 01:40:16.320: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 12.07649ms)
Jan 22 01:40:16.320: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 12.166224ms)
Jan 22 01:40:16.320: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 12.286737ms)
Jan 22 01:40:16.320: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 12.36761ms)
Jan 22 01:40:16.320: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 12.484629ms)
Jan 22 01:40:16.322: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 14.602094ms)
Jan 22 01:40:16.326: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 19.134185ms)
Jan 22 01:40:16.327: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 19.571146ms)
Jan 22 01:40:16.327: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 19.656902ms)
Jan 22 01:40:16.327: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 19.52862ms)
Jan 22 01:40:16.327: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 19.812833ms)
Jan 22 01:40:16.336: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 8.938ms)
Jan 22 01:40:16.339: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.753736ms)
Jan 22 01:40:16.339: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 11.660486ms)
Jan 22 01:40:16.339: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.932995ms)
Jan 22 01:40:16.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 11.277117ms)
Jan 22 01:40:16.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 11.606485ms)
Jan 22 01:40:16.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 11.614724ms)
Jan 22 01:40:16.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 11.124298ms)
Jan 22 01:40:16.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 11.484261ms)
Jan 22 01:40:16.340: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 12.479438ms)
Jan 22 01:40:16.341: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 12.484429ms)
Jan 22 01:40:16.344: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 15.363228ms)
Jan 22 01:40:16.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 17.673244ms)
Jan 22 01:40:16.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 18.688716ms)
Jan 22 01:40:16.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 18.510815ms)
Jan 22 01:40:16.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 18.409376ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:1080/proxy/... (200; 13.287681ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:460/proxy/: tls baz (200; 13.861886ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 13.39534ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:1080/proxy/rewri... (200; 13.832562ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 14.249504ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:462/proxy/: tls qux (200; 13.750818ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/proxy-service-6s7n2-fdx22/proxy/rewriteme"... (200; 13.686136ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:160/proxy/: foo (200; 14.058246ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/http:proxy-service-6s7n2-fdx22:162/proxy/: bar (200; 13.88307ms)
Jan 22 01:40:16.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jt896/pods/https:proxy-service-6s7n2-fdx22:443/proxy/... (200; 13.680541ms)
Jan 22 01:40:16.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname2/proxy/: bar (200; 15.750275ms)
Jan 22 01:40:16.366: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname1/proxy/: tls baz (200; 18.936144ms)
Jan 22 01:40:16.367: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname2/proxy/: bar (200; 20.375659ms)
Jan 22 01:40:16.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/services/http:proxy-service-6s7n2:portname1/proxy/: foo (200; 20.447349ms)
Jan 22 01:40:16.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/services/https:proxy-service-6s7n2:tlsportname2/proxy/: tls qux (200; 20.088824ms)
Jan 22 01:40:16.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jt896/services/proxy-service-6s7n2:portname1/proxy/: foo (200; 20.314693ms)
STEP: deleting { ReplicationController} proxy-service-6s7n2 in namespace e2e-tests-proxy-jt896, will wait for the garbage collector to delete the pods
Jan 22 01:40:16.452: INFO: Deleting { ReplicationController} proxy-service-6s7n2 took: 26.967632ms
Jan 22 01:40:16.553: INFO: Terminating { ReplicationController} proxy-service-6s7n2 pods took: 100.203678ms
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:40:27.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jt896" for this suite.
Jan 22 01:40:33.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:40:33.332: INFO: namespace: e2e-tests-proxy-jt896, resource: bindings, ignored listing per whitelist
Jan 22 01:40:33.538: INFO: namespace e2e-tests-proxy-jt896 deletion completed in 6.273476995s

â€¢ [SLOW TEST:27.991 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:40:33.538: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cqppk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 22 01:40:33.931: INFO: Waiting up to 5m0s for pod "pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-cqppk" to be "success or failure"
Jan 22 01:40:33.943: INFO: Pod "pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.292425ms
Jan 22 01:40:35.949: INFO: Pod "pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018424474s
STEP: Saw pod success
Jan 22 01:40:35.950: INFO: Pod "pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:40:35.955: INFO: Trying to get logs from node 10.191.28.14 pod pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:40:36.036: INFO: Waiting for pod pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:40:36.041: INFO: Pod pod-b59f275d-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:40:36.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cqppk" for this suite.
Jan 22 01:40:42.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:40:42.321: INFO: namespace: e2e-tests-emptydir-cqppk, resource: bindings, ignored listing per whitelist
Jan 22 01:40:42.321: INFO: namespace e2e-tests-emptydir-cqppk deletion completed in 6.269427549s

â€¢ [SLOW TEST:8.783 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:40:42.323: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2lx2f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-bad62694-1de6-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:40:42.600: INFO: Waiting up to 5m0s for pod "pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-2lx2f" to be "success or failure"
Jan 22 01:40:42.605: INFO: Pod "pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.872668ms
Jan 22 01:40:44.612: INFO: Pod "pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.01167246s
Jan 22 01:40:46.618: INFO: Pod "pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017774887s
STEP: Saw pod success
Jan 22 01:40:46.618: INFO: Pod "pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:40:46.623: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc container secret-env-test: <nil>
STEP: delete the pod
Jan 22 01:40:46.660: INFO: Waiting for pod pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:40:46.664: INFO: Pod pod-secrets-bad793a9-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:40:46.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2lx2f" for this suite.
Jan 22 01:40:52.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:40:52.738: INFO: namespace: e2e-tests-secrets-2lx2f, resource: bindings, ignored listing per whitelist
Jan 22 01:40:52.935: INFO: namespace e2e-tests-secrets-2lx2f deletion completed in 6.259998756s

â€¢ [SLOW TEST:10.612 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:40:52.937: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gnznq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-c12de36b-1de6-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:40:53.241: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-gnznq" to be "success or failure"
Jan 22 01:40:53.250: INFO: Pod "pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.008656ms
Jan 22 01:40:55.255: INFO: Pod "pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01449829s
STEP: Saw pod success
Jan 22 01:40:55.255: INFO: Pod "pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:40:55.261: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:40:55.297: INFO: Waiting for pod pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:40:55.302: INFO: Pod pod-projected-configmaps-c12efea0-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:40:55.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gnznq" for this suite.
Jan 22 01:41:01.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:41:01.468: INFO: namespace: e2e-tests-projected-gnznq, resource: bindings, ignored listing per whitelist
Jan 22 01:41:01.640: INFO: namespace e2e-tests-projected-gnznq deletion completed in 6.328256297s

â€¢ [SLOW TEST:8.704 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:41:01.642: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vtvng
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vtvng
Jan 22 01:41:03.901: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vtvng
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 01:41:03.907: INFO: Initial restart count of pod liveness-http is 0
Jan 22 01:41:21.973: INFO: Restart count of pod e2e-tests-container-probe-vtvng/liveness-http is now 1 (18.065225676s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:41:21.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vtvng" for this suite.
Jan 22 01:41:28.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:41:28.307: INFO: namespace: e2e-tests-container-probe-vtvng, resource: bindings, ignored listing per whitelist
Jan 22 01:41:28.338: INFO: namespace e2e-tests-container-probe-vtvng deletion completed in 6.335399369s

â€¢ [SLOW TEST:26.696 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:41:28.339: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6xwlr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
Jan 22 01:41:28.609: INFO: Waiting up to 5m0s for pod "client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-containers-6xwlr" to be "success or failure"
Jan 22 01:41:28.614: INFO: Pod "client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.190139ms
Jan 22 01:41:30.620: INFO: Pod "client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010750107s
STEP: Saw pod success
Jan 22 01:41:30.620: INFO: Pod "client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:41:30.626: INFO: Trying to get logs from node 10.191.28.14 pod client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:41:30.720: INFO: Waiting for pod client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:41:30.725: INFO: Pod client-containers-d643f1f9-1de6-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:41:30.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6xwlr" for this suite.
Jan 22 01:41:36.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:41:36.947: INFO: namespace: e2e-tests-containers-6xwlr, resource: bindings, ignored listing per whitelist
Jan 22 01:41:37.018: INFO: namespace e2e-tests-containers-6xwlr deletion completed in 6.282449543s

â€¢ [SLOW TEST:8.679 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:41:37.018: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-f9n2b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jan 22 01:41:39.851: INFO: Successfully updated pod "annotationupdatedb70db25-1de6-11e9-8691-1e7d95aa6bfc"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:41:43.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f9n2b" for this suite.
Jan 22 01:42:05.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:42:05.986: INFO: namespace: e2e-tests-downward-api-f9n2b, resource: bindings, ignored listing per whitelist
Jan 22 01:42:06.175: INFO: namespace e2e-tests-downward-api-f9n2b deletion completed in 22.258017942s

â€¢ [SLOW TEST:29.157 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:42:06.176: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ddrbf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 22 01:42:06.443: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77461,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 01:42:06.443: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77461,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 22 01:42:16.456: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77478,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 22 01:42:16.456: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77478,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 22 01:42:26.471: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77495,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 01:42:26.471: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77495,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 22 01:42:36.484: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77512,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 01:42:36.484: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-a,UID:ecd2144a-1de6-11e9-b13b-16990c636477,ResourceVersion:77512,Generation:0,CreationTimestamp:2019-01-22 01:42:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 22 01:42:46.500: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-b,UID:04b0eb5b-1de7-11e9-b13b-16990c636477,ResourceVersion:77529,Generation:0,CreationTimestamp:2019-01-22 01:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 01:42:46.500: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-b,UID:04b0eb5b-1de7-11e9-b13b-16990c636477,ResourceVersion:77529,Generation:0,CreationTimestamp:2019-01-22 01:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 22 01:42:56.512: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-b,UID:04b0eb5b-1de7-11e9-b13b-16990c636477,ResourceVersion:77546,Generation:0,CreationTimestamp:2019-01-22 01:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 01:42:56.513: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ddrbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-ddrbf/configmaps/e2e-watch-test-configmap-b,UID:04b0eb5b-1de7-11e9-b13b-16990c636477,ResourceVersion:77546,Generation:0,CreationTimestamp:2019-01-22 01:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:43:06.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ddrbf" for this suite.
Jan 22 01:43:12.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:43:12.662: INFO: namespace: e2e-tests-watch-ddrbf, resource: bindings, ignored listing per whitelist
Jan 22 01:43:12.822: INFO: namespace e2e-tests-watch-ddrbf deletion completed in 6.29795394s

â€¢ [SLOW TEST:66.646 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:43:12.822: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9zss9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 01:43:13.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-9zss9'
Jan 22 01:43:13.404: INFO: stderr: ""
Jan 22 01:43:13.405: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
Jan 22 01:43:13.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-9zss9'
Jan 22 01:43:13.572: INFO: stderr: ""
Jan 22 01:43:13.572: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:43:13.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9zss9" for this suite.
Jan 22 01:43:19.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:43:19.790: INFO: namespace: e2e-tests-kubectl-9zss9, resource: bindings, ignored listing per whitelist
Jan 22 01:43:19.931: INFO: namespace e2e-tests-kubectl-9zss9 deletion completed in 6.345919732s

â€¢ [SLOW TEST:7.109 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:43:19.933: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bxqll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-bxqll
Jan 22 01:43:22.199: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-bxqll
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 01:43:22.204: INFO: Initial restart count of pod liveness-exec is 0
Jan 22 01:44:10.365: INFO: Restart count of pod e2e-tests-container-probe-bxqll/liveness-exec is now 1 (48.160633091s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:44:10.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bxqll" for this suite.
Jan 22 01:44:16.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:44:16.622: INFO: namespace: e2e-tests-container-probe-bxqll, resource: bindings, ignored listing per whitelist
Jan 22 01:44:16.777: INFO: namespace e2e-tests-container-probe-bxqll deletion completed in 6.356478367s

â€¢ [SLOW TEST:56.844 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:44:16.779: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9zf67
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:44:17.049: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-9zf67" to be "success or failure"
Jan 22 01:44:17.057: INFO: Pod "downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.412557ms
Jan 22 01:44:19.063: INFO: Pod "downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013753595s
Jan 22 01:44:21.070: INFO: Pod "downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020731958s
STEP: Saw pod success
Jan 22 01:44:21.070: INFO: Pod "downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:44:21.075: INFO: Trying to get logs from node 10.191.28.26 pod downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:44:21.114: INFO: Waiting for pod downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:44:21.120: INFO: Pod downwardapi-volume-3aa9d05d-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:44:21.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zf67" for this suite.
Jan 22 01:44:27.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:44:27.318: INFO: namespace: e2e-tests-projected-9zf67, resource: bindings, ignored listing per whitelist
Jan 22 01:44:27.423: INFO: namespace e2e-tests-projected-9zf67 deletion completed in 6.287380724s

â€¢ [SLOW TEST:10.644 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:44:27.423: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-sgznx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
Jan 22 01:44:27.690: INFO: Waiting up to 5m0s for pod "var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-var-expansion-sgznx" to be "success or failure"
Jan 22 01:44:27.695: INFO: Pod "var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.255934ms
Jan 22 01:44:29.700: INFO: Pod "var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0106941s
Jan 22 01:44:31.707: INFO: Pod "var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01700522s
STEP: Saw pod success
Jan 22 01:44:31.707: INFO: Pod "var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:44:31.712: INFO: Trying to get logs from node 10.191.28.14 pod var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:44:31.751: INFO: Waiting for pod var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:44:31.756: INFO: Pod var-expansion-41015322-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:44:31.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-sgznx" for this suite.
Jan 22 01:44:37.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:44:37.858: INFO: namespace: e2e-tests-var-expansion-sgznx, resource: bindings, ignored listing per whitelist
Jan 22 01:44:38.022: INFO: namespace e2e-tests-var-expansion-sgznx deletion completed in 6.254585515s

â€¢ [SLOW TEST:10.599 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:44:38.024: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xj945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Jan 22 01:44:40.884: INFO: Successfully updated pod "labelsupdate47542921-1de7-11e9-8691-1e7d95aa6bfc"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:44:45.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xj945" for this suite.
Jan 22 01:45:07.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:45:07.486: INFO: namespace: e2e-tests-projected-xj945, resource: bindings, ignored listing per whitelist
Jan 22 01:45:07.569: INFO: namespace e2e-tests-projected-xj945 deletion completed in 22.379674485s

â€¢ [SLOW TEST:29.546 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:45:07.569: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xddg9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 01:45:07.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-xddg9'
Jan 22 01:45:08.000: INFO: stderr: ""
Jan 22 01:45:08.000: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
Jan 22 01:45:10.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xddg9'
Jan 22 01:45:10.171: INFO: stderr: ""
Jan 22 01:45:10.171: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:45:10.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xddg9" for this suite.
Jan 22 01:45:32.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:45:32.247: INFO: namespace: e2e-tests-kubectl-xddg9, resource: bindings, ignored listing per whitelist
Jan 22 01:45:32.447: INFO: namespace e2e-tests-kubectl-xddg9 deletion completed in 22.263335677s

â€¢ [SLOW TEST:24.878 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:45:32.447: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sfdv5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-67c8079b-1de7-11e9-8691-1e7d95aa6bfc
STEP: Creating configMap with name cm-test-opt-upd-67c807e0-1de7-11e9-8691-1e7d95aa6bfc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-67c8079b-1de7-11e9-8691-1e7d95aa6bfc
STEP: Updating configmap cm-test-opt-upd-67c807e0-1de7-11e9-8691-1e7d95aa6bfc
STEP: Creating configMap with name cm-test-opt-create-67c807fb-1de7-11e9-8691-1e7d95aa6bfc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:45:37.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sfdv5" for this suite.
Jan 22 01:46:01.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:46:01.139: INFO: namespace: e2e-tests-projected-sfdv5, resource: bindings, ignored listing per whitelist
Jan 22 01:46:01.276: INFO: namespace e2e-tests-projected-sfdv5 deletion completed in 24.247733132s

â€¢ [SLOW TEST:28.829 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:46:01.277: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-xh5rs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
Jan 22 01:46:01.558: INFO: Waiting up to 5m0s for pod "client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-containers-xh5rs" to be "success or failure"
Jan 22 01:46:01.563: INFO: Pod "client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.785612ms
Jan 22 01:46:03.572: INFO: Pod "client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013477582s
STEP: Saw pod success
Jan 22 01:46:03.572: INFO: Pod "client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:46:03.577: INFO: Trying to get logs from node 10.191.28.14 pod client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:46:03.613: INFO: Waiting for pod client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:46:03.618: INFO: Pod client-containers-78f427eb-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:46:03.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xh5rs" for this suite.
Jan 22 01:46:09.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:46:09.809: INFO: namespace: e2e-tests-containers-xh5rs, resource: bindings, ignored listing per whitelist
Jan 22 01:46:09.924: INFO: namespace e2e-tests-containers-xh5rs deletion completed in 6.295379413s

â€¢ [SLOW TEST:8.646 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:46:09.925: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-z9x52
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 22 01:46:10.203: INFO: Waiting up to 5m0s for pod "pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-z9x52" to be "success or failure"
Jan 22 01:46:10.211: INFO: Pod "pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.533328ms
Jan 22 01:46:12.225: INFO: Pod "pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021970237s
STEP: Saw pod success
Jan 22 01:46:12.225: INFO: Pod "pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:46:12.236: INFO: Trying to get logs from node 10.191.28.14 pod pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:46:12.275: INFO: Waiting for pod pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:46:12.280: INFO: Pod pod-7e1bc866-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:46:12.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z9x52" for this suite.
Jan 22 01:46:18.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:46:18.461: INFO: namespace: e2e-tests-emptydir-z9x52, resource: bindings, ignored listing per whitelist
Jan 22 01:46:18.639: INFO: namespace e2e-tests-emptydir-z9x52 deletion completed in 6.348982395s

â€¢ [SLOW TEST:8.715 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:46:18.640: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4qdst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:46:18.919: INFO: Waiting up to 5m0s for pod "downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-4qdst" to be "success or failure"
Jan 22 01:46:18.927: INFO: Pod "downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.868662ms
Jan 22 01:46:20.933: INFO: Pod "downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013343802s
STEP: Saw pod success
Jan 22 01:46:20.933: INFO: Pod "downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:46:20.939: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:46:20.974: INFO: Waiting for pod downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:46:20.978: INFO: Pod downwardapi-volume-834db43e-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:46:20.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4qdst" for this suite.
Jan 22 01:46:27.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:46:27.144: INFO: namespace: e2e-tests-downward-api-4qdst, resource: bindings, ignored listing per whitelist
Jan 22 01:46:27.359: INFO: namespace e2e-tests-downward-api-4qdst deletion completed in 6.369974801s

â€¢ [SLOW TEST:8.719 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:46:27.359: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4fvcf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:46:27.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-4fvcf" to be "success or failure"
Jan 22 01:46:27.639: INFO: Pod "downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.205709ms
Jan 22 01:46:29.645: INFO: Pod "downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013333316s
STEP: Saw pod success
Jan 22 01:46:29.645: INFO: Pod "downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:46:29.650: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:46:29.684: INFO: Waiting for pod downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:46:29.720: INFO: Pod downwardapi-volume-887d7f1d-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:46:29.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4fvcf" for this suite.
Jan 22 01:46:35.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:46:35.894: INFO: namespace: e2e-tests-projected-4fvcf, resource: bindings, ignored listing per whitelist
Jan 22 01:46:36.022: INFO: namespace e2e-tests-projected-4fvcf deletion completed in 6.289493819s

â€¢ [SLOW TEST:8.663 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:46:36.022: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rzbjq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:46:36.297: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-rzbjq" to be "success or failure"
Jan 22 01:46:36.302: INFO: Pod "downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.792441ms
Jan 22 01:46:38.307: INFO: Pod "downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.010631328s
Jan 22 01:46:40.314: INFO: Pod "downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016775762s
STEP: Saw pod success
Jan 22 01:46:40.314: INFO: Pod "downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:46:40.319: INFO: Trying to get logs from node 10.191.28.14 pod downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:46:40.355: INFO: Waiting for pod downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:46:40.359: INFO: Pod downwardapi-volume-8da98392-1de7-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:46:40.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rzbjq" for this suite.
Jan 22 01:46:46.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:46:46.486: INFO: namespace: e2e-tests-downward-api-rzbjq, resource: bindings, ignored listing per whitelist
Jan 22 01:46:46.629: INFO: namespace e2e-tests-downward-api-rzbjq deletion completed in 6.259091785s

â€¢ [SLOW TEST:10.607 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:46:46.632: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-qz4nz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-qz4nz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qz4nz to expose endpoints map[]
Jan 22 01:46:46.923: INFO: Get endpoints failed (8.571559ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 22 01:46:47.934: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qz4nz exposes endpoints map[] (1.020040684s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-qz4nz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qz4nz to expose endpoints map[pod1:[100]]
Jan 22 01:46:50.054: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qz4nz exposes endpoints map[pod1:[100]] (2.107616393s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-qz4nz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qz4nz to expose endpoints map[pod1:[100] pod2:[101]]
Jan 22 01:46:52.162: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qz4nz exposes endpoints map[pod1:[100] pod2:[101]] (2.098007618s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-qz4nz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qz4nz to expose endpoints map[pod2:[101]]
Jan 22 01:46:53.196: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qz4nz exposes endpoints map[pod2:[101]] (1.024098803s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-qz4nz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qz4nz to expose endpoints map[]
Jan 22 01:46:53.231: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qz4nz exposes endpoints map[] (25.412009ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:46:53.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qz4nz" for this suite.
Jan 22 01:47:15.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:47:15.446: INFO: namespace: e2e-tests-services-qz4nz, resource: bindings, ignored listing per whitelist
Jan 22 01:47:15.540: INFO: namespace e2e-tests-services-qz4nz deletion completed in 22.246616261s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

â€¢ [SLOW TEST:28.909 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:47:15.542: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-f8xbb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
STEP: creating an rc
Jan 22 01:47:15.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-f8xbb'
Jan 22 01:47:16.033: INFO: stderr: ""
Jan 22 01:47:16.033: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Waiting for Redis master to start.
Jan 22 01:47:17.039: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:47:17.039: INFO: Found 0 / 1
Jan 22 01:47:18.039: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:47:18.039: INFO: Found 1 / 1
Jan 22 01:47:18.039: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 22 01:47:18.048: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:47:18.048: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 22 01:47:18.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 logs redis-master-b9d4w redis-master --namespace=e2e-tests-kubectl-f8xbb'
Jan 22 01:47:18.181: INFO: stderr: ""
Jan 22 01:47:18.181: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Jan 01:47:17.097 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Jan 01:47:17.097 # Server started, Redis version 3.2.12\n1:M 22 Jan 01:47:17.097 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Jan 01:47:17.097 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 22 01:47:18.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 log redis-master-b9d4w redis-master --namespace=e2e-tests-kubectl-f8xbb --tail=1'
Jan 22 01:47:18.363: INFO: stderr: ""
Jan 22 01:47:18.363: INFO: stdout: "1:M 22 Jan 01:47:17.097 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 22 01:47:18.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 log redis-master-b9d4w redis-master --namespace=e2e-tests-kubectl-f8xbb --limit-bytes=1'
Jan 22 01:47:18.505: INFO: stderr: ""
Jan 22 01:47:18.505: INFO: stdout: " "
STEP: exposing timestamps
Jan 22 01:47:18.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 log redis-master-b9d4w redis-master --namespace=e2e-tests-kubectl-f8xbb --tail=1 --timestamps'
Jan 22 01:47:18.642: INFO: stderr: ""
Jan 22 01:47:18.642: INFO: stdout: "2019-01-22T01:47:17.097481733Z 1:M 22 Jan 01:47:17.097 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 22 01:47:21.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 log redis-master-b9d4w redis-master --namespace=e2e-tests-kubectl-f8xbb --since=1s'
Jan 22 01:47:21.354: INFO: stderr: ""
Jan 22 01:47:21.354: INFO: stdout: ""
Jan 22 01:47:21.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 log redis-master-b9d4w redis-master --namespace=e2e-tests-kubectl-f8xbb --since=24h'
Jan 22 01:47:21.529: INFO: stderr: ""
Jan 22 01:47:21.529: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Jan 01:47:17.097 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Jan 01:47:17.097 # Server started, Redis version 3.2.12\n1:M 22 Jan 01:47:17.097 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Jan 01:47:17.097 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
STEP: using delete to clean up resources
Jan 22 01:47:21.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f8xbb'
Jan 22 01:47:21.661: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 01:47:21.661: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 22 01:47:21.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-f8xbb'
Jan 22 01:47:21.814: INFO: stderr: "No resources found.\n"
Jan 22 01:47:21.815: INFO: stdout: ""
Jan 22 01:47:21.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 get pods -l name=nginx --namespace=e2e-tests-kubectl-f8xbb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 01:47:21.936: INFO: stderr: ""
Jan 22 01:47:21.936: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:47:21.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f8xbb" for this suite.
Jan 22 01:47:28.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:47:28.210: INFO: namespace: e2e-tests-kubectl-f8xbb, resource: bindings, ignored listing per whitelist
Jan 22 01:47:28.231: INFO: namespace e2e-tests-kubectl-f8xbb deletion completed in 6.28093668s

â€¢ [SLOW TEST:12.690 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:47:28.233: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-j7t2w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-j7t2w
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-j7t2w
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-j7t2w
Jan 22 01:47:28.532: INFO: Found 0 stateful pods, waiting for 1
Jan 22 01:47:38.540: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 22 01:47:38.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:47:38.922: INFO: stderr: ""
Jan 22 01:47:38.922: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:47:38.922: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:47:38.928: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 22 01:47:48.935: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:47:48.935: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:47:49.035: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998886s
Jan 22 01:47:50.041: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994452813s
Jan 22 01:47:51.048: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987643511s
Jan 22 01:47:52.055: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.981578045s
Jan 22 01:47:53.061: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974448147s
Jan 22 01:47:54.067: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.968518098s
Jan 22 01:47:55.073: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.962381123s
Jan 22 01:47:56.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.955920407s
Jan 22 01:47:57.086: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.949373439s
Jan 22 01:47:58.092: INFO: Verifying statefulset ss doesn't scale past 1 for another 943.044272ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-j7t2w
Jan 22 01:47:59.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:47:59.427: INFO: stderr: ""
Jan 22 01:47:59.427: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 01:47:59.427: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 01:47:59.432: INFO: Found 1 stateful pods, waiting for 3
Jan 22 01:48:09.439: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:48:09.439: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 01:48:09.439: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 22 01:48:09.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:48:09.846: INFO: stderr: ""
Jan 22 01:48:09.846: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:48:09.846: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:48:09.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:48:10.333: INFO: stderr: ""
Jan 22 01:48:10.333: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:48:10.333: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:48:10.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 01:48:10.646: INFO: stderr: ""
Jan 22 01:48:10.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 01:48:10.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 01:48:10.646: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:48:10.654: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan 22 01:48:20.668: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:48:20.668: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:48:20.668: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 01:48:20.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998892s
Jan 22 01:48:21.698: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994681903s
Jan 22 01:48:22.705: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987616726s
Jan 22 01:48:23.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981059379s
Jan 22 01:48:24.719: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.973807357s
Jan 22 01:48:25.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967144448s
Jan 22 01:48:26.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960543028s
Jan 22 01:48:27.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954455814s
Jan 22 01:48:28.746: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.945919957s
Jan 22 01:48:29.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.3398ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-j7t2w
Jan 22 01:48:30.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:48:31.183: INFO: stderr: ""
Jan 22 01:48:31.183: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 01:48:31.183: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 01:48:31.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:48:31.573: INFO: stderr: ""
Jan 22 01:48:31.573: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 01:48:31.573: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 01:48:31.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:48:31.932: INFO: rc: 1
Jan 22 01:48:31.932: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "0cac15043122d69a5bfe1d7220b313e45f8d9c6de803873fe2528d2a3e28b046": OCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused "process_linux.go:86: executing setns process caused \"exit status 21\"": unknown
 [] <nil> 0xc42141ec30 exit status 1 <nil> <nil> true [0xc421bda800 0xc421bda818 0xc421bda830] [0xc421bda800 0xc421bda818 0xc421bda830] [0xc421bda810 0xc421bda828] [0x8f9b60 0x8f9b60] 0xc421f07b60 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: failed to start exec "0cac15043122d69a5bfe1d7220b313e45f8d9c6de803873fe2528d2a3e28b046": OCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused "process_linux.go:86: executing setns process caused \"exit status 21\"": unknown

error:
exit status 1

Jan 22 01:48:41.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:48:42.054: INFO: rc: 1
Jan 22 01:48:42.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162510 exit status 1 <nil> <nil> true [0xc42000e110 0xc42000e150 0xc42000e1e8] [0xc42000e110 0xc42000e150 0xc42000e1e8] [0xc42000e128 0xc42000e1a8] [0x8f9b60 0x8f9b60] 0xc421ea80c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:48:52.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:48:52.175: INFO: rc: 1
Jan 22 01:48:52.176: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4221629f0 exit status 1 <nil> <nil> true [0xc42000e200 0xc42000e250 0xc42000e280] [0xc42000e200 0xc42000e250 0xc42000e280] [0xc42000e230 0xc42000e268] [0x8f9b60 0x8f9b60] 0xc421ea8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:49:02.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:49:02.300: INFO: rc: 1
Jan 22 01:49:02.300: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f85a0 exit status 1 <nil> <nil> true [0xc4200dddb0 0xc4200dde40 0xc4200ddf10] [0xc4200dddb0 0xc4200dde40 0xc4200ddf10] [0xc4200dde38 0xc4200dde88] [0x8f9b60 0x8f9b60] 0xc4211ea0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:49:12.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:49:12.438: INFO: rc: 1
Jan 22 01:49:12.438: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f8a20 exit status 1 <nil> <nil> true [0xc4200ddf48 0xc42034c008 0xc42034c108] [0xc4200ddf48 0xc42034c008 0xc42034c108] [0xc4200ddf98 0xc42034c0a8] [0x8f9b60 0x8f9b60] 0xc4211eb620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:49:22.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:49:22.560: INFO: rc: 1
Jan 22 01:49:22.560: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162e40 exit status 1 <nil> <nil> true [0xc42000e2a8 0xc42000e390 0xc42000e3d0] [0xc42000e2a8 0xc42000e390 0xc42000e3d0] [0xc42000e2f8 0xc42000e3c8] [0x8f9b60 0x8f9b60] 0xc421ea8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:49:32.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:49:32.745: INFO: rc: 1
Jan 22 01:49:32.745: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f8e70 exit status 1 <nil> <nil> true [0xc42034c1e0 0xc42034c518 0xc42034c768] [0xc42034c1e0 0xc42034c518 0xc42034c768] [0xc42034c440 0xc42034c6b0] [0x8f9b60 0x8f9b60] 0xc4211eba40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:49:42.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:49:42.874: INFO: rc: 1
Jan 22 01:49:42.874: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422163260 exit status 1 <nil> <nil> true [0xc42000e3d8 0xc42000e3f0 0xc42000e408] [0xc42000e3d8 0xc42000e3f0 0xc42000e408] [0xc42000e3e8 0xc42000e400] [0x8f9b60 0x8f9b60] 0xc421ea8780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:49:52.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:49:53.038: INFO: rc: 1
Jan 22 01:49:53.038: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f9230 exit status 1 <nil> <nil> true [0xc42034c7a8 0xc42034c7d8 0xc42034c828] [0xc42034c7a8 0xc42034c7d8 0xc42034c828] [0xc42034c7d0 0xc42034c808] [0x8f9b60 0x8f9b60] 0xc4211ebda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:50:03.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:50:03.153: INFO: rc: 1
Jan 22 01:50:03.154: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422163650 exit status 1 <nil> <nil> true [0xc42000e410 0xc42000e448 0xc42000e460] [0xc42000e410 0xc42000e448 0xc42000e460] [0xc42000e440 0xc42000e458] [0x8f9b60 0x8f9b60] 0xc421ea89c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:50:13.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:50:13.308: INFO: rc: 1
Jan 22 01:50:13.308: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422163a10 exit status 1 <nil> <nil> true [0xc42000e478 0xc42000e4b8 0xc42000e4d8] [0xc42000e478 0xc42000e4b8 0xc42000e4d8] [0xc42000e4a8 0xc42000e4d0] [0x8f9b60 0x8f9b60] 0xc421ea8b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:50:23.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:50:23.413: INFO: rc: 1
Jan 22 01:50:23.414: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422163dd0 exit status 1 <nil> <nil> true [0xc42000e4e0 0xc42000e520 0xc42000f6a0] [0xc42000e4e0 0xc42000e520 0xc42000f6a0] [0xc42000e4f8 0xc42000f690] [0x8f9b60 0x8f9b60] 0xc421ea8e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:50:33.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:50:33.554: INFO: rc: 1
Jan 22 01:50:33.554: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4210561b0 exit status 1 <nil> <nil> true [0xc42000f6a8 0xc42000f6e0 0xc42000f720] [0xc42000f6a8 0xc42000f6e0 0xc42000f720] [0xc42000f6d8 0xc42000f700] [0x8f9b60 0x8f9b60] 0xc421ea8fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:50:43.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:50:43.713: INFO: rc: 1
Jan 22 01:50:43.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162540 exit status 1 <nil> <nil> true [0xc4200dde08 0xc4200dde58 0xc4200ddf48] [0xc4200dde08 0xc4200dde58 0xc4200ddf48] [0xc4200dde40 0xc4200ddf10] [0x8f9b60 0x8f9b60] 0xc4211ea0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:50:53.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:50:53.849: INFO: rc: 1
Jan 22 01:50:53.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f85d0 exit status 1 <nil> <nil> true [0xc42034c008 0xc42034c108 0xc42034c440] [0xc42034c008 0xc42034c108 0xc42034c440] [0xc42034c0a8 0xc42034c420] [0x8f9b60 0x8f9b60] 0xc421ea80c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:51:03.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:51:03.979: INFO: rc: 1
Jan 22 01:51:03.979: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f8ab0 exit status 1 <nil> <nil> true [0xc42034c518 0xc42034c768 0xc42034c7d0] [0xc42034c518 0xc42034c768 0xc42034c7d0] [0xc42034c6b0 0xc42034c7c0] [0x8f9b60 0x8f9b60] 0xc421ea8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:51:13.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:51:14.128: INFO: rc: 1
Jan 22 01:51:14.128: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f8ed0 exit status 1 <nil> <nil> true [0xc42034c7d8 0xc42034c828 0xc42034c8d0] [0xc42034c7d8 0xc42034c828 0xc42034c8d0] [0xc42034c808 0xc42034c898] [0x8f9b60 0x8f9b60] 0xc421ea8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:51:24.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:51:24.271: INFO: rc: 1
Jan 22 01:51:24.271: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f92c0 exit status 1 <nil> <nil> true [0xc42034c938 0xc42034cab0 0xc42034cb50] [0xc42034c938 0xc42034cab0 0xc42034cb50] [0xc42034ca60 0xc42034cb20] [0x8f9b60 0x8f9b60] 0xc421ea8780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:51:34.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:51:34.398: INFO: rc: 1
Jan 22 01:51:34.398: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f96e0 exit status 1 <nil> <nil> true [0xc42034cb70 0xc42034cc18 0xc42034cca8] [0xc42034cb70 0xc42034cc18 0xc42034cca8] [0xc42034cbe8 0xc42034cca0] [0x8f9b60 0x8f9b60] 0xc421ea89c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:51:44.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:51:44.622: INFO: rc: 1
Jan 22 01:51:44.622: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162a50 exit status 1 <nil> <nil> true [0xc4200ddf68 0xc42000e110 0xc42000e150] [0xc4200ddf68 0xc42000e110 0xc42000e150] [0xc42000e0c8 0xc42000e128] [0x8f9b60 0x8f9b60] 0xc4211eb620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:51:54.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:51:54.733: INFO: rc: 1
Jan 22 01:51:54.733: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f9aa0 exit status 1 <nil> <nil> true [0xc42034cce0 0xc42034cdd8 0xc42034cdf8] [0xc42034cce0 0xc42034cdd8 0xc42034cdf8] [0xc42034cdc8 0xc42034cdf0] [0x8f9b60 0x8f9b60] 0xc421ea8b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:52:04.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:52:04.897: INFO: rc: 1
Jan 22 01:52:04.898: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f9e60 exit status 1 <nil> <nil> true [0xc42034ce10 0xc42034ced8 0xc42034cf78] [0xc42034ce10 0xc42034ced8 0xc42034cf78] [0xc42034ce98 0xc42034cf58] [0x8f9b60 0x8f9b60] 0xc421ea8e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:52:14.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:52:15.019: INFO: rc: 1
Jan 22 01:52:15.019: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162f00 exit status 1 <nil> <nil> true [0xc42000e170 0xc42000e200 0xc42000e250] [0xc42000e170 0xc42000e200 0xc42000e250] [0xc42000e1e8 0xc42000e230] [0x8f9b60 0x8f9b60] 0xc4211eba40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:52:25.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:52:25.142: INFO: rc: 1
Jan 22 01:52:25.142: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422163350 exit status 1 <nil> <nil> true [0xc42000e260 0xc42000e2a8 0xc42000e390] [0xc42000e260 0xc42000e2a8 0xc42000e390] [0xc42000e280 0xc42000e2f8] [0x8f9b60 0x8f9b60] 0xc4211ebda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:52:35.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:52:35.283: INFO: rc: 1
Jan 22 01:52:35.284: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422163740 exit status 1 <nil> <nil> true [0xc42000e3b0 0xc42000e3d8 0xc42000e3f0] [0xc42000e3b0 0xc42000e3d8 0xc42000e3f0] [0xc42000e3d0 0xc42000e3e8] [0x8f9b60 0x8f9b60] 0xc421d781e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:52:45.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:52:45.409: INFO: rc: 1
Jan 22 01:52:45.409: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f85a0 exit status 1 <nil> <nil> true [0xc4200dde08 0xc4200dde58 0xc4200ddf48] [0xc4200dde08 0xc4200dde58 0xc4200ddf48] [0xc4200dde40 0xc4200ddf10] [0x8f9b60 0x8f9b60] 0xc4211ea000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:52:55.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:52:55.521: INFO: rc: 1
Jan 22 01:52:55.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162510 exit status 1 <nil> <nil> true [0xc42034c008 0xc42034c108 0xc42034c440] [0xc42034c008 0xc42034c108 0xc42034c440] [0xc42034c0a8 0xc42034c420] [0x8f9b60 0x8f9b60] 0xc421ea8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:53:05.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:53:05.643: INFO: rc: 1
Jan 22 01:53:05.643: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162a20 exit status 1 <nil> <nil> true [0xc42034c518 0xc42034c768 0xc42034c7d0] [0xc42034c518 0xc42034c768 0xc42034c7d0] [0xc42034c6b0 0xc42034c7c0] [0x8f9b60 0x8f9b60] 0xc421ea8360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:53:15.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:53:15.758: INFO: rc: 1
Jan 22 01:53:15.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4220f8a80 exit status 1 <nil> <nil> true [0xc4200ddf68 0xc42000e110 0xc42000e150] [0xc4200ddf68 0xc42000e110 0xc42000e150] [0xc42000e0c8 0xc42000e128] [0x8f9b60 0x8f9b60] 0xc4211eb560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:53:25.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:53:25.941: INFO: rc: 1
Jan 22 01:53:25.941: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422162ed0 exit status 1 <nil> <nil> true [0xc42034c7d8 0xc42034c828 0xc42034c8d0] [0xc42034c7d8 0xc42034c828 0xc42034c8d0] [0xc42034c808 0xc42034c898] [0x8f9b60 0x8f9b60] 0xc421ea85a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 01:53:35.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 exec --namespace=e2e-tests-statefulset-j7t2w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 01:53:36.076: INFO: rc: 1
Jan 22 01:53:36.076: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jan 22 01:53:36.076: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jan 22 01:53:36.098: INFO: Deleting all statefulset in ns e2e-tests-statefulset-j7t2w
Jan 22 01:53:36.105: INFO: Scaling statefulset ss to 0
Jan 22 01:53:36.126: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:53:36.133: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:53:36.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-j7t2w" for this suite.
Jan 22 01:53:42.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:53:42.379: INFO: namespace: e2e-tests-statefulset-j7t2w, resource: bindings, ignored listing per whitelist
Jan 22 01:53:42.428: INFO: namespace e2e-tests-statefulset-j7t2w deletion completed in 6.252727329s

â€¢ [SLOW TEST:374.196 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:53:42.429: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-n27wq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 22 01:53:42.718: INFO: Waiting up to 5m0s for pod "pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-n27wq" to be "success or failure"
Jan 22 01:53:42.727: INFO: Pod "pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.582824ms
Jan 22 01:53:44.733: INFO: Pod "pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015683576s
STEP: Saw pod success
Jan 22 01:53:44.733: INFO: Pod "pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:53:44.739: INFO: Trying to get logs from node 10.191.28.14 pod pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:53:44.777: INFO: Waiting for pod pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:53:44.782: INFO: Pod pod-8bd418f4-1de8-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:53:44.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n27wq" for this suite.
Jan 22 01:53:50.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:53:50.964: INFO: namespace: e2e-tests-emptydir-n27wq, resource: bindings, ignored listing per whitelist
Jan 22 01:53:51.135: INFO: namespace e2e-tests-emptydir-n27wq deletion completed in 6.342016202s

â€¢ [SLOW TEST:8.706 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:53:51.136: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-592nh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 22 01:53:51.400: INFO: Waiting up to 5m0s for pod "pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-592nh" to be "success or failure"
Jan 22 01:53:51.405: INFO: Pod "pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.204735ms
Jan 22 01:53:53.411: INFO: Pod "pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011047402s
STEP: Saw pod success
Jan 22 01:53:53.411: INFO: Pod "pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:53:53.416: INFO: Trying to get logs from node 10.191.28.14 pod pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:53:53.456: INFO: Waiting for pod pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:53:53.520: INFO: Pod pod-9100ddc9-1de8-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:53:53.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-592nh" for this suite.
Jan 22 01:53:59.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:53:59.775: INFO: namespace: e2e-tests-emptydir-592nh, resource: bindings, ignored listing per whitelist
Jan 22 01:53:59.856: INFO: namespace e2e-tests-emptydir-592nh deletion completed in 6.323279379s

â€¢ [SLOW TEST:8.720 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:53:59.856: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2bvx5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:54:00.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 version --client'
Jan 22 01:54:00.194: INFO: stderr: ""
Jan 22 01:54:00.194: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 22 01:54:00.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-2bvx5'
Jan 22 01:54:00.557: INFO: stderr: ""
Jan 22 01:54:00.557: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 22 01:54:00.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 create -f - --namespace=e2e-tests-kubectl-2bvx5'
Jan 22 01:54:00.771: INFO: stderr: ""
Jan 22 01:54:00.771: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 22 01:54:01.777: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:54:01.777: INFO: Found 0 / 1
Jan 22 01:54:02.777: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:54:02.777: INFO: Found 1 / 1
Jan 22 01:54:02.777: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 22 01:54:02.782: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 01:54:02.783: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 22 01:54:02.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 describe pod redis-master-4tthp --namespace=e2e-tests-kubectl-2bvx5'
Jan 22 01:54:02.946: INFO: stderr: ""
Jan 22 01:54:02.946: INFO: stdout: "Name:               redis-master-4tthp\nNamespace:          e2e-tests-kubectl-2bvx5\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.191.28.14/10.191.28.14\nStart Time:         Tue, 22 Jan 2019 01:54:00 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp=e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.27.217\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://f455ca592bd469a91a8cca0fcf8ca98d537ab7a474b58abfc8013a4ad3483d92\n    Image:          gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis-amd64@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 22 Jan 2019 01:54:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-bb2z5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-bb2z5:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-bb2z5\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  2s    default-scheduler      Successfully assigned e2e-tests-kubectl-2bvx5/redis-master-4tthp to 10.191.28.14\n  Normal  Pulled     1s    kubelet, 10.191.28.14  Container image \"gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.191.28.14  Created container\n  Normal  Started    1s    kubelet, 10.191.28.14  Started container\n"
Jan 22 01:54:02.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 describe rc redis-master --namespace=e2e-tests-kubectl-2bvx5'
Jan 22 01:54:03.151: INFO: stderr: ""
Jan 22 01:54:03.151: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-2bvx5\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-4tthp\n"
Jan 22 01:54:03.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 describe service redis-master --namespace=e2e-tests-kubectl-2bvx5'
Jan 22 01:54:03.361: INFO: stderr: ""
Jan 22 01:54:03.361: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-2bvx5\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.90.86\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.27.217:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 22 01:54:03.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 describe node 10.191.28.14'
Jan 22 01:54:03.564: INFO: stderr: ""
Jan 22 01:54:03.564: INFO: stdout: "Name:               10.191.28.14\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=u2c.2x4.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=u2c.2x4.encrypted\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=0b5c16297bbf4bbfa9fb2cacc25c67cf-fe22b5c\n                    ibm-cloud.kubernetes.io/worker-version=1.11.6_1540\n                    kubernetes.io/hostname=10.191.28.14\n                    privateVLAN=2530551\n                    publicVLAN=2530549\nAnnotations:        node.alpha.kubernetes.io/ttl=0\n                    volumes.kubernetes.io/controller-managed-attach-detach=true\nCreationTimestamp:  Mon, 21 Jan 2019 19:04:23 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 22 Jan 2019 01:53:58 +0000   Mon, 21 Jan 2019 19:04:23 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 22 Jan 2019 01:53:58 +0000   Mon, 21 Jan 2019 19:04:23 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 22 Jan 2019 01:53:58 +0000   Mon, 21 Jan 2019 19:04:23 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 22 Jan 2019 01:53:58 +0000   Mon, 21 Jan 2019 19:04:23 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 22 Jan 2019 01:53:58 +0000   Mon, 21 Jan 2019 19:04:43 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.191.28.14\n  ExternalIP:  169.61.92.171\n  Hostname:    10.191.28.14\nCapacity:\n cpu:                2\n ephemeral-storage:  103079200Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             4041600Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  100275445682\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3535744Ki\n pods:               110\nSystem Info:\n Machine ID:                 266c2075dace453da02500b328c9e325\n System UUID:                C9E9C686-1F8B-FFFC-30AB-0423AFA32A66\n Boot ID:                    7c6b7f46-c97b-4b68-98c5-fec3cf734b0f\n Kernel Version:             4.4.0-141-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.5\n Kubelet Version:            v1.11.6+IKS\n Kube-Proxy Version:         v1.11.6+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///0b5c16297bbf4bbfa9fb2cacc25c67cf/kube-wdc07-cr0b5c16297bbf4bbfa9fb2cacc25c67cf-w2\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-2bvx5    redis-master-4tthp                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d5cecaed80dc4fff-229zh    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-kube-controllers-5d496bb754-hxbr6                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-knwhb                                          250m (13%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                ibm-file-plugin-5f6f89cc66-wm2bv                           50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                ibm-keepalived-watcher-c6qjp                               0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                ibm-kube-fluentd-s6x85                                     25m (1%)      300m (15%)  50Mi (1%)        800M (22%)\n  kube-system                ibm-master-proxy-static-10.191.28.14                       25m (1%)      300m (15%)  32M (0%)         512M (14%)\n  kube-system                ibm-storage-watcher-785496b956-24q6x                       50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                kube-dns-amd64-74d5cf9648-srzhn                            260m (13%)    0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                kube-dns-autoscaler-7d4745b6b-kpbmp                        20m (1%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kubernetes-dashboard-7b545fbb4d-jtwpf                      0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                vpn-6bff56d46f-p84d6                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests        Limits\n  --------  --------        ------\n  cpu       680m (35%)      1 (52%)\n  memory    410130Ki (11%)  1490257920 (41%)\nEvents:     <none>\n"
Jan 22 01:54:03.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 describe namespace e2e-tests-kubectl-2bvx5'
Jan 22 01:54:03.709: INFO: stderr: ""
Jan 22 01:54:03.709: INFO: stdout: "Name:         e2e-tests-kubectl-2bvx5\nLabels:       e2e-framework=kubectl\n              e2e-run=2a6595ff-1dde-11e9-8691-1e7d95aa6bfc\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:54:03.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2bvx5" for this suite.
Jan 22 01:54:19.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:54:19.871: INFO: namespace: e2e-tests-kubectl-2bvx5, resource: bindings, ignored listing per whitelist
Jan 22 01:54:20.295: INFO: namespace e2e-tests-kubectl-2bvx5 deletion completed in 16.574890031s

â€¢ [SLOW TEST:20.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:54:20.295: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-jl9k2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 22 01:54:20.639: INFO: Number of nodes with available pods: 0
Jan 22 01:54:20.639: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:54:21.656: INFO: Number of nodes with available pods: 1
Jan 22 01:54:21.656: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:54:22.659: INFO: Number of nodes with available pods: 3
Jan 22 01:54:22.659: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 22 01:54:22.759: INFO: Number of nodes with available pods: 2
Jan 22 01:54:22.759: INFO: Node 10.191.28.15 is running more than one daemon pod
Jan 22 01:54:23.827: INFO: Number of nodes with available pods: 2
Jan 22 01:54:23.827: INFO: Node 10.191.28.15 is running more than one daemon pod
Jan 22 01:54:24.777: INFO: Number of nodes with available pods: 2
Jan 22 01:54:24.777: INFO: Node 10.191.28.15 is running more than one daemon pod
Jan 22 01:54:25.784: INFO: Number of nodes with available pods: 2
Jan 22 01:54:25.784: INFO: Node 10.191.28.15 is running more than one daemon pod
Jan 22 01:54:26.777: INFO: Number of nodes with available pods: 3
Jan 22 01:54:26.777: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-jl9k2, will wait for the garbage collector to delete the pods
Jan 22 01:54:26.853: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.561546ms
Jan 22 01:54:26.953: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.201908ms
Jan 22 01:54:39.625: INFO: Number of nodes with available pods: 0
Jan 22 01:54:39.625: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 01:54:39.632: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jl9k2/daemonsets","resourceVersion":"79793"},"items":null}

Jan 22 01:54:39.637: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jl9k2/pods","resourceVersion":"79793"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:54:39.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jl9k2" for this suite.
Jan 22 01:54:47.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:54:47.741: INFO: namespace: e2e-tests-daemonsets-jl9k2, resource: bindings, ignored listing per whitelist
Jan 22 01:54:47.970: INFO: namespace e2e-tests-daemonsets-jl9k2 deletion completed in 8.286506846s

â€¢ [SLOW TEST:27.675 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:54:47.972: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-n2rsd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-n2rsd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 01:54:48.233: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 01:55:10.372: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.27.223:8080/dial?request=hostName&protocol=http&host=172.30.118.132&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-n2rsd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:55:10.372: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:55:10.630: INFO: Waiting for endpoints: map[]
Jan 22 01:55:10.636: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.27.223:8080/dial?request=hostName&protocol=http&host=172.30.27.221&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-n2rsd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:55:10.636: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:55:10.886: INFO: Waiting for endpoints: map[]
Jan 22 01:55:10.925: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.27.223:8080/dial?request=hostName&protocol=http&host=172.30.171.215&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-n2rsd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 01:55:10.925: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
Jan 22 01:55:11.168: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:55:11.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-n2rsd" for this suite.
Jan 22 01:55:35.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:55:35.475: INFO: namespace: e2e-tests-pod-network-test-n2rsd, resource: bindings, ignored listing per whitelist
Jan 22 01:55:35.522: INFO: namespace e2e-tests-pod-network-test-n2rsd deletion completed in 24.342338126s

â€¢ [SLOW TEST:47.550 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:55:35.522: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-z8ff9
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 22 01:55:35.786: INFO: Waiting up to 5m0s for pod "pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-z8ff9" to be "success or failure"
Jan 22 01:55:35.794: INFO: Pod "pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.044826ms
Jan 22 01:55:37.806: INFO: Pod "pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019333394s
STEP: Saw pod success
Jan 22 01:55:37.806: INFO: Pod "pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:55:37.810: INFO: Trying to get logs from node 10.191.28.14 pod pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:55:37.846: INFO: Waiting for pod pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:55:37.920: INFO: Pod pod-cf38f47a-1de8-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:55:37.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z8ff9" for this suite.
Jan 22 01:55:43.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:55:44.097: INFO: namespace: e2e-tests-emptydir-z8ff9, resource: bindings, ignored listing per whitelist
Jan 22 01:55:44.170: INFO: namespace e2e-tests-emptydir-z8ff9 deletion completed in 6.239290393s

â€¢ [SLOW TEST:8.647 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:55:44.173: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wcthj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:55:44.437: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-wcthj" to be "success or failure"
Jan 22 01:55:44.525: INFO: Pod "downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 87.691961ms
Jan 22 01:55:46.531: INFO: Pod "downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093399775s
Jan 22 01:55:48.537: INFO: Pod "downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.099281957s
STEP: Saw pod success
Jan 22 01:55:48.537: INFO: Pod "downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:55:48.543: INFO: Trying to get logs from node 10.191.28.26 pod downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:55:48.620: INFO: Waiting for pod downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:55:48.626: INFO: Pod downwardapi-volume-d461208b-1de8-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:55:48.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wcthj" for this suite.
Jan 22 01:55:54.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:55:55.003: INFO: namespace: e2e-tests-downward-api-wcthj, resource: bindings, ignored listing per whitelist
Jan 22 01:55:55.032: INFO: namespace e2e-tests-downward-api-wcthj deletion completed in 6.393588516s

â€¢ [SLOW TEST:10.860 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:55:55.032: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-v6h7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 22 01:55:55.356: INFO: Number of nodes with available pods: 0
Jan 22 01:55:55.356: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:55:56.373: INFO: Number of nodes with available pods: 0
Jan 22 01:55:56.373: INFO: Node 10.191.28.14 is running more than one daemon pod
Jan 22 01:55:57.420: INFO: Number of nodes with available pods: 3
Jan 22 01:55:57.420: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 22 01:55:57.460: INFO: Number of nodes with available pods: 2
Jan 22 01:55:57.460: INFO: Node 10.191.28.26 is running more than one daemon pod
Jan 22 01:55:58.479: INFO: Number of nodes with available pods: 2
Jan 22 01:55:58.479: INFO: Node 10.191.28.26 is running more than one daemon pod
Jan 22 01:55:59.520: INFO: Number of nodes with available pods: 2
Jan 22 01:55:59.520: INFO: Node 10.191.28.26 is running more than one daemon pod
Jan 22 01:56:00.520: INFO: Number of nodes with available pods: 3
Jan 22 01:56:00.520: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-v6h7r, will wait for the garbage collector to delete the pods
Jan 22 01:56:00.602: INFO: Deleting {extensions DaemonSet} daemon-set took: 13.060786ms
Jan 22 01:56:00.702: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.198689ms
Jan 22 01:56:07.509: INFO: Number of nodes with available pods: 0
Jan 22 01:56:07.509: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 01:56:07.516: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-v6h7r/daemonsets","resourceVersion":"80280"},"items":null}

Jan 22 01:56:07.521: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-v6h7r/pods","resourceVersion":"80280"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:56:07.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-v6h7r" for this suite.
Jan 22 01:56:13.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:56:13.655: INFO: namespace: e2e-tests-daemonsets-v6h7r, resource: bindings, ignored listing per whitelist
Jan 22 01:56:13.802: INFO: namespace e2e-tests-daemonsets-v6h7r deletion completed in 6.233091094s

â€¢ [SLOW TEST:18.770 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:56:13.804: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-djhvh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
Jan 22 01:56:14.132: INFO: Waiting up to 5m0s for pod "var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-var-expansion-djhvh" to be "success or failure"
Jan 22 01:56:14.141: INFO: Pod "var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.581068ms
Jan 22 01:56:16.147: INFO: Pod "var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.014457851s
Jan 22 01:56:18.153: INFO: Pod "var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02066323s
STEP: Saw pod success
Jan 22 01:56:18.153: INFO: Pod "var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:56:18.158: INFO: Trying to get logs from node 10.191.28.14 pod var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc container dapi-container: <nil>
STEP: delete the pod
Jan 22 01:56:18.239: INFO: Waiting for pod var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:56:18.244: INFO: Pod var-expansion-e60b4962-1de8-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:56:18.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-djhvh" for this suite.
Jan 22 01:56:24.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:56:24.376: INFO: namespace: e2e-tests-var-expansion-djhvh, resource: bindings, ignored listing per whitelist
Jan 22 01:56:24.533: INFO: namespace e2e-tests-var-expansion-djhvh deletion completed in 6.275474038s

â€¢ [SLOW TEST:10.729 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:56:24.533: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8rrz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Jan 22 01:56:24.807: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-downward-api-8rrz4" to be "success or failure"
Jan 22 01:56:24.816: INFO: Pod "downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.093364ms
Jan 22 01:56:26.823: INFO: Pod "downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015338699s
STEP: Saw pod success
Jan 22 01:56:26.823: INFO: Pod "downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:56:26.828: INFO: Trying to get logs from node 10.191.28.26 pod downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc container client-container: <nil>
STEP: delete the pod
Jan 22 01:56:26.937: INFO: Waiting for pod downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:56:26.941: INFO: Pod downwardapi-volume-ec70fd53-1de8-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:56:26.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8rrz4" for this suite.
Jan 22 01:56:32.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:56:33.102: INFO: namespace: e2e-tests-downward-api-8rrz4, resource: bindings, ignored listing per whitelist
Jan 22 01:56:33.234: INFO: namespace e2e-tests-downward-api-8rrz4 deletion completed in 6.282423555s

â€¢ [SLOW TEST:8.701 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:56:33.234: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-xfcc2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Jan 22 01:56:33.509: INFO: (0) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.432447ms)
Jan 22 01:56:33.525: INFO: (1) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.178055ms)
Jan 22 01:56:33.540: INFO: (2) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.427359ms)
Jan 22 01:56:33.555: INFO: (3) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.304674ms)
Jan 22 01:56:33.568: INFO: (4) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.511877ms)
Jan 22 01:56:33.581: INFO: (5) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.879457ms)
Jan 22 01:56:33.593: INFO: (6) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.906255ms)
Jan 22 01:56:33.608: INFO: (7) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.40431ms)
Jan 22 01:56:33.620: INFO: (8) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.844901ms)
Jan 22 01:56:33.636: INFO: (9) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.116992ms)
Jan 22 01:56:33.648: INFO: (10) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.444743ms)
Jan 22 01:56:33.661: INFO: (11) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.123016ms)
Jan 22 01:56:33.673: INFO: (12) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.642145ms)
Jan 22 01:56:33.685: INFO: (13) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.421966ms)
Jan 22 01:56:33.696: INFO: (14) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.254301ms)
Jan 22 01:56:33.710: INFO: (15) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.11716ms)
Jan 22 01:56:33.722: INFO: (16) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.898265ms)
Jan 22 01:56:33.735: INFO: (17) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.347261ms)
Jan 22 01:56:33.747: INFO: (18) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.325867ms)
Jan 22 01:56:33.762: INFO: (19) /api/v1/nodes/10.191.28.14:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.448832ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:56:33.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xfcc2" for this suite.
Jan 22 01:56:39.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:56:39.990: INFO: namespace: e2e-tests-proxy-xfcc2, resource: bindings, ignored listing per whitelist
Jan 22 01:56:40.022: INFO: namespace e2e-tests-proxy-xfcc2 deletion completed in 6.250729764s

â€¢ [SLOW TEST:6.788 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:56:40.022: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-69lzb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0122 01:56:50.394337      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 01:56:50.394: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:56:50.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-69lzb" for this suite.
Jan 22 01:56:56.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:56:56.584: INFO: namespace: e2e-tests-gc-69lzb, resource: bindings, ignored listing per whitelist
Jan 22 01:56:56.721: INFO: namespace e2e-tests-gc-69lzb deletion completed in 6.291149186s

â€¢ [SLOW TEST:16.699 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:56:56.723: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-k9vfn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
Jan 22 01:57:23.012: INFO: Pod pod-hostip-ffa026f1-1de8-11e9-8691-1e7d95aa6bfc has hostIP: 10.191.28.14
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:57:23.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-k9vfn" for this suite.
Jan 22 01:57:45.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:57:45.224: INFO: namespace: e2e-tests-pods-k9vfn, resource: bindings, ignored listing per whitelist
Jan 22 01:57:45.425: INFO: namespace e2e-tests-pods-k9vfn deletion completed in 22.397036568s

â€¢ [SLOW TEST:48.703 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:57:45.427: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kvjcg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 22 01:57:45.712: INFO: Waiting up to 5m0s for pod "pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-kvjcg" to be "success or failure"
Jan 22 01:57:45.719: INFO: Pod "pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.501213ms
Jan 22 01:57:47.724: INFO: Pod "pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011700261s
STEP: Saw pod success
Jan 22 01:57:47.724: INFO: Pod "pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:57:47.728: INFO: Trying to get logs from node 10.191.28.14 pod pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:57:47.768: INFO: Waiting for pod pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:57:47.780: INFO: Pod pod-1caa34f1-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:57:47.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kvjcg" for this suite.
Jan 22 01:57:53.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:57:54.052: INFO: namespace: e2e-tests-emptydir-kvjcg, resource: bindings, ignored listing per whitelist
Jan 22 01:57:54.138: INFO: namespace e2e-tests-emptydir-kvjcg deletion completed in 6.341835684s

â€¢ [SLOW TEST:8.711 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:57:54.138: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lmwfx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-21d6f6bf-1de9-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:57:54.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-lmwfx" to be "success or failure"
Jan 22 01:57:54.448: INFO: Pod "pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.08669ms
Jan 22 01:57:56.454: INFO: Pod "pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011070725s
STEP: Saw pod success
Jan 22 01:57:56.454: INFO: Pod "pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:57:56.459: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:57:56.520: INFO: Waiting for pod pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:57:56.525: INFO: Pod pod-configmaps-21de1de3-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:57:56.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lmwfx" for this suite.
Jan 22 01:58:02.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:58:02.719: INFO: namespace: e2e-tests-configmap-lmwfx, resource: bindings, ignored listing per whitelist
Jan 22 01:58:02.827: INFO: namespace e2e-tests-configmap-lmwfx deletion completed in 6.290866461s

â€¢ [SLOW TEST:8.689 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:58:02.829: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qjqfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-27082285-1de9-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:58:03.113: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-qjqfw" to be "success or failure"
Jan 22 01:58:03.121: INFO: Pod "pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.369587ms
Jan 22 01:58:05.126: INFO: Pod "pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013818193s
STEP: Saw pod success
Jan 22 01:58:05.127: INFO: Pod "pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:58:05.132: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:58:05.165: INFO: Waiting for pod pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:58:05.169: INFO: Pod pod-projected-configmaps-27092582-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:58:05.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qjqfw" for this suite.
Jan 22 01:58:11.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:58:11.399: INFO: namespace: e2e-tests-projected-qjqfw, resource: bindings, ignored listing per whitelist
Jan 22 01:58:11.531: INFO: namespace e2e-tests-projected-qjqfw deletion completed in 6.297988348s

â€¢ [SLOW TEST:8.702 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:58:11.531: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-zztfq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-2c356a5c-1de9-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:58:11.799: INFO: Waiting up to 5m0s for pod "pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-secrets-zztfq" to be "success or failure"
Jan 22 01:58:11.804: INFO: Pod "pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.915708ms
Jan 22 01:58:13.810: INFO: Pod "pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011060609s
Jan 22 01:58:15.816: INFO: Pod "pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016867589s
STEP: Saw pod success
Jan 22 01:58:15.816: INFO: Pod "pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:58:15.822: INFO: Trying to get logs from node 10.191.28.14 pod pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:58:15.856: INFO: Waiting for pod pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:58:15.861: INFO: Pod pod-secrets-2c36e45f-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:58:15.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zztfq" for this suite.
Jan 22 01:58:21.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:58:22.095: INFO: namespace: e2e-tests-secrets-zztfq, resource: bindings, ignored listing per whitelist
Jan 22 01:58:22.132: INFO: namespace e2e-tests-secrets-zztfq deletion completed in 6.259167959s

â€¢ [SLOW TEST:10.601 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:58:22.132: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qjkzg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Jan 22 01:58:22.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-qjkzg'
Jan 22 01:58:22.583: INFO: stderr: ""
Jan 22 01:58:22.583: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 22 01:58:24.602: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-swltl]
Jan 22 01:58:24.602: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-swltl" in namespace "e2e-tests-kubectl-qjkzg" to be "running and ready"
Jan 22 01:58:24.608: INFO: Pod "e2e-test-nginx-rc-swltl": Phase="Running", Reason="", readiness=true. Elapsed: 5.295719ms
Jan 22 01:58:24.608: INFO: Pod "e2e-test-nginx-rc-swltl" satisfied condition "running and ready"
Jan 22 01:58:24.608: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-swltl]
Jan 22 01:58:24.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qjkzg'
Jan 22 01:58:24.789: INFO: stderr: ""
Jan 22 01:58:24.789: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
Jan 22 01:58:24.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059299132 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qjkzg'
Jan 22 01:58:24.934: INFO: stderr: ""
Jan 22 01:58:24.934: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:58:24.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qjkzg" for this suite.
Jan 22 01:58:30.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:58:31.108: INFO: namespace: e2e-tests-kubectl-qjkzg, resource: bindings, ignored listing per whitelist
Jan 22 01:58:31.225: INFO: namespace e2e-tests-kubectl-qjkzg deletion completed in 6.278557312s

â€¢ [SLOW TEST:9.093 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:58:31.226: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h5gqn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-37f2e9d8-1de9-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume secrets
Jan 22 01:58:31.498: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-projected-h5gqn" to be "success or failure"
Jan 22 01:58:31.510: INFO: Pod "pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.281407ms
Jan 22 01:58:33.518: INFO: Pod "pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020031319s
STEP: Saw pod success
Jan 22 01:58:33.518: INFO: Pod "pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:58:33.527: INFO: Trying to get logs from node 10.191.28.14 pod pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 01:58:33.620: INFO: Waiting for pod pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:58:33.626: INFO: Pod pod-projected-secrets-37f465aa-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:58:33.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h5gqn" for this suite.
Jan 22 01:58:39.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:58:39.895: INFO: namespace: e2e-tests-projected-h5gqn, resource: bindings, ignored listing per whitelist
Jan 22 01:58:39.918: INFO: namespace e2e-tests-projected-h5gqn deletion completed in 6.282211555s

â€¢ [SLOW TEST:8.692 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:58:39.920: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4vvhl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 22 01:58:40.189: INFO: Waiting up to 5m0s for pod "pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-emptydir-4vvhl" to be "success or failure"
Jan 22 01:58:40.194: INFO: Pod "pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.25453ms
Jan 22 01:58:42.201: INFO: Pod "pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012077634s
STEP: Saw pod success
Jan 22 01:58:42.201: INFO: Pod "pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:58:42.206: INFO: Trying to get logs from node 10.191.28.14 pod pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc container test-container: <nil>
STEP: delete the pod
Jan 22 01:58:42.240: INFO: Waiting for pod pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:58:42.320: INFO: Pod pod-3d221f0a-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:58:42.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4vvhl" for this suite.
Jan 22 01:58:48.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:58:48.495: INFO: namespace: e2e-tests-emptydir-4vvhl, resource: bindings, ignored listing per whitelist
Jan 22 01:58:48.650: INFO: namespace e2e-tests-emptydir-4vvhl deletion completed in 6.31720535s

â€¢ [SLOW TEST:8.731 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:58:48.652: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-qdqxg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 22 01:58:50.945: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-4256784a-1de9-11e9-8691-1e7d95aa6bfc", GenerateName:"", Namespace:"e2e-tests-pods-qdqxg", SelfLink:"/api/v1/namespaces/e2e-tests-pods-qdqxg/pods/pod-submit-remove-4256784a-1de9-11e9-8691-1e7d95aa6bfc", UID:"42585300-1de9-11e9-b13b-16990c636477", ResourceVersion:"81055", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683719128, loc:(*time.Location)(0x642e6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"905945843"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tt5vt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4220f4180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tt5vt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421fbcdf8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.191.28.14", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422737980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421fbce40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421fbce60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421fbce68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683719128, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683719130, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683719128, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.191.28.14", PodIP:"172.30.27.232", StartTime:(*v1.Time)(0xc4219b1ac0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4219b1ae0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"containerd://aee6eeacf61590282081a0ec85b6bf0c1c9adfa90397062bbc46b297372ba718"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:58:57.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qdqxg" for this suite.
Jan 22 01:59:03.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:59:03.435: INFO: namespace: e2e-tests-pods-qdqxg, resource: bindings, ignored listing per whitelist
Jan 22 01:59:03.477: INFO: namespace e2e-tests-pods-qdqxg deletion completed in 6.245820258s

â€¢ [SLOW TEST:14.826 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:59:03.477: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-nn9gb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-nn9gb
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-nn9gb
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-nn9gb
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-nn9gb
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-nn9gb
Jan 22 01:59:05.871: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-nn9gb, name: ss-0, uid: 4c19125f-1de9-11e9-b13b-16990c636477, status phase: Pending. Waiting for statefulset controller to delete.
Jan 22 01:59:06.665: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-nn9gb, name: ss-0, uid: 4c19125f-1de9-11e9-b13b-16990c636477, status phase: Failed. Waiting for statefulset controller to delete.
Jan 22 01:59:06.674: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-nn9gb, name: ss-0, uid: 4c19125f-1de9-11e9-b13b-16990c636477, status phase: Failed. Waiting for statefulset controller to delete.
Jan 22 01:59:06.681: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-nn9gb
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-nn9gb
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-nn9gb and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Jan 22 01:59:10.716: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nn9gb
Jan 22 01:59:10.723: INFO: Scaling statefulset ss to 0
Jan 22 01:59:20.755: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 01:59:20.764: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:59:20.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nn9gb" for this suite.
Jan 22 01:59:26.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:59:27.126: INFO: namespace: e2e-tests-statefulset-nn9gb, resource: bindings, ignored listing per whitelist
Jan 22 01:59:27.128: INFO: namespace e2e-tests-statefulset-nn9gb deletion completed in 6.307935573s

â€¢ [SLOW TEST:23.651 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Jan 22 01:59:27.129: INFO: >>> kubeConfig: /tmp/kubeconfig-059299132
STEP: Building a namespace api object
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8p4jz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-59480986-1de9-11e9-8691-1e7d95aa6bfc
STEP: Creating a pod to test consume configMaps
Jan 22 01:59:27.416: INFO: Waiting up to 5m0s for pod "pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc" in namespace "e2e-tests-configmap-8p4jz" to be "success or failure"
Jan 22 01:59:27.420: INFO: Pod "pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.4981ms
Jan 22 01:59:29.427: INFO: Pod "pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010765931s
Jan 22 01:59:31.432: INFO: Pod "pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016398736s
Jan 22 01:59:33.438: INFO: Pod "pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022438646s
STEP: Saw pod success
Jan 22 01:59:33.438: INFO: Pod "pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc" satisfied condition "success or failure"
Jan 22 01:59:33.443: INFO: Trying to get logs from node 10.191.28.14 pod pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 01:59:33.481: INFO: Waiting for pod pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc to disappear
Jan 22 01:59:33.520: INFO: Pod pod-configmaps-5948fa20-1de9-11e9-8691-1e7d95aa6bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Jan 22 01:59:33.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8p4jz" for this suite.
Jan 22 01:59:41.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 01:59:41.582: INFO: namespace: e2e-tests-configmap-8p4jz, resource: bindings, ignored listing per whitelist
Jan 22 01:59:41.780: INFO: namespace e2e-tests-configmap-8p4jz deletion completed in 8.248907546s

â€¢ [SLOW TEST:14.651 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSJan 22 01:59:41.781: INFO: Running AfterSuite actions on all node
Jan 22 01:59:41.781: INFO: Running AfterSuite actions on node 1
Jan 22 01:59:41.781: INFO: Skipping dumping logs from cluster

Ran 165 of 996 Specs in 4817.092 seconds
SUCCESS! -- 165 Passed | 0 Failed | 0 Pending | 831 Skipped PASS

Ginkgo ran 1 suite in 1h20m17.632502878s
Test Suite Passed
