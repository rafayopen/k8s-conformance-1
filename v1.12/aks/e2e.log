Jan 22 18:24:49.974: INFO: Overriding default scale value of zero to 1
Jan 22 18:24:49.974: INFO: Overriding default milliseconds value of zero to 5000
I0122 18:24:50.487678      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-545960299
I0122 18:24:50.487752      15 e2e.go:304] Starting e2e run "00fe3434-1e73-11e9-9ccc-2ee9843eaab3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1548181489 - Will randomize all specs
Will run 188 of 1814 specs

Jan 22 18:24:50.655: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:24:51.084: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 22 18:24:51.128: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 22 18:24:51.157: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 22 18:24:51.157: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Jan 22 18:24:51.157: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 22 18:24:51.166: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jan 22 18:24:51.166: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-svc-redirect' (0 seconds elapsed)
Jan 22 18:24:51.166: INFO: e2e test version: v1.12.1
Jan 22 18:24:51.167: INFO: kube-apiserver version: v1.12.4
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:24:51.168: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
Jan 22 18:24:51.301: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 18:24:51.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gjhhn'
Jan 22 18:24:53.638: INFO: stderr: ""
Jan 22 18:24:53.638: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 22 18:25:03.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gjhhn -o json'
Jan 22 18:25:03.819: INFO: stderr: ""
Jan 22 18:25:03.819: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-22T18:24:53Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-gjhhn\",\n        \"resourceVersion\": \"2833\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-gjhhn/pods/e2e-test-nginx-pod\",\n        \"uid\": \"03420400-1e73-11e9-a380-de5a8a93737b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_PORT_443_TCP_ADDR\",\n                        \"value\": \"levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io\"\n                    },\n                    {\n                        \"name\": \"KUBERNETES_PORT\",\n                        \"value\": \"tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443\"\n                    },\n                    {\n                        \"name\": \"KUBERNETES_PORT_443_TCP\",\n                        \"value\": \"tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443\"\n                    },\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io\"\n                    }\n                ],\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gdhg6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"aks-nodepool1-25266157-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gdhg6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gdhg6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T18:24:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T18:24:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T18:24:59Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-22T18:24:53Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f68ebef16131564b4ccc7404c8d56378fb6d25d358e0247bd4d27023f263134e\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-22T18:24:59Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.240.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.3\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-22T18:24:53Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 22 18:25:03.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 replace -f - --namespace=e2e-tests-kubectl-gjhhn'
Jan 22 18:25:04.285: INFO: stderr: ""
Jan 22 18:25:04.285: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan 22 18:25:04.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gjhhn'
Jan 22 18:25:08.895: INFO: stderr: ""
Jan 22 18:25:08.895: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:25:08.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gjhhn" for this suite.
Jan 22 18:25:14.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:25:14.994: INFO: namespace: e2e-tests-kubectl-gjhhn, resource: bindings, ignored listing per whitelist
Jan 22 18:25:15.135: INFO: namespace e2e-tests-kubectl-gjhhn deletion completed in 6.233985692s

• [SLOW TEST:23.966 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:25:15.135: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 22 18:25:20.074: INFO: Successfully updated pod "labelsupdate10347a87-1e73-11e9-9ccc-2ee9843eaab3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:25:22.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mx4s7" for this suite.
Jan 22 18:25:44.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:25:44.227: INFO: namespace: e2e-tests-downward-api-mx4s7, resource: bindings, ignored listing per whitelist
Jan 22 18:25:44.357: INFO: namespace e2e-tests-downward-api-mx4s7 deletion completed in 22.170544122s

• [SLOW TEST:29.222 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:25:44.357: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 22 18:25:44.546: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8vs4z,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vs4z/configmaps/e2e-watch-test-watch-closed,UID:219a2949-1e73-11e9-a380-de5a8a93737b,ResourceVersion:2958,Generation:0,CreationTimestamp:2019-01-22 18:25:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 18:25:44.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8vs4z,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vs4z/configmaps/e2e-watch-test-watch-closed,UID:219a2949-1e73-11e9-a380-de5a8a93737b,ResourceVersion:2959,Generation:0,CreationTimestamp:2019-01-22 18:25:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 22 18:25:44.571: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8vs4z,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vs4z/configmaps/e2e-watch-test-watch-closed,UID:219a2949-1e73-11e9-a380-de5a8a93737b,ResourceVersion:2960,Generation:0,CreationTimestamp:2019-01-22 18:25:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 18:25:44.571: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8vs4z,SelfLink:/api/v1/namespaces/e2e-tests-watch-8vs4z/configmaps/e2e-watch-test-watch-closed,UID:219a2949-1e73-11e9-a380-de5a8a93737b,ResourceVersion:2961,Generation:0,CreationTimestamp:2019-01-22 18:25:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:25:44.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8vs4z" for this suite.
Jan 22 18:25:50.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:25:50.713: INFO: namespace: e2e-tests-watch-8vs4z, resource: bindings, ignored listing per whitelist
Jan 22 18:25:50.792: INFO: namespace e2e-tests-watch-8vs4z deletion completed in 6.215744875s

• [SLOW TEST:6.435 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:25:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-2568ea08-1e73-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 18:25:50.946: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-wcfk2" to be "success or failure"
Jan 22 18:25:50.958: INFO: Pod "pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.677615ms
Jan 22 18:25:53.047: INFO: Pod "pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1005005s
Jan 22 18:25:55.052: INFO: Pod "pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105648905s
STEP: Saw pod success
Jan 22 18:25:55.052: INFO: Pod "pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:25:55.055: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 18:25:55.136: INFO: Waiting for pod pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:25:55.139: INFO: Pod pod-projected-secrets-256a2611-1e73-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:25:55.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wcfk2" for this suite.
Jan 22 18:26:01.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:26:01.240: INFO: namespace: e2e-tests-projected-wcfk2, resource: bindings, ignored listing per whitelist
Jan 22 18:26:01.353: INFO: namespace e2e-tests-projected-wcfk2 deletion completed in 6.199914971s

• [SLOW TEST:10.560 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:26:01.353: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 22 18:26:01.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:01.889: INFO: stderr: ""
Jan 22 18:26:01.889: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 18:26:01.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:02.028: INFO: stderr: ""
Jan 22 18:26:02.028: INFO: stdout: "update-demo-nautilus-4c46r update-demo-nautilus-rdrj8 "
Jan 22 18:26:02.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-4c46r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:02.166: INFO: stderr: ""
Jan 22 18:26:02.166: INFO: stdout: ""
Jan 22 18:26:02.166: INFO: update-demo-nautilus-4c46r is created but not running
Jan 22 18:26:07.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:07.293: INFO: stderr: ""
Jan 22 18:26:07.293: INFO: stdout: "update-demo-nautilus-4c46r update-demo-nautilus-rdrj8 "
Jan 22 18:26:07.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-4c46r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:07.420: INFO: stderr: ""
Jan 22 18:26:07.420: INFO: stdout: "true"
Jan 22 18:26:07.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-4c46r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:07.552: INFO: stderr: ""
Jan 22 18:26:07.552: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:26:07.552: INFO: validating pod update-demo-nautilus-4c46r
Jan 22 18:26:07.604: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:26:07.604: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:26:07.604: INFO: update-demo-nautilus-4c46r is verified up and running
Jan 22 18:26:07.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-rdrj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:07.755: INFO: stderr: ""
Jan 22 18:26:07.755: INFO: stdout: "true"
Jan 22 18:26:07.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-rdrj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:07.875: INFO: stderr: ""
Jan 22 18:26:07.875: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:26:07.875: INFO: validating pod update-demo-nautilus-rdrj8
Jan 22 18:26:07.924: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:26:07.924: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:26:07.925: INFO: update-demo-nautilus-rdrj8 is verified up and running
STEP: scaling down the replication controller
Jan 22 18:26:07.929: INFO: scanned /root for discovery docs: <nil>
Jan 22 18:26:07.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:09.127: INFO: stderr: ""
Jan 22 18:26:09.127: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 18:26:09.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:09.246: INFO: stderr: ""
Jan 22 18:26:09.247: INFO: stdout: "update-demo-nautilus-4c46r update-demo-nautilus-rdrj8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 22 18:26:14.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:14.374: INFO: stderr: ""
Jan 22 18:26:14.374: INFO: stdout: "update-demo-nautilus-4c46r update-demo-nautilus-rdrj8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 22 18:26:19.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:19.499: INFO: stderr: ""
Jan 22 18:26:19.499: INFO: stdout: "update-demo-nautilus-rdrj8 "
Jan 22 18:26:19.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-rdrj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:19.607: INFO: stderr: ""
Jan 22 18:26:19.607: INFO: stdout: "true"
Jan 22 18:26:19.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-rdrj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:19.727: INFO: stderr: ""
Jan 22 18:26:19.727: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:26:19.727: INFO: validating pod update-demo-nautilus-rdrj8
Jan 22 18:26:19.739: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:26:19.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:26:19.739: INFO: update-demo-nautilus-rdrj8 is verified up and running
STEP: scaling up the replication controller
Jan 22 18:26:19.741: INFO: scanned /root for discovery docs: <nil>
Jan 22 18:26:19.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:20.905: INFO: stderr: ""
Jan 22 18:26:20.905: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 18:26:20.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:21.035: INFO: stderr: ""
Jan 22 18:26:21.035: INFO: stdout: "update-demo-nautilus-k68p4 update-demo-nautilus-rdrj8 "
Jan 22 18:26:21.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-k68p4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:21.155: INFO: stderr: ""
Jan 22 18:26:21.155: INFO: stdout: ""
Jan 22 18:26:21.155: INFO: update-demo-nautilus-k68p4 is created but not running
Jan 22 18:26:26.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:26.292: INFO: stderr: ""
Jan 22 18:26:26.292: INFO: stdout: "update-demo-nautilus-k68p4 update-demo-nautilus-rdrj8 "
Jan 22 18:26:26.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-k68p4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:26.428: INFO: stderr: ""
Jan 22 18:26:26.428: INFO: stdout: "true"
Jan 22 18:26:26.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-k68p4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:26.542: INFO: stderr: ""
Jan 22 18:26:26.542: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:26:26.542: INFO: validating pod update-demo-nautilus-k68p4
Jan 22 18:26:26.600: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:26:26.600: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:26:26.600: INFO: update-demo-nautilus-k68p4 is verified up and running
Jan 22 18:26:26.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-rdrj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:26.720: INFO: stderr: ""
Jan 22 18:26:26.720: INFO: stdout: "true"
Jan 22 18:26:26.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-rdrj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:26.846: INFO: stderr: ""
Jan 22 18:26:26.846: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:26:26.846: INFO: validating pod update-demo-nautilus-rdrj8
Jan 22 18:26:26.854: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:26:26.854: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:26:26.854: INFO: update-demo-nautilus-rdrj8 is verified up and running
STEP: using delete to clean up resources
Jan 22 18:26:26.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:26.972: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:26:26.972: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 22 18:26:26.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-44vjr'
Jan 22 18:26:27.118: INFO: stderr: "No resources found.\n"
Jan 22 18:26:27.119: INFO: stdout: ""
Jan 22 18:26:27.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -l name=update-demo --namespace=e2e-tests-kubectl-44vjr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 18:26:27.251: INFO: stderr: ""
Jan 22 18:26:27.251: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:26:27.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-44vjr" for this suite.
Jan 22 18:26:33.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:26:33.306: INFO: namespace: e2e-tests-kubectl-44vjr, resource: bindings, ignored listing per whitelist
Jan 22 18:26:33.464: INFO: namespace e2e-tests-kubectl-44vjr deletion completed in 6.207410963s

• [SLOW TEST:32.111 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:26:33.464: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gh99k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 18:26:33.668: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 18:26:59.830: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.10:8080/dial?request=hostName&protocol=http&host=10.244.1.9&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-gh99k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 18:26:59.830: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:27:00.099: INFO: Waiting for endpoints: map[]
Jan 22 18:27:00.106: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.10:8080/dial?request=hostName&protocol=http&host=10.244.2.5&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-gh99k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 18:27:00.106: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:27:00.584: INFO: Waiting for endpoints: map[]
Jan 22 18:27:00.589: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.10:8080/dial?request=hostName&protocol=http&host=10.244.0.11&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-gh99k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 18:27:00.589: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:27:00.844: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:27:00.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gh99k" for this suite.
Jan 22 18:27:24.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:27:24.942: INFO: namespace: e2e-tests-pod-network-test-gh99k, resource: bindings, ignored listing per whitelist
Jan 22 18:27:25.057: INFO: namespace e2e-tests-pod-network-test-gh99k deletion completed in 24.207744613s

• [SLOW TEST:51.593 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:27:25.058: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Jan 22 18:27:34.570: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:27:51.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-w2hhb" for this suite.
Jan 22 18:27:57.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:27:57.425: INFO: namespace: e2e-tests-namespaces-w2hhb, resource: bindings, ignored listing per whitelist
Jan 22 18:27:57.543: INFO: namespace e2e-tests-namespaces-w2hhb deletion completed in 6.153514283s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vmlqb" for this suite.
Jan 22 18:27:57.546: INFO: Namespace e2e-tests-nsdeletetest-vmlqb was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-z5mvg" for this suite.
Jan 22 18:28:03.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:28:03.758: INFO: namespace: e2e-tests-nsdeletetest-z5mvg, resource: bindings, ignored listing per whitelist
Jan 22 18:28:03.789: INFO: namespace e2e-tests-nsdeletetest-z5mvg deletion completed in 6.242659789s

• [SLOW TEST:38.731 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:28:03.789: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 22 18:28:03.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 cluster-info'
Jan 22 18:28:04.095: INFO: stderr: ""
Jan 22 18:28:04.095: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443\x1b[0m\n\x1b[0;32maddon-http-application-routing-default-http-backend\x1b[0m is running at \x1b[0;33mhttps://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/addon-http-application-routing-default-http-backend/proxy\x1b[0m\n\x1b[0;32maddon-http-application-routing-nginx-ingress\x1b[0m is running at \x1b[0;33mhttp://52.175.226.225:80 http://52.175.226.225:443 \x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:28:04.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4tzhf" for this suite.
Jan 22 18:28:10.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:28:10.215: INFO: namespace: e2e-tests-kubectl-4tzhf, resource: bindings, ignored listing per whitelist
Jan 22 18:28:10.359: INFO: namespace e2e-tests-kubectl-4tzhf deletion completed in 6.257864432s

• [SLOW TEST:6.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:28:10.360: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:28:10.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-l47tr" to be "success or failure"
Jan 22 18:28:10.565: INFO: Pod "downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.424806ms
Jan 22 18:28:12.570: INFO: Pod "downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017040253s
Jan 22 18:28:14.576: INFO: Pod "downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023435298s
STEP: Saw pod success
Jan 22 18:28:14.576: INFO: Pod "downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:28:14.580: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:28:14.665: INFO: Waiting for pod downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:28:14.669: INFO: Pod downwardapi-volume-789f4bc4-1e73-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:28:14.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l47tr" for this suite.
Jan 22 18:28:20.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:28:20.784: INFO: namespace: e2e-tests-projected-l47tr, resource: bindings, ignored listing per whitelist
Jan 22 18:28:20.883: INFO: namespace e2e-tests-projected-l47tr deletion completed in 6.205022598s

• [SLOW TEST:10.524 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:28:20.885: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-647tp;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-647tp;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-647tp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-647tp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-647tp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 1.231.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.231.1_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 1.231.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.231.1_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-647tp;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-647tp;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-647tp.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-647tp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-647tp.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-647tp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-647tp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 1.231.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.231.1_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 1.231.0.10.in-addr.arpa. PTR)" && echo OK > /results/10.0.231.1_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 22 18:28:53.198: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.206: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.212: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-647tp from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.223: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-647tp from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.240: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.249: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.255: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.263: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.534: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.541: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.550: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-647tp from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.556: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-647tp from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.563: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.572: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.579: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.588: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc from pod e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3: the server could not find the requested resource (get pods dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3)
Jan 22 18:28:53.836: INFO: Lookups using e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-647tp wheezy_tcp@dns-test-service.e2e-tests-dns-647tp wheezy_udp@dns-test-service.e2e-tests-dns-647tp.svc wheezy_tcp@dns-test-service.e2e-tests-dns-647tp.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-647tp jessie_tcp@dns-test-service.e2e-tests-dns-647tp jessie_udp@dns-test-service.e2e-tests-dns-647tp.svc jessie_tcp@dns-test-service.e2e-tests-dns-647tp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-647tp.svc]

Jan 22 18:29:04.508: INFO: DNS probes using e2e-tests-dns-647tp/dns-test-7ee7e41c-1e73-11e9-9ccc-2ee9843eaab3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:29:04.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-647tp" for this suite.
Jan 22 18:29:10.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:29:10.665: INFO: namespace: e2e-tests-dns-647tp, resource: bindings, ignored listing per whitelist
Jan 22 18:29:10.811: INFO: namespace e2e-tests-dns-647tp deletion completed in 6.192524758s

• [SLOW TEST:49.927 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:29:10.812: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:29:10.981: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-gkfc5" to be "success or failure"
Jan 22 18:29:10.985: INFO: Pod "downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74032ms
Jan 22 18:29:12.989: INFO: Pod "downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007925789s
Jan 22 18:29:14.994: INFO: Pod "downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012687327s
STEP: Saw pod success
Jan 22 18:29:14.994: INFO: Pod "downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:29:14.998: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:29:15.066: INFO: Waiting for pod downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:29:15.073: INFO: Pod downwardapi-volume-9ca2c010-1e73-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:29:15.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gkfc5" for this suite.
Jan 22 18:29:21.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:29:21.292: INFO: namespace: e2e-tests-downward-api-gkfc5, resource: bindings, ignored listing per whitelist
Jan 22 18:29:21.309: INFO: namespace e2e-tests-downward-api-gkfc5 deletion completed in 6.223406153s

• [SLOW TEST:10.497 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:29:21.309: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-d25dz
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-d25dz
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-d25dz
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-d25dz
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-d25dz
Jan 22 18:29:29.557: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d25dz, name: ss-0, uid: a5fb36cd-1e73-11e9-a380-de5a8a93737b, status phase: Pending. Waiting for statefulset controller to delete.
Jan 22 18:29:35.947: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d25dz, name: ss-0, uid: a5fb36cd-1e73-11e9-a380-de5a8a93737b, status phase: Failed. Waiting for statefulset controller to delete.
Jan 22 18:29:35.977: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d25dz, name: ss-0, uid: a5fb36cd-1e73-11e9-a380-de5a8a93737b, status phase: Failed. Waiting for statefulset controller to delete.
Jan 22 18:29:35.985: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-d25dz
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-d25dz
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-d25dz and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 22 18:29:40.041: INFO: Deleting all statefulset in ns e2e-tests-statefulset-d25dz
Jan 22 18:29:40.045: INFO: Scaling statefulset ss to 0
Jan 22 18:29:50.077: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 18:29:50.081: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:29:50.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-d25dz" for this suite.
Jan 22 18:29:56.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:29:56.294: INFO: namespace: e2e-tests-statefulset-d25dz, resource: bindings, ignored listing per whitelist
Jan 22 18:29:56.356: INFO: namespace e2e-tests-statefulset-d25dz deletion completed in 6.24899243s

• [SLOW TEST:35.046 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:29:56.357: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-mhx6
STEP: Creating a pod to test atomic-volume-subpath
Jan 22 18:29:56.555: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mhx6" in namespace "e2e-tests-subpath-87wm9" to be "success or failure"
Jan 22 18:29:56.559: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.314104ms
Jan 22 18:29:58.564: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008132473s
Jan 22 18:30:00.569: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 4.013565121s
Jan 22 18:30:02.574: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 6.018590816s
Jan 22 18:30:04.578: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 8.022879648s
Jan 22 18:30:06.583: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 10.027103437s
Jan 22 18:30:08.587: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 12.031713298s
Jan 22 18:30:10.592: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 14.036020011s
Jan 22 18:30:12.625: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 16.069923008s
Jan 22 18:30:14.630: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 18.074322645s
Jan 22 18:30:16.638: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 20.082408159s
Jan 22 18:30:18.643: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Running", Reason="", readiness=false. Elapsed: 22.087565745s
Jan 22 18:30:20.650: INFO: Pod "pod-subpath-test-secret-mhx6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.094370443s
STEP: Saw pod success
Jan 22 18:30:20.650: INFO: Pod "pod-subpath-test-secret-mhx6" satisfied condition "success or failure"
Jan 22 18:30:20.653: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-subpath-test-secret-mhx6 container test-container-subpath-secret-mhx6: <nil>
STEP: delete the pod
Jan 22 18:30:20.731: INFO: Waiting for pod pod-subpath-test-secret-mhx6 to disappear
Jan 22 18:30:20.735: INFO: Pod pod-subpath-test-secret-mhx6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-mhx6
Jan 22 18:30:20.735: INFO: Deleting pod "pod-subpath-test-secret-mhx6" in namespace "e2e-tests-subpath-87wm9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:30:20.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-87wm9" for this suite.
Jan 22 18:30:26.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:30:26.923: INFO: namespace: e2e-tests-subpath-87wm9, resource: bindings, ignored listing per whitelist
Jan 22 18:30:26.978: INFO: namespace e2e-tests-subpath-87wm9 deletion completed in 6.233989794s

• [SLOW TEST:30.621 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:30:26.978: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ca244f48-1e73-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:30:27.330: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-k6g2p" to be "success or failure"
Jan 22 18:30:27.335: INFO: Pod "pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.765748ms
Jan 22 18:30:29.341: INFO: Pod "pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010834963s
Jan 22 18:30:31.346: INFO: Pod "pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015748107s
STEP: Saw pod success
Jan 22 18:30:31.346: INFO: Pod "pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:30:31.350: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 18:30:31.385: INFO: Waiting for pod pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:30:31.388: INFO: Pod pod-projected-configmaps-ca261c02-1e73-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:30:31.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k6g2p" for this suite.
Jan 22 18:30:37.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:30:37.562: INFO: namespace: e2e-tests-projected-k6g2p, resource: bindings, ignored listing per whitelist
Jan 22 18:30:37.628: INFO: namespace e2e-tests-projected-k6g2p deletion completed in 6.234102899s

• [SLOW TEST:10.651 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:30:37.629: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8j8dn
Jan 22 18:30:39.844: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8j8dn
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 18:30:39.847: INFO: Initial restart count of pod liveness-exec is 0
Jan 22 18:31:25.985: INFO: Restart count of pod e2e-tests-container-probe-8j8dn/liveness-exec is now 1 (46.13808695s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:31:26.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8j8dn" for this suite.
Jan 22 18:31:32.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:31:32.113: INFO: namespace: e2e-tests-container-probe-8j8dn, resource: bindings, ignored listing per whitelist
Jan 22 18:31:32.212: INFO: namespace e2e-tests-container-probe-8j8dn deletion completed in 6.201934113s

• [SLOW TEST:54.583 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:31:32.213: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f0ebfca4-1e73-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 18:31:32.382: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-bfqz8" to be "success or failure"
Jan 22 18:31:32.388: INFO: Pod "pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21709ms
Jan 22 18:31:34.393: INFO: Pod "pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010780217s
Jan 22 18:31:36.401: INFO: Pod "pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01904753s
STEP: Saw pod success
Jan 22 18:31:36.401: INFO: Pod "pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:31:36.404: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 18:31:36.443: INFO: Waiting for pod pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:31:36.447: INFO: Pod pod-projected-secrets-f0ed2445-1e73-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:31:36.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bfqz8" for this suite.
Jan 22 18:31:42.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:31:42.485: INFO: namespace: e2e-tests-projected-bfqz8, resource: bindings, ignored listing per whitelist
Jan 22 18:31:42.601: INFO: namespace e2e-tests-projected-bfqz8 deletion completed in 6.149463464s

• [SLOW TEST:10.388 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:31:42.601: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-8mzgt
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-8mzgt
STEP: Deleting pre-stop pod
Jan 22 18:31:57.901: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:31:57.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-8mzgt" for this suite.
Jan 22 18:32:35.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:32:36.094: INFO: namespace: e2e-tests-prestop-8mzgt, resource: bindings, ignored listing per whitelist
Jan 22 18:32:36.094: INFO: namespace e2e-tests-prestop-8mzgt deletion completed in 38.174932458s

• [SLOW TEST:53.494 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:32:36.095: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:32:36.263: INFO: Creating ReplicaSet my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3
Jan 22 18:32:36.280: INFO: Pod name my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3: Found 0 pods out of 1
Jan 22 18:32:41.289: INFO: Pod name my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3: Found 1 pods out of 1
Jan 22 18:32:41.289: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3" is running
Jan 22 18:32:41.294: INFO: Pod "my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3-pwmn5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 18:32:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 18:32:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 18:32:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 18:32:36 +0000 UTC Reason: Message:}])
Jan 22 18:32:41.294: INFO: Trying to dial the pod
Jan 22 18:32:46.381: INFO: Controller my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3: Got expected result from replica 1 [my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3-pwmn5]: "my-hostname-basic-17032978-1e74-11e9-9ccc-2ee9843eaab3-pwmn5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:32:46.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2fc95" for this suite.
Jan 22 18:32:52.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:32:52.558: INFO: namespace: e2e-tests-replicaset-2fc95, resource: bindings, ignored listing per whitelist
Jan 22 18:32:52.589: INFO: namespace e2e-tests-replicaset-2fc95 deletion completed in 6.203847325s

• [SLOW TEST:16.495 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:32:52.589: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 22 18:32:52.743: INFO: PodSpec: initContainers in spec.initContainers
Jan 22 18:33:36.419: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-20d5c620-1e74-11e9-9ccc-2ee9843eaab3", GenerateName:"", Namespace:"e2e-tests-init-container-ldc8v", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-ldc8v/pods/pod-init-20d5c620-1e74-11e9-9ccc-2ee9843eaab3", UID:"20d7434a-1e74-11e9-a380-de5a8a93737b", ResourceVersion:"4447", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683778772, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"743148883"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-65cwj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420ea2780), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-65cwj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-65cwj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_PORT_443_TCP_ADDR", Value:"levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"KUBERNETES_PORT", Value:"tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"KUBERNETES_PORT_443_TCP", Value:"tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-65cwj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4211fcbd8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"aks-nodepool1-25266157-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42145a180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4211fcc50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4211fcc70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4211fcc78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683778772, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683778772, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683778772, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683778772, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.4", PodIP:"10.244.1.23", StartTime:(*v1.Time)(0xc422087720), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421bdf500)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421bdf5e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://d9e7d68d9938e3444d69afd0611ea47c86cb074c419346157962aa4f7cac6045"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc422087760), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc422087740), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:33:36.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ldc8v" for this suite.
Jan 22 18:33:58.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:33:58.489: INFO: namespace: e2e-tests-init-container-ldc8v, resource: bindings, ignored listing per whitelist
Jan 22 18:33:58.582: INFO: namespace e2e-tests-init-container-ldc8v deletion completed in 22.153752186s

• [SLOW TEST:65.993 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:33:58.582: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 22 18:33:58.767: INFO: Waiting up to 5m0s for pod "pod-482df104-1e74-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-9l8s9" to be "success or failure"
Jan 22 18:33:58.786: INFO: Pod "pod-482df104-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 19.413277ms
Jan 22 18:34:00.791: INFO: Pod "pod-482df104-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024444655s
Jan 22 18:34:02.797: INFO: Pod "pod-482df104-1e74-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030056334s
STEP: Saw pod success
Jan 22 18:34:02.797: INFO: Pod "pod-482df104-1e74-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:34:02.804: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-482df104-1e74-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 18:34:02.837: INFO: Waiting for pod pod-482df104-1e74-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:34:02.841: INFO: Pod pod-482df104-1e74-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:34:02.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9l8s9" for this suite.
Jan 22 18:34:08.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:34:08.991: INFO: namespace: e2e-tests-emptydir-9l8s9, resource: bindings, ignored listing per whitelist
Jan 22 18:34:08.991: INFO: namespace e2e-tests-emptydir-9l8s9 deletion completed in 6.144859842s

• [SLOW TEST:10.409 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:34:08.991: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:34:09.134: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-q5djp" to be "success or failure"
Jan 22 18:34:09.138: INFO: Pod "downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.746611ms
Jan 22 18:34:11.227: INFO: Pod "downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.092381089s
STEP: Saw pod success
Jan 22 18:34:11.227: INFO: Pod "downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:34:11.231: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:34:11.275: INFO: Waiting for pod downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:34:11.279: INFO: Pod downwardapi-volume-4e5b5222-1e74-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:34:11.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q5djp" for this suite.
Jan 22 18:34:17.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:34:17.464: INFO: namespace: e2e-tests-downward-api-q5djp, resource: bindings, ignored listing per whitelist
Jan 22 18:34:17.511: INFO: namespace e2e-tests-downward-api-q5djp deletion completed in 6.22667357s

• [SLOW TEST:8.520 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:34:17.511: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0122 18:34:27.719006      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 18:34:27.719: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:34:27.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ztkdw" for this suite.
Jan 22 18:34:33.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:34:33.815: INFO: namespace: e2e-tests-gc-ztkdw, resource: bindings, ignored listing per whitelist
Jan 22 18:34:33.952: INFO: namespace e2e-tests-gc-ztkdw deletion completed in 6.229313078s

• [SLOW TEST:16.441 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:34:33.952: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 22 18:34:34.176: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-mrj9v,SelfLink:/api/v1/namespaces/e2e-tests-watch-mrj9v/configmaps/e2e-watch-test-resource-version,UID:5d457ca8-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4651,Generation:0,CreationTimestamp:2019-01-22 18:34:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 18:34:34.176: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-mrj9v,SelfLink:/api/v1/namespaces/e2e-tests-watch-mrj9v/configmaps/e2e-watch-test-resource-version,UID:5d457ca8-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4652,Generation:0,CreationTimestamp:2019-01-22 18:34:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:34:34.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mrj9v" for this suite.
Jan 22 18:34:40.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:34:40.308: INFO: namespace: e2e-tests-watch-mrj9v, resource: bindings, ignored listing per whitelist
Jan 22 18:34:40.396: INFO: namespace e2e-tests-watch-mrj9v deletion completed in 6.215675137s

• [SLOW TEST:6.444 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:34:40.396: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:34:40.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jbhgk" for this suite.
Jan 22 18:35:02.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:35:02.774: INFO: namespace: e2e-tests-pods-jbhgk, resource: bindings, ignored listing per whitelist
Jan 22 18:35:02.787: INFO: namespace e2e-tests-pods-jbhgk deletion completed in 22.196636538s

• [SLOW TEST:22.391 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:35:02.788: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:35:02.946: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-c87gq" to be "success or failure"
Jan 22 18:35:02.950: INFO: Pod "downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535504ms
Jan 22 18:35:04.955: INFO: Pod "downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008347326s
Jan 22 18:35:06.959: INFO: Pod "downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012550317s
STEP: Saw pod success
Jan 22 18:35:06.959: INFO: Pod "downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:35:06.963: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:35:07.010: INFO: Waiting for pod downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:35:07.014: INFO: Pod downwardapi-volume-6e6e209e-1e74-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:35:07.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c87gq" for this suite.
Jan 22 18:35:13.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:35:13.102: INFO: namespace: e2e-tests-downward-api-c87gq, resource: bindings, ignored listing per whitelist
Jan 22 18:35:13.214: INFO: namespace e2e-tests-downward-api-c87gq deletion completed in 6.194806468s

• [SLOW TEST:10.427 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:35:13.214: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:35:13.353: INFO: Creating deployment "nginx-deployment"
Jan 22 18:35:13.361: INFO: Waiting for observed generation 1
Jan 22 18:35:15.378: INFO: Waiting for all required pods to come up
Jan 22 18:35:15.384: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 22 18:35:17.413: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 22 18:35:17.421: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 22 18:35:17.435: INFO: Updating deployment nginx-deployment
Jan 22 18:35:17.435: INFO: Waiting for observed generation 2
Jan 22 18:35:19.451: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 22 18:35:19.454: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 22 18:35:19.458: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 22 18:35:19.472: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 22 18:35:19.472: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 22 18:35:19.476: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 22 18:35:19.483: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 22 18:35:19.483: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 22 18:35:19.497: INFO: Updating deployment nginx-deployment
Jan 22 18:35:19.497: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 22 18:35:19.508: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 22 18:35:19.521: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 22 18:35:19.573: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-djnsp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-djnsp/deployments/nginx-deployment,UID:74a5cbc6-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4963,Generation:3,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-01-22 18:35:17 +0000 UTC 2019-01-22 18:35:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-01-22 18:35:19 +0000 UTC 2019-01-22 18:35:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 22 18:35:19.625: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-djnsp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-djnsp/replicasets/nginx-deployment-7dc8f79789,UID:7714b120-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4954,Generation:3,CreationTimestamp:2019-01-22 18:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 74a5cbc6-1e74-11e9-a380-de5a8a93737b 0xc421325197 0xc421325198}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 22 18:35:19.625: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 22 18:35:19.625: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-djnsp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-djnsp/replicasets/nginx-deployment-7f9675fb8b,UID:74a93834-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4953,Generation:3,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 74a5cbc6-1e74-11e9-a380-de5a8a93737b 0xc4213252d7 0xc4213252d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 22 18:35:19.727: INFO: Pod "nginx-deployment-7dc8f79789-4lk47" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4lk47,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-4lk47,UID:7718b4eb-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4912,Generation:0,CreationTimestamp:2019-01-22 18:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc0e0 0xc4211fc0e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc2a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-01-22 18:35:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.727: INFO: Pod "nginx-deployment-7dc8f79789-7mb8z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7mb8z,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-7mb8z,UID:785589f4-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4978,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc360 0xc4211fc361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc3e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.728: INFO: Pod "nginx-deployment-7dc8f79789-9dt4k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9dt4k,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-9dt4k,UID:785b52aa-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4982,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc480 0xc4211fc481}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.728: INFO: Pod "nginx-deployment-7dc8f79789-g59t6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-g59t6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-g59t6,UID:771b4505-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4918,Generation:0,CreationTimestamp:2019-01-22 18:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc577 0xc4211fc578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:,StartTime:2019-01-22 18:35:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.728: INFO: Pod "nginx-deployment-7dc8f79789-jjgpm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jjgpm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-jjgpm,UID:785ae1f9-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4979,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc6d0 0xc4211fc6d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.728: INFO: Pod "nginx-deployment-7dc8f79789-jzzwb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jzzwb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-jzzwb,UID:77308224-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4939,Generation:0,CreationTimestamp:2019-01-22 18:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc7c7 0xc4211fc7c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-01-22 18:35:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.728: INFO: Pod "nginx-deployment-7dc8f79789-mnnvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mnnvv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-mnnvv,UID:771b4872-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4921,Generation:0,CreationTimestamp:2019-01-22 18:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fc920 0xc4211fc921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fc9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fc9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2019-01-22 18:35:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.729: INFO: Pod "nginx-deployment-7dc8f79789-ql495" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ql495,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-ql495,UID:772e3543-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4937,Generation:0,CreationTimestamp:2019-01-22 18:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fca80 0xc4211fca81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fcb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fcb20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:,StartTime:2019-01-22 18:35:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.729: INFO: Pod "nginx-deployment-7dc8f79789-rrxnk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rrxnk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-rrxnk,UID:7852adc8-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4965,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fcbe0 0xc4211fcbe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fcc60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fcc80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.729: INFO: Pod "nginx-deployment-7dc8f79789-v8zmk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-v8zmk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-v8zmk,UID:78554728-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4976,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fccf0 0xc4211fccf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fcd70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fcd90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.729: INFO: Pod "nginx-deployment-7dc8f79789-xsppx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xsppx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-xsppx,UID:785b578c-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4981,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fce00 0xc4211fce01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fce80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fcea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.729: INFO: Pod "nginx-deployment-7dc8f79789-zwvx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zwvx5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7dc8f79789-zwvx5,UID:785af4dc-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4980,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 7714b120-1e74-11e9-a380-de5a8a93737b 0xc4211fcef7 0xc4211fcef8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fcf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fcf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.729: INFO: Pod "nginx-deployment-7f9675fb8b-4h6g8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4h6g8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-4h6g8,UID:78534481-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4968,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fcfe7 0xc4211fcfe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.730: INFO: Pod "nginx-deployment-7f9675fb8b-655m9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-655m9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-655m9,UID:74c2d47c-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4853,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd0f0 0xc4211fd0f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.0.15,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f6bafa98e271c639e77ab27068baa2d01515f23533512650607b16d125c6c82d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.730: INFO: Pod "nginx-deployment-7f9675fb8b-9lqx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9lqx9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-9lqx9,UID:7857c532-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4974,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd240 0xc4211fd241}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.730: INFO: Pod "nginx-deployment-7f9675fb8b-9z492" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9z492,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-9z492,UID:78536fbf-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4970,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd327 0xc4211fd328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.730: INFO: Pod "nginx-deployment-7f9675fb8b-dlzcp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dlzcp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-dlzcp,UID:7850f8a5-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4962,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd430 0xc4211fd431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.730: INFO: Pod "nginx-deployment-7f9675fb8b-f7n8s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f7n8s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-f7n8s,UID:74bc0228-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4875,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd530 0xc4211fd531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.8,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://de187c3a3260242754c0578dd89e5a62258ba0f89a8bee430d8d78cca579275c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.730: INFO: Pod "nginx-deployment-7f9675fb8b-ghc7s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ghc7s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-ghc7s,UID:74c2d9d7-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4881,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd680 0xc4211fd681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.9,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://2396f71428a32673636322d536ed81d6d22d4bb5539885f368f9cdfeff39e1bc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.731: INFO: Pod "nginx-deployment-7f9675fb8b-jfk5k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jfk5k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-jfk5k,UID:7857c359-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4973,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd7d0 0xc4211fd7d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.731: INFO: Pod "nginx-deployment-7f9675fb8b-ktvq8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ktvq8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-ktvq8,UID:7857c7e1-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4975,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd8b7 0xc4211fd8b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fd930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fd950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.731: INFO: Pod "nginx-deployment-7f9675fb8b-lkwz5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lkwz5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-lkwz5,UID:74b83959-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4856,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fd9a7 0xc4211fd9a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fda20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fda40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.6,PodIP:10.244.0.14,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://b5d25bd8e94a63445222220bf2390f967b6e07d01fcc71847fcf4d4ff07b0e12}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.731: INFO: Pod "nginx-deployment-7f9675fb8b-m6gt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m6gt8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-m6gt8,UID:78575ef6-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4983,Generation:0,CreationTimestamp:2019-01-22 18:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fdb00 0xc4211fdb01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fdb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fdb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.731: INFO: Pod "nginx-deployment-7f9675fb8b-nj8np" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nj8np,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-nj8np,UID:74c31e5e-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4884,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fdc00 0xc4211fdc01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fdc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fdc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.10,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://a5a55479e0406f8d5ffb47073925622eac75e10c3e923077163cf90122836787}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.732: INFO: Pod "nginx-deployment-7f9675fb8b-qpkxl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qpkxl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-qpkxl,UID:74bc713c-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4868,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fdd50 0xc4211fdd51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fddc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fdde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.31,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f2541a91e4eccf4f1949fa376721bd98e8b17caa4ed5dee373ace037bd23a7ff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.732: INFO: Pod "nginx-deployment-7f9675fb8b-r4fck" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-r4fck,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-r4fck,UID:74bc5332-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4863,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fdea0 0xc4211fdea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211fdf10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211fdf30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.29,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://e98a5e2f4bfdeef032846c05f1893e864607ae82ae3f08bbe86a7c95797a7a96}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 22 18:35:19.732: INFO: Pod "nginx-deployment-7f9675fb8b-vfffb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vfffb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-djnsp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-djnsp/pods/nginx-deployment-7f9675fb8b-vfffb,UID:74b83474-1e74-11e9-a380-de5a8a93737b,ResourceVersion:4878,Generation:0,CreationTimestamp:2019-01-22 18:35:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 74a93834-1e74-11e9-a380-de5a8a93737b 0xc4211fdff0 0xc4211fdff1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7nmc2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7nmc2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-7nmc2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b020a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b020c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 18:35:13 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.5,PodIP:10.244.2.7,StartTime:2019-01-22 18:35:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 18:35:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://1591c14f15d42cf50153694652e949555c899f9c1687ec084c96c49f94dcffd3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:35:19.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-djnsp" for this suite.
Jan 22 18:35:28.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:35:28.080: INFO: namespace: e2e-tests-deployment-djnsp, resource: bindings, ignored listing per whitelist
Jan 22 18:35:28.205: INFO: namespace e2e-tests-deployment-djnsp deletion completed in 8.375780103s

• [SLOW TEST:14.990 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:35:28.206: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:35:28.353: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-6vg5t" to be "success or failure"
Jan 22 18:35:28.357: INFO: Pod "downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.170023ms
Jan 22 18:35:30.362: INFO: Pod "downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009071998s
Jan 22 18:35:32.367: INFO: Pod "downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01421897s
STEP: Saw pod success
Jan 22 18:35:32.367: INFO: Pod "downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:35:32.372: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:35:32.414: INFO: Waiting for pod downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:35:32.425: INFO: Pod downwardapi-volume-7d93fb82-1e74-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:35:32.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6vg5t" for this suite.
Jan 22 18:35:38.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:35:38.462: INFO: namespace: e2e-tests-downward-api-6vg5t, resource: bindings, ignored listing per whitelist
Jan 22 18:35:38.601: INFO: namespace e2e-tests-downward-api-6vg5t deletion completed in 6.168004431s

• [SLOW TEST:10.395 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:35:38.602: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-svg72/configmap-test-83cc77e4-1e74-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:35:38.802: INFO: Waiting up to 5m0s for pod "pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-svg72" to be "success or failure"
Jan 22 18:35:38.806: INFO: Pod "pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.872213ms
Jan 22 18:35:40.810: INFO: Pod "pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007772902s
STEP: Saw pod success
Jan 22 18:35:40.810: INFO: Pod "pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:35:40.813: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3 container env-test: <nil>
STEP: delete the pod
Jan 22 18:35:40.845: INFO: Waiting for pod pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:35:40.850: INFO: Pod pod-configmaps-83cd910f-1e74-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:35:40.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-svg72" for this suite.
Jan 22 18:35:46.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:35:46.958: INFO: namespace: e2e-tests-configmap-svg72, resource: bindings, ignored listing per whitelist
Jan 22 18:35:47.023: INFO: namespace e2e-tests-configmap-svg72 deletion completed in 6.161415999s

• [SLOW TEST:8.422 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:35:47.024: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-t6t2c
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t6t2c to expose endpoints map[]
Jan 22 18:35:47.183: INFO: Get endpoints failed (4.268226ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 22 18:35:48.186: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t6t2c exposes endpoints map[] (1.007730694s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-t6t2c
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t6t2c to expose endpoints map[pod1:[100]]
Jan 22 18:35:50.239: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t6t2c exposes endpoints map[pod1:[100]] (2.03625889s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-t6t2c
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t6t2c to expose endpoints map[pod1:[100] pod2:[101]]
Jan 22 18:35:53.334: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t6t2c exposes endpoints map[pod1:[100] pod2:[101]] (3.064365057s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-t6t2c
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t6t2c to expose endpoints map[pod2:[101]]
Jan 22 18:35:54.368: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t6t2c exposes endpoints map[pod2:[101]] (1.021611285s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-t6t2c
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t6t2c to expose endpoints map[]
Jan 22 18:35:55.389: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t6t2c exposes endpoints map[] (1.012421012s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:35:55.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-t6t2c" for this suite.
Jan 22 18:36:17.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:36:17.622: INFO: namespace: e2e-tests-services-t6t2c, resource: bindings, ignored listing per whitelist
Jan 22 18:36:17.636: INFO: namespace e2e-tests-services-t6t2c deletion completed in 22.165439278s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.612 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:36:17.637: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 22 18:36:17.794: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-j4g2m" to be "success or failure"
Jan 22 18:36:17.798: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062319ms
Jan 22 18:36:19.802: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008243922s
Jan 22 18:36:21.807: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013313142s
STEP: Saw pod success
Jan 22 18:36:21.808: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 22 18:36:21.811: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 22 18:36:21.859: INFO: Waiting for pod pod-host-path-test to disappear
Jan 22 18:36:21.863: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:36:21.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-j4g2m" for this suite.
Jan 22 18:36:27.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:36:27.952: INFO: namespace: e2e-tests-hostpath-j4g2m, resource: bindings, ignored listing per whitelist
Jan 22 18:36:28.106: INFO: namespace e2e-tests-hostpath-j4g2m deletion completed in 6.237458411s

• [SLOW TEST:10.469 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:36:28.108: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 18:36:28.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-fvx4m'
Jan 22 18:36:29.669: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 22 18:36:29.669: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 22 18:36:31.682: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-mqcrk]
Jan 22 18:36:31.682: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-mqcrk" in namespace "e2e-tests-kubectl-fvx4m" to be "running and ready"
Jan 22 18:36:31.686: INFO: Pod "e2e-test-nginx-rc-mqcrk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.574834ms
Jan 22 18:36:33.691: INFO: Pod "e2e-test-nginx-rc-mqcrk": Phase="Running", Reason="", readiness=true. Elapsed: 2.008780276s
Jan 22 18:36:33.691: INFO: Pod "e2e-test-nginx-rc-mqcrk" satisfied condition "running and ready"
Jan 22 18:36:33.691: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-mqcrk]
Jan 22 18:36:33.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fvx4m'
Jan 22 18:36:33.870: INFO: stderr: ""
Jan 22 18:36:33.870: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan 22 18:36:33.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fvx4m'
Jan 22 18:36:34.012: INFO: stderr: ""
Jan 22 18:36:34.012: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:36:34.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fvx4m" for this suite.
Jan 22 18:36:40.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:36:40.264: INFO: namespace: e2e-tests-kubectl-fvx4m, resource: bindings, ignored listing per whitelist
Jan 22 18:36:40.301: INFO: namespace e2e-tests-kubectl-fvx4m deletion completed in 6.283747899s

• [SLOW TEST:12.194 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:36:40.301: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 22 18:36:40.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:41.072: INFO: stderr: ""
Jan 22 18:36:41.072: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 18:36:41.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:41.211: INFO: stderr: ""
Jan 22 18:36:41.211: INFO: stdout: "update-demo-nautilus-7h9ps update-demo-nautilus-bljbl "
Jan 22 18:36:41.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-7h9ps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:41.338: INFO: stderr: ""
Jan 22 18:36:41.338: INFO: stdout: ""
Jan 22 18:36:41.338: INFO: update-demo-nautilus-7h9ps is created but not running
Jan 22 18:36:46.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:46.464: INFO: stderr: ""
Jan 22 18:36:46.464: INFO: stdout: "update-demo-nautilus-7h9ps update-demo-nautilus-bljbl "
Jan 22 18:36:46.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-7h9ps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:46.604: INFO: stderr: ""
Jan 22 18:36:46.604: INFO: stdout: "true"
Jan 22 18:36:46.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-7h9ps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:46.726: INFO: stderr: ""
Jan 22 18:36:46.726: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:36:46.726: INFO: validating pod update-demo-nautilus-7h9ps
Jan 22 18:36:46.777: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:36:46.777: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:36:46.777: INFO: update-demo-nautilus-7h9ps is verified up and running
Jan 22 18:36:46.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-bljbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:46.904: INFO: stderr: ""
Jan 22 18:36:46.904: INFO: stdout: "true"
Jan 22 18:36:46.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-bljbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:36:47.009: INFO: stderr: ""
Jan 22 18:36:47.009: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 18:36:47.009: INFO: validating pod update-demo-nautilus-bljbl
Jan 22 18:36:47.060: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 18:36:47.061: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 18:36:47.061: INFO: update-demo-nautilus-bljbl is verified up and running
STEP: rolling-update to new replication controller
Jan 22 18:36:47.063: INFO: scanned /root for discovery docs: <nil>
Jan 22 18:36:47.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:37:09.833: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 22 18:37:09.833: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 18:37:09.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:37:09.971: INFO: stderr: ""
Jan 22 18:37:09.971: INFO: stdout: "update-demo-kitten-lbt8x update-demo-kitten-qpz7t "
Jan 22 18:37:09.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-kitten-lbt8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:37:10.127: INFO: stderr: ""
Jan 22 18:37:10.127: INFO: stdout: "true"
Jan 22 18:37:10.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-kitten-lbt8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:37:10.260: INFO: stderr: ""
Jan 22 18:37:10.260: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 22 18:37:10.260: INFO: validating pod update-demo-kitten-lbt8x
Jan 22 18:37:10.313: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 22 18:37:10.313: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 22 18:37:10.313: INFO: update-demo-kitten-lbt8x is verified up and running
Jan 22 18:37:10.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-kitten-qpz7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:37:10.438: INFO: stderr: ""
Jan 22 18:37:10.438: INFO: stdout: "true"
Jan 22 18:37:10.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-kitten-qpz7t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9p282'
Jan 22 18:37:10.578: INFO: stderr: ""
Jan 22 18:37:10.578: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 22 18:37:10.578: INFO: validating pod update-demo-kitten-qpz7t
Jan 22 18:37:10.632: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 22 18:37:10.632: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 22 18:37:10.632: INFO: update-demo-kitten-qpz7t is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:37:10.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9p282" for this suite.
Jan 22 18:37:34.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:37:34.852: INFO: namespace: e2e-tests-kubectl-9p282, resource: bindings, ignored listing per whitelist
Jan 22 18:37:34.892: INFO: namespace e2e-tests-kubectl-9p282 deletion completed in 24.247338374s

• [SLOW TEST:54.591 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:37:34.893: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:37:35.029: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 22 18:37:35.049: INFO: Number of nodes with available pods: 0
Jan 22 18:37:35.049: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:37:36.060: INFO: Number of nodes with available pods: 0
Jan 22 18:37:36.060: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:37:37.065: INFO: Number of nodes with available pods: 0
Jan 22 18:37:37.065: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:37:38.062: INFO: Number of nodes with available pods: 1
Jan 22 18:37:38.062: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:37:39.127: INFO: Number of nodes with available pods: 3
Jan 22 18:37:39.127: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 22 18:37:39.180: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:39.180: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:39.180: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:40.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:40.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:40.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:41.214: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:41.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:41.214: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:42.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:42.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:42.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:43.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:43.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:43.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:44.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:44.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:44.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:45.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:45.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:45.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:46.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:46.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:46.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:47.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:47.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:47.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:48.215: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:48.215: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:48.215: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:49.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:49.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:49.214: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:50.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:50.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:50.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:51.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:51.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:51.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:52.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:52.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:52.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:53.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:53.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:53.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:54.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:54.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:54.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:55.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:55.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:55.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:56.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:56.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:56.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:57.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:57.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:57.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:58.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:58.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:58.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:59.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:59.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:37:59.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:00.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:00.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:00.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:01.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:01.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:01.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:02.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:02.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:02.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:03.227: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:03.227: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:03.227: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:04.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:04.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:04.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:05.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:05.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:05.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:06.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:06.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:06.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:07.214: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:07.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:07.214: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:08.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:08.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:08.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:09.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:09.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:09.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:10.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:10.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:10.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:11.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:11.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:11.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:12.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:12.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:12.212: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:12.212: INFO: Pod daemon-set-tsmdh is not available
Jan 22 18:38:13.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:13.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:13.213: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:13.213: INFO: Pod daemon-set-tsmdh is not available
Jan 22 18:38:14.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:14.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:14.214: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:14.214: INFO: Pod daemon-set-tsmdh is not available
Jan 22 18:38:15.215: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:15.215: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:15.215: INFO: Wrong image for pod: daemon-set-tsmdh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:15.215: INFO: Pod daemon-set-tsmdh is not available
Jan 22 18:38:16.212: INFO: Pod daemon-set-cjq45 is not available
Jan 22 18:38:16.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:16.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:17.212: INFO: Pod daemon-set-cjq45 is not available
Jan 22 18:38:17.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:17.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:18.213: INFO: Pod daemon-set-cjq45 is not available
Jan 22 18:38:18.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:18.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:19.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:19.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:20.214: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:20.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:21.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:21.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:22.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:22.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:23.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:23.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:24.216: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:24.216: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:25.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:25.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:26.225: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:26.225: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:27.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:27.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:28.296: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:28.296: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:29.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:29.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:30.214: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:30.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:31.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:31.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:32.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:32.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:33.214: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:33.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:34.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:34.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:35.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:35.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:36.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:36.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:37.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:37.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:38.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:38.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:39.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:39.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:40.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:40.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:41.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:41.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:42.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:42.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:43.217: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:43.217: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:44.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:44.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:45.214: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:45.214: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:46.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:46.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:47.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:47.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:48.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:48.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:49.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:49.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:50.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:50.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:51.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:51.213: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:51.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:52.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:52.213: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:52.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:53.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:53.213: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:53.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:54.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:54.212: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:54.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:55.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:55.212: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:55.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:56.212: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:56.212: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:56.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:57.224: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:57.224: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:57.224: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:58.213: INFO: Wrong image for pod: daemon-set-svth2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:58.213: INFO: Pod daemon-set-svth2 is not available
Jan 22 18:38:58.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:59.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:38:59.213: INFO: Pod daemon-set-zqwgv is not available
Jan 22 18:39:00.218: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:00.218: INFO: Pod daemon-set-zqwgv is not available
Jan 22 18:39:01.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:01.213: INFO: Pod daemon-set-zqwgv is not available
Jan 22 18:39:02.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:03.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:04.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:05.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:06.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:07.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:08.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:09.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:10.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:11.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:12.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:13.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:14.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:15.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:16.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:17.215: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:18.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:19.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:20.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:21.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:22.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:23.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:24.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:25.216: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:26.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:27.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:28.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:29.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:30.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:31.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:32.212: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:33.213: INFO: Wrong image for pod: daemon-set-t795q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 22 18:39:33.213: INFO: Pod daemon-set-t795q is not available
Jan 22 18:39:34.216: INFO: Pod daemon-set-4445v is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 22 18:39:34.228: INFO: Number of nodes with available pods: 2
Jan 22 18:39:34.228: INFO: Node aks-nodepool1-25266157-1 is running more than one daemon pod
Jan 22 18:39:35.236: INFO: Number of nodes with available pods: 2
Jan 22 18:39:35.237: INFO: Node aks-nodepool1-25266157-1 is running more than one daemon pod
Jan 22 18:39:36.237: INFO: Number of nodes with available pods: 2
Jan 22 18:39:36.237: INFO: Node aks-nodepool1-25266157-1 is running more than one daemon pod
Jan 22 18:39:37.237: INFO: Number of nodes with available pods: 3
Jan 22 18:39:37.237: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-5gljp, will wait for the garbage collector to delete the pods
Jan 22 18:39:37.327: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.507763ms
Jan 22 18:39:37.427: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.196503ms
Jan 22 18:39:48.430: INFO: Number of nodes with available pods: 0
Jan 22 18:39:48.430: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 18:39:48.435: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5gljp/daemonsets","resourceVersion":"6093"},"items":null}

Jan 22 18:39:48.438: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5gljp/pods","resourceVersion":"6093"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:39:48.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5gljp" for this suite.
Jan 22 18:39:54.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:39:54.546: INFO: namespace: e2e-tests-daemonsets-5gljp, resource: bindings, ignored listing per whitelist
Jan 22 18:39:54.657: INFO: namespace e2e-tests-daemonsets-5gljp deletion completed in 6.192202022s

• [SLOW TEST:139.765 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:39:54.658: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1c690e11-1e75-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:39:54.854: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-77pnt" to be "success or failure"
Jan 22 18:39:54.902: INFO: Pod "pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 47.855786ms
Jan 22 18:39:56.907: INFO: Pod "pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052398828s
Jan 22 18:39:58.912: INFO: Pod "pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057999896s
STEP: Saw pod success
Jan 22 18:39:58.912: INFO: Pod "pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:39:58.916: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 18:39:58.954: INFO: Waiting for pod pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:39:58.958: INFO: Pod pod-configmaps-1c6a88f3-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:39:58.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-77pnt" for this suite.
Jan 22 18:40:04.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:40:05.044: INFO: namespace: e2e-tests-configmap-77pnt, resource: bindings, ignored listing per whitelist
Jan 22 18:40:05.126: INFO: namespace e2e-tests-configmap-77pnt deletion completed in 6.163961142s

• [SLOW TEST:10.469 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:40:05.127: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-22a98440-1e75-11e9-9ccc-2ee9843eaab3
STEP: Creating secret with name secret-projected-all-test-volume-22a9842b-1e75-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 22 18:40:05.342: INFO: Waiting up to 5m0s for pod "projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-7l7vj" to be "success or failure"
Jan 22 18:40:05.346: INFO: Pod "projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.883012ms
Jan 22 18:40:07.350: INFO: Pod "projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008081924s
Jan 22 18:40:09.355: INFO: Pod "projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012581641s
STEP: Saw pod success
Jan 22 18:40:09.355: INFO: Pod "projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:40:09.359: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 22 18:40:09.395: INFO: Waiting for pod projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:40:09.398: INFO: Pod projected-volume-22a983fc-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:40:09.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7l7vj" for this suite.
Jan 22 18:40:15.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:40:15.567: INFO: namespace: e2e-tests-projected-7l7vj, resource: bindings, ignored listing per whitelist
Jan 22 18:40:15.591: INFO: namespace e2e-tests-projected-7l7vj deletion completed in 6.187960875s

• [SLOW TEST:10.464 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:40:15.592: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:40:15.843: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"28ed8bab-1e75-11e9-a380-de5a8a93737b", Controller:(*bool)(0xc4221c0222), BlockOwnerDeletion:(*bool)(0xc4221c0223)}}
Jan 22 18:40:15.853: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"28e989ae-1e75-11e9-a380-de5a8a93737b", Controller:(*bool)(0xc4221ebd0a), BlockOwnerDeletion:(*bool)(0xc4221ebd0b)}}
Jan 22 18:40:15.871: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"28eb6f5a-1e75-11e9-a380-de5a8a93737b", Controller:(*bool)(0xc4221ebf52), BlockOwnerDeletion:(*bool)(0xc4221ebf53)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:40:20.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9ncw6" for this suite.
Jan 22 18:40:26.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:40:26.977: INFO: namespace: e2e-tests-gc-9ncw6, resource: bindings, ignored listing per whitelist
Jan 22 18:40:27.138: INFO: namespace e2e-tests-gc-9ncw6 deletion completed in 6.228859994s

• [SLOW TEST:11.547 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:40:27.138: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:40:27.438: INFO: (0) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 149.207816ms)
Jan 22 18:40:27.444: INFO: (1) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.077176ms)
Jan 22 18:40:27.451: INFO: (2) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.635392ms)
Jan 22 18:40:27.456: INFO: (3) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.670264ms)
Jan 22 18:40:27.461: INFO: (4) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 4.84374ms)
Jan 22 18:40:27.467: INFO: (5) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.762566ms)
Jan 22 18:40:27.472: INFO: (6) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.145949ms)
Jan 22 18:40:27.478: INFO: (7) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.439458ms)
Jan 22 18:40:27.492: INFO: (8) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 14.49002ms)
Jan 22 18:40:27.498: INFO: (9) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.064776ms)
Jan 22 18:40:27.504: INFO: (10) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.257252ms)
Jan 22 18:40:27.509: INFO: (11) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.469159ms)
Jan 22 18:40:27.514: INFO: (12) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.134849ms)
Jan 22 18:40:27.525: INFO: (13) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 10.585407ms)
Jan 22 18:40:27.532: INFO: (14) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.774596ms)
Jan 22 18:40:27.537: INFO: (15) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.402956ms)
Jan 22 18:40:27.544: INFO: (16) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.493388ms)
Jan 22 18:40:27.549: INFO: (17) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.444657ms)
Jan 22 18:40:27.555: INFO: (18) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.89117ms)
Jan 22 18:40:27.563: INFO: (19) /api/v1/nodes/aks-nodepool1-25266157-0/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 8.052333ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:40:27.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-np8pg" for this suite.
Jan 22 18:40:33.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:40:33.606: INFO: namespace: e2e-tests-proxy-np8pg, resource: bindings, ignored listing per whitelist
Jan 22 18:40:33.713: INFO: namespace e2e-tests-proxy-np8pg deletion completed in 6.143538491s

• [SLOW TEST:6.575 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:40:33.714: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:40:55.901: INFO: Container started at 2019-01-22 18:40:35 +0000 UTC, pod became ready at 2019-01-22 18:40:55 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:40:55.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wb6mr" for this suite.
Jan 22 18:41:17.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:41:18.052: INFO: namespace: e2e-tests-container-probe-wb6mr, resource: bindings, ignored listing per whitelist
Jan 22 18:41:18.081: INFO: namespace e2e-tests-container-probe-wb6mr deletion completed in 22.157147303s

• [SLOW TEST:44.367 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:41:18.082: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 22 18:41:18.234: INFO: Waiting up to 5m0s for pod "client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-containers-wkhg5" to be "success or failure"
Jan 22 18:41:18.238: INFO: Pod "client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.152046ms
Jan 22 18:41:20.243: INFO: Pod "client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008663792s
Jan 22 18:41:22.247: INFO: Pod "client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01309329s
STEP: Saw pod success
Jan 22 18:41:22.247: INFO: Pod "client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:41:22.251: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 18:41:22.329: INFO: Waiting for pod client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:41:22.335: INFO: Pod client-containers-4e1e874a-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:41:22.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wkhg5" for this suite.
Jan 22 18:41:28.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:41:28.506: INFO: namespace: e2e-tests-containers-wkhg5, resource: bindings, ignored listing per whitelist
Jan 22 18:41:28.566: INFO: namespace e2e-tests-containers-wkhg5 deletion completed in 6.225233562s

• [SLOW TEST:10.485 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:41:28.567: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0122 18:42:08.868569      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 18:42:08.868: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:42:08.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xpbtn" for this suite.
Jan 22 18:42:16.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:42:17.011: INFO: namespace: e2e-tests-gc-xpbtn, resource: bindings, ignored listing per whitelist
Jan 22 18:42:17.051: INFO: namespace e2e-tests-gc-xpbtn deletion completed in 8.179393145s

• [SLOW TEST:48.484 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:42:17.051: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-k8qdq
Jan 22 18:42:21.241: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-k8qdq
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 18:42:21.244: INFO: Initial restart count of pod liveness-http is 0
Jan 22 18:42:45.319: INFO: Restart count of pod e2e-tests-container-probe-k8qdq/liveness-http is now 1 (24.074797197s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:42:45.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k8qdq" for this suite.
Jan 22 18:42:51.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:42:51.400: INFO: namespace: e2e-tests-container-probe-k8qdq, resource: bindings, ignored listing per whitelist
Jan 22 18:42:51.494: INFO: namespace e2e-tests-container-probe-k8qdq deletion completed in 6.153444866s

• [SLOW TEST:34.443 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:42:51.494: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 22 18:42:51.675: INFO: Waiting up to 5m0s for pod "downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-k2prm" to be "success or failure"
Jan 22 18:42:51.697: INFO: Pod "downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 21.799248ms
Jan 22 18:42:53.702: INFO: Pod "downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026514161s
Jan 22 18:42:55.706: INFO: Pod "downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03073072s
STEP: Saw pod success
Jan 22 18:42:55.706: INFO: Pod "downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:42:55.710: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 18:42:55.742: INFO: Waiting for pod downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:42:55.745: INFO: Pod downward-api-85d19f36-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:42:55.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k2prm" for this suite.
Jan 22 18:43:01.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:43:01.782: INFO: namespace: e2e-tests-downward-api-k2prm, resource: bindings, ignored listing per whitelist
Jan 22 18:43:01.943: INFO: namespace e2e-tests-downward-api-k2prm deletion completed in 6.193988949s

• [SLOW TEST:10.449 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:43:01.947: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 22 18:43:02.102: INFO: Waiting up to 5m0s for pod "client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-containers-sdx66" to be "success or failure"
Jan 22 18:43:02.109: INFO: Pod "client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.097343ms
Jan 22 18:43:04.113: INFO: Pod "client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011276043s
STEP: Saw pod success
Jan 22 18:43:04.113: INFO: Pod "client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:43:04.117: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 18:43:04.155: INFO: Waiting for pod client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:43:04.160: INFO: Pod client-containers-8c07f196-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:43:04.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-sdx66" for this suite.
Jan 22 18:43:10.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:43:10.268: INFO: namespace: e2e-tests-containers-sdx66, resource: bindings, ignored listing per whitelist
Jan 22 18:43:10.328: INFO: namespace e2e-tests-containers-sdx66 deletion completed in 6.16335852s

• [SLOW TEST:8.382 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:43:10.329: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 22 18:43:10.475: INFO: Waiting up to 5m0s for pod "pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-ww7dr" to be "success or failure"
Jan 22 18:43:10.485: INFO: Pod "pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018542ms
Jan 22 18:43:12.489: INFO: Pod "pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014699705s
Jan 22 18:43:14.494: INFO: Pod "pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019351231s
STEP: Saw pod success
Jan 22 18:43:14.494: INFO: Pod "pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:43:14.499: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 18:43:14.548: INFO: Waiting for pod pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:43:14.552: INFO: Pod pod-91049c95-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:43:14.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ww7dr" for this suite.
Jan 22 18:43:20.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:43:20.609: INFO: namespace: e2e-tests-emptydir-ww7dr, resource: bindings, ignored listing per whitelist
Jan 22 18:43:20.743: INFO: namespace e2e-tests-emptydir-ww7dr deletion completed in 6.185901607s

• [SLOW TEST:10.414 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:43:20.744: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:43:20.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 version'
Jan 22 18:43:21.116: INFO: stderr: ""
Jan 22 18:43:21.116: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.4\", GitCommit:\"f49fa022dbe63faafd0da106ef7e05a29721d3f1\", GitTreeState:\"clean\", BuildDate:\"2018-12-14T06:59:37Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:43:21.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9b9zk" for this suite.
Jan 22 18:43:27.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:43:27.314: INFO: namespace: e2e-tests-kubectl-9b9zk, resource: bindings, ignored listing per whitelist
Jan 22 18:43:27.366: INFO: namespace e2e-tests-kubectl-9b9zk deletion completed in 6.245163555s

• [SLOW TEST:6.623 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:43:27.367: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-htld4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 18:43:27.539: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 18:43:49.718: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.0.26:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-htld4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 18:43:49.718: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:43:50.057: INFO: Found all expected endpoints: [netserver-0]
Jan 22 18:43:50.061: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.2.32:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-htld4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 18:43:50.061: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:43:50.328: INFO: Found all expected endpoints: [netserver-1]
Jan 22 18:43:50.332: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.1.66:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-htld4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 18:43:50.332: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 18:43:50.685: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:43:50.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-htld4" for this suite.
Jan 22 18:44:10.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:44:10.847: INFO: namespace: e2e-tests-pod-network-test-htld4, resource: bindings, ignored listing per whitelist
Jan 22 18:44:11.059: INFO: namespace e2e-tests-pod-network-test-htld4 deletion completed in 20.366738627s

• [SLOW TEST:43.691 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:44:11.060: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:44:15.259: INFO: Waiting up to 5m0s for pod "client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-pods-znpjw" to be "success or failure"
Jan 22 18:44:15.269: INFO: Pod "client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.861431ms
Jan 22 18:44:17.273: INFO: Pod "client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013986166s
Jan 22 18:44:19.277: INFO: Pod "client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017726256s
STEP: Saw pod success
Jan 22 18:44:19.277: INFO: Pod "client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:44:19.281: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3 container env3cont: <nil>
STEP: delete the pod
Jan 22 18:44:19.316: INFO: Waiting for pod client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:44:19.320: INFO: Pod client-envvars-b7a3d288-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:44:19.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-znpjw" for this suite.
Jan 22 18:44:59.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:44:59.555: INFO: namespace: e2e-tests-pods-znpjw, resource: bindings, ignored listing per whitelist
Jan 22 18:44:59.558: INFO: namespace e2e-tests-pods-znpjw deletion completed in 40.233195393s

• [SLOW TEST:48.498 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:44:59.559: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d221b71e-1e75-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 18:44:59.713: INFO: Waiting up to 5m0s for pod "pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-v4slm" to be "success or failure"
Jan 22 18:44:59.723: INFO: Pod "pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.831927ms
Jan 22 18:45:01.727: INFO: Pod "pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013773972s
Jan 22 18:45:03.732: INFO: Pod "pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018407311s
STEP: Saw pod success
Jan 22 18:45:03.732: INFO: Pod "pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:45:03.736: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 18:45:03.778: INFO: Waiting for pod pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:45:03.787: INFO: Pod pod-secrets-d222d15d-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:45:03.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v4slm" for this suite.
Jan 22 18:45:09.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:45:09.987: INFO: namespace: e2e-tests-secrets-v4slm, resource: bindings, ignored listing per whitelist
Jan 22 18:45:10.030: INFO: namespace e2e-tests-secrets-v4slm deletion completed in 6.239174503s

• [SLOW TEST:10.472 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:45:10.030: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d864e77d-1e75-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:45:10.226: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-xv4pc" to be "success or failure"
Jan 22 18:45:10.229: INFO: Pod "pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.342911ms
Jan 22 18:45:12.233: INFO: Pod "pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007625314s
Jan 22 18:45:14.237: INFO: Pod "pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011852286s
STEP: Saw pod success
Jan 22 18:45:14.238: INFO: Pod "pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:45:14.242: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 18:45:14.275: INFO: Waiting for pod pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:45:14.279: INFO: Pod pod-projected-configmaps-d865f805-1e75-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:45:14.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xv4pc" for this suite.
Jan 22 18:45:20.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:45:20.477: INFO: namespace: e2e-tests-projected-xv4pc, resource: bindings, ignored listing per whitelist
Jan 22 18:45:20.525: INFO: namespace e2e-tests-projected-xv4pc deletion completed in 6.241029794s

• [SLOW TEST:10.494 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:45:20.525: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 22 18:45:23.253: INFO: Successfully updated pod "annotationupdatedea5cc94-1e75-11e9-9ccc-2ee9843eaab3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:45:25.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7jnhc" for this suite.
Jan 22 18:45:47.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:45:47.474: INFO: namespace: e2e-tests-projected-7jnhc, resource: bindings, ignored listing per whitelist
Jan 22 18:45:47.551: INFO: namespace e2e-tests-projected-7jnhc deletion completed in 22.265393935s

• [SLOW TEST:27.026 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:45:47.551: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:45:47.739: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:45:48.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-tl4xg" for this suite.
Jan 22 18:45:54.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:45:55.025: INFO: namespace: e2e-tests-custom-resource-definition-tl4xg, resource: bindings, ignored listing per whitelist
Jan 22 18:45:55.075: INFO: namespace e2e-tests-custom-resource-definition-tl4xg deletion completed in 6.203711286s

• [SLOW TEST:7.524 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:45:55.076: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-mc5qq.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-mc5qq.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-mc5qq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-mc5qq.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-mc5qq.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-mc5qq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 22 18:46:10.301: INFO: DNS probes using e2e-tests-dns-mc5qq/dns-test-f33729c8-1e75-11e9-9ccc-2ee9843eaab3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:46:10.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-mc5qq" for this suite.
Jan 22 18:46:16.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:46:16.545: INFO: namespace: e2e-tests-dns-mc5qq, resource: bindings, ignored listing per whitelist
Jan 22 18:46:16.553: INFO: namespace e2e-tests-dns-mc5qq deletion completed in 6.187755495s

• [SLOW TEST:21.477 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:46:16.553: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan 22 18:46:16.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-srnns'
Jan 22 18:46:17.224: INFO: stderr: ""
Jan 22 18:46:17.224: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 22 18:46:18.230: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:46:18.230: INFO: Found 0 / 1
Jan 22 18:46:19.229: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:46:19.229: INFO: Found 0 / 1
Jan 22 18:46:20.229: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:46:20.229: INFO: Found 1 / 1
Jan 22 18:46:20.229: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 22 18:46:20.234: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:46:20.234: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 22 18:46:20.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 logs redis-master-chng5 redis-master --namespace=e2e-tests-kubectl-srnns'
Jan 22 18:46:20.385: INFO: stderr: ""
Jan 22 18:46:20.385: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Jan 18:46:18.723 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Jan 18:46:18.723 # Server started, Redis version 3.2.12\n1:M 22 Jan 18:46:18.723 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Jan 18:46:18.723 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 22 18:46:20.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 log redis-master-chng5 redis-master --namespace=e2e-tests-kubectl-srnns --tail=1'
Jan 22 18:46:20.535: INFO: stderr: ""
Jan 22 18:46:20.535: INFO: stdout: "1:M 22 Jan 18:46:18.723 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 22 18:46:20.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 log redis-master-chng5 redis-master --namespace=e2e-tests-kubectl-srnns --limit-bytes=1'
Jan 22 18:46:20.668: INFO: stderr: ""
Jan 22 18:46:20.668: INFO: stdout: " "
STEP: exposing timestamps
Jan 22 18:46:20.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 log redis-master-chng5 redis-master --namespace=e2e-tests-kubectl-srnns --tail=1 --timestamps'
Jan 22 18:46:20.814: INFO: stderr: ""
Jan 22 18:46:20.814: INFO: stdout: "2019-01-22T18:46:18.723693711Z 1:M 22 Jan 18:46:18.723 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 22 18:46:23.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 log redis-master-chng5 redis-master --namespace=e2e-tests-kubectl-srnns --since=1s'
Jan 22 18:46:23.460: INFO: stderr: ""
Jan 22 18:46:23.460: INFO: stdout: ""
Jan 22 18:46:23.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 log redis-master-chng5 redis-master --namespace=e2e-tests-kubectl-srnns --since=24h'
Jan 22 18:46:23.602: INFO: stderr: ""
Jan 22 18:46:23.602: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Jan 18:46:18.723 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Jan 18:46:18.723 # Server started, Redis version 3.2.12\n1:M 22 Jan 18:46:18.723 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Jan 18:46:18.723 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan 22 18:46:23.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-srnns'
Jan 22 18:46:23.733: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:46:23.733: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 22 18:46:23.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-srnns'
Jan 22 18:46:23.876: INFO: stderr: "No resources found.\n"
Jan 22 18:46:23.876: INFO: stdout: ""
Jan 22 18:46:23.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -l name=nginx --namespace=e2e-tests-kubectl-srnns -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 18:46:23.993: INFO: stderr: ""
Jan 22 18:46:23.993: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:46:23.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-srnns" for this suite.
Jan 22 18:46:30.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:46:30.221: INFO: namespace: e2e-tests-kubectl-srnns, resource: bindings, ignored listing per whitelist
Jan 22 18:46:30.259: INFO: namespace e2e-tests-kubectl-srnns deletion completed in 6.259251595s

• [SLOW TEST:13.705 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:46:30.259: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 22 18:46:30.378: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 22 18:46:30.401: INFO: Waiting for terminating namespaces to be deleted...
Jan 22 18:46:30.405: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-0 before test
Jan 22 18:46:30.462: INFO: addon-http-application-routing-default-http-backend-8cdc9dxj4t8 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container addon-http-application-routing-default-http-backend ready: true, restart count 0
Jan 22 18:46:30.462: INFO: kube-svc-redirect-qsqw9 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 18:46:30.462: INFO: 	Container redirector ready: true, restart count 0
Jan 22 18:46:30.462: INFO: kube-proxy-2v8rv from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 18:46:30.462: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-vcfbq from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 18:46:30.462: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:46:30.462: INFO: heapster-5fb7488d97-c8mth from kube-system started at 2019-01-22 18:06:47 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container heapster ready: true, restart count 0
Jan 22 18:46:30.462: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 22 18:46:30.462: INFO: addon-http-application-routing-external-dns-748b5c76c5-6jkzs from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container addon-http-application-routing-external-dns ready: true, restart count 0
Jan 22 18:46:30.462: INFO: kubernetes-dashboard-847bb4ddc6-d6279 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container main ready: true, restart count 0
Jan 22 18:46:30.462: INFO: coredns-autoscaler-6fcdb7d64-b7f2f from kube-system started at 2019-01-22 18:06:47 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container autoscaler ready: true, restart count 0
Jan 22 18:46:30.462: INFO: metrics-server-7b97f9cd9-5m9b9 from kube-system started at 2019-01-22 18:06:47 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container metrics-server ready: true, restart count 1
Jan 22 18:46:30.462: INFO: coredns-7d6976d69b-cwx7h from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container coredns ready: true, restart count 0
Jan 22 18:46:30.462: INFO: tunnelfront-7d7c8dd874-mmz7c from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container tunnel-front ready: true, restart count 0
Jan 22 18:46:30.462: INFO: addon-http-application-routing-nginx-ingress-controller-8fgw98w from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.462: INFO: 	Container addon-http-application-routing-nginx-ingress-controller ready: true, restart count 0
Jan 22 18:46:30.462: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-1 before test
Jan 22 18:46:30.630: INFO: kube-svc-redirect-79xvb from kube-system started at 2019-01-22 18:07:06 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.630: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 18:46:30.630: INFO: 	Container redirector ready: true, restart count 0
Jan 22 18:46:30.630: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z4tt7 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.630: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 18:46:30.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:46:30.630: INFO: sonobuoy-e2e-job-28ff8d7933fc4391 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.630: INFO: 	Container e2e ready: true, restart count 0
Jan 22 18:46:30.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:46:30.630: INFO: kube-proxy-5t82s from kube-system started at 2019-01-22 18:07:06 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.630: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 18:46:30.630: INFO: coredns-7d6976d69b-bx6qf from kube-system started at 2019-01-22 18:07:18 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.630: INFO: 	Container coredns ready: true, restart count 0
Jan 22 18:46:30.630: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-2 before test
Jan 22 18:46:30.682: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-22 18:23:38 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.682: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 22 18:46:30.682: INFO: kube-svc-redirect-gzjdx from kube-system started at 2019-01-22 18:07:01 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.682: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 18:46:30.682: INFO: 	Container redirector ready: true, restart count 0
Jan 22 18:46:30.682: INFO: kube-proxy-8rjdt from kube-system started at 2019-01-22 18:07:01 +0000 UTC (1 container statuses recorded)
Jan 22 18:46:30.682: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 18:46:30.682: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z68w9 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:46:30.682: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 18:46:30.682: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node aks-nodepool1-25266157-0
STEP: verifying the node has the label node aks-nodepool1-25266157-1
STEP: verifying the node has the label node aks-nodepool1-25266157-2
Jan 22 18:46:30.749: INFO: Pod sonobuoy requesting resource cpu=0m on Node aks-nodepool1-25266157-2
Jan 22 18:46:30.749: INFO: Pod sonobuoy-e2e-job-28ff8d7933fc4391 requesting resource cpu=0m on Node aks-nodepool1-25266157-1
Jan 22 18:46:30.749: INFO: Pod sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-vcfbq requesting resource cpu=0m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z4tt7 requesting resource cpu=0m on Node aks-nodepool1-25266157-1
Jan 22 18:46:30.749: INFO: Pod sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z68w9 requesting resource cpu=0m on Node aks-nodepool1-25266157-2
Jan 22 18:46:30.749: INFO: Pod addon-http-application-routing-default-http-backend-8cdc9dxj4t8 requesting resource cpu=10m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod addon-http-application-routing-external-dns-748b5c76c5-6jkzs requesting resource cpu=0m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod addon-http-application-routing-nginx-ingress-controller-8fgw98w requesting resource cpu=0m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod coredns-7d6976d69b-bx6qf requesting resource cpu=100m on Node aks-nodepool1-25266157-1
Jan 22 18:46:30.749: INFO: Pod coredns-7d6976d69b-cwx7h requesting resource cpu=100m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod coredns-autoscaler-6fcdb7d64-b7f2f requesting resource cpu=20m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod heapster-5fb7488d97-c8mth requesting resource cpu=130m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod kube-proxy-2v8rv requesting resource cpu=100m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod kube-proxy-5t82s requesting resource cpu=100m on Node aks-nodepool1-25266157-1
Jan 22 18:46:30.749: INFO: Pod kube-proxy-8rjdt requesting resource cpu=100m on Node aks-nodepool1-25266157-2
Jan 22 18:46:30.749: INFO: Pod kube-svc-redirect-79xvb requesting resource cpu=10m on Node aks-nodepool1-25266157-1
Jan 22 18:46:30.749: INFO: Pod kube-svc-redirect-gzjdx requesting resource cpu=10m on Node aks-nodepool1-25266157-2
Jan 22 18:46:30.749: INFO: Pod kube-svc-redirect-qsqw9 requesting resource cpu=10m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod kubernetes-dashboard-847bb4ddc6-d6279 requesting resource cpu=100m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod metrics-server-7b97f9cd9-5m9b9 requesting resource cpu=0m on Node aks-nodepool1-25266157-0
Jan 22 18:46:30.749: INFO: Pod tunnelfront-7d7c8dd874-mmz7c requesting resource cpu=10m on Node aks-nodepool1-25266157-0
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0867a232-1e76-11e9-9ccc-2ee9843eaab3.157c400bab86b5a1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4d99k/filler-pod-0867a232-1e76-11e9-9ccc-2ee9843eaab3 to aks-nodepool1-25266157-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0867a232-1e76-11e9-9ccc-2ee9843eaab3.157c400beb6ce7f5], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0867a232-1e76-11e9-9ccc-2ee9843eaab3.157c400c0baa18cb], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0867a232-1e76-11e9-9ccc-2ee9843eaab3.157c400c1bfa7052], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0867a232-1e76-11e9-9ccc-2ee9843eaab3.157c400c27cfb577], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086988d5-1e76-11e9-9ccc-2ee9843eaab3.157c400bac570021], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4d99k/filler-pod-086988d5-1e76-11e9-9ccc-2ee9843eaab3 to aks-nodepool1-25266157-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086988d5-1e76-11e9-9ccc-2ee9843eaab3.157c400be62c545f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086988d5-1e76-11e9-9ccc-2ee9843eaab3.157c400bf498505d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086988d5-1e76-11e9-9ccc-2ee9843eaab3.157c400bff525fa2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086b9fbd-1e76-11e9-9ccc-2ee9843eaab3.157c400bad418775], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-4d99k/filler-pod-086b9fbd-1e76-11e9-9ccc-2ee9843eaab3 to aks-nodepool1-25266157-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086b9fbd-1e76-11e9-9ccc-2ee9843eaab3.157c400bf3902a6d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086b9fbd-1e76-11e9-9ccc-2ee9843eaab3.157c400c02a025a7], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-086b9fbd-1e76-11e9-9ccc-2ee9843eaab3.157c400c0d7e85dc], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157c400c9d818da7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node aks-nodepool1-25266157-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node aks-nodepool1-25266157-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node aks-nodepool1-25266157-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:46:35.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4d99k" for this suite.
Jan 22 18:46:42.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:46:42.197: INFO: namespace: e2e-tests-sched-pred-4d99k, resource: bindings, ignored listing per whitelist
Jan 22 18:46:42.292: INFO: namespace e2e-tests-sched-pred-4d99k deletion completed in 6.253821257s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.033 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:46:42.292: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:46:42.433: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-g9l6b" to be "success or failure"
Jan 22 18:46:42.437: INFO: Pod "downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.98833ms
Jan 22 18:46:44.441: INFO: Pod "downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007959205s
STEP: Saw pod success
Jan 22 18:46:44.441: INFO: Pod "downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:46:44.445: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:46:44.473: INFO: Waiting for pod downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:46:44.479: INFO: Pod downwardapi-volume-0f5c5e61-1e76-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:46:44.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g9l6b" for this suite.
Jan 22 18:46:50.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:46:50.648: INFO: namespace: e2e-tests-downward-api-g9l6b, resource: bindings, ignored listing per whitelist
Jan 22 18:46:50.676: INFO: namespace e2e-tests-downward-api-g9l6b deletion completed in 6.192084634s

• [SLOW TEST:8.384 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:46:50.676: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 22 18:46:50.820: INFO: Waiting up to 5m0s for pod "pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-5kdwc" to be "success or failure"
Jan 22 18:46:50.823: INFO: Pod "pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.458812ms
Jan 22 18:46:52.828: INFO: Pod "pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007763699s
Jan 22 18:46:54.832: INFO: Pod "pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012389372s
STEP: Saw pod success
Jan 22 18:46:54.832: INFO: Pod "pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:46:54.836: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 18:46:54.870: INFO: Waiting for pod pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:46:54.873: INFO: Pod pod-145bc984-1e76-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:46:54.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5kdwc" for this suite.
Jan 22 18:47:00.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:47:01.000: INFO: namespace: e2e-tests-emptydir-5kdwc, resource: bindings, ignored listing per whitelist
Jan 22 18:47:01.033: INFO: namespace e2e-tests-emptydir-5kdwc deletion completed in 6.155462967s

• [SLOW TEST:10.357 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:47:01.033: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 22 18:47:01.354: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 22 18:47:01.362: INFO: Waiting for terminating namespaces to be deleted...
Jan 22 18:47:01.365: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-0 before test
Jan 22 18:47:01.380: INFO: addon-http-application-routing-external-dns-748b5c76c5-6jkzs from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container addon-http-application-routing-external-dns ready: true, restart count 0
Jan 22 18:47:01.380: INFO: kubernetes-dashboard-847bb4ddc6-d6279 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container main ready: true, restart count 0
Jan 22 18:47:01.380: INFO: coredns-autoscaler-6fcdb7d64-b7f2f from kube-system started at 2019-01-22 18:06:47 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container autoscaler ready: true, restart count 0
Jan 22 18:47:01.380: INFO: metrics-server-7b97f9cd9-5m9b9 from kube-system started at 2019-01-22 18:06:47 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container metrics-server ready: true, restart count 1
Jan 22 18:47:01.380: INFO: heapster-5fb7488d97-c8mth from kube-system started at 2019-01-22 18:06:47 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container heapster ready: true, restart count 0
Jan 22 18:47:01.380: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 22 18:47:01.380: INFO: tunnelfront-7d7c8dd874-mmz7c from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container tunnel-front ready: true, restart count 0
Jan 22 18:47:01.380: INFO: addon-http-application-routing-nginx-ingress-controller-8fgw98w from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container addon-http-application-routing-nginx-ingress-controller ready: true, restart count 0
Jan 22 18:47:01.380: INFO: coredns-7d6976d69b-cwx7h from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container coredns ready: true, restart count 0
Jan 22 18:47:01.380: INFO: addon-http-application-routing-default-http-backend-8cdc9dxj4t8 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container addon-http-application-routing-default-http-backend ready: true, restart count 0
Jan 22 18:47:01.380: INFO: kube-svc-redirect-qsqw9 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 18:47:01.380: INFO: 	Container redirector ready: true, restart count 0
Jan 22 18:47:01.380: INFO: kube-proxy-2v8rv from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 18:47:01.380: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-vcfbq from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.380: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 18:47:01.380: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:47:01.380: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-1 before test
Jan 22 18:47:01.437: INFO: kube-svc-redirect-79xvb from kube-system started at 2019-01-22 18:07:06 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.437: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 18:47:01.437: INFO: 	Container redirector ready: true, restart count 0
Jan 22 18:47:01.437: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z4tt7 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.437: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 18:47:01.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:47:01.437: INFO: sonobuoy-e2e-job-28ff8d7933fc4391 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.437: INFO: 	Container e2e ready: true, restart count 0
Jan 22 18:47:01.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:47:01.437: INFO: kube-proxy-5t82s from kube-system started at 2019-01-22 18:07:06 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.437: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 18:47:01.437: INFO: coredns-7d6976d69b-bx6qf from kube-system started at 2019-01-22 18:07:18 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.437: INFO: 	Container coredns ready: true, restart count 0
Jan 22 18:47:01.437: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-2 before test
Jan 22 18:47:01.579: INFO: kube-svc-redirect-gzjdx from kube-system started at 2019-01-22 18:07:01 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.579: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 18:47:01.579: INFO: 	Container redirector ready: true, restart count 0
Jan 22 18:47:01.580: INFO: kube-proxy-8rjdt from kube-system started at 2019-01-22 18:07:01 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.580: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 18:47:01.580: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z68w9 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 18:47:01.580: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 22 18:47:01.580: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 18:47:01.580: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-22 18:23:38 +0000 UTC (1 container statuses recorded)
Jan 22 18:47:01.580: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1d33089e-1e76-11e9-9ccc-2ee9843eaab3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-1d33089e-1e76-11e9-9ccc-2ee9843eaab3 off the node aks-nodepool1-25266157-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1d33089e-1e76-11e9-9ccc-2ee9843eaab3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:47:07.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qp94r" for this suite.
Jan 22 18:47:15.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:47:15.906: INFO: namespace: e2e-tests-sched-pred-qp94r, resource: bindings, ignored listing per whitelist
Jan 22 18:47:15.938: INFO: namespace e2e-tests-sched-pred-qp94r deletion completed in 8.229785895s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:14.905 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:47:15.938: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0122 18:47:22.164309      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 18:47:22.164: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:47:22.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4w2mq" for this suite.
Jan 22 18:47:28.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:47:28.447: INFO: namespace: e2e-tests-gc-4w2mq, resource: bindings, ignored listing per whitelist
Jan 22 18:47:28.458: INFO: namespace e2e-tests-gc-4w2mq deletion completed in 6.289593438s

• [SLOW TEST:12.520 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:47:28.458: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2ae5239f-1e76-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:47:28.637: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-bgnwp" to be "success or failure"
Jan 22 18:47:28.640: INFO: Pod "pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.319407ms
Jan 22 18:47:30.644: INFO: Pod "pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00758536s
Jan 22 18:47:32.649: INFO: Pod "pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012017296s
STEP: Saw pod success
Jan 22 18:47:32.649: INFO: Pod "pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:47:32.653: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 18:47:32.776: INFO: Waiting for pod pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:47:32.779: INFO: Pod pod-configmaps-2ae62713-1e76-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:47:32.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bgnwp" for this suite.
Jan 22 18:47:38.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:47:38.990: INFO: namespace: e2e-tests-configmap-bgnwp, resource: bindings, ignored listing per whitelist
Jan 22 18:47:39.050: INFO: namespace e2e-tests-configmap-bgnwp deletion completed in 6.264962579s

• [SLOW TEST:10.592 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:47:39.052: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-31379d26-1e76-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:47:39.247: INFO: Waiting up to 5m0s for pod "pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-59qq6" to be "success or failure"
Jan 22 18:47:39.251: INFO: Pod "pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.981028ms
Jan 22 18:47:41.258: INFO: Pod "pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010712645s
Jan 22 18:47:43.262: INFO: Pod "pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01524337s
STEP: Saw pod success
Jan 22 18:47:43.262: INFO: Pod "pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:47:43.265: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 18:47:43.296: INFO: Waiting for pod pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:47:43.299: INFO: Pod pod-configmaps-31393844-1e76-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:47:43.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-59qq6" for this suite.
Jan 22 18:47:49.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:47:49.377: INFO: namespace: e2e-tests-configmap-59qq6, resource: bindings, ignored listing per whitelist
Jan 22 18:47:49.555: INFO: namespace e2e-tests-configmap-59qq6 deletion completed in 6.252090711s

• [SLOW TEST:10.504 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:47:49.556: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 22 18:47:49.727: INFO: Waiting up to 5m0s for pod "pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-dhc8w" to be "success or failure"
Jan 22 18:47:49.732: INFO: Pod "pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.019062ms
Jan 22 18:47:51.737: INFO: Pod "pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009496594s
STEP: Saw pod success
Jan 22 18:47:51.737: INFO: Pod "pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:47:51.741: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 18:47:51.774: INFO: Waiting for pod pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:47:51.778: INFO: Pod pod-377872d9-1e76-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:47:51.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dhc8w" for this suite.
Jan 22 18:47:57.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:47:57.861: INFO: namespace: e2e-tests-emptydir-dhc8w, resource: bindings, ignored listing per whitelist
Jan 22 18:47:57.930: INFO: namespace e2e-tests-emptydir-dhc8w deletion completed in 6.147739382s

• [SLOW TEST:8.375 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:47:57.930: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:48:58.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dp2l2" for this suite.
Jan 22 18:49:12.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:49:12.251: INFO: namespace: e2e-tests-container-probe-dp2l2, resource: bindings, ignored listing per whitelist
Jan 22 18:49:12.399: INFO: namespace e2e-tests-container-probe-dp2l2 deletion completed in 14.266247965s

• [SLOW TEST:74.469 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:49:12.400: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 18:49:12.576: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 22 18:49:12.588: INFO: Number of nodes with available pods: 0
Jan 22 18:49:12.588: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 22 18:49:12.632: INFO: Number of nodes with available pods: 0
Jan 22 18:49:12.632: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:13.637: INFO: Number of nodes with available pods: 0
Jan 22 18:49:13.637: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:14.637: INFO: Number of nodes with available pods: 0
Jan 22 18:49:14.637: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:15.637: INFO: Number of nodes with available pods: 1
Jan 22 18:49:15.637: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 22 18:49:16.057: INFO: Number of nodes with available pods: 1
Jan 22 18:49:16.057: INFO: Number of running nodes: 0, number of available pods: 1
Jan 22 18:49:17.061: INFO: Number of nodes with available pods: 0
Jan 22 18:49:17.061: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 22 18:49:17.096: INFO: Number of nodes with available pods: 0
Jan 22 18:49:17.096: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:18.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:18.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:19.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:19.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:20.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:20.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:21.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:21.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:22.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:22.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:23.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:23.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:24.103: INFO: Number of nodes with available pods: 0
Jan 22 18:49:24.103: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:25.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:25.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:26.102: INFO: Number of nodes with available pods: 0
Jan 22 18:49:26.102: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:27.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:27.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:28.105: INFO: Number of nodes with available pods: 0
Jan 22 18:49:28.105: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:29.102: INFO: Number of nodes with available pods: 0
Jan 22 18:49:29.102: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:30.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:30.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:32.828: INFO: Number of nodes with available pods: 0
Jan 22 18:49:32.828: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:33.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:33.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:34.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:34.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:35.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:35.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:36.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:36.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:37.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:37.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:38.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:38.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:39.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:39.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:40.106: INFO: Number of nodes with available pods: 0
Jan 22 18:49:40.106: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:41.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:41.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:42.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:42.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:43.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:43.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:44.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:44.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:45.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:45.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:46.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:46.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:47.109: INFO: Number of nodes with available pods: 0
Jan 22 18:49:47.109: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:48.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:48.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:49.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:49.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:50.101: INFO: Number of nodes with available pods: 0
Jan 22 18:49:50.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:51.102: INFO: Number of nodes with available pods: 0
Jan 22 18:49:51.102: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:52.103: INFO: Number of nodes with available pods: 0
Jan 22 18:49:52.103: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:53.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:53.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:54.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:54.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:55.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:55.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:56.105: INFO: Number of nodes with available pods: 0
Jan 22 18:49:56.105: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:57.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:57.100: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:58.100: INFO: Number of nodes with available pods: 0
Jan 22 18:49:58.101: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 18:49:59.100: INFO: Number of nodes with available pods: 1
Jan 22 18:49:59.101: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-h6q5f, will wait for the garbage collector to delete the pods
Jan 22 18:49:59.175: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.088781ms
Jan 22 18:49:59.275: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.17086ms
Jan 22 18:50:35.979: INFO: Number of nodes with available pods: 0
Jan 22 18:50:35.979: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 18:50:35.983: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h6q5f/daemonsets","resourceVersion":"8448"},"items":null}

Jan 22 18:50:35.986: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h6q5f/pods","resourceVersion":"8448"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:50:36.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h6q5f" for this suite.
Jan 22 18:50:42.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:50:42.220: INFO: namespace: e2e-tests-daemonsets-h6q5f, resource: bindings, ignored listing per whitelist
Jan 22 18:50:42.288: INFO: namespace e2e-tests-daemonsets-h6q5f deletion completed in 6.236684557s

• [SLOW TEST:89.889 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:50:42.291: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-pn6t
STEP: Creating a pod to test atomic-volume-subpath
Jan 22 18:50:42.466: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pn6t" in namespace "e2e-tests-subpath-hhzfx" to be "success or failure"
Jan 22 18:50:42.470: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Pending", Reason="", readiness=false. Elapsed: 3.402207ms
Jan 22 18:50:44.476: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009626745s
Jan 22 18:50:46.480: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 4.014208218s
Jan 22 18:50:48.485: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 6.018934679s
Jan 22 18:50:50.490: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 8.023408518s
Jan 22 18:50:52.494: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 10.027653235s
Jan 22 18:50:54.498: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 12.032079742s
Jan 22 18:50:56.502: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 14.036079922s
Jan 22 18:50:58.507: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 16.040591302s
Jan 22 18:51:00.516: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 18.049386903s
Jan 22 18:51:02.520: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 20.054262565s
Jan 22 18:51:04.525: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Running", Reason="", readiness=false. Elapsed: 22.058726901s
Jan 22 18:51:06.530: INFO: Pod "pod-subpath-test-downwardapi-pn6t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.063726538s
STEP: Saw pod success
Jan 22 18:51:06.530: INFO: Pod "pod-subpath-test-downwardapi-pn6t" satisfied condition "success or failure"
Jan 22 18:51:06.534: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-subpath-test-downwardapi-pn6t container test-container-subpath-downwardapi-pn6t: <nil>
STEP: delete the pod
Jan 22 18:51:06.576: INFO: Waiting for pod pod-subpath-test-downwardapi-pn6t to disappear
Jan 22 18:51:06.580: INFO: Pod pod-subpath-test-downwardapi-pn6t no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-pn6t
Jan 22 18:51:06.580: INFO: Deleting pod "pod-subpath-test-downwardapi-pn6t" in namespace "e2e-tests-subpath-hhzfx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:51:06.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hhzfx" for this suite.
Jan 22 18:51:12.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:51:12.817: INFO: namespace: e2e-tests-subpath-hhzfx, resource: bindings, ignored listing per whitelist
Jan 22 18:51:12.827: INFO: namespace e2e-tests-subpath-hhzfx deletion completed in 6.239136632s

• [SLOW TEST:30.538 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:51:12.827: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-f5jzj
Jan 22 18:51:14.976: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-f5jzj
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 18:51:14.980: INFO: Initial restart count of pod liveness-http is 0
Jan 22 18:51:35.313: INFO: Restart count of pod e2e-tests-container-probe-f5jzj/liveness-http is now 1 (20.332740316s elapsed)
Jan 22 18:51:55.369: INFO: Restart count of pod e2e-tests-container-probe-f5jzj/liveness-http is now 2 (40.38950964s elapsed)
Jan 22 18:52:15.421: INFO: Restart count of pod e2e-tests-container-probe-f5jzj/liveness-http is now 3 (1m0.441434699s elapsed)
Jan 22 18:52:35.466: INFO: Restart count of pod e2e-tests-container-probe-f5jzj/liveness-http is now 4 (1m20.485943466s elapsed)
Jan 22 18:53:35.614: INFO: Restart count of pod e2e-tests-container-probe-f5jzj/liveness-http is now 5 (2m20.633536201s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:53:35.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f5jzj" for this suite.
Jan 22 18:53:41.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:53:41.849: INFO: namespace: e2e-tests-container-probe-f5jzj, resource: bindings, ignored listing per whitelist
Jan 22 18:53:41.928: INFO: namespace e2e-tests-container-probe-f5jzj deletion completed in 6.264382029s

• [SLOW TEST:149.101 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:53:41.928: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 22 18:53:42.152: INFO: Waiting up to 5m0s for pod "downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-l8hrv" to be "success or failure"
Jan 22 18:53:42.170: INFO: Pod "downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 17.619143ms
Jan 22 18:53:44.175: INFO: Pod "downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022512098s
Jan 22 18:53:46.180: INFO: Pod "downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027809855s
STEP: Saw pod success
Jan 22 18:53:46.180: INFO: Pod "downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:53:46.184: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 18:53:46.230: INFO: Waiting for pod downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:53:46.234: INFO: Pod downward-api-0987849a-1e77-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:53:46.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l8hrv" for this suite.
Jan 22 18:53:52.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:53:52.314: INFO: namespace: e2e-tests-downward-api-l8hrv, resource: bindings, ignored listing per whitelist
Jan 22 18:53:52.481: INFO: namespace e2e-tests-downward-api-l8hrv deletion completed in 6.241723957s

• [SLOW TEST:10.553 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:53:52.481: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 22 18:53:52.673: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 22 18:53:52.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:53:54.006: INFO: stderr: ""
Jan 22 18:53:54.006: INFO: stdout: "service/redis-slave created\n"
Jan 22 18:53:54.006: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 22 18:53:54.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:53:54.414: INFO: stderr: ""
Jan 22 18:53:54.414: INFO: stdout: "service/redis-master created\n"
Jan 22 18:53:54.414: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 22 18:53:54.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:53:54.792: INFO: stderr: ""
Jan 22 18:53:54.792: INFO: stdout: "service/frontend created\n"
Jan 22 18:53:54.792: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 22 18:53:54.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:53:55.195: INFO: stderr: ""
Jan 22 18:53:55.195: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 22 18:53:55.195: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 22 18:53:55.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:53:55.556: INFO: stderr: ""
Jan 22 18:53:55.556: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 22 18:53:55.557: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 22 18:53:55.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:53:56.038: INFO: stderr: ""
Jan 22 18:53:56.038: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 22 18:53:56.038: INFO: Waiting for all frontend pods to be Running.
Jan 22 18:54:31.089: INFO: Waiting for frontend to serve content.
Jan 22 18:54:36.111: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jan 22 18:54:41.165: INFO: Trying to add a new entry to the guestbook.
Jan 22 18:54:41.217: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 22 18:54:41.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:54:41.404: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:54:41.404: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 18:54:41.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:54:41.565: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:54:41.565: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 18:54:41.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:54:41.739: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:54:41.739: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 18:54:41.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:54:41.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:54:41.867: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 18:54:41.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:54:42.001: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:54:42.001: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 22 18:54:42.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqkbj'
Jan 22 18:54:42.264: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 18:54:42.264: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:54:42.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hqkbj" for this suite.
Jan 22 18:55:22.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:55:22.460: INFO: namespace: e2e-tests-kubectl-hqkbj, resource: bindings, ignored listing per whitelist
Jan 22 18:55:22.513: INFO: namespace e2e-tests-kubectl-hqkbj deletion completed in 40.235275228s

• [SLOW TEST:90.031 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:55:22.513: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 18:55:22.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-d2jwk" to be "success or failure"
Jan 22 18:55:22.672: INFO: Pod "downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.885902ms
Jan 22 18:55:24.677: INFO: Pod "downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014336459s
Jan 22 18:55:26.681: INFO: Pod "downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018235291s
STEP: Saw pod success
Jan 22 18:55:26.681: INFO: Pod "downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:55:26.685: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 18:55:26.715: INFO: Waiting for pod downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:55:26.718: INFO: Pod downwardapi-volume-4570fe13-1e77-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:55:26.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2jwk" for this suite.
Jan 22 18:55:32.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:55:32.863: INFO: namespace: e2e-tests-projected-d2jwk, resource: bindings, ignored listing per whitelist
Jan 22 18:55:32.926: INFO: namespace e2e-tests-projected-d2jwk deletion completed in 6.203010886s

• [SLOW TEST:10.413 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:55:32.926: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 22 18:55:33.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-kfqz7'
Jan 22 18:55:33.534: INFO: stderr: ""
Jan 22 18:55:33.534: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 22 18:55:34.543: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:55:34.543: INFO: Found 0 / 1
Jan 22 18:55:35.539: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:55:35.539: INFO: Found 0 / 1
Jan 22 18:55:36.539: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:55:36.539: INFO: Found 1 / 1
Jan 22 18:55:36.539: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 22 18:55:36.543: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:55:36.543: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 22 18:55:36.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 patch pod redis-master-5nwh6 --namespace=e2e-tests-kubectl-kfqz7 -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 22 18:55:36.667: INFO: stderr: ""
Jan 22 18:55:36.667: INFO: stdout: "pod/redis-master-5nwh6 patched\n"
STEP: checking annotations
Jan 22 18:55:36.671: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 18:55:36.671: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:55:36.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kfqz7" for this suite.
Jan 22 18:55:58.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:55:58.889: INFO: namespace: e2e-tests-kubectl-kfqz7, resource: bindings, ignored listing per whitelist
Jan 22 18:55:58.917: INFO: namespace e2e-tests-kubectl-kfqz7 deletion completed in 22.235551496s

• [SLOW TEST:25.991 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:55:58.918: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5b336437-1e77-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 18:55:59.182: INFO: Waiting up to 5m0s for pod "pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-x5fn9" to be "success or failure"
Jan 22 18:55:59.187: INFO: Pod "pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803847ms
Jan 22 18:56:01.192: INFO: Pod "pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009658063s
Jan 22 18:56:03.196: INFO: Pod "pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014215162s
STEP: Saw pod success
Jan 22 18:56:03.196: INFO: Pod "pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:56:03.200: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3 container secret-env-test: <nil>
STEP: delete the pod
Jan 22 18:56:03.236: INFO: Waiting for pod pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:56:03.240: INFO: Pod pod-secrets-5b351c13-1e77-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:56:03.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x5fn9" for this suite.
Jan 22 18:56:09.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:56:09.427: INFO: namespace: e2e-tests-secrets-x5fn9, resource: bindings, ignored listing per whitelist
Jan 22 18:56:09.479: INFO: namespace e2e-tests-secrets-x5fn9 deletion completed in 6.22709295s

• [SLOW TEST:10.561 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:56:09.479: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 22 18:56:09.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 --namespace=e2e-tests-kubectl-cvb25 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 22 18:56:12.461: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 22 18:56:12.461: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:56:14.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cvb25" for this suite.
Jan 22 18:56:20.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:56:20.637: INFO: namespace: e2e-tests-kubectl-cvb25, resource: bindings, ignored listing per whitelist
Jan 22 18:56:20.720: INFO: namespace e2e-tests-kubectl-cvb25 deletion completed in 6.232563878s

• [SLOW TEST:11.241 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:56:20.721: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 22 18:56:25.419: INFO: Successfully updated pod "pod-update-activedeadlineseconds-68254c24-1e77-11e9-9ccc-2ee9843eaab3"
Jan 22 18:56:25.419: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-68254c24-1e77-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-pods-fclkp" to be "terminated due to deadline exceeded"
Jan 22 18:56:25.423: INFO: Pod "pod-update-activedeadlineseconds-68254c24-1e77-11e9-9ccc-2ee9843eaab3": Phase="Running", Reason="", readiness=true. Elapsed: 3.96482ms
Jan 22 18:56:27.427: INFO: Pod "pod-update-activedeadlineseconds-68254c24-1e77-11e9-9ccc-2ee9843eaab3": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.008189613s
Jan 22 18:56:27.427: INFO: Pod "pod-update-activedeadlineseconds-68254c24-1e77-11e9-9ccc-2ee9843eaab3" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:56:27.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fclkp" for this suite.
Jan 22 18:56:33.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:56:33.657: INFO: namespace: e2e-tests-pods-fclkp, resource: bindings, ignored listing per whitelist
Jan 22 18:56:33.735: INFO: namespace e2e-tests-pods-fclkp deletion completed in 6.301998734s

• [SLOW TEST:13.015 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:56:33.736: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6feb64ed-1e77-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 18:56:33.938: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-dtskc" to be "success or failure"
Jan 22 18:56:33.942: INFO: Pod "pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96592ms
Jan 22 18:56:35.946: INFO: Pod "pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00814748s
Jan 22 18:56:37.950: INFO: Pod "pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012075624s
STEP: Saw pod success
Jan 22 18:56:37.950: INFO: Pod "pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:56:37.954: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 18:56:37.984: INFO: Waiting for pod pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:56:37.987: INFO: Pod pod-projected-configmaps-6fec668e-1e77-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:56:37.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dtskc" for this suite.
Jan 22 18:56:44.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:56:44.114: INFO: namespace: e2e-tests-projected-dtskc, resource: bindings, ignored listing per whitelist
Jan 22 18:56:44.178: INFO: namespace e2e-tests-projected-dtskc deletion completed in 6.18594568s

• [SLOW TEST:10.442 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:56:44.178: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 22 18:56:44.367: INFO: Waiting up to 5m0s for pod "downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-7zg9d" to be "success or failure"
Jan 22 18:56:44.370: INFO: Pod "downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.345802ms
Jan 22 18:56:46.382: INFO: Pod "downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014790443s
Jan 22 18:56:48.386: INFO: Pod "downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019233164s
STEP: Saw pod success
Jan 22 18:56:48.386: INFO: Pod "downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 18:56:48.391: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 18:56:48.427: INFO: Waiting for pod downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 18:56:48.432: INFO: Pod downward-api-76240031-1e77-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:56:48.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7zg9d" for this suite.
Jan 22 18:56:54.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:56:54.608: INFO: namespace: e2e-tests-downward-api-7zg9d, resource: bindings, ignored listing per whitelist
Jan 22 18:56:54.625: INFO: namespace e2e-tests-downward-api-7zg9d deletion completed in 6.188482238s

• [SLOW TEST:10.447 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:56:54.635: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 22 18:56:58.817: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 22 18:56:58.821: INFO: Pod pod-with-prestop-http-hook still exists
Jan 22 18:57:00.821: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 22 18:57:00.826: INFO: Pod pod-with-prestop-http-hook still exists
Jan 22 18:57:02.821: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 22 18:57:02.855: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:57:02.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-89gv8" for this suite.
Jan 22 18:57:24.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:57:24.915: INFO: namespace: e2e-tests-container-lifecycle-hook-89gv8, resource: bindings, ignored listing per whitelist
Jan 22 18:57:25.052: INFO: namespace e2e-tests-container-lifecycle-hook-89gv8 deletion completed in 22.177047964s

• [SLOW TEST:30.417 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:57:25.053: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 22 18:57:25.257: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vc422,SelfLink:/api/v1/namespaces/e2e-tests-watch-vc422/configmaps/e2e-watch-test-label-changed,UID:8e82315f-1e77-11e9-a380-de5a8a93737b,ResourceVersion:9660,Generation:0,CreationTimestamp:2019-01-22 18:57:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 18:57:25.257: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vc422,SelfLink:/api/v1/namespaces/e2e-tests-watch-vc422/configmaps/e2e-watch-test-label-changed,UID:8e82315f-1e77-11e9-a380-de5a8a93737b,ResourceVersion:9661,Generation:0,CreationTimestamp:2019-01-22 18:57:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 22 18:57:25.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vc422,SelfLink:/api/v1/namespaces/e2e-tests-watch-vc422/configmaps/e2e-watch-test-label-changed,UID:8e82315f-1e77-11e9-a380-de5a8a93737b,ResourceVersion:9662,Generation:0,CreationTimestamp:2019-01-22 18:57:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 22 18:57:35.303: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vc422,SelfLink:/api/v1/namespaces/e2e-tests-watch-vc422/configmaps/e2e-watch-test-label-changed,UID:8e82315f-1e77-11e9-a380-de5a8a93737b,ResourceVersion:9680,Generation:0,CreationTimestamp:2019-01-22 18:57:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 18:57:35.303: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vc422,SelfLink:/api/v1/namespaces/e2e-tests-watch-vc422/configmaps/e2e-watch-test-label-changed,UID:8e82315f-1e77-11e9-a380-de5a8a93737b,ResourceVersion:9681,Generation:0,CreationTimestamp:2019-01-22 18:57:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 22 18:57:35.303: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-vc422,SelfLink:/api/v1/namespaces/e2e-tests-watch-vc422/configmaps/e2e-watch-test-label-changed,UID:8e82315f-1e77-11e9-a380-de5a8a93737b,ResourceVersion:9682,Generation:0,CreationTimestamp:2019-01-22 18:57:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 18:57:35.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vc422" for this suite.
Jan 22 18:57:41.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 18:57:41.491: INFO: namespace: e2e-tests-watch-vc422, resource: bindings, ignored listing per whitelist
Jan 22 18:57:41.498: INFO: namespace e2e-tests-watch-vc422 deletion completed in 6.189836572s

• [SLOW TEST:16.445 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 18:57:41.498: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-c7jdq
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-c7jdq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-c7jdq
Jan 22 18:57:41.666: INFO: Found 0 stateful pods, waiting for 1
Jan 22 18:57:51.674: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 22 18:57:51.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 18:57:52.176: INFO: stderr: ""
Jan 22 18:57:52.176: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 18:57:52.176: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 18:57:52.181: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 22 18:58:02.187: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 18:58:02.187: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 18:58:02.208: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999997s
Jan 22 18:58:03.216: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996050217s
Jan 22 18:58:04.220: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988408924s
Jan 22 18:58:05.225: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983867326s
Jan 22 18:58:06.231: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979279429s
Jan 22 18:58:07.235: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.973400894s
Jan 22 18:58:08.240: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.968952403s
Jan 22 18:58:09.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964556917s
Jan 22 18:58:10.252: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.957936464s
Jan 22 18:58:11.257: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.052835ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-c7jdq
Jan 22 18:58:12.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:58:12.734: INFO: stderr: ""
Jan 22 18:58:12.734: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 18:58:12.734: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 18:58:12.739: INFO: Found 1 stateful pods, waiting for 3
Jan 22 18:58:22.744: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 18:58:22.744: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 18:58:22.744: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 22 18:58:22.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 18:58:23.175: INFO: stderr: ""
Jan 22 18:58:23.175: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 18:58:23.175: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 18:58:23.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 18:58:23.620: INFO: stderr: ""
Jan 22 18:58:23.620: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 18:58:23.620: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 18:58:23.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 18:58:24.018: INFO: stderr: ""
Jan 22 18:58:24.018: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 18:58:24.018: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 18:58:24.018: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 18:58:24.022: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 22 18:58:34.031: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 18:58:34.031: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 18:58:34.031: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 18:58:34.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999997s
Jan 22 18:58:35.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993250882s
Jan 22 18:58:36.061: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988267218s
Jan 22 18:58:37.066: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982855543s
Jan 22 18:58:38.134: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977143661s
Jan 22 18:58:39.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.909556011s
Jan 22 18:58:40.146: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.903898733s
Jan 22 18:58:41.228: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.89733233s
Jan 22 18:58:42.233: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.815723761s
Jan 22 18:58:43.239: INFO: Verifying statefulset ss doesn't scale past 3 for another 810.998016ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-c7jdq
Jan 22 18:58:44.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:58:44.643: INFO: stderr: ""
Jan 22 18:58:44.643: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 18:58:44.643: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 18:58:44.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:58:45.027: INFO: stderr: ""
Jan 22 18:58:45.027: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 18:58:45.027: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 18:58:45.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:58:45.614: INFO: rc: 1
Jan 22 18:58:45.614: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (e20c9136489ca18b33dcc46b484f8566a0a19b515d218e261fafbf6e272e92fa)
 [] <nil> 0xc42278acc0 exit status 1 <nil> <nil> true [0xc42387be68 0xc42387be80 0xc42387be98] [0xc42387be68 0xc42387be80 0xc42387be98] [0xc42387be78 0xc42387be90] [0x8fd520 0x8fd520] 0xc421396360 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (e20c9136489ca18b33dcc46b484f8566a0a19b515d218e261fafbf6e272e92fa)

error:
exit status 1

Jan 22 18:58:55.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:58:55.891: INFO: rc: 1
Jan 22 18:58:55.892: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc423756300 exit status 1 <nil> <nil> true [0xc4200cc188 0xc4200cc1c0 0xc4200cc288] [0xc4200cc188 0xc4200cc1c0 0xc4200cc288] [0xc4200cc1b8 0xc4200cc218] [0x8fd520 0x8fd520] 0xc423662060 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jan 22 18:59:05.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:59:06.006: INFO: rc: 1
Jan 22 18:59:06.006: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756840 exit status 1 <nil> <nil> true [0xc4200cc2a0 0xc4200cc3e0 0xc4200cc530] [0xc4200cc2a0 0xc4200cc3e0 0xc4200cc530] [0xc4200cc3d0 0xc4200cc448] [0x8fd520 0x8fd520] 0xc423662180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 18:59:16.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:59:16.120: INFO: rc: 1
Jan 22 18:59:16.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756bd0 exit status 1 <nil> <nil> true [0xc4200cc548 0xc4200cc790 0xc4200cc830] [0xc4200cc548 0xc4200cc790 0xc4200cc830] [0xc4200cc700 0xc4200cc7f8] [0x8fd520 0x8fd520] 0xc4236622a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 18:59:26.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:59:26.238: INFO: rc: 1
Jan 22 18:59:26.238: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c0360 exit status 1 <nil> <nil> true [0xc42000e010 0xc422a52010 0xc422a52028] [0xc42000e010 0xc422a52010 0xc422a52028] [0xc422a52008 0xc422a52020] [0x8fd520 0x8fd520] 0xc421b960c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 18:59:36.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:59:36.360: INFO: rc: 1
Jan 22 18:59:36.361: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c07b0 exit status 1 <nil> <nil> true [0xc422a52030 0xc422a52048 0xc422a52060] [0xc422a52030 0xc422a52048 0xc422a52060] [0xc422a52040 0xc422a52058] [0x8fd520 0x8fd520] 0xc421b96300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 18:59:46.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:59:46.477: INFO: rc: 1
Jan 22 18:59:46.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c0ae0 exit status 1 <nil> <nil> true [0xc422a52068 0xc422a52080 0xc422a52098] [0xc422a52068 0xc422a52080 0xc422a52098] [0xc422a52078 0xc422a52090] [0x8fd520 0x8fd520] 0xc421b96420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 18:59:56.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 18:59:56.592: INFO: rc: 1
Jan 22 18:59:56.592: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756f60 exit status 1 <nil> <nil> true [0xc4200cc890 0xc4200ccd98 0xc4200cd9d8] [0xc4200cc890 0xc4200ccd98 0xc4200cd9d8] [0xc4200ccd10 0xc4200cce88] [0x8fd520 0x8fd520] 0xc4236623c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:00:06.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:00:06.725: INFO: rc: 1
Jan 22 19:00:06.725: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757320 exit status 1 <nil> <nil> true [0xc4200cda20 0xc4200cda88 0xc4200cdaf8] [0xc4200cda20 0xc4200cda88 0xc4200cdaf8] [0xc4200cda60 0xc4200cdae8] [0x8fd520 0x8fd520] 0xc4236624e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:00:16.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:00:16.882: INFO: rc: 1
Jan 22 19:00:16.882: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757650 exit status 1 <nil> <nil> true [0xc4200cdb08 0xc4200cdbd0 0xc4200cdca0] [0xc4200cdb08 0xc4200cdbd0 0xc4200cdca0] [0xc4200cdba8 0xc4200cdc50] [0x8fd520 0x8fd520] 0xc423662600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:00:26.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:00:26.998: INFO: rc: 1
Jan 22 19:00:26.998: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757980 exit status 1 <nil> <nil> true [0xc4200cdcc0 0xc4200cdd98 0xc42387a010] [0xc4200cdcc0 0xc4200cdd98 0xc42387a010] [0xc4200cdd08 0xc42387a008] [0x8fd520 0x8fd520] 0xc423662720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:00:36.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:00:37.113: INFO: rc: 1
Jan 22 19:00:37.113: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757cb0 exit status 1 <nil> <nil> true [0xc42387a018 0xc42387a030 0xc42387a048] [0xc42387a018 0xc42387a030 0xc42387a048] [0xc42387a028 0xc42387a040] [0x8fd520 0x8fd520] 0xc423662840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:00:47.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:00:47.228: INFO: rc: 1
Jan 22 19:00:47.228: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c0e10 exit status 1 <nil> <nil> true [0xc422a520a0 0xc422a520b8 0xc422a520d0] [0xc422a520a0 0xc422a520b8 0xc422a520d0] [0xc422a520b0 0xc422a520c8] [0x8fd520 0x8fd520] 0xc421b96540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:00:57.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:00:57.365: INFO: rc: 1
Jan 22 19:00:57.365: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c1230 exit status 1 <nil> <nil> true [0xc422a520e0 0xc422a520f8 0xc422a52110] [0xc422a520e0 0xc422a520f8 0xc422a52110] [0xc422a520f0 0xc422a52108] [0x8fd520 0x8fd520] 0xc421b96660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:01:07.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:01:07.487: INFO: rc: 1
Jan 22 19:01:07.487: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756330 exit status 1 <nil> <nil> true [0xc42000e010 0xc4200cc198 0xc4200cc1e8] [0xc42000e010 0xc4200cc198 0xc4200cc1e8] [0xc4200cc188 0xc4200cc1c0] [0x8fd520 0x8fd520] 0xc423662060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:01:17.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:01:17.606: INFO: rc: 1
Jan 22 19:01:17.606: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4237568d0 exit status 1 <nil> <nil> true [0xc4200cc218 0xc4200cc2b8 0xc4200cc410] [0xc4200cc218 0xc4200cc2b8 0xc4200cc410] [0xc4200cc2a0 0xc4200cc3e0] [0x8fd520 0x8fd520] 0xc423662180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:01:27.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:01:27.717: INFO: rc: 1
Jan 22 19:01:27.717: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756c90 exit status 1 <nil> <nil> true [0xc4200cc448 0xc4200cc568 0xc4200cc7e0] [0xc4200cc448 0xc4200cc568 0xc4200cc7e0] [0xc4200cc548 0xc4200cc790] [0x8fd520 0x8fd520] 0xc4236622a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:01:37.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:01:37.869: INFO: rc: 1
Jan 22 19:01:37.869: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c0330 exit status 1 <nil> <nil> true [0xc42387a000 0xc42387a018 0xc42387a030] [0xc42387a000 0xc42387a018 0xc42387a030] [0xc42387a010 0xc42387a028] [0x8fd520 0x8fd520] 0xc421b960c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:01:47.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:01:47.996: INFO: rc: 1
Jan 22 19:01:47.996: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c07e0 exit status 1 <nil> <nil> true [0xc42387a038 0xc42387a050 0xc42387a068] [0xc42387a038 0xc42387a050 0xc42387a068] [0xc42387a048 0xc42387a060] [0x8fd520 0x8fd520] 0xc421b96300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:01:57.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:01:58.110: INFO: rc: 1
Jan 22 19:01:58.110: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c0b40 exit status 1 <nil> <nil> true [0xc42387a070 0xc42387a088 0xc42387a0a0] [0xc42387a070 0xc42387a088 0xc42387a0a0] [0xc42387a080 0xc42387a098] [0x8fd520 0x8fd520] 0xc421b96420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:02:08.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:02:08.227: INFO: rc: 1
Jan 22 19:02:08.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4237570b0 exit status 1 <nil> <nil> true [0xc4200cc7f8 0xc4200cccf8 0xc4200ccdc0] [0xc4200cc7f8 0xc4200cccf8 0xc4200ccdc0] [0xc4200cc890 0xc4200ccd98] [0x8fd520 0x8fd520] 0xc4236623c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:02:18.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:02:18.343: INFO: rc: 1
Jan 22 19:02:18.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757470 exit status 1 <nil> <nil> true [0xc4200cce88 0xc4200cda48 0xc4200cdab0] [0xc4200cce88 0xc4200cda48 0xc4200cdab0] [0xc4200cda20 0xc4200cda88] [0x8fd520 0x8fd520] 0xc4236624e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:02:28.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:02:28.463: INFO: rc: 1
Jan 22 19:02:28.464: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4237577d0 exit status 1 <nil> <nil> true [0xc4200cdae8 0xc4200cdb48 0xc4200cdc00] [0xc4200cdae8 0xc4200cdb48 0xc4200cdc00] [0xc4200cdb08 0xc4200cdbd0] [0x8fd520 0x8fd520] 0xc423662600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:02:38.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:02:38.594: INFO: rc: 1
Jan 22 19:02:38.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4204c1260 exit status 1 <nil> <nil> true [0xc42387a0a8 0xc42387a0c0 0xc42387a0d8] [0xc42387a0a8 0xc42387a0c0 0xc42387a0d8] [0xc42387a0b8 0xc42387a0d0] [0x8fd520 0x8fd520] 0xc421b96540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:02:48.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:02:48.713: INFO: rc: 1
Jan 22 19:02:48.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757b60 exit status 1 <nil> <nil> true [0xc4200cdc50 0xc4200cdcd8 0xc422a52000] [0xc4200cdc50 0xc4200cdcd8 0xc422a52000] [0xc4200cdcc0 0xc4200cdd98] [0x8fd520 0x8fd520] 0xc423662720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:02:58.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:02:58.856: INFO: rc: 1
Jan 22 19:02:58.856: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423757f20 exit status 1 <nil> <nil> true [0xc422a52010 0xc422a52028 0xc422a52040] [0xc422a52010 0xc422a52028 0xc422a52040] [0xc422a52020 0xc422a52038] [0x8fd520 0x8fd520] 0xc423662840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:03:08.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:03:09.012: INFO: rc: 1
Jan 22 19:03:09.012: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756300 exit status 1 <nil> <nil> true [0xc4200cc0f8 0xc4200cc1b8 0xc4200cc218] [0xc4200cc0f8 0xc4200cc1b8 0xc4200cc218] [0xc4200cc198 0xc4200cc1e8] [0x8fd520 0x8fd520] 0xc423662060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:03:19.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:03:19.124: INFO: rc: 1
Jan 22 19:03:19.124: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4237568a0 exit status 1 <nil> <nil> true [0xc4200cc288 0xc4200cc3d0 0xc4200cc448] [0xc4200cc288 0xc4200cc3d0 0xc4200cc448] [0xc4200cc2b8 0xc4200cc410] [0x8fd520 0x8fd520] 0xc423662180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:03:29.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:03:29.236: INFO: rc: 1
Jan 22 19:03:29.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756c30 exit status 1 <nil> <nil> true [0xc4200cc530 0xc4200cc700 0xc4200cc7f8] [0xc4200cc530 0xc4200cc700 0xc4200cc7f8] [0xc4200cc568 0xc4200cc7e0] [0x8fd520 0x8fd520] 0xc4236622a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:03:39.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:03:39.364: INFO: rc: 1
Jan 22 19:03:39.364: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc423756f90 exit status 1 <nil> <nil> true [0xc4200cc830 0xc4200ccd10 0xc4200cce88] [0xc4200cc830 0xc4200ccd10 0xc4200cce88] [0xc4200cccf8 0xc4200ccdc0] [0x8fd520 0x8fd520] 0xc4236623c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jan 22 19:03:49.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-c7jdq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:03:49.503: INFO: rc: 1
Jan 22 19:03:49.503: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jan 22 19:03:49.503: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 22 19:03:49.522: INFO: Deleting all statefulset in ns e2e-tests-statefulset-c7jdq
Jan 22 19:03:49.527: INFO: Scaling statefulset ss to 0
Jan 22 19:03:49.537: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 19:03:49.548: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:03:49.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-c7jdq" for this suite.
Jan 22 19:03:55.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:03:55.735: INFO: namespace: e2e-tests-statefulset-c7jdq, resource: bindings, ignored listing per whitelist
Jan 22 19:03:55.813: INFO: namespace e2e-tests-statefulset-c7jdq deletion completed in 6.242010485s

• [SLOW TEST:374.315 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:03:55.813: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jtncb
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 22 19:03:55.965: INFO: Found 0 stateful pods, waiting for 3
Jan 22 19:04:05.970: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:04:05.970: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:04:05.970: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 22 19:04:06.009: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 22 19:04:16.050: INFO: Updating stateful set ss2
Jan 22 19:04:16.059: INFO: Waiting for Pod e2e-tests-statefulset-jtncb/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:04:26.067: INFO: Waiting for Pod e2e-tests-statefulset-jtncb/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 22 19:04:36.142: INFO: Found 2 stateful pods, waiting for 3
Jan 22 19:04:46.148: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:04:46.148: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:04:46.148: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 22 19:04:46.178: INFO: Updating stateful set ss2
Jan 22 19:04:46.203: INFO: Waiting for Pod e2e-tests-statefulset-jtncb/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:04:56.235: INFO: Updating stateful set ss2
Jan 22 19:04:56.246: INFO: Waiting for StatefulSet e2e-tests-statefulset-jtncb/ss2 to complete update
Jan 22 19:04:56.246: INFO: Waiting for Pod e2e-tests-statefulset-jtncb/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:05:06.255: INFO: Waiting for StatefulSet e2e-tests-statefulset-jtncb/ss2 to complete update
Jan 22 19:05:06.255: INFO: Waiting for Pod e2e-tests-statefulset-jtncb/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 22 19:05:16.264: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jtncb
Jan 22 19:05:16.268: INFO: Scaling statefulset ss2 to 0
Jan 22 19:05:36.310: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 19:05:36.313: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:05:36.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jtncb" for this suite.
Jan 22 19:05:42.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:05:42.504: INFO: namespace: e2e-tests-statefulset-jtncb, resource: bindings, ignored listing per whitelist
Jan 22 19:05:42.504: INFO: namespace e2e-tests-statefulset-jtncb deletion completed in 6.156096843s

• [SLOW TEST:106.690 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:05:42.504: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 22 19:05:42.693: INFO: Waiting up to 5m0s for pod "pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-gcdzq" to be "success or failure"
Jan 22 19:05:42.697: INFO: Pod "pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.506504ms
Jan 22 19:05:44.704: INFO: Pod "pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010385068s
Jan 22 19:05:46.708: INFO: Pod "pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01457745s
STEP: Saw pod success
Jan 22 19:05:46.708: INFO: Pod "pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:05:46.712: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:05:46.744: INFO: Waiting for pod pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:05:46.749: INFO: Pod pod-b7028b64-1e78-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:05:46.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gcdzq" for this suite.
Jan 22 19:05:52.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:05:52.970: INFO: namespace: e2e-tests-emptydir-gcdzq, resource: bindings, ignored listing per whitelist
Jan 22 19:05:52.989: INFO: namespace e2e-tests-emptydir-gcdzq deletion completed in 6.232522677s

• [SLOW TEST:10.485 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:05:52.990: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 22 19:06:01.559: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 22 19:06:01.562: INFO: Pod pod-with-poststart-http-hook still exists
Jan 22 19:06:03.563: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 22 19:06:03.568: INFO: Pod pod-with-poststart-http-hook still exists
Jan 22 19:06:05.563: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 22 19:06:05.568: INFO: Pod pod-with-poststart-http-hook still exists
Jan 22 19:06:07.563: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 22 19:06:07.567: INFO: Pod pod-with-poststart-http-hook still exists
Jan 22 19:06:09.563: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 22 19:06:09.567: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:06:09.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gqm82" for this suite.
Jan 22 19:06:31.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:06:31.800: INFO: namespace: e2e-tests-container-lifecycle-hook-gqm82, resource: bindings, ignored listing per whitelist
Jan 22 19:06:31.814: INFO: namespace e2e-tests-container-lifecycle-hook-gqm82 deletion completed in 22.242653263s

• [SLOW TEST:38.824 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:06:31.815: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-g99kv
Jan 22 19:06:36.054: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-g99kv
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 19:06:36.058: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:10:36.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-g99kv" for this suite.
Jan 22 19:10:42.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:10:42.980: INFO: namespace: e2e-tests-container-probe-g99kv, resource: bindings, ignored listing per whitelist
Jan 22 19:10:43.109: INFO: namespace e2e-tests-container-probe-g99kv deletion completed in 6.228997691s

• [SLOW TEST:251.294 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:10:43.110: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 19:10:43.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-mwswn'
Jan 22 19:10:44.745: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 22 19:10:44.745: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan 22 19:10:44.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-mwswn'
Jan 22 19:10:44.884: INFO: stderr: ""
Jan 22 19:10:44.884: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:10:44.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mwswn" for this suite.
Jan 22 19:10:50.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:10:51.070: INFO: namespace: e2e-tests-kubectl-mwswn, resource: bindings, ignored listing per whitelist
Jan 22 19:10:51.113: INFO: namespace e2e-tests-kubectl-mwswn deletion completed in 6.223461909s

• [SLOW TEST:8.003 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:10:51.114: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 22 19:10:51.292: INFO: Waiting up to 5m0s for pod "var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-var-expansion-xvk7k" to be "success or failure"
Jan 22 19:10:51.303: INFO: Pod "var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.033426ms
Jan 22 19:10:53.326: INFO: Pod "var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033961965s
Jan 22 19:10:55.331: INFO: Pod "var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038829667s
STEP: Saw pod success
Jan 22 19:10:55.331: INFO: Pod "var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:10:55.335: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 19:10:55.388: INFO: Waiting for pod var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:10:55.395: INFO: Pod var-expansion-6ef22e06-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:10:55.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xvk7k" for this suite.
Jan 22 19:11:01.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:11:01.529: INFO: namespace: e2e-tests-var-expansion-xvk7k, resource: bindings, ignored listing per whitelist
Jan 22 19:11:01.628: INFO: namespace e2e-tests-var-expansion-xvk7k deletion completed in 6.228650139s

• [SLOW TEST:10.514 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:11:01.628: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:11:01.761: INFO: Creating deployment "test-recreate-deployment"
Jan 22 19:11:01.769: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 22 19:11:02.162: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 22 19:11:04.170: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 22 19:11:04.174: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781062, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781062, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781062, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781062, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:11:06.178: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 22 19:11:06.192: INFO: Updating deployment test-recreate-deployment
Jan 22 19:11:06.192: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 22 19:11:06.360: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-kg2cj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kg2cj/deployments/test-recreate-deployment,UID:75330423-1e79-11e9-a380-de5a8a93737b,ResourceVersion:11562,Generation:2,CreationTimestamp:2019-01-22 19:11:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-22 19:11:06 +0000 UTC 2019-01-22 19:11:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-22 19:11:06 +0000 UTC 2019-01-22 19:11:02 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 22 19:11:06.366: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-kg2cj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kg2cj/replicasets/test-recreate-deployment-7cf749666b,UID:77e211a3-1e79-11e9-a380-de5a8a93737b,ResourceVersion:11561,Generation:1,CreationTimestamp:2019-01-22 19:11:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 75330423-1e79-11e9-a380-de5a8a93737b 0xc42117bc17 0xc42117bc18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 22 19:11:06.366: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 22 19:11:06.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-kg2cj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kg2cj/replicasets/test-recreate-deployment-79f694ff59,UID:7548b46e-1e79-11e9-a380-de5a8a93737b,ResourceVersion:11551,Generation:2,CreationTimestamp:2019-01-22 19:11:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 75330423-1e79-11e9-a380-de5a8a93737b 0xc42117ba67 0xc42117ba68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 22 19:11:06.373: INFO: Pod "test-recreate-deployment-7cf749666b-6j7f6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-6j7f6,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-kg2cj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kg2cj/pods/test-recreate-deployment-7cf749666b-6j7f6,UID:77e3ecbd-1e79-11e9-a380-de5a8a93737b,ResourceVersion:11563,Generation:0,CreationTimestamp:2019-01-22 19:11:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 77e211a3-1e79-11e9-a380-de5a8a93737b 0xc42224ea47 0xc42224ea48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dl2wc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dl2wc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-dl2wc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42224eac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42224eae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:11:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:11:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:11:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:11:06 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:,StartTime:2019-01-22 19:11:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:11:06.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kg2cj" for this suite.
Jan 22 19:11:12.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:11:12.463: INFO: namespace: e2e-tests-deployment-kg2cj, resource: bindings, ignored listing per whitelist
Jan 22 19:11:12.624: INFO: namespace e2e-tests-deployment-kg2cj deletion completed in 6.239778845s

• [SLOW TEST:10.995 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:11:12.624: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 22 19:11:14.842: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-7bc66a96-1e79-11e9-9ccc-2ee9843eaab3", GenerateName:"", Namespace:"e2e-tests-pods-p5shn", SelfLink:"/api/v1/namespaces/e2e-tests-pods-p5shn/pods/pod-submit-remove-7bc66a96-1e79-11e9-9ccc-2ee9843eaab3", UID:"7bc8a187-1e79-11e9-a380-de5a8a93737b", ResourceVersion:"11615", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683781072, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"798790251"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-p9s5w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4204cb200), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_PORT_443_TCP_ADDR", Value:"levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"KUBERNETES_PORT", Value:"tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"KUBERNETES_PORT_443_TCP", Value:"tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-p9s5w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4211fd908), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"aks-nodepool1-25266157-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421a552c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4211fdae0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4211fdb70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4211fdb78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781072, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781074, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781074, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683781072, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.240.0.4", PodIP:"10.244.1.122", StartTime:(*v1.Time)(0xc420e4b7c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420e4b7e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://78455f617640f577f0fc2a7d829ee432c2b3f6bcdd8680889cc8b12745cfe4ef"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 22 19:11:19.872: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:11:19.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p5shn" for this suite.
Jan 22 19:11:25.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:11:26.087: INFO: namespace: e2e-tests-pods-p5shn, resource: bindings, ignored listing per whitelist
Jan 22 19:11:26.120: INFO: namespace e2e-tests-pods-p5shn deletion completed in 6.240027024s

• [SLOW TEST:13.496 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:11:26.121: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:11:26.333: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-6lkmz" to be "success or failure"
Jan 22 19:11:26.352: INFO: Pod "downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 19.717784ms
Jan 22 19:11:28.357: INFO: Pod "downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024522762s
Jan 22 19:11:30.362: INFO: Pod "downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029913855s
STEP: Saw pod success
Jan 22 19:11:30.363: INFO: Pod "downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:11:30.376: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:11:30.433: INFO: Waiting for pod downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:11:30.436: INFO: Pod downwardapi-volume-83d4b756-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:11:30.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6lkmz" for this suite.
Jan 22 19:11:36.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:11:36.591: INFO: namespace: e2e-tests-projected-6lkmz, resource: bindings, ignored listing per whitelist
Jan 22 19:11:36.591: INFO: namespace e2e-tests-projected-6lkmz deletion completed in 6.151373577s

• [SLOW TEST:10.471 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:11:36.592: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8a08b9d4-1e79-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:11:36.743: INFO: Waiting up to 5m0s for pod "pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-q57np" to be "success or failure"
Jan 22 19:11:36.746: INFO: Pod "pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.219395ms
Jan 22 19:11:38.751: INFO: Pod "pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007878262s
Jan 22 19:11:40.755: INFO: Pod "pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011900708s
STEP: Saw pod success
Jan 22 19:11:40.755: INFO: Pod "pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:11:40.758: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:11:40.792: INFO: Waiting for pod pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:11:40.800: INFO: Pod pod-configmaps-8a0a26d3-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:11:40.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q57np" for this suite.
Jan 22 19:11:46.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:11:46.950: INFO: namespace: e2e-tests-configmap-q57np, resource: bindings, ignored listing per whitelist
Jan 22 19:11:47.038: INFO: namespace e2e-tests-configmap-q57np deletion completed in 6.23320548s

• [SLOW TEST:10.446 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:11:47.039: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 22 19:11:47.185: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:11:51.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-llrbp" for this suite.
Jan 22 19:11:57.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:11:57.603: INFO: namespace: e2e-tests-init-container-llrbp, resource: bindings, ignored listing per whitelist
Jan 22 19:11:57.629: INFO: namespace e2e-tests-init-container-llrbp deletion completed in 6.175729157s

• [SLOW TEST:10.591 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:11:57.632: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 22 19:11:57.811: INFO: Waiting up to 5m0s for pod "pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-qddv7" to be "success or failure"
Jan 22 19:11:57.826: INFO: Pod "pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.825268ms
Jan 22 19:11:59.833: INFO: Pod "pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02279959s
STEP: Saw pod success
Jan 22 19:11:59.833: INFO: Pod "pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:11:59.837: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:11:59.873: INFO: Waiting for pod pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:11:59.880: INFO: Pod pod-9698a8d3-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:11:59.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qddv7" for this suite.
Jan 22 19:12:05.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:12:05.965: INFO: namespace: e2e-tests-emptydir-qddv7, resource: bindings, ignored listing per whitelist
Jan 22 19:12:06.182: INFO: namespace e2e-tests-emptydir-qddv7 deletion completed in 6.297074433s

• [SLOW TEST:8.551 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:12:06.182: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:12:06.386: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-qpc84" to be "success or failure"
Jan 22 19:12:06.391: INFO: Pod "downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.74367ms
Jan 22 19:12:08.396: INFO: Pod "downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010227013s
Jan 22 19:12:10.404: INFO: Pod "downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01793315s
STEP: Saw pod success
Jan 22 19:12:10.404: INFO: Pod "downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:12:10.407: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:12:10.459: INFO: Waiting for pod downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:12:10.462: INFO: Pod downwardapi-volume-9bb39c4b-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:12:10.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qpc84" for this suite.
Jan 22 19:12:16.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:12:16.612: INFO: namespace: e2e-tests-downward-api-qpc84, resource: bindings, ignored listing per whitelist
Jan 22 19:12:16.654: INFO: namespace e2e-tests-downward-api-qpc84 deletion completed in 6.182583224s

• [SLOW TEST:10.471 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:12:16.654: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:12:16.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qgvpc" for this suite.
Jan 22 19:12:22.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:12:23.153: INFO: namespace: e2e-tests-services-qgvpc, resource: bindings, ignored listing per whitelist
Jan 22 19:12:23.157: INFO: namespace e2e-tests-services-qgvpc deletion completed in 6.343867486s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.503 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:12:23.157: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 22 19:12:23.331: INFO: Waiting up to 5m0s for pod "pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-4tv6m" to be "success or failure"
Jan 22 19:12:23.335: INFO: Pod "pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155123ms
Jan 22 19:12:25.340: INFO: Pod "pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008850862s
STEP: Saw pod success
Jan 22 19:12:25.340: INFO: Pod "pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:12:25.344: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:12:25.380: INFO: Waiting for pod pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:12:25.384: INFO: Pod pod-a5cea170-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:12:25.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4tv6m" for this suite.
Jan 22 19:12:31.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:12:31.567: INFO: namespace: e2e-tests-emptydir-4tv6m, resource: bindings, ignored listing per whitelist
Jan 22 19:12:31.637: INFO: namespace e2e-tests-emptydir-4tv6m deletion completed in 6.247497317s

• [SLOW TEST:8.480 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:12:31.638: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 22 19:12:31.785: INFO: namespace e2e-tests-kubectl-hckpz
Jan 22 19:12:31.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-hckpz'
Jan 22 19:12:32.170: INFO: stderr: ""
Jan 22 19:12:32.170: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 22 19:12:33.175: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:12:33.175: INFO: Found 0 / 1
Jan 22 19:12:34.175: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:12:34.175: INFO: Found 0 / 1
Jan 22 19:12:35.178: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:12:35.178: INFO: Found 1 / 1
Jan 22 19:12:35.178: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 22 19:12:35.184: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:12:35.184: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 22 19:12:35.184: INFO: wait on redis-master startup in e2e-tests-kubectl-hckpz 
Jan 22 19:12:35.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 logs redis-master-25krr redis-master --namespace=e2e-tests-kubectl-hckpz'
Jan 22 19:12:35.334: INFO: stderr: ""
Jan 22 19:12:35.334: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Jan 19:12:33.858 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Jan 19:12:33.858 # Server started, Redis version 3.2.12\n1:M 22 Jan 19:12:33.858 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Jan 19:12:33.858 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 22 19:12:35.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hckpz'
Jan 22 19:12:35.478: INFO: stderr: ""
Jan 22 19:12:35.478: INFO: stdout: "service/rm2 exposed\n"
Jan 22 19:12:35.481: INFO: Service rm2 in namespace e2e-tests-kubectl-hckpz found.
STEP: exposing service
Jan 22 19:12:37.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hckpz'
Jan 22 19:12:37.644: INFO: stderr: ""
Jan 22 19:12:37.644: INFO: stdout: "service/rm3 exposed\n"
Jan 22 19:12:37.656: INFO: Service rm3 in namespace e2e-tests-kubectl-hckpz found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:12:39.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hckpz" for this suite.
Jan 22 19:13:01.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:13:01.731: INFO: namespace: e2e-tests-kubectl-hckpz, resource: bindings, ignored listing per whitelist
Jan 22 19:13:01.820: INFO: namespace e2e-tests-kubectl-hckpz deletion completed in 22.148404022s

• [SLOW TEST:30.182 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:13:01.820: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 22 19:13:01.949: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-545960299 proxy --unix-socket=/tmp/kubectl-proxy-unix414405070/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:13:02.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-55p2k" for this suite.
Jan 22 19:13:08.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:13:08.193: INFO: namespace: e2e-tests-kubectl-55p2k, resource: bindings, ignored listing per whitelist
Jan 22 19:13:08.276: INFO: namespace e2e-tests-kubectl-55p2k deletion completed in 6.248572984s

• [SLOW TEST:6.456 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:13:08.277: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-4xr2x
I0122 19:13:08.399856      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-4xr2x, replica count: 1
I0122 19:13:09.450253      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 19:13:10.450473      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 19:13:11.450713      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 22 19:13:11.573: INFO: Created: latency-svc-skb2k
Jan 22 19:13:11.587: INFO: Got endpoints: latency-svc-skb2k [36.606383ms]
Jan 22 19:13:11.613: INFO: Created: latency-svc-l4zqr
Jan 22 19:13:11.629: INFO: Got endpoints: latency-svc-l4zqr [39.87158ms]
Jan 22 19:13:11.638: INFO: Created: latency-svc-98sls
Jan 22 19:13:11.660: INFO: Created: latency-svc-4mx9d
Jan 22 19:13:11.663: INFO: Got endpoints: latency-svc-98sls [74.469804ms]
Jan 22 19:13:11.672: INFO: Got endpoints: latency-svc-4mx9d [82.669946ms]
Jan 22 19:13:11.682: INFO: Created: latency-svc-fbq7b
Jan 22 19:13:11.695: INFO: Got endpoints: latency-svc-fbq7b [105.555223ms]
Jan 22 19:13:11.708: INFO: Created: latency-svc-tdb52
Jan 22 19:13:11.717: INFO: Got endpoints: latency-svc-tdb52 [126.577645ms]
Jan 22 19:13:11.722: INFO: Created: latency-svc-g9w78
Jan 22 19:13:11.732: INFO: Got endpoints: latency-svc-g9w78 [142.359412ms]
Jan 22 19:13:11.743: INFO: Created: latency-svc-sbk97
Jan 22 19:13:11.768: INFO: Got endpoints: latency-svc-sbk97 [177.400249ms]
Jan 22 19:13:11.773: INFO: Created: latency-svc-xtlqk
Jan 22 19:13:11.785: INFO: Got endpoints: latency-svc-xtlqk [194.467754ms]
Jan 22 19:13:11.790: INFO: Created: latency-svc-v9kr4
Jan 22 19:13:11.803: INFO: Got endpoints: latency-svc-v9kr4 [212.953701ms]
Jan 22 19:13:11.807: INFO: Created: latency-svc-q8m9x
Jan 22 19:13:11.817: INFO: Got endpoints: latency-svc-q8m9x [226.617505ms]
Jan 22 19:13:11.824: INFO: Created: latency-svc-5jpqh
Jan 22 19:13:11.834: INFO: Got endpoints: latency-svc-5jpqh [242.786783ms]
Jan 22 19:13:11.838: INFO: Created: latency-svc-n9sdt
Jan 22 19:13:11.849: INFO: Got endpoints: latency-svc-n9sdt [258.21784ms]
Jan 22 19:13:11.861: INFO: Created: latency-svc-ks698
Jan 22 19:13:11.875: INFO: Got endpoints: latency-svc-ks698 [284.309412ms]
Jan 22 19:13:11.886: INFO: Created: latency-svc-8w526
Jan 22 19:13:11.899: INFO: Got endpoints: latency-svc-8w526 [308.193718ms]
Jan 22 19:13:11.905: INFO: Created: latency-svc-55lsq
Jan 22 19:13:11.914: INFO: Got endpoints: latency-svc-55lsq [324.006086ms]
Jan 22 19:13:11.919: INFO: Created: latency-svc-2mzbv
Jan 22 19:13:11.932: INFO: Got endpoints: latency-svc-2mzbv [302.18194ms]
Jan 22 19:13:11.940: INFO: Created: latency-svc-fm42s
Jan 22 19:13:11.948: INFO: Got endpoints: latency-svc-fm42s [284.329912ms]
Jan 22 19:13:11.956: INFO: Created: latency-svc-t8bq8
Jan 22 19:13:11.964: INFO: Got endpoints: latency-svc-t8bq8 [291.951338ms]
Jan 22 19:13:11.971: INFO: Created: latency-svc-hbn2b
Jan 22 19:13:11.990: INFO: Got endpoints: latency-svc-hbn2b [295.476042ms]
Jan 22 19:13:12.017: INFO: Created: latency-svc-vct7m
Jan 22 19:13:12.023: INFO: Got endpoints: latency-svc-vct7m [59.009746ms]
Jan 22 19:13:12.070: INFO: Created: latency-svc-z89qw
Jan 22 19:13:12.081: INFO: Got endpoints: latency-svc-z89qw [364.077872ms]
Jan 22 19:13:12.089: INFO: Created: latency-svc-8qdzv
Jan 22 19:13:12.101: INFO: Got endpoints: latency-svc-8qdzv [368.77951ms]
Jan 22 19:13:12.108: INFO: Created: latency-svc-28kg9
Jan 22 19:13:12.117: INFO: Got endpoints: latency-svc-28kg9 [349.707046ms]
Jan 22 19:13:12.142: INFO: Created: latency-svc-ks288
Jan 22 19:13:12.155: INFO: Got endpoints: latency-svc-ks288 [370.060949ms]
Jan 22 19:13:12.167: INFO: Created: latency-svc-6852q
Jan 22 19:13:12.183: INFO: Got endpoints: latency-svc-6852q [380.012743ms]
Jan 22 19:13:12.214: INFO: Created: latency-svc-bvt4j
Jan 22 19:13:12.225: INFO: Got endpoints: latency-svc-bvt4j [407.261449ms]
Jan 22 19:13:12.231: INFO: Created: latency-svc-8vxpl
Jan 22 19:13:12.238: INFO: Got endpoints: latency-svc-8vxpl [404.462666ms]
Jan 22 19:13:12.256: INFO: Created: latency-svc-2r4ds
Jan 22 19:13:12.282: INFO: Got endpoints: latency-svc-2r4ds [433.197416ms]
Jan 22 19:13:12.285: INFO: Created: latency-svc-x4jjk
Jan 22 19:13:12.306: INFO: Got endpoints: latency-svc-x4jjk [429.2401ms]
Jan 22 19:13:12.311: INFO: Created: latency-svc-vbr8x
Jan 22 19:13:12.328: INFO: Got endpoints: latency-svc-vbr8x [428.898189ms]
Jan 22 19:13:12.348: INFO: Created: latency-svc-bs22z
Jan 22 19:13:12.361: INFO: Got endpoints: latency-svc-bs22z [446.726117ms]
Jan 22 19:13:12.374: INFO: Created: latency-svc-6zwwp
Jan 22 19:13:12.379: INFO: Got endpoints: latency-svc-6zwwp [446.995625ms]
Jan 22 19:13:12.394: INFO: Created: latency-svc-9sd9r
Jan 22 19:13:12.404: INFO: Got endpoints: latency-svc-9sd9r [455.995291ms]
Jan 22 19:13:12.417: INFO: Created: latency-svc-jx4mz
Jan 22 19:13:12.463: INFO: Got endpoints: latency-svc-jx4mz [472.826089ms]
Jan 22 19:13:12.468: INFO: Created: latency-svc-nsrnn
Jan 22 19:13:12.499: INFO: Got endpoints: latency-svc-nsrnn [475.992983ms]
Jan 22 19:13:12.503: INFO: Created: latency-svc-fwmjf
Jan 22 19:13:12.509: INFO: Got endpoints: latency-svc-fwmjf [425.316684ms]
Jan 22 19:13:12.535: INFO: Created: latency-svc-4cmqm
Jan 22 19:13:12.548: INFO: Got endpoints: latency-svc-4cmqm [445.600083ms]
Jan 22 19:13:12.553: INFO: Created: latency-svc-x748x
Jan 22 19:13:12.576: INFO: Got endpoints: latency-svc-x748x [457.98395ms]
Jan 22 19:13:12.582: INFO: Created: latency-svc-mh2hx
Jan 22 19:13:12.596: INFO: Got endpoints: latency-svc-mh2hx [440.879544ms]
Jan 22 19:13:12.600: INFO: Created: latency-svc-zqrg6
Jan 22 19:13:12.610: INFO: Got endpoints: latency-svc-zqrg6 [423.723636ms]
Jan 22 19:13:12.631: INFO: Created: latency-svc-mdfs2
Jan 22 19:13:12.637: INFO: Got endpoints: latency-svc-mdfs2 [411.780083ms]
Jan 22 19:13:12.653: INFO: Created: latency-svc-f6cn5
Jan 22 19:13:12.663: INFO: Got endpoints: latency-svc-f6cn5 [422.84751ms]
Jan 22 19:13:12.673: INFO: Created: latency-svc-jd2b2
Jan 22 19:13:12.691: INFO: Got endpoints: latency-svc-jd2b2 [406.327122ms]
Jan 22 19:13:12.701: INFO: Created: latency-svc-4pxlw
Jan 22 19:13:12.718: INFO: Got endpoints: latency-svc-4pxlw [412.061092ms]
Jan 22 19:13:12.726: INFO: Created: latency-svc-tdlv4
Jan 22 19:13:12.731: INFO: Got endpoints: latency-svc-tdlv4 [402.042195ms]
Jan 22 19:13:12.761: INFO: Created: latency-svc-tlmdn
Jan 22 19:13:12.764: INFO: Got endpoints: latency-svc-tlmdn [401.737586ms]
Jan 22 19:13:12.774: INFO: Created: latency-svc-6xjkz
Jan 22 19:13:12.791: INFO: Got endpoints: latency-svc-6xjkz [410.186336ms]
Jan 22 19:13:12.804: INFO: Created: latency-svc-h55sw
Jan 22 19:13:12.827: INFO: Got endpoints: latency-svc-h55sw [422.4921ms]
Jan 22 19:13:12.827: INFO: Created: latency-svc-bjxs8
Jan 22 19:13:12.843: INFO: Got endpoints: latency-svc-bjxs8 [377.990483ms]
Jan 22 19:13:12.847: INFO: Created: latency-svc-fkqz5
Jan 22 19:13:12.861: INFO: Got endpoints: latency-svc-fkqz5 [361.599998ms]
Jan 22 19:13:12.875: INFO: Created: latency-svc-ch7dp
Jan 22 19:13:12.885: INFO: Got endpoints: latency-svc-ch7dp [374.157769ms]
Jan 22 19:13:12.899: INFO: Created: latency-svc-s5wr9
Jan 22 19:13:12.906: INFO: Got endpoints: latency-svc-s5wr9 [357.994992ms]
Jan 22 19:13:12.929: INFO: Created: latency-svc-pszrx
Jan 22 19:13:12.937: INFO: Got endpoints: latency-svc-pszrx [358.307901ms]
Jan 22 19:13:12.951: INFO: Created: latency-svc-qj96c
Jan 22 19:13:12.964: INFO: Got endpoints: latency-svc-qj96c [366.691649ms]
Jan 22 19:13:12.986: INFO: Created: latency-svc-f9nqk
Jan 22 19:13:13.002: INFO: Got endpoints: latency-svc-f9nqk [392.138902ms]
Jan 22 19:13:13.033: INFO: Created: latency-svc-76zmb
Jan 22 19:13:13.050: INFO: Got endpoints: latency-svc-76zmb [411.126564ms]
Jan 22 19:13:13.053: INFO: Created: latency-svc-czgfs
Jan 22 19:13:13.067: INFO: Got endpoints: latency-svc-czgfs [403.323833ms]
Jan 22 19:13:13.077: INFO: Created: latency-svc-pmcll
Jan 22 19:13:13.098: INFO: Got endpoints: latency-svc-pmcll [406.847938ms]
Jan 22 19:13:13.101: INFO: Created: latency-svc-sk429
Jan 22 19:13:13.121: INFO: Created: latency-svc-wwz78
Jan 22 19:13:13.130: INFO: Got endpoints: latency-svc-sk429 [408.764994ms]
Jan 22 19:13:13.147: INFO: Got endpoints: latency-svc-wwz78 [415.852504ms]
Jan 22 19:13:13.169: INFO: Created: latency-svc-zqtpb
Jan 22 19:13:13.182: INFO: Got endpoints: latency-svc-zqtpb [417.053939ms]
Jan 22 19:13:13.185: INFO: Created: latency-svc-59hhx
Jan 22 19:13:13.201: INFO: Created: latency-svc-d475l
Jan 22 19:13:13.217: INFO: Created: latency-svc-6glsn
Jan 22 19:13:13.240: INFO: Got endpoints: latency-svc-59hhx [449.456197ms]
Jan 22 19:13:13.242: INFO: Created: latency-svc-pp7vh
Jan 22 19:13:13.274: INFO: Created: latency-svc-tv27m
Jan 22 19:13:13.285: INFO: Got endpoints: latency-svc-d475l [458.34236ms]
Jan 22 19:13:13.290: INFO: Created: latency-svc-wnhqc
Jan 22 19:13:13.313: INFO: Created: latency-svc-6wffj
Jan 22 19:13:13.333: INFO: Created: latency-svc-5qndh
Jan 22 19:13:13.336: INFO: Got endpoints: latency-svc-6glsn [492.097759ms]
Jan 22 19:13:13.371: INFO: Created: latency-svc-hlb8b
Jan 22 19:13:13.381: INFO: Created: latency-svc-nnnk9
Jan 22 19:13:13.384: INFO: Got endpoints: latency-svc-pp7vh [522.387856ms]
Jan 22 19:13:13.417: INFO: Created: latency-svc-pkw99
Jan 22 19:13:13.432: INFO: Got endpoints: latency-svc-tv27m [546.161559ms]
Jan 22 19:13:13.460: INFO: Created: latency-svc-wtrrw
Jan 22 19:13:13.488: INFO: Got endpoints: latency-svc-wnhqc [581.106792ms]
Jan 22 19:13:13.490: INFO: Created: latency-svc-sdkzd
Jan 22 19:13:13.507: INFO: Created: latency-svc-vq6sd
Jan 22 19:13:13.534: INFO: Created: latency-svc-f75cx
Jan 22 19:13:13.537: INFO: Got endpoints: latency-svc-6wffj [596.88606ms]
Jan 22 19:13:13.563: INFO: Created: latency-svc-jgjfk
Jan 22 19:13:13.585: INFO: Created: latency-svc-km25r
Jan 22 19:13:13.607: INFO: Got endpoints: latency-svc-5qndh [641.52208ms]
Jan 22 19:13:13.615: INFO: Created: latency-svc-7rfnl
Jan 22 19:13:13.642: INFO: Created: latency-svc-66ppf
Jan 22 19:13:13.647: INFO: Got endpoints: latency-svc-hlb8b [644.872379ms]
Jan 22 19:13:13.662: INFO: Created: latency-svc-mb8c4
Jan 22 19:13:13.687: INFO: Got endpoints: latency-svc-nnnk9 [633.822352ms]
Jan 22 19:13:13.693: INFO: Created: latency-svc-t8w7d
Jan 22 19:13:13.749: INFO: Created: latency-svc-68p8l
Jan 22 19:13:13.752: INFO: Created: latency-svc-8fsf8
Jan 22 19:13:13.759: INFO: Got endpoints: latency-svc-pkw99 [691.713665ms]
Jan 22 19:13:13.797: INFO: Got endpoints: latency-svc-wtrrw [696.441705ms]
Jan 22 19:13:13.801: INFO: Created: latency-svc-m5xdm
Jan 22 19:13:13.816: INFO: Created: latency-svc-q9mh6
Jan 22 19:13:13.834: INFO: Created: latency-svc-6pwn5
Jan 22 19:13:13.842: INFO: Got endpoints: latency-svc-sdkzd [711.970664ms]
Jan 22 19:13:13.865: INFO: Created: latency-svc-kvz8f
Jan 22 19:13:13.885: INFO: Created: latency-svc-kl5fv
Jan 22 19:13:13.890: INFO: Got endpoints: latency-svc-vq6sd [731.953056ms]
Jan 22 19:13:13.922: INFO: Created: latency-svc-kgw2g
Jan 22 19:13:13.930: INFO: Got endpoints: latency-svc-f75cx [748.33114ms]
Jan 22 19:13:13.954: INFO: Created: latency-svc-w2s9m
Jan 22 19:13:13.986: INFO: Got endpoints: latency-svc-jgjfk [745.322051ms]
Jan 22 19:13:14.019: INFO: Created: latency-svc-6jxjs
Jan 22 19:13:14.036: INFO: Got endpoints: latency-svc-km25r [751.484733ms]
Jan 22 19:13:14.076: INFO: Created: latency-svc-clzfb
Jan 22 19:13:14.103: INFO: Got endpoints: latency-svc-7rfnl [766.970191ms]
Jan 22 19:13:14.134: INFO: Created: latency-svc-r2nrn
Jan 22 19:13:14.147: INFO: Got endpoints: latency-svc-66ppf [762.822169ms]
Jan 22 19:13:14.188: INFO: Got endpoints: latency-svc-mb8c4 [752.941976ms]
Jan 22 19:13:14.267: INFO: Created: latency-svc-gvskf
Jan 22 19:13:14.297: INFO: Got endpoints: latency-svc-t8w7d [809.040236ms]
Jan 22 19:13:14.303: INFO: Got endpoints: latency-svc-68p8l [760.225892ms]
Jan 22 19:13:14.307: INFO: Created: latency-svc-46nx9
Jan 22 19:13:14.333: INFO: Created: latency-svc-tzjf2
Jan 22 19:13:14.353: INFO: Got endpoints: latency-svc-8fsf8 [742.94678ms]
Jan 22 19:13:14.394: INFO: Created: latency-svc-9tjm6
Jan 22 19:13:14.402: INFO: Got endpoints: latency-svc-m5xdm [754.670028ms]
Jan 22 19:13:14.453: INFO: Created: latency-svc-cqblg
Jan 22 19:13:14.459: INFO: Got endpoints: latency-svc-q9mh6 [768.348032ms]
Jan 22 19:13:14.480: INFO: Got endpoints: latency-svc-6pwn5 [719.669692ms]
Jan 22 19:13:14.489: INFO: Created: latency-svc-llsb5
Jan 22 19:13:14.511: INFO: Created: latency-svc-h2stg
Jan 22 19:13:14.531: INFO: Created: latency-svc-n9wz6
Jan 22 19:13:14.538: INFO: Got endpoints: latency-svc-kvz8f [736.935003ms]
Jan 22 19:13:14.564: INFO: Created: latency-svc-4d6sp
Jan 22 19:13:14.581: INFO: Got endpoints: latency-svc-kl5fv [738.760457ms]
Jan 22 19:13:14.624: INFO: Created: latency-svc-zxgh7
Jan 22 19:13:14.634: INFO: Got endpoints: latency-svc-kgw2g [744.009112ms]
Jan 22 19:13:14.665: INFO: Created: latency-svc-6dkbq
Jan 22 19:13:14.679: INFO: Got endpoints: latency-svc-w2s9m [748.865155ms]
Jan 22 19:13:14.707: INFO: Created: latency-svc-7nstp
Jan 22 19:13:14.740: INFO: Got endpoints: latency-svc-6jxjs [754.720729ms]
Jan 22 19:13:14.764: INFO: Created: latency-svc-4tl2l
Jan 22 19:13:14.783: INFO: Got endpoints: latency-svc-clzfb [743.610201ms]
Jan 22 19:13:14.810: INFO: Created: latency-svc-wx8s5
Jan 22 19:13:14.829: INFO: Got endpoints: latency-svc-r2nrn [725.665569ms]
Jan 22 19:13:14.855: INFO: Created: latency-svc-bhz7j
Jan 22 19:13:14.887: INFO: Got endpoints: latency-svc-gvskf [739.950192ms]
Jan 22 19:13:14.911: INFO: Created: latency-svc-2rwnv
Jan 22 19:13:14.930: INFO: Got endpoints: latency-svc-46nx9 [741.820647ms]
Jan 22 19:13:14.967: INFO: Created: latency-svc-j8cnb
Jan 22 19:13:14.981: INFO: Got endpoints: latency-svc-tzjf2 [681.672068ms]
Jan 22 19:13:15.009: INFO: Created: latency-svc-lrqqs
Jan 22 19:13:15.031: INFO: Got endpoints: latency-svc-9tjm6 [724.739742ms]
Jan 22 19:13:15.054: INFO: Created: latency-svc-tbjfv
Jan 22 19:13:15.083: INFO: Got endpoints: latency-svc-cqblg [729.818792ms]
Jan 22 19:13:15.114: INFO: Created: latency-svc-cqftl
Jan 22 19:13:15.147: INFO: Got endpoints: latency-svc-llsb5 [744.975341ms]
Jan 22 19:13:15.190: INFO: Got endpoints: latency-svc-h2stg [728.701759ms]
Jan 22 19:13:15.196: INFO: Created: latency-svc-87k8w
Jan 22 19:13:15.222: INFO: Created: latency-svc-662zr
Jan 22 19:13:15.230: INFO: Got endpoints: latency-svc-n9wz6 [750.146594ms]
Jan 22 19:13:15.267: INFO: Created: latency-svc-6bvxb
Jan 22 19:13:15.311: INFO: Got endpoints: latency-svc-4d6sp [773.456983ms]
Jan 22 19:13:15.353: INFO: Got endpoints: latency-svc-zxgh7 [768.94365ms]
Jan 22 19:13:15.368: INFO: Created: latency-svc-5k25t
Jan 22 19:13:15.388: INFO: Got endpoints: latency-svc-6dkbq [751.259126ms]
Jan 22 19:13:15.400: INFO: Created: latency-svc-mtp8l
Jan 22 19:13:15.422: INFO: Created: latency-svc-vntf4
Jan 22 19:13:15.435: INFO: Got endpoints: latency-svc-7nstp [755.889663ms]
Jan 22 19:13:15.467: INFO: Created: latency-svc-45ln7
Jan 22 19:13:15.481: INFO: Got endpoints: latency-svc-4tl2l [737.672624ms]
Jan 22 19:13:15.500: INFO: Created: latency-svc-frfpc
Jan 22 19:13:15.539: INFO: Got endpoints: latency-svc-wx8s5 [755.499952ms]
Jan 22 19:13:15.561: INFO: Created: latency-svc-gc7pl
Jan 22 19:13:15.581: INFO: Got endpoints: latency-svc-bhz7j [751.316729ms]
Jan 22 19:13:15.612: INFO: Created: latency-svc-jw492
Jan 22 19:13:15.630: INFO: Got endpoints: latency-svc-2rwnv [742.210358ms]
Jan 22 19:13:15.661: INFO: Created: latency-svc-ncwnr
Jan 22 19:13:15.680: INFO: Got endpoints: latency-svc-j8cnb [749.224666ms]
Jan 22 19:13:15.737: INFO: Created: latency-svc-8bn5g
Jan 22 19:13:15.740: INFO: Got endpoints: latency-svc-lrqqs [756.244473ms]
Jan 22 19:13:15.782: INFO: Created: latency-svc-62kx4
Jan 22 19:13:15.786: INFO: Got endpoints: latency-svc-tbjfv [751.752041ms]
Jan 22 19:13:15.823: INFO: Created: latency-svc-k8zqk
Jan 22 19:13:15.830: INFO: Got endpoints: latency-svc-cqftl [747.130004ms]
Jan 22 19:13:15.859: INFO: Created: latency-svc-xjwkq
Jan 22 19:13:15.883: INFO: Got endpoints: latency-svc-87k8w [732.841082ms]
Jan 22 19:13:15.909: INFO: Created: latency-svc-9d56b
Jan 22 19:13:15.935: INFO: Got endpoints: latency-svc-662zr [743.408094ms]
Jan 22 19:13:15.967: INFO: Created: latency-svc-vsqc6
Jan 22 19:13:15.981: INFO: Got endpoints: latency-svc-6bvxb [746.951099ms]
Jan 22 19:13:16.021: INFO: Created: latency-svc-75lt8
Jan 22 19:13:16.034: INFO: Got endpoints: latency-svc-5k25t [721.61585ms]
Jan 22 19:13:16.066: INFO: Created: latency-svc-lwzj8
Jan 22 19:13:16.083: INFO: Got endpoints: latency-svc-mtp8l [728.509954ms]
Jan 22 19:13:16.117: INFO: Created: latency-svc-jq9rp
Jan 22 19:13:16.132: INFO: Got endpoints: latency-svc-vntf4 [744.054013ms]
Jan 22 19:13:16.166: INFO: Created: latency-svc-lrrrq
Jan 22 19:13:16.180: INFO: Got endpoints: latency-svc-45ln7 [741.505837ms]
Jan 22 19:13:16.204: INFO: Created: latency-svc-zql4t
Jan 22 19:13:16.235: INFO: Got endpoints: latency-svc-frfpc [753.782001ms]
Jan 22 19:13:16.278: INFO: Created: latency-svc-sklc9
Jan 22 19:13:16.282: INFO: Got endpoints: latency-svc-gc7pl [742.451266ms]
Jan 22 19:13:16.329: INFO: Created: latency-svc-s594j
Jan 22 19:13:16.361: INFO: Got endpoints: latency-svc-jw492 [780.086579ms]
Jan 22 19:13:16.384: INFO: Got endpoints: latency-svc-ncwnr [754.283515ms]
Jan 22 19:13:16.407: INFO: Created: latency-svc-wlbbt
Jan 22 19:13:16.435: INFO: Got endpoints: latency-svc-8bn5g [754.41272ms]
Jan 22 19:13:16.439: INFO: Created: latency-svc-4lrhp
Jan 22 19:13:16.464: INFO: Created: latency-svc-pt8t8
Jan 22 19:13:16.483: INFO: Got endpoints: latency-svc-62kx4 [742.645772ms]
Jan 22 19:13:16.509: INFO: Created: latency-svc-9szxv
Jan 22 19:13:16.531: INFO: Got endpoints: latency-svc-k8zqk [743.692802ms]
Jan 22 19:13:16.559: INFO: Created: latency-svc-mxmq2
Jan 22 19:13:16.582: INFO: Got endpoints: latency-svc-xjwkq [748.409742ms]
Jan 22 19:13:16.619: INFO: Created: latency-svc-kh2cr
Jan 22 19:13:16.639: INFO: Got endpoints: latency-svc-9d56b [755.726558ms]
Jan 22 19:13:16.676: INFO: Created: latency-svc-z2rts
Jan 22 19:13:16.681: INFO: Got endpoints: latency-svc-vsqc6 [745.836366ms]
Jan 22 19:13:16.710: INFO: Created: latency-svc-dp5sw
Jan 22 19:13:16.733: INFO: Got endpoints: latency-svc-75lt8 [751.982847ms]
Jan 22 19:13:16.761: INFO: Created: latency-svc-c5xph
Jan 22 19:13:16.781: INFO: Got endpoints: latency-svc-lwzj8 [746.842296ms]
Jan 22 19:13:16.809: INFO: Created: latency-svc-m26lt
Jan 22 19:13:16.831: INFO: Got endpoints: latency-svc-jq9rp [746.372482ms]
Jan 22 19:13:16.852: INFO: Created: latency-svc-f5d7s
Jan 22 19:13:16.880: INFO: Got endpoints: latency-svc-lrrrq [744.781535ms]
Jan 22 19:13:16.923: INFO: Created: latency-svc-qbnfn
Jan 22 19:13:16.930: INFO: Got endpoints: latency-svc-zql4t [748.02153ms]
Jan 22 19:13:16.982: INFO: Got endpoints: latency-svc-sklc9 [738.356345ms]
Jan 22 19:13:16.986: INFO: Created: latency-svc-pwm9d
Jan 22 19:13:17.004: INFO: Created: latency-svc-pnx5r
Jan 22 19:13:17.039: INFO: Got endpoints: latency-svc-s594j [755.000537ms]
Jan 22 19:13:17.064: INFO: Created: latency-svc-5ptwb
Jan 22 19:13:17.080: INFO: Got endpoints: latency-svc-wlbbt [719.399884ms]
Jan 22 19:13:17.104: INFO: Created: latency-svc-x2pgm
Jan 22 19:13:17.135: INFO: Got endpoints: latency-svc-4lrhp [750.635708ms]
Jan 22 19:13:17.159: INFO: Created: latency-svc-gjfdt
Jan 22 19:13:17.182: INFO: Got endpoints: latency-svc-pt8t8 [746.868996ms]
Jan 22 19:13:17.216: INFO: Created: latency-svc-9gw26
Jan 22 19:13:17.236: INFO: Got endpoints: latency-svc-9szxv [752.948576ms]
Jan 22 19:13:17.269: INFO: Created: latency-svc-lgt9j
Jan 22 19:13:17.279: INFO: Got endpoints: latency-svc-mxmq2 [748.68915ms]
Jan 22 19:13:17.319: INFO: Created: latency-svc-v6gvq
Jan 22 19:13:17.335: INFO: Got endpoints: latency-svc-kh2cr [752.853273ms]
Jan 22 19:13:17.356: INFO: Created: latency-svc-bgbrs
Jan 22 19:13:17.381: INFO: Got endpoints: latency-svc-z2rts [742.117456ms]
Jan 22 19:13:17.415: INFO: Created: latency-svc-7xm7g
Jan 22 19:13:17.430: INFO: Got endpoints: latency-svc-dp5sw [746.30968ms]
Jan 22 19:13:17.454: INFO: Created: latency-svc-gtxg6
Jan 22 19:13:17.490: INFO: Got endpoints: latency-svc-c5xph [756.907993ms]
Jan 22 19:13:17.537: INFO: Got endpoints: latency-svc-m26lt [752.782371ms]
Jan 22 19:13:17.544: INFO: Created: latency-svc-zhcd6
Jan 22 19:13:17.568: INFO: Created: latency-svc-9mrgs
Jan 22 19:13:17.584: INFO: Got endpoints: latency-svc-f5d7s [752.034549ms]
Jan 22 19:13:17.614: INFO: Created: latency-svc-8zll5
Jan 22 19:13:17.633: INFO: Got endpoints: latency-svc-qbnfn [752.890375ms]
Jan 22 19:13:17.666: INFO: Created: latency-svc-nbhtw
Jan 22 19:13:17.680: INFO: Got endpoints: latency-svc-pwm9d [748.509045ms]
Jan 22 19:13:17.731: INFO: Got endpoints: latency-svc-pnx5r [748.549246ms]
Jan 22 19:13:17.782: INFO: Got endpoints: latency-svc-5ptwb [740.274401ms]
Jan 22 19:13:17.808: INFO: Created: latency-svc-jz5q8
Jan 22 19:13:17.833: INFO: Created: latency-svc-w4xph
Jan 22 19:13:17.834: INFO: Got endpoints: latency-svc-x2pgm [753.402889ms]
Jan 22 19:13:17.847: INFO: Created: latency-svc-qfbd4
Jan 22 19:13:17.862: INFO: Created: latency-svc-sg2r4
Jan 22 19:13:17.881: INFO: Got endpoints: latency-svc-gjfdt [746.135474ms]
Jan 22 19:13:17.914: INFO: Created: latency-svc-rjwvj
Jan 22 19:13:17.940: INFO: Got endpoints: latency-svc-9gw26 [743.654001ms]
Jan 22 19:13:17.963: INFO: Created: latency-svc-jgll5
Jan 22 19:13:17.980: INFO: Got endpoints: latency-svc-lgt9j [744.076713ms]
Jan 22 19:13:18.001: INFO: Created: latency-svc-kn8pt
Jan 22 19:13:18.029: INFO: Got endpoints: latency-svc-v6gvq [749.684879ms]
Jan 22 19:13:18.055: INFO: Created: latency-svc-ffcl6
Jan 22 19:13:18.084: INFO: Got endpoints: latency-svc-bgbrs [749.749681ms]
Jan 22 19:13:18.106: INFO: Created: latency-svc-2mnst
Jan 22 19:13:18.130: INFO: Got endpoints: latency-svc-7xm7g [747.744022ms]
Jan 22 19:13:18.164: INFO: Created: latency-svc-ldc92
Jan 22 19:13:18.180: INFO: Got endpoints: latency-svc-gtxg6 [747.407112ms]
Jan 22 19:13:18.200: INFO: Created: latency-svc-gqtfj
Jan 22 19:13:18.233: INFO: Got endpoints: latency-svc-zhcd6 [726.947407ms]
Jan 22 19:13:18.254: INFO: Created: latency-svc-g296k
Jan 22 19:13:18.280: INFO: Got endpoints: latency-svc-9mrgs [738.004933ms]
Jan 22 19:13:18.303: INFO: Created: latency-svc-xhpft
Jan 22 19:13:18.330: INFO: Got endpoints: latency-svc-8zll5 [742.311162ms]
Jan 22 19:13:18.360: INFO: Created: latency-svc-4xspc
Jan 22 19:13:18.388: INFO: Got endpoints: latency-svc-nbhtw [751.477033ms]
Jan 22 19:13:18.411: INFO: Created: latency-svc-xb8c2
Jan 22 19:13:18.429: INFO: Got endpoints: latency-svc-jz5q8 [748.885655ms]
Jan 22 19:13:18.451: INFO: Created: latency-svc-s4gxx
Jan 22 19:13:18.483: INFO: Got endpoints: latency-svc-w4xph [749.123063ms]
Jan 22 19:13:18.507: INFO: Created: latency-svc-l7g46
Jan 22 19:13:18.529: INFO: Got endpoints: latency-svc-qfbd4 [742.687072ms]
Jan 22 19:13:18.550: INFO: Created: latency-svc-jzttz
Jan 22 19:13:18.579: INFO: Got endpoints: latency-svc-sg2r4 [745.445854ms]
Jan 22 19:13:18.608: INFO: Created: latency-svc-ff9ds
Jan 22 19:13:18.630: INFO: Got endpoints: latency-svc-rjwvj [749.437072ms]
Jan 22 19:13:18.652: INFO: Created: latency-svc-zx5lb
Jan 22 19:13:18.682: INFO: Got endpoints: latency-svc-jgll5 [741.586239ms]
Jan 22 19:13:18.702: INFO: Created: latency-svc-fphkm
Jan 22 19:13:18.734: INFO: Got endpoints: latency-svc-kn8pt [753.501692ms]
Jan 22 19:13:18.761: INFO: Created: latency-svc-dzwsq
Jan 22 19:13:18.782: INFO: Got endpoints: latency-svc-ffcl6 [752.768771ms]
Jan 22 19:13:18.821: INFO: Created: latency-svc-4ffld
Jan 22 19:13:18.838: INFO: Got endpoints: latency-svc-2mnst [753.693498ms]
Jan 22 19:13:18.863: INFO: Created: latency-svc-jxhf7
Jan 22 19:13:18.882: INFO: Got endpoints: latency-svc-ldc92 [748.649948ms]
Jan 22 19:13:18.921: INFO: Created: latency-svc-64t9j
Jan 22 19:13:18.932: INFO: Got endpoints: latency-svc-gqtfj [749.36537ms]
Jan 22 19:13:18.958: INFO: Created: latency-svc-c2lgf
Jan 22 19:13:18.982: INFO: Got endpoints: latency-svc-g296k [748.754951ms]
Jan 22 19:13:19.007: INFO: Created: latency-svc-4v5cc
Jan 22 19:13:19.030: INFO: Got endpoints: latency-svc-xhpft [746.31868ms]
Jan 22 19:13:19.063: INFO: Created: latency-svc-qpkjg
Jan 22 19:13:19.080: INFO: Got endpoints: latency-svc-4xspc [749.966187ms]
Jan 22 19:13:19.102: INFO: Created: latency-svc-txmlx
Jan 22 19:13:19.132: INFO: Got endpoints: latency-svc-xb8c2 [741.369633ms]
Jan 22 19:13:19.153: INFO: Created: latency-svc-8rrmk
Jan 22 19:13:19.181: INFO: Got endpoints: latency-svc-s4gxx [748.721251ms]
Jan 22 19:13:19.203: INFO: Created: latency-svc-l46zp
Jan 22 19:13:19.229: INFO: Got endpoints: latency-svc-l7g46 [745.268748ms]
Jan 22 19:13:19.263: INFO: Created: latency-svc-bbdn7
Jan 22 19:13:19.285: INFO: Got endpoints: latency-svc-jzttz [753.688597ms]
Jan 22 19:13:19.308: INFO: Created: latency-svc-ttr8x
Jan 22 19:13:19.329: INFO: Got endpoints: latency-svc-ff9ds [749.873285ms]
Jan 22 19:13:19.355: INFO: Created: latency-svc-b7nrc
Jan 22 19:13:19.380: INFO: Got endpoints: latency-svc-zx5lb [749.169864ms]
Jan 22 19:13:19.409: INFO: Created: latency-svc-6bqfk
Jan 22 19:13:19.430: INFO: Got endpoints: latency-svc-fphkm [748.659449ms]
Jan 22 19:13:19.480: INFO: Got endpoints: latency-svc-dzwsq [746.024471ms]
Jan 22 19:13:19.533: INFO: Got endpoints: latency-svc-4ffld [750.72631ms]
Jan 22 19:13:19.580: INFO: Got endpoints: latency-svc-jxhf7 [741.386433ms]
Jan 22 19:13:19.631: INFO: Got endpoints: latency-svc-64t9j [745.578757ms]
Jan 22 19:13:19.679: INFO: Got endpoints: latency-svc-c2lgf [743.505796ms]
Jan 22 19:13:19.731: INFO: Got endpoints: latency-svc-4v5cc [748.955857ms]
Jan 22 19:13:19.784: INFO: Got endpoints: latency-svc-qpkjg [754.766829ms]
Jan 22 19:13:19.832: INFO: Got endpoints: latency-svc-txmlx [749.110262ms]
Jan 22 19:13:19.883: INFO: Got endpoints: latency-svc-8rrmk [748.490444ms]
Jan 22 19:13:19.932: INFO: Got endpoints: latency-svc-l46zp [750.341398ms]
Jan 22 19:13:19.980: INFO: Got endpoints: latency-svc-bbdn7 [747.965028ms]
Jan 22 19:13:20.030: INFO: Got endpoints: latency-svc-ttr8x [744.132015ms]
Jan 22 19:13:20.083: INFO: Got endpoints: latency-svc-b7nrc [753.591995ms]
Jan 22 19:13:20.131: INFO: Got endpoints: latency-svc-6bqfk [751.360128ms]
Jan 22 19:13:20.134: INFO: Latencies: [39.87158ms 59.009746ms 74.469804ms 82.669946ms 105.555223ms 126.577645ms 142.359412ms 177.400249ms 194.467754ms 212.953701ms 226.617505ms 242.786783ms 258.21784ms 284.309412ms 284.329912ms 291.951338ms 295.476042ms 302.18194ms 308.193718ms 324.006086ms 349.707046ms 357.994992ms 358.307901ms 361.599998ms 364.077872ms 366.691649ms 368.77951ms 370.060949ms 374.157769ms 377.990483ms 380.012743ms 392.138902ms 401.737586ms 402.042195ms 403.323833ms 404.462666ms 406.327122ms 406.847938ms 407.261449ms 408.764994ms 410.186336ms 411.126564ms 411.780083ms 412.061092ms 415.852504ms 417.053939ms 422.4921ms 422.84751ms 423.723636ms 425.316684ms 428.898189ms 429.2401ms 433.197416ms 440.879544ms 445.600083ms 446.726117ms 446.995625ms 449.456197ms 455.995291ms 457.98395ms 458.34236ms 472.826089ms 475.992983ms 492.097759ms 522.387856ms 546.161559ms 581.106792ms 596.88606ms 633.822352ms 641.52208ms 644.872379ms 681.672068ms 691.713665ms 696.441705ms 711.970664ms 719.399884ms 719.669692ms 721.61585ms 724.739742ms 725.665569ms 726.947407ms 728.509954ms 728.701759ms 729.818792ms 731.953056ms 732.841082ms 736.935003ms 737.672624ms 738.004933ms 738.356345ms 738.760457ms 739.950192ms 740.274401ms 741.369633ms 741.386433ms 741.505837ms 741.586239ms 741.820647ms 742.117456ms 742.210358ms 742.311162ms 742.451266ms 742.645772ms 742.687072ms 742.94678ms 743.408094ms 743.505796ms 743.610201ms 743.654001ms 743.692802ms 744.009112ms 744.054013ms 744.076713ms 744.132015ms 744.781535ms 744.975341ms 745.268748ms 745.322051ms 745.445854ms 745.578757ms 745.836366ms 746.024471ms 746.135474ms 746.30968ms 746.31868ms 746.372482ms 746.842296ms 746.868996ms 746.951099ms 747.130004ms 747.407112ms 747.744022ms 747.965028ms 748.02153ms 748.33114ms 748.409742ms 748.490444ms 748.509045ms 748.549246ms 748.649948ms 748.659449ms 748.68915ms 748.721251ms 748.754951ms 748.865155ms 748.885655ms 748.955857ms 749.110262ms 749.123063ms 749.169864ms 749.224666ms 749.36537ms 749.437072ms 749.684879ms 749.749681ms 749.873285ms 749.966187ms 750.146594ms 750.341398ms 750.635708ms 750.72631ms 751.259126ms 751.316729ms 751.360128ms 751.477033ms 751.484733ms 751.752041ms 751.982847ms 752.034549ms 752.768771ms 752.782371ms 752.853273ms 752.890375ms 752.941976ms 752.948576ms 753.402889ms 753.501692ms 753.591995ms 753.688597ms 753.693498ms 753.782001ms 754.283515ms 754.41272ms 754.670028ms 754.720729ms 754.766829ms 755.000537ms 755.499952ms 755.726558ms 755.889663ms 756.244473ms 756.907993ms 760.225892ms 762.822169ms 766.970191ms 768.348032ms 768.94365ms 773.456983ms 780.086579ms 809.040236ms]
Jan 22 19:13:20.134: INFO: 50 %ile: 742.311162ms
Jan 22 19:13:20.134: INFO: 90 %ile: 753.782001ms
Jan 22 19:13:20.134: INFO: 99 %ile: 780.086579ms
Jan 22 19:13:20.134: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:13:20.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-4xr2x" for this suite.
Jan 22 19:13:40.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:13:40.347: INFO: namespace: e2e-tests-svc-latency-4xr2x, resource: bindings, ignored listing per whitelist
Jan 22 19:13:40.576: INFO: namespace e2e-tests-svc-latency-4xr2x deletion completed in 20.434856396s

• [SLOW TEST:32.299 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:13:40.577: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 19:13:40.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c8w2g'
Jan 22 19:13:40.955: INFO: stderr: ""
Jan 22 19:13:40.955: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan 22 19:13:40.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-c8w2g'
Jan 22 19:13:48.442: INFO: stderr: ""
Jan 22 19:13:48.442: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:13:48.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c8w2g" for this suite.
Jan 22 19:13:54.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:13:54.677: INFO: namespace: e2e-tests-kubectl-c8w2g, resource: bindings, ignored listing per whitelist
Jan 22 19:13:54.680: INFO: namespace e2e-tests-kubectl-c8w2g deletion completed in 6.230868685s

• [SLOW TEST:14.104 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:13:54.681: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 22 19:13:54.880: INFO: Waiting up to 5m0s for pod "pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-ffjqc" to be "success or failure"
Jan 22 19:13:54.884: INFO: Pod "pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.868414ms
Jan 22 19:13:56.889: INFO: Pod "pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008329696s
Jan 22 19:13:58.893: INFO: Pod "pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01221076s
STEP: Saw pod success
Jan 22 19:13:58.893: INFO: Pod "pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:13:58.897: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:13:58.939: INFO: Waiting for pod pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:13:58.942: INFO: Pod pod-dc5f2e13-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:13:58.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ffjqc" for this suite.
Jan 22 19:14:04.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:14:05.138: INFO: namespace: e2e-tests-emptydir-ffjqc, resource: bindings, ignored listing per whitelist
Jan 22 19:14:05.163: INFO: namespace e2e-tests-emptydir-ffjqc deletion completed in 6.216129334s

• [SLOW TEST:10.483 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:14:05.163: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3
Jan 22 19:14:05.373: INFO: Pod name my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3: Found 0 pods out of 1
Jan 22 19:14:10.378: INFO: Pod name my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3: Found 1 pods out of 1
Jan 22 19:14:10.378: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3" are running
Jan 22 19:14:10.381: INFO: Pod "my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3-fsmx6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 19:14:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 19:14:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 19:14:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-22 19:14:05 +0000 UTC Reason: Message:}])
Jan 22 19:14:10.381: INFO: Trying to dial the pod
Jan 22 19:14:15.443: INFO: Controller my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3: Got expected result from replica 1 [my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3-fsmx6]: "my-hostname-basic-e2a10f69-1e79-11e9-9ccc-2ee9843eaab3-fsmx6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:14:15.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-b2rlp" for this suite.
Jan 22 19:14:21.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:14:21.615: INFO: namespace: e2e-tests-replication-controller-b2rlp, resource: bindings, ignored listing per whitelist
Jan 22 19:14:21.689: INFO: namespace e2e-tests-replication-controller-b2rlp deletion completed in 6.241368755s

• [SLOW TEST:16.527 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:14:21.692: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:14:21.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-wpjsb" to be "success or failure"
Jan 22 19:14:21.913: INFO: Pod "downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.036015ms
Jan 22 19:14:23.917: INFO: Pod "downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018673889s
Jan 22 19:14:25.922: INFO: Pod "downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023141558s
STEP: Saw pod success
Jan 22 19:14:25.922: INFO: Pod "downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:14:25.926: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:14:25.958: INFO: Waiting for pod downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:14:25.962: INFO: Pod downwardapi-volume-ec796a6c-1e79-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:14:25.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wpjsb" for this suite.
Jan 22 19:14:31.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:14:32.094: INFO: namespace: e2e-tests-projected-wpjsb, resource: bindings, ignored listing per whitelist
Jan 22 19:14:32.218: INFO: namespace e2e-tests-projected-wpjsb deletion completed in 6.251841149s

• [SLOW TEST:10.527 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:14:32.221: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:14:32.546: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 22 19:14:37.551: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 22 19:14:37.551: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 22 19:14:37.585: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-n8ts8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n8ts8/deployments/test-cleanup-deployment,UID:f5d34158-1e79-11e9-a380-de5a8a93737b,ResourceVersion:13645,Generation:1,CreationTimestamp:2019-01-22 19:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 22 19:14:37.597: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 22 19:14:37.597: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 22 19:14:37.597: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-n8ts8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n8ts8/replicasets/test-cleanup-controller,UID:f2d3bee3-1e79-11e9-a380-de5a8a93737b,ResourceVersion:13646,Generation:1,CreationTimestamp:2019-01-22 19:14:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f5d34158-1e79-11e9-a380-de5a8a93737b 0xc422b12767 0xc422b12768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 22 19:14:37.604: INFO: Pod "test-cleanup-controller-lsl7p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-lsl7p,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-n8ts8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-n8ts8/pods/test-cleanup-controller-lsl7p,UID:f2d7c6b3-1e79-11e9-a380-de5a8a93737b,ResourceVersion:13639,Generation:0,CreationTimestamp:2019-01-22 19:14:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller f2d3bee3-1e79-11e9-a380-de5a8a93737b 0xc422b12dc7 0xc422b12dc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sfgf4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sfgf4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-sfgf4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422b12e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422b12e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:14:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:14:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:14:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:14:32 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.137,StartTime:2019-01-22 19:14:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-22 19:14:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://45f27c367f52680def4243dfce057bf09e43d27c973650f4eb9e47576748b2ad}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:14:37.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-n8ts8" for this suite.
Jan 22 19:14:43.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:14:43.800: INFO: namespace: e2e-tests-deployment-n8ts8, resource: bindings, ignored listing per whitelist
Jan 22 19:14:43.834: INFO: namespace e2e-tests-deployment-n8ts8 deletion completed in 6.224888836s

• [SLOW TEST:11.614 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:14:43.835: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-gxfz
STEP: Creating a pod to test atomic-volume-subpath
Jan 22 19:14:44.024: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-gxfz" in namespace "e2e-tests-subpath-dmpk9" to be "success or failure"
Jan 22 19:14:44.028: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.811413ms
Jan 22 19:14:46.032: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007610353s
Jan 22 19:14:48.037: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 4.012483523s
Jan 22 19:14:50.044: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 6.019379052s
Jan 22 19:14:52.050: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 8.025358653s
Jan 22 19:14:54.057: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 10.032310682s
Jan 22 19:14:56.061: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 12.036852039s
Jan 22 19:14:58.066: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 14.041614901s
Jan 22 19:15:00.072: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 16.047683902s
Jan 22 19:15:02.081: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 18.056689488s
Jan 22 19:15:04.086: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 20.061318144s
Jan 22 19:15:06.091: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Running", Reason="", readiness=false. Elapsed: 22.066784424s
Jan 22 19:15:08.098: INFO: Pod "pod-subpath-test-projected-gxfz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073203831s
STEP: Saw pod success
Jan 22 19:15:08.098: INFO: Pod "pod-subpath-test-projected-gxfz" satisfied condition "success or failure"
Jan 22 19:15:08.102: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-subpath-test-projected-gxfz container test-container-subpath-projected-gxfz: <nil>
STEP: delete the pod
Jan 22 19:15:08.152: INFO: Waiting for pod pod-subpath-test-projected-gxfz to disappear
Jan 22 19:15:08.161: INFO: Pod pod-subpath-test-projected-gxfz no longer exists
STEP: Deleting pod pod-subpath-test-projected-gxfz
Jan 22 19:15:08.161: INFO: Deleting pod "pod-subpath-test-projected-gxfz" in namespace "e2e-tests-subpath-dmpk9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:15:08.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dmpk9" for this suite.
Jan 22 19:15:14.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:15:14.318: INFO: namespace: e2e-tests-subpath-dmpk9, resource: bindings, ignored listing per whitelist
Jan 22 19:15:14.423: INFO: namespace e2e-tests-subpath-dmpk9 deletion completed in 6.249596831s

• [SLOW TEST:30.589 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:15:14.423: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 22 19:15:18.684: INFO: Pod pod-hostip-0bee31d3-1e7a-11e9-9ccc-2ee9843eaab3 has hostIP: 10.240.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:15:18.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-snm99" for this suite.
Jan 22 19:15:40.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:15:40.774: INFO: namespace: e2e-tests-pods-snm99, resource: bindings, ignored listing per whitelist
Jan 22 19:15:40.929: INFO: namespace e2e-tests-pods-snm99 deletion completed in 22.239790205s

• [SLOW TEST:26.505 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:15:40.929: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1bbf5fe8-1e7a-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:15:41.215: INFO: Waiting up to 5m0s for pod "pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-znn67" to be "success or failure"
Jan 22 19:15:41.219: INFO: Pod "pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.949961ms
Jan 22 19:15:43.223: INFO: Pod "pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008141946s
Jan 22 19:15:45.230: INFO: Pod "pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015352181s
STEP: Saw pod success
Jan 22 19:15:45.230: INFO: Pod "pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:15:45.242: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:15:45.357: INFO: Waiting for pod pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:15:45.366: INFO: Pod pod-secrets-1bc16872-1e7a-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:15:45.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-znn67" for this suite.
Jan 22 19:15:51.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:15:51.664: INFO: namespace: e2e-tests-secrets-znn67, resource: bindings, ignored listing per whitelist
Jan 22 19:15:51.825: INFO: namespace e2e-tests-secrets-znn67 deletion completed in 6.454478458s

• [SLOW TEST:10.896 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:15:51.825: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:15:52.027: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-rw6w6" to be "success or failure"
Jan 22 19:15:52.036: INFO: Pod "downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.989763ms
Jan 22 19:15:54.039: INFO: Pod "downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012840645s
STEP: Saw pod success
Jan 22 19:15:54.039: INFO: Pod "downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:15:54.044: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:15:54.090: INFO: Waiting for pod downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:15:54.093: INFO: Pod downwardapi-volume-22330dcf-1e7a-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:15:54.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rw6w6" for this suite.
Jan 22 19:16:00.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:16:00.206: INFO: namespace: e2e-tests-downward-api-rw6w6, resource: bindings, ignored listing per whitelist
Jan 22 19:16:00.289: INFO: namespace e2e-tests-downward-api-rw6w6 deletion completed in 6.190987438s

• [SLOW TEST:8.464 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:16:00.289: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gl82v
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-gl82v
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-gl82v
Jan 22 19:16:00.480: INFO: Found 0 stateful pods, waiting for 1
Jan 22 19:16:10.487: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 22 19:16:10.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 19:16:10.948: INFO: stderr: ""
Jan 22 19:16:10.948: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 19:16:10.948: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 19:16:10.955: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 22 19:16:20.959: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 19:16:20.959: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 19:16:20.980: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan 22 19:16:20.980: INFO: ss-0  aks-nodepool1-25266157-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  }]
Jan 22 19:16:20.980: INFO: 
Jan 22 19:16:20.980: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 22 19:16:21.988: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995263492s
Jan 22 19:16:22.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987242569s
Jan 22 19:16:23.999: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982439992s
Jan 22 19:16:25.015: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976727695s
Jan 22 19:16:26.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960299889s
Jan 22 19:16:27.024: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.956123887s
Jan 22 19:16:28.029: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.951287776s
Jan 22 19:16:29.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.946594288s
Jan 22 19:16:30.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 941.639606ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-gl82v
Jan 22 19:16:31.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:16:31.488: INFO: stderr: ""
Jan 22 19:16:31.488: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 19:16:31.488: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 19:16:31.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:16:31.956: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 22 19:16:31.956: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 19:16:31.956: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 19:16:31.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:16:32.350: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 22 19:16:32.350: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 19:16:32.350: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 19:16:32.356: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:16:32.356: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:16:32.356: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 22 19:16:32.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 19:16:32.736: INFO: stderr: ""
Jan 22 19:16:32.736: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 19:16:32.736: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 19:16:32.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 19:16:33.140: INFO: stderr: ""
Jan 22 19:16:33.140: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 19:16:33.140: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 19:16:33.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-gl82v ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 19:16:33.549: INFO: stderr: ""
Jan 22 19:16:33.549: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 19:16:33.549: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 19:16:33.549: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 19:16:33.555: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 22 19:16:43.563: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 19:16:43.563: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 19:16:43.563: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 22 19:16:43.616: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan 22 19:16:43.616: INFO: ss-0  aks-nodepool1-25266157-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  }]
Jan 22 19:16:43.616: INFO: ss-1  aks-nodepool1-25266157-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:20 +0000 UTC  }]
Jan 22 19:16:43.616: INFO: ss-2  aks-nodepool1-25266157-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  }]
Jan 22 19:16:43.616: INFO: 
Jan 22 19:16:43.616: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 19:16:44.621: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan 22 19:16:44.621: INFO: ss-0  aks-nodepool1-25266157-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  }]
Jan 22 19:16:44.621: INFO: ss-1  aks-nodepool1-25266157-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:20 +0000 UTC  }]
Jan 22 19:16:44.622: INFO: ss-2  aks-nodepool1-25266157-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  }]
Jan 22 19:16:44.622: INFO: 
Jan 22 19:16:44.622: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 22 19:16:45.628: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan 22 19:16:45.628: INFO: ss-0  aks-nodepool1-25266157-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  }]
Jan 22 19:16:45.628: INFO: ss-2  aks-nodepool1-25266157-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:21 +0000 UTC  }]
Jan 22 19:16:45.628: INFO: 
Jan 22 19:16:45.628: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 22 19:16:46.633: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan 22 19:16:46.633: INFO: ss-0  aks-nodepool1-25266157-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  }]
Jan 22 19:16:46.633: INFO: 
Jan 22 19:16:46.633: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 22 19:16:47.638: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Jan 22 19:16:47.638: INFO: ss-0  aks-nodepool1-25266157-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:16:00 +0000 UTC  }]
Jan 22 19:16:47.638: INFO: 
Jan 22 19:16:47.638: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 22 19:16:48.643: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.938231489s
Jan 22 19:16:49.648: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.933493936s
Jan 22 19:16:50.652: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.928938807s
Jan 22 19:16:51.657: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.924206587s
Jan 22 19:16:52.663: INFO: Verifying statefulset ss doesn't scale past 0 for another 919.735994ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-gl82v
Jan 22 19:16:53.670: INFO: Scaling statefulset ss to 0
Jan 22 19:16:53.686: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 22 19:16:53.696: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gl82v
Jan 22 19:16:53.701: INFO: Scaling statefulset ss to 0
Jan 22 19:16:53.713: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 19:16:53.717: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:16:53.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gl82v" for this suite.
Jan 22 19:16:59.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:16:59.847: INFO: namespace: e2e-tests-statefulset-gl82v, resource: bindings, ignored listing per whitelist
Jan 22 19:17:00.056: INFO: namespace e2e-tests-statefulset-gl82v deletion completed in 6.304200123s

• [SLOW TEST:59.767 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:17:00.057: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:17:00.233: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-bt8pv" to be "success or failure"
Jan 22 19:17:00.237: INFO: Pod "downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.712746ms
Jan 22 19:17:02.242: INFO: Pod "downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00816877s
Jan 22 19:17:04.246: INFO: Pod "downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012617831s
STEP: Saw pod success
Jan 22 19:17:04.246: INFO: Pod "downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:17:04.251: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:17:04.289: INFO: Waiting for pod downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:17:04.295: INFO: Pod downwardapi-volume-4ada3fd5-1e7a-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:17:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bt8pv" for this suite.
Jan 22 19:17:10.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:17:10.445: INFO: namespace: e2e-tests-projected-bt8pv, resource: bindings, ignored listing per whitelist
Jan 22 19:17:10.531: INFO: namespace e2e-tests-projected-bt8pv deletion completed in 6.229827375s

• [SLOW TEST:10.474 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:17:10.531: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 19:17:10.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-gv5tq'
Jan 22 19:17:10.885: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 22 19:17:10.885: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan 22 19:17:14.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-gv5tq'
Jan 22 19:17:15.055: INFO: stderr: ""
Jan 22 19:17:15.055: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:17:15.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gv5tq" for this suite.
Jan 22 19:17:39.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:17:39.274: INFO: namespace: e2e-tests-kubectl-gv5tq, resource: bindings, ignored listing per whitelist
Jan 22 19:17:39.305: INFO: namespace e2e-tests-kubectl-gv5tq deletion completed in 24.237292251s

• [SLOW TEST:28.774 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:17:39.305: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 22 19:17:39.489: INFO: Waiting up to 5m0s for pod "var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-var-expansion-f8lxk" to be "success or failure"
Jan 22 19:17:39.498: INFO: Pod "var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.894644ms
Jan 22 19:17:41.503: INFO: Pod "var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014061713s
Jan 22 19:17:43.507: INFO: Pod "var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018560998s
STEP: Saw pod success
Jan 22 19:17:43.507: INFO: Pod "var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:17:43.512: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 19:17:43.545: INFO: Waiting for pod var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:17:43.549: INFO: Pod var-expansion-6240b564-1e7a-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:17:43.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-f8lxk" for this suite.
Jan 22 19:17:49.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:17:49.671: INFO: namespace: e2e-tests-var-expansion-f8lxk, resource: bindings, ignored listing per whitelist
Jan 22 19:17:49.775: INFO: namespace e2e-tests-var-expansion-f8lxk deletion completed in 6.219883264s

• [SLOW TEST:10.470 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:17:49.775: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-687e8179-1e7a-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-687e8179-1e7a-11e9-9ccc-2ee9843eaab3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:17:54.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-57fq4" for this suite.
Jan 22 19:18:16.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:18:16.243: INFO: namespace: e2e-tests-projected-57fq4, resource: bindings, ignored listing per whitelist
Jan 22 19:18:16.251: INFO: namespace e2e-tests-projected-57fq4 deletion completed in 22.161051689s

• [SLOW TEST:26.476 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:18:16.252: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-w5fh4
Jan 22 19:18:18.474: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-w5fh4
STEP: checking the pod's current state and verifying that restartCount is present
Jan 22 19:18:18.478: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:22:19.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-w5fh4" for this suite.
Jan 22 19:22:25.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:22:25.294: INFO: namespace: e2e-tests-container-probe-w5fh4, resource: bindings, ignored listing per whitelist
Jan 22 19:22:25.324: INFO: namespace e2e-tests-container-probe-w5fh4 deletion completed in 6.202295816s

• [SLOW TEST:249.073 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:22:25.324: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0cbb1f31-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:22:25.514: INFO: Waiting up to 5m0s for pod "pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-psslv" to be "success or failure"
Jan 22 19:22:25.518: INFO: Pod "pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.774234ms
Jan 22 19:22:27.523: INFO: Pod "pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008212429s
Jan 22 19:22:29.528: INFO: Pod "pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013056504s
STEP: Saw pod success
Jan 22 19:22:29.528: INFO: Pod "pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:22:29.532: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:22:29.583: INFO: Waiting for pod pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:22:29.587: INFO: Pod pod-configmaps-0cbc4877-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:22:29.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-psslv" for this suite.
Jan 22 19:22:35.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:22:35.770: INFO: namespace: e2e-tests-configmap-psslv, resource: bindings, ignored listing per whitelist
Jan 22 19:22:35.845: INFO: namespace e2e-tests-configmap-psslv deletion completed in 6.252243352s

• [SLOW TEST:10.521 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:22:35.846: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:22:36.059: INFO: (0) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 7.823577ms)
Jan 22 19:22:36.065: INFO: (1) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.020413ms)
Jan 22 19:22:36.072: INFO: (2) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 7.296458ms)
Jan 22 19:22:36.078: INFO: (3) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.93911ms)
Jan 22 19:22:36.084: INFO: (4) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.6363ms)
Jan 22 19:22:36.090: INFO: (5) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.241921ms)
Jan 22 19:22:36.097: INFO: (6) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.883544ms)
Jan 22 19:22:36.103: INFO: (7) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.411092ms)
Jan 22 19:22:36.109: INFO: (8) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.109017ms)
Jan 22 19:22:36.115: INFO: (9) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.853207ms)
Jan 22 19:22:36.121: INFO: (10) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.695137ms)
Jan 22 19:22:36.127: INFO: (11) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.165018ms)
Jan 22 19:22:36.133: INFO: (12) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.37569ms)
Jan 22 19:22:36.141: INFO: (13) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 8.009884ms)
Jan 22 19:22:36.148: INFO: (14) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.751739ms)
Jan 22 19:22:36.153: INFO: (15) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 5.521996ms)
Jan 22 19:22:36.159: INFO: (16) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.20112ms)
Jan 22 19:22:36.166: INFO: (17) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.244822ms)
Jan 22 19:22:36.172: INFO: (18) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.658336ms)
Jan 22 19:22:36.179: INFO: (19) /api/v1/nodes/aks-nodepool1-25266157-0:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="azure/">azure/</a>
<a href... (200; 6.513931ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:22:36.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-q726d" for this suite.
Jan 22 19:22:42.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:22:42.304: INFO: namespace: e2e-tests-proxy-q726d, resource: bindings, ignored listing per whitelist
Jan 22 19:22:42.445: INFO: namespace e2e-tests-proxy-q726d deletion completed in 6.261311838s

• [SLOW TEST:6.599 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:22:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:22:42.746: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-nlkm4" to be "success or failure"
Jan 22 19:22:42.760: INFO: Pod "downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.258505ms
Jan 22 19:22:44.765: INFO: Pod "downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018697018s
Jan 22 19:22:46.770: INFO: Pod "downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023564615s
STEP: Saw pod success
Jan 22 19:22:46.770: INFO: Pod "downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:22:46.774: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:22:46.811: INFO: Waiting for pod downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:22:46.814: INFO: Pod downwardapi-volume-16f74325-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:22:46.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nlkm4" for this suite.
Jan 22 19:22:52.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:22:52.985: INFO: namespace: e2e-tests-downward-api-nlkm4, resource: bindings, ignored listing per whitelist
Jan 22 19:22:53.115: INFO: namespace e2e-tests-downward-api-nlkm4 deletion completed in 6.296032033s

• [SLOW TEST:10.670 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:22:53.115: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xcp2x
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 22 19:22:53.350: INFO: Found 0 stateful pods, waiting for 3
Jan 22 19:23:03.357: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:23:03.357: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:23:03.357: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 22 19:23:03.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-xcp2x ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 19:23:03.900: INFO: stderr: ""
Jan 22 19:23:03.900: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 19:23:03.900: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 22 19:23:13.944: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 22 19:23:24.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-xcp2x ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:23:24.505: INFO: stderr: ""
Jan 22 19:23:24.505: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 19:23:24.505: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 19:23:34.529: INFO: Waiting for StatefulSet e2e-tests-statefulset-xcp2x/ss2 to complete update
Jan 22 19:23:34.529: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:23:34.529: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:23:34.529: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:23:44.538: INFO: Waiting for StatefulSet e2e-tests-statefulset-xcp2x/ss2 to complete update
Jan 22 19:23:44.538: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 22 19:23:44.538: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan 22 19:23:54.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-xcp2x ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 22 19:23:54.995: INFO: stderr: ""
Jan 22 19:23:54.995: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 22 19:23:54.995: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 22 19:24:05.042: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 22 19:24:15.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 exec --namespace=e2e-tests-statefulset-xcp2x ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 22 19:24:15.478: INFO: stderr: ""
Jan 22 19:24:15.478: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 22 19:24:15.478: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 22 19:24:15.518: INFO: Waiting for StatefulSet e2e-tests-statefulset-xcp2x/ss2 to complete update
Jan 22 19:24:15.518: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 22 19:24:15.518: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 22 19:24:15.518: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 22 19:24:25.528: INFO: Waiting for StatefulSet e2e-tests-statefulset-xcp2x/ss2 to complete update
Jan 22 19:24:25.528: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 22 19:24:25.528: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 22 19:24:25.528: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 22 19:24:35.529: INFO: Waiting for StatefulSet e2e-tests-statefulset-xcp2x/ss2 to complete update
Jan 22 19:24:35.530: INFO: Waiting for Pod e2e-tests-statefulset-xcp2x/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 22 19:24:45.528: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xcp2x
Jan 22 19:24:45.533: INFO: Scaling statefulset ss2 to 0
Jan 22 19:25:15.555: INFO: Waiting for statefulset status.replicas updated to 0
Jan 22 19:25:15.560: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:25:15.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xcp2x" for this suite.
Jan 22 19:25:21.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:25:21.748: INFO: namespace: e2e-tests-statefulset-xcp2x, resource: bindings, ignored listing per whitelist
Jan 22 19:25:21.753: INFO: namespace e2e-tests-statefulset-xcp2x deletion completed in 6.155598903s

• [SLOW TEST:148.638 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:25:21.753: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:25:21.928: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-6mdt5" to be "success or failure"
Jan 22 19:25:21.936: INFO: Pod "downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.509692ms
Jan 22 19:25:23.941: INFO: Pod "downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012953915s
Jan 22 19:25:25.945: INFO: Pod "downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017074804s
STEP: Saw pod success
Jan 22 19:25:25.945: INFO: Pod "downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:25:25.950: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:25:25.985: INFO: Waiting for pod downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:25:25.989: INFO: Pod downwardapi-volume-75e31bfb-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:25:25.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6mdt5" for this suite.
Jan 22 19:25:32.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:25:32.126: INFO: namespace: e2e-tests-projected-6mdt5, resource: bindings, ignored listing per whitelist
Jan 22 19:25:32.178: INFO: namespace e2e-tests-projected-6mdt5 deletion completed in 6.185281345s

• [SLOW TEST:10.425 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:25:32.179: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 22 19:25:32.329: INFO: Waiting up to 5m0s for pod "var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-var-expansion-97pc6" to be "success or failure"
Jan 22 19:25:32.333: INFO: Pod "var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752828ms
Jan 22 19:25:34.337: INFO: Pod "var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008520042s
Jan 22 19:25:36.343: INFO: Pod "var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013918754s
STEP: Saw pod success
Jan 22 19:25:36.343: INFO: Pod "var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:25:36.346: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 19:25:36.384: INFO: Waiting for pod var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:25:36.388: INFO: Pod var-expansion-7c15cde2-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:25:36.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-97pc6" for this suite.
Jan 22 19:25:42.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:25:42.554: INFO: namespace: e2e-tests-var-expansion-97pc6, resource: bindings, ignored listing per whitelist
Jan 22 19:25:42.600: INFO: namespace e2e-tests-var-expansion-97pc6 deletion completed in 6.207500036s

• [SLOW TEST:10.421 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:25:42.600: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tf4j4/configmap-test-8260ec98-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:25:42.895: INFO: Waiting up to 5m0s for pod "pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-tf4j4" to be "success or failure"
Jan 22 19:25:42.904: INFO: Pod "pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.920505ms
Jan 22 19:25:44.910: INFO: Pod "pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Running", Reason="", readiness=true. Elapsed: 2.01462173s
Jan 22 19:25:46.931: INFO: Pod "pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035650057s
STEP: Saw pod success
Jan 22 19:25:46.931: INFO: Pod "pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:25:46.935: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3 container env-test: <nil>
STEP: delete the pod
Jan 22 19:25:47.004: INFO: Waiting for pod pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:25:47.008: INFO: Pod pod-configmaps-82624f30-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:25:47.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tf4j4" for this suite.
Jan 22 19:25:53.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:25:53.097: INFO: namespace: e2e-tests-configmap-tf4j4, resource: bindings, ignored listing per whitelist
Jan 22 19:25:53.210: INFO: namespace e2e-tests-configmap-tf4j4 deletion completed in 6.19736952s

• [SLOW TEST:10.610 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:25:53.210: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-88a37a43-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating secret with name s-test-opt-upd-88a37a81-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-88a37a43-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Updating secret s-test-opt-upd-88a37a81-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating secret with name s-test-opt-create-88a37a96-1e7b-11e9-9ccc-2ee9843eaab3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:26:01.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rmgz4" for this suite.
Jan 22 19:26:23.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:26:23.878: INFO: namespace: e2e-tests-projected-rmgz4, resource: bindings, ignored listing per whitelist
Jan 22 19:26:23.909: INFO: namespace e2e-tests-projected-rmgz4 deletion completed in 22.185800888s

• [SLOW TEST:30.699 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:26:23.909: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-9aef464a-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:26:24.098: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-m4gst" to be "success or failure"
Jan 22 19:26:24.108: INFO: Pod "pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.965538ms
Jan 22 19:26:26.112: INFO: Pod "pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014354573s
Jan 22 19:26:28.116: INFO: Pod "pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018621883s
STEP: Saw pod success
Jan 22 19:26:28.116: INFO: Pod "pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:26:28.120: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:26:28.152: INFO: Waiting for pod pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:26:28.156: INFO: Pod pod-projected-configmaps-9af08d69-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:26:28.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m4gst" for this suite.
Jan 22 19:26:34.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:26:34.349: INFO: namespace: e2e-tests-projected-m4gst, resource: bindings, ignored listing per whitelist
Jan 22 19:26:34.368: INFO: namespace e2e-tests-projected-m4gst deletion completed in 6.207425902s

• [SLOW TEST:10.459 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:26:34.368: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 22 19:26:39.053: INFO: Successfully updated pod "pod-update-a1277407-1e7b-11e9-9ccc-2ee9843eaab3"
STEP: verifying the updated pod is in kubernetes
Jan 22 19:26:39.062: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:26:39.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5pdpf" for this suite.
Jan 22 19:27:01.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:27:01.132: INFO: namespace: e2e-tests-pods-5pdpf, resource: bindings, ignored listing per whitelist
Jan 22 19:27:01.235: INFO: namespace e2e-tests-pods-5pdpf deletion completed in 22.167230719s

• [SLOW TEST:26.867 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:27:01.235: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-b13206ef-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:27:05.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ll2lx" for this suite.
Jan 22 19:27:27.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:27:27.652: INFO: namespace: e2e-tests-configmap-ll2lx, resource: bindings, ignored listing per whitelist
Jan 22 19:27:27.771: INFO: namespace e2e-tests-configmap-ll2lx deletion completed in 22.237386958s

• [SLOW TEST:26.536 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:27:27.771: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:27:27.921: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-f44pn" to be "success or failure"
Jan 22 19:27:27.925: INFO: Pod "downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.16434ms
Jan 22 19:27:29.932: INFO: Pod "downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011507751s
Jan 22 19:27:31.939: INFO: Pod "downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018469731s
STEP: Saw pod success
Jan 22 19:27:31.939: INFO: Pod "downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:27:31.944: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:27:31.977: INFO: Waiting for pod downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:27:31.980: INFO: Pod downwardapi-volume-c0fc407a-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:27:31.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f44pn" for this suite.
Jan 22 19:27:38.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:27:38.153: INFO: namespace: e2e-tests-projected-f44pn, resource: bindings, ignored listing per whitelist
Jan 22 19:27:38.231: INFO: namespace e2e-tests-projected-f44pn deletion completed in 6.244037324s

• [SLOW TEST:10.460 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:27:38.232: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0122 19:28:08.956578      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 19:28:08.956: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:28:08.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8thnw" for this suite.
Jan 22 19:28:14.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:28:15.143: INFO: namespace: e2e-tests-gc-8thnw, resource: bindings, ignored listing per whitelist
Jan 22 19:28:15.207: INFO: namespace e2e-tests-gc-8thnw deletion completed in 6.246078886s

• [SLOW TEST:36.975 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:28:15.208: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-dd4b2d81-1e7b-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:28:15.562: INFO: Waiting up to 5m0s for pod "pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-vwcd4" to be "success or failure"
Jan 22 19:28:15.566: INFO: Pod "pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.337345ms
Jan 22 19:28:17.571: INFO: Pod "pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009352861s
Jan 22 19:28:19.576: INFO: Pod "pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014053549s
STEP: Saw pod success
Jan 22 19:28:19.576: INFO: Pod "pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:28:19.580: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:28:19.626: INFO: Waiting for pod pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:28:19.630: INFO: Pod pod-secrets-dd5dfb83-1e7b-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:28:19.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vwcd4" for this suite.
Jan 22 19:28:25.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:28:25.674: INFO: namespace: e2e-tests-secrets-vwcd4, resource: bindings, ignored listing per whitelist
Jan 22 19:28:25.830: INFO: namespace e2e-tests-secrets-vwcd4 deletion completed in 6.194106374s
STEP: Destroying namespace "e2e-tests-secret-namespace-hvhrh" for this suite.
Jan 22 19:28:31.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:28:31.870: INFO: namespace: e2e-tests-secret-namespace-hvhrh, resource: bindings, ignored listing per whitelist
Jan 22 19:28:31.968: INFO: namespace e2e-tests-secret-namespace-hvhrh deletion completed in 6.138414259s

• [SLOW TEST:16.760 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:28:31.968: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 22 19:28:36.231: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:36.235: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:38.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:38.242: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:40.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:40.239: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:42.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:42.240: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:44.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:44.239: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:46.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:46.239: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:48.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:48.241: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:50.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:50.239: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:52.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:52.239: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:54.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:54.239: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 22 19:28:56.235: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 22 19:28:56.240: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:28:56.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5w7pc" for this suite.
Jan 22 19:29:12.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:29:12.494: INFO: namespace: e2e-tests-container-lifecycle-hook-5w7pc, resource: bindings, ignored listing per whitelist
Jan 22 19:29:12.509: INFO: namespace e2e-tests-container-lifecycle-hook-5w7pc deletion completed in 16.182544506s

• [SLOW TEST:40.540 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:29:12.509: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:29:12.639: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 22 19:29:12.650: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 22 19:29:17.657: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 22 19:29:17.657: INFO: Creating deployment "test-rolling-update-deployment"
Jan 22 19:29:17.665: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 22 19:29:17.683: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 22 19:29:19.695: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 22 19:29:19.699: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 22 19:29:19.710: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-vgbld,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vgbld/deployments/test-rolling-update-deployment,UID:026711e8-1e7c-11e9-a380-de5a8a93737b,ResourceVersion:16378,Generation:1,CreationTimestamp:2019-01-22 19:29:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-22 19:29:17 +0000 UTC 2019-01-22 19:29:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-22 19:29:19 +0000 UTC 2019-01-22 19:29:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 22 19:29:19.717: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-vgbld,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vgbld/replicasets/test-rolling-update-deployment-65b7695dcf,UID:026ca19d-1e7c-11e9-a380-de5a8a93737b,ResourceVersion:16369,Generation:1,CreationTimestamp:2019-01-22 19:29:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 026711e8-1e7c-11e9-a380-de5a8a93737b 0xc422b44bd7 0xc422b44bd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 22 19:29:19.717: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 22 19:29:19.717: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-vgbld,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vgbld/replicasets/test-rolling-update-controller,UID:ff69681a-1e7b-11e9-a380-de5a8a93737b,ResourceVersion:16377,Generation:2,CreationTimestamp:2019-01-22 19:29:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 026711e8-1e7c-11e9-a380-de5a8a93737b 0xc422b44b0e 0xc422b44b0f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 22 19:29:19.721: INFO: Pod "test-rolling-update-deployment-65b7695dcf-h6htb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-h6htb,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-vgbld,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vgbld/pods/test-rolling-update-deployment-65b7695dcf-h6htb,UID:026e39f9-1e7c-11e9-a380-de5a8a93737b,ResourceVersion:16368,Generation:0,CreationTimestamp:2019-01-22 19:29:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 026ca19d-1e7c-11e9-a380-de5a8a93737b 0xc422b45f37 0xc422b45f38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pczn8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pczn8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-pczn8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422b45ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f54140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:29:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:29:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:29:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:29:17 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.174,StartTime:2019-01-22 19:29:17 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-22 19:29:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a2bf0518b268db6dd758a1932fd8f66a65b92e2668eb92f51249f043c5b620c9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:29:19.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vgbld" for this suite.
Jan 22 19:29:25.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:29:25.803: INFO: namespace: e2e-tests-deployment-vgbld, resource: bindings, ignored listing per whitelist
Jan 22 19:29:25.910: INFO: namespace e2e-tests-deployment-vgbld deletion completed in 6.184145898s

• [SLOW TEST:13.401 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:29:25.912: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 19:29:26.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nw4tt'
Jan 22 19:29:27.304: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 22 19:29:27.304: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 22 19:29:27.312: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 22 19:29:27.332: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 22 19:29:27.344: INFO: scanned /root for discovery docs: <nil>
Jan 22 19:29:27.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-nw4tt'
Jan 22 19:29:43.208: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 22 19:29:43.208: INFO: stdout: "Created e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376\nScaling up e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 22 19:29:43.208: INFO: stdout: "Created e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376\nScaling up e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 22 19:29:43.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nw4tt'
Jan 22 19:29:43.330: INFO: stderr: ""
Jan 22 19:29:43.330: INFO: stdout: "e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376-rscvr "
Jan 22 19:29:43.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376-rscvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nw4tt'
Jan 22 19:29:43.477: INFO: stderr: ""
Jan 22 19:29:43.477: INFO: stdout: "true"
Jan 22 19:29:43.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376-rscvr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nw4tt'
Jan 22 19:29:43.595: INFO: stderr: ""
Jan 22 19:29:43.595: INFO: stdout: "nginx:1.14-alpine"
Jan 22 19:29:43.595: INFO: e2e-test-nginx-rc-1c2caf8d1044052098915f7b22191376-rscvr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan 22 19:29:43.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nw4tt'
Jan 22 19:29:43.726: INFO: stderr: ""
Jan 22 19:29:43.726: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:29:43.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nw4tt" for this suite.
Jan 22 19:29:49.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:29:49.873: INFO: namespace: e2e-tests-kubectl-nw4tt, resource: bindings, ignored listing per whitelist
Jan 22 19:29:49.935: INFO: namespace e2e-tests-kubectl-nw4tt deletion completed in 6.203670213s

• [SLOW TEST:24.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:29:49.936: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-15b8cb08-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:29:50.093: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-fl7kv" to be "success or failure"
Jan 22 19:29:50.099: INFO: Pod "pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017399ms
Jan 22 19:29:52.104: INFO: Pod "pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01060418s
Jan 22 19:29:54.111: INFO: Pod "pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018078241s
STEP: Saw pod success
Jan 22 19:29:54.112: INFO: Pod "pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:29:54.116: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:29:54.147: INFO: Waiting for pod pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:29:54.156: INFO: Pod pod-projected-secrets-15b9e0d9-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:29:54.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fl7kv" for this suite.
Jan 22 19:30:00.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:30:00.190: INFO: namespace: e2e-tests-projected-fl7kv, resource: bindings, ignored listing per whitelist
Jan 22 19:30:00.350: INFO: namespace e2e-tests-projected-fl7kv deletion completed in 6.188665393s

• [SLOW TEST:10.414 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:30:00.350: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 22 19:30:04.501: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-1bea02ef-1e7c-11e9-9ccc-2ee9843eaab3,GenerateName:,Namespace:e2e-tests-events-xbx92,SelfLink:/api/v1/namespaces/e2e-tests-events-xbx92/pods/send-events-1bea02ef-1e7c-11e9-9ccc-2ee9843eaab3,UID:1beb35db-1e7c-11e9-a380-de5a8a93737b,ResourceVersion:16592,Generation:0,CreationTimestamp:2019-01-22 19:30:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 460982601,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hmztf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hmztf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-hmztf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b67380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b673a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:30:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:30:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:30:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:30:00 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.178,StartTime:2019-01-22 19:30:00 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-22 19:30:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://737132f700bcd523ce065b14b0980a242a18db41c27fb1c48a59f5f35acf1ea7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 22 19:30:06.505: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 22 19:30:08.510: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:30:08.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xbx92" for this suite.
Jan 22 19:30:50.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:30:50.619: INFO: namespace: e2e-tests-events-xbx92, resource: bindings, ignored listing per whitelist
Jan 22 19:30:50.772: INFO: namespace e2e-tests-events-xbx92 deletion completed in 42.24266021s

• [SLOW TEST:50.422 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:30:50.772: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 22 19:30:50.940: INFO: Waiting up to 5m0s for pod "pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-46nsm" to be "success or failure"
Jan 22 19:30:50.946: INFO: Pod "pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.455712ms
Jan 22 19:30:52.951: INFO: Pod "pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011260201s
Jan 22 19:30:54.956: INFO: Pod "pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016323886s
STEP: Saw pod success
Jan 22 19:30:54.956: INFO: Pod "pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:30:54.961: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:30:55.006: INFO: Waiting for pod pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:30:55.011: INFO: Pod pod-39fe607f-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:30:55.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-46nsm" for this suite.
Jan 22 19:31:01.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:31:01.167: INFO: namespace: e2e-tests-emptydir-46nsm, resource: bindings, ignored listing per whitelist
Jan 22 19:31:01.205: INFO: namespace e2e-tests-emptydir-46nsm deletion completed in 6.190081224s

• [SLOW TEST:10.433 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:31:01.205: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-403732b2-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:31:01.396: INFO: Waiting up to 5m0s for pod "pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-6rtm4" to be "success or failure"
Jan 22 19:31:01.405: INFO: Pod "pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.060298ms
Jan 22 19:31:03.412: INFO: Pod "pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01680732s
Jan 22 19:31:05.418: INFO: Pod "pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022689968s
STEP: Saw pod success
Jan 22 19:31:05.418: INFO: Pod "pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:31:05.422: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:31:05.461: INFO: Waiting for pod pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:31:05.466: INFO: Pod pod-secrets-4039f746-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:31:05.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6rtm4" for this suite.
Jan 22 19:31:11.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:31:11.561: INFO: namespace: e2e-tests-secrets-6rtm4, resource: bindings, ignored listing per whitelist
Jan 22 19:31:11.681: INFO: namespace e2e-tests-secrets-6rtm4 deletion completed in 6.210594103s

• [SLOW TEST:10.475 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:31:11.681: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-46724394-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:31:11.846: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-4v477" to be "success or failure"
Jan 22 19:31:11.852: INFO: Pod "pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.542215ms
Jan 22 19:31:13.867: INFO: Pod "pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02147701s
STEP: Saw pod success
Jan 22 19:31:13.867: INFO: Pod "pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:31:13.874: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:31:13.931: INFO: Waiting for pod pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:31:13.935: INFO: Pod pod-projected-secrets-46737929-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:31:13.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4v477" for this suite.
Jan 22 19:31:19.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:31:20.030: INFO: namespace: e2e-tests-projected-4v477, resource: bindings, ignored listing per whitelist
Jan 22 19:31:20.115: INFO: namespace e2e-tests-projected-4v477 deletion completed in 6.175432594s

• [SLOW TEST:8.435 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:31:20.116: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dg88m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 19:31:20.233: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 19:31:42.396: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.0.38 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dg88m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:31:42.397: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:31:43.725: INFO: Found all expected endpoints: [netserver-0]
Jan 22 19:31:43.729: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.1.184 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dg88m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:31:43.729: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:31:45.034: INFO: Found all expected endpoints: [netserver-1]
Jan 22 19:31:45.040: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.2.49 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dg88m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:31:45.040: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:31:46.301: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:31:46.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dg88m" for this suite.
Jan 22 19:32:08.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:32:08.441: INFO: namespace: e2e-tests-pod-network-test-dg88m, resource: bindings, ignored listing per whitelist
Jan 22 19:32:08.507: INFO: namespace e2e-tests-pod-network-test-dg88m deletion completed in 22.200762547s

• [SLOW TEST:48.391 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:32:08.507: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 22 19:32:11.211: INFO: Successfully updated pod "annotationupdate685042f2-1e7c-11e9-9ccc-2ee9843eaab3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:32:13.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-slx54" for this suite.
Jan 22 19:32:35.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:32:35.388: INFO: namespace: e2e-tests-downward-api-slx54, resource: bindings, ignored listing per whitelist
Jan 22 19:32:35.450: INFO: namespace e2e-tests-downward-api-slx54 deletion completed in 22.192977416s

• [SLOW TEST:26.943 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:32:35.450: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-78673171-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:32:35.679: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-tzfdv" to be "success or failure"
Jan 22 19:32:35.683: INFO: Pod "pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00163ms
Jan 22 19:32:37.687: INFO: Pod "pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008596128s
Jan 22 19:32:39.692: INFO: Pod "pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013416224s
STEP: Saw pod success
Jan 22 19:32:39.692: INFO: Pod "pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:32:39.696: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:32:39.733: INFO: Waiting for pod pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:32:39.737: INFO: Pod pod-projected-configmaps-786c6bcb-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:32:39.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzfdv" for this suite.
Jan 22 19:32:45.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:32:45.912: INFO: namespace: e2e-tests-projected-tzfdv, resource: bindings, ignored listing per whitelist
Jan 22 19:32:45.946: INFO: namespace e2e-tests-projected-tzfdv deletion completed in 6.204106899s

• [SLOW TEST:10.496 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:32:45.946: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 22 19:32:46.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 api-versions'
Jan 22 19:32:46.214: INFO: stderr: ""
Jan 22 19:32:46.214: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:32:46.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l6lqb" for this suite.
Jan 22 19:32:52.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:32:52.351: INFO: namespace: e2e-tests-kubectl-l6lqb, resource: bindings, ignored listing per whitelist
Jan 22 19:32:52.397: INFO: namespace e2e-tests-kubectl-l6lqb deletion completed in 6.173942018s

• [SLOW TEST:6.451 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:32:52.399: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 22 19:32:52.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:52.915: INFO: stderr: ""
Jan 22 19:32:52.915: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 22 19:32:52.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:53.041: INFO: stderr: ""
Jan 22 19:32:53.041: INFO: stdout: "update-demo-nautilus-2hs64 update-demo-nautilus-xct5b "
Jan 22 19:32:53.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-2hs64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:53.162: INFO: stderr: ""
Jan 22 19:32:53.162: INFO: stdout: ""
Jan 22 19:32:53.162: INFO: update-demo-nautilus-2hs64 is created but not running
Jan 22 19:32:58.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:58.286: INFO: stderr: ""
Jan 22 19:32:58.286: INFO: stdout: "update-demo-nautilus-2hs64 update-demo-nautilus-xct5b "
Jan 22 19:32:58.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-2hs64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:58.411: INFO: stderr: ""
Jan 22 19:32:58.411: INFO: stdout: "true"
Jan 22 19:32:58.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-2hs64 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:58.528: INFO: stderr: ""
Jan 22 19:32:58.528: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 19:32:58.528: INFO: validating pod update-demo-nautilus-2hs64
Jan 22 19:32:58.578: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 19:32:58.578: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 19:32:58.578: INFO: update-demo-nautilus-2hs64 is verified up and running
Jan 22 19:32:58.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-xct5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:58.710: INFO: stderr: ""
Jan 22 19:32:58.710: INFO: stdout: "true"
Jan 22 19:32:58.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods update-demo-nautilus-xct5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:58.859: INFO: stderr: ""
Jan 22 19:32:58.859: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 22 19:32:58.859: INFO: validating pod update-demo-nautilus-xct5b
Jan 22 19:32:58.910: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 22 19:32:58.910: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 22 19:32:58.910: INFO: update-demo-nautilus-xct5b is verified up and running
STEP: using delete to clean up resources
Jan 22 19:32:58.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:59.043: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 19:32:59.043: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 22 19:32:59.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-m54rw'
Jan 22 19:32:59.178: INFO: stderr: "No resources found.\n"
Jan 22 19:32:59.178: INFO: stdout: ""
Jan 22 19:32:59.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -l name=update-demo --namespace=e2e-tests-kubectl-m54rw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 19:32:59.317: INFO: stderr: ""
Jan 22 19:32:59.317: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:32:59.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m54rw" for this suite.
Jan 22 19:33:05.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:33:05.431: INFO: namespace: e2e-tests-kubectl-m54rw, resource: bindings, ignored listing per whitelist
Jan 22 19:33:05.475: INFO: namespace e2e-tests-kubectl-m54rw deletion completed in 6.153048944s

• [SLOW TEST:13.077 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:33:05.475: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8a5d5170-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:33:05.860: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-dmxt2" to be "success or failure"
Jan 22 19:33:05.865: INFO: Pod "pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.092566ms
Jan 22 19:33:07.910: INFO: Pod "pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049944325s
Jan 22 19:33:09.918: INFO: Pod "pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057354058s
STEP: Saw pod success
Jan 22 19:33:09.918: INFO: Pod "pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:33:09.924: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:33:09.957: INFO: Waiting for pod pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:33:09.960: INFO: Pod pod-projected-configmaps-8a5e662b-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:33:09.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dmxt2" for this suite.
Jan 22 19:33:15.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:33:16.104: INFO: namespace: e2e-tests-projected-dmxt2, resource: bindings, ignored listing per whitelist
Jan 22 19:33:16.167: INFO: namespace e2e-tests-projected-dmxt2 deletion completed in 6.200842743s

• [SLOW TEST:10.692 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:33:16.168: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 22 19:33:16.397: INFO: Waiting up to 5m0s for pod "downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-4gwv6" to be "success or failure"
Jan 22 19:33:16.405: INFO: Pod "downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.594647ms
Jan 22 19:33:18.410: INFO: Pod "downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012255951s
Jan 22 19:33:20.415: INFO: Pod "downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017358359s
STEP: Saw pod success
Jan 22 19:33:20.415: INFO: Pod "downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:33:20.419: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 19:33:20.461: INFO: Waiting for pod downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:33:20.465: INFO: Pod downward-api-90b02e48-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:33:20.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4gwv6" for this suite.
Jan 22 19:33:26.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:33:26.566: INFO: namespace: e2e-tests-downward-api-4gwv6, resource: bindings, ignored listing per whitelist
Jan 22 19:33:26.700: INFO: namespace e2e-tests-downward-api-4gwv6 deletion completed in 6.22914381s

• [SLOW TEST:10.532 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:33:26.700: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-56dm
STEP: Creating a pod to test atomic-volume-subpath
Jan 22 19:33:26.903: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-56dm" in namespace "e2e-tests-subpath-nxbn4" to be "success or failure"
Jan 22 19:33:26.928: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Pending", Reason="", readiness=false. Elapsed: 24.6294ms
Jan 22 19:33:28.933: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03005038s
Jan 22 19:33:30.939: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 4.035802561s
Jan 22 19:33:32.947: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 6.043241689s
Jan 22 19:33:34.954: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 8.050541503s
Jan 22 19:33:36.962: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 10.058452927s
Jan 22 19:33:38.966: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 12.062807827s
Jan 22 19:33:40.971: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 14.067724337s
Jan 22 19:33:42.976: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 16.072306827s
Jan 22 19:33:44.981: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 18.077413525s
Jan 22 19:33:46.986: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 20.082633018s
Jan 22 19:33:48.990: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Running", Reason="", readiness=false. Elapsed: 22.086753366s
Jan 22 19:33:50.995: INFO: Pod "pod-subpath-test-configmap-56dm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.091485826s
STEP: Saw pod success
Jan 22 19:33:50.995: INFO: Pod "pod-subpath-test-configmap-56dm" satisfied condition "success or failure"
Jan 22 19:33:50.999: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-subpath-test-configmap-56dm container test-container-subpath-configmap-56dm: <nil>
STEP: delete the pod
Jan 22 19:33:51.040: INFO: Waiting for pod pod-subpath-test-configmap-56dm to disappear
Jan 22 19:33:51.043: INFO: Pod pod-subpath-test-configmap-56dm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-56dm
Jan 22 19:33:51.043: INFO: Deleting pod "pod-subpath-test-configmap-56dm" in namespace "e2e-tests-subpath-nxbn4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:33:51.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nxbn4" for this suite.
Jan 22 19:33:57.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:33:57.124: INFO: namespace: e2e-tests-subpath-nxbn4, resource: bindings, ignored listing per whitelist
Jan 22 19:33:57.206: INFO: namespace e2e-tests-subpath-nxbn4 deletion completed in 6.153810147s

• [SLOW TEST:30.506 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:33:57.206: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0122 19:33:58.419044      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 19:33:58.419: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:33:58.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hgrtx" for this suite.
Jan 22 19:34:04.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:34:04.475: INFO: namespace: e2e-tests-gc-hgrtx, resource: bindings, ignored listing per whitelist
Jan 22 19:34:04.562: INFO: namespace e2e-tests-gc-hgrtx deletion completed in 6.139044573s

• [SLOW TEST:7.356 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:34:04.562: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ad7d2994-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating configMap with name cm-test-opt-upd-ad7d29cf-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ad7d2994-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Updating configmap cm-test-opt-upd-ad7d29cf-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating configMap with name cm-test-opt-create-ad7d29e4-1e7c-11e9-9ccc-2ee9843eaab3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:35:40.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8527q" for this suite.
Jan 22 19:36:02.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:36:02.406: INFO: namespace: e2e-tests-configmap-8527q, resource: bindings, ignored listing per whitelist
Jan 22 19:36:02.536: INFO: namespace e2e-tests-configmap-8527q deletion completed in 22.191915378s

• [SLOW TEST:117.974 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:36:02.537: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f3ceea0c-1e7c-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:36:02.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-gjbvr" to be "success or failure"
Jan 22 19:36:02.702: INFO: Pod "pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03353ms
Jan 22 19:36:04.706: INFO: Pod "pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008100956s
Jan 22 19:36:06.710: INFO: Pod "pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0129529s
STEP: Saw pod success
Jan 22 19:36:06.711: INFO: Pod "pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:36:06.714: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:36:06.763: INFO: Waiting for pod pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:36:06.768: INFO: Pod pod-configmaps-f3d01f0c-1e7c-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:36:06.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gjbvr" for this suite.
Jan 22 19:36:12.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:36:12.890: INFO: namespace: e2e-tests-configmap-gjbvr, resource: bindings, ignored listing per whitelist
Jan 22 19:36:13.015: INFO: namespace e2e-tests-configmap-gjbvr deletion completed in 6.242532718s

• [SLOW TEST:10.478 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:36:13.015: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-9rbl
STEP: Creating a pod to test atomic-volume-subpath
Jan 22 19:36:13.222: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9rbl" in namespace "e2e-tests-subpath-c6vdn" to be "success or failure"
Jan 22 19:36:13.235: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Pending", Reason="", readiness=false. Elapsed: 12.411499ms
Jan 22 19:36:15.239: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017246815s
Jan 22 19:36:17.245: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 4.023003454s
Jan 22 19:36:19.250: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 6.027498045s
Jan 22 19:36:21.255: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 8.032345542s
Jan 22 19:36:23.259: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 10.036668515s
Jan 22 19:36:25.263: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 12.041223489s
Jan 22 19:36:27.267: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 14.045206138s
Jan 22 19:36:29.272: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 16.049974706s
Jan 22 19:36:31.277: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 18.054557162s
Jan 22 19:36:33.326: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 20.103610638s
Jan 22 19:36:35.333: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Running", Reason="", readiness=false. Elapsed: 22.110917969s
Jan 22 19:36:37.339: INFO: Pod "pod-subpath-test-configmap-9rbl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.116537138s
STEP: Saw pod success
Jan 22 19:36:37.339: INFO: Pod "pod-subpath-test-configmap-9rbl" satisfied condition "success or failure"
Jan 22 19:36:37.342: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-subpath-test-configmap-9rbl container test-container-subpath-configmap-9rbl: <nil>
STEP: delete the pod
Jan 22 19:36:37.380: INFO: Waiting for pod pod-subpath-test-configmap-9rbl to disappear
Jan 22 19:36:37.385: INFO: Pod pod-subpath-test-configmap-9rbl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9rbl
Jan 22 19:36:37.385: INFO: Deleting pod "pod-subpath-test-configmap-9rbl" in namespace "e2e-tests-subpath-c6vdn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:36:37.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-c6vdn" for this suite.
Jan 22 19:36:43.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:36:43.453: INFO: namespace: e2e-tests-subpath-c6vdn, resource: bindings, ignored listing per whitelist
Jan 22 19:36:43.587: INFO: namespace e2e-tests-subpath-c6vdn deletion completed in 6.192792516s

• [SLOW TEST:30.572 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:36:43.588: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 22 19:36:43.761: INFO: Waiting up to 5m0s for pod "client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-containers-pq6vd" to be "success or failure"
Jan 22 19:36:43.765: INFO: Pod "client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.06273ms
Jan 22 19:36:45.770: INFO: Pod "client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008217427s
Jan 22 19:36:47.781: INFO: Pod "client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019204636s
STEP: Saw pod success
Jan 22 19:36:47.781: INFO: Pod "client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:36:47.785: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:36:47.818: INFO: Waiting for pod client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:36:47.822: INFO: Pod client-containers-0c4a87a4-1e7d-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:36:47.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pq6vd" for this suite.
Jan 22 19:36:53.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:36:54.013: INFO: namespace: e2e-tests-containers-pq6vd, resource: bindings, ignored listing per whitelist
Jan 22 19:36:54.081: INFO: namespace e2e-tests-containers-pq6vd deletion completed in 6.253719271s

• [SLOW TEST:10.494 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:36:54.081: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 22 19:36:58.824: INFO: Successfully updated pod "labelsupdate128e24ce-1e7d-11e9-9ccc-2ee9843eaab3"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:37:00.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ph6lx" for this suite.
Jan 22 19:37:22.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:37:23.015: INFO: namespace: e2e-tests-projected-ph6lx, resource: bindings, ignored listing per whitelist
Jan 22 19:37:23.125: INFO: namespace e2e-tests-projected-ph6lx deletion completed in 22.230401979s

• [SLOW TEST:29.044 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:37:23.126: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-23d6af78-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:37:23.284: INFO: Waiting up to 5m0s for pod "pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-tpjf6" to be "success or failure"
Jan 22 19:37:23.289: INFO: Pod "pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.625948ms
Jan 22 19:37:25.293: INFO: Pod "pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00888953s
Jan 22 19:37:27.346: INFO: Pod "pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061824265s
STEP: Saw pod success
Jan 22 19:37:27.346: INFO: Pod "pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:37:27.351: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:37:27.387: INFO: Waiting for pod pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:37:27.391: INFO: Pod pod-secrets-23d93c1e-1e7d-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:37:27.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tpjf6" for this suite.
Jan 22 19:37:33.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:37:33.487: INFO: namespace: e2e-tests-secrets-tpjf6, resource: bindings, ignored listing per whitelist
Jan 22 19:37:33.559: INFO: namespace e2e-tests-secrets-tpjf6 deletion completed in 6.162764396s

• [SLOW TEST:10.433 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:37:33.559: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0122 19:37:43.808003      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 22 19:37:43.808: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:37:43.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-87tfb" for this suite.
Jan 22 19:37:51.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:37:52.022: INFO: namespace: e2e-tests-gc-87tfb, resource: bindings, ignored listing per whitelist
Jan 22 19:37:52.041: INFO: namespace e2e-tests-gc-87tfb deletion completed in 8.228751937s

• [SLOW TEST:18.482 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:37:52.042: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-3515940e-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:37:52.216: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-dpp57" to be "success or failure"
Jan 22 19:37:52.220: INFO: Pod "pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005228ms
Jan 22 19:37:54.224: INFO: Pod "pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008073424s
Jan 22 19:37:56.228: INFO: Pod "pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01264373s
STEP: Saw pod success
Jan 22 19:37:56.228: INFO: Pod "pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:37:56.232: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:37:56.276: INFO: Waiting for pod pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:37:56.289: INFO: Pod pod-projected-secrets-351756e6-1e7d-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:37:56.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dpp57" for this suite.
Jan 22 19:38:02.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:38:02.461: INFO: namespace: e2e-tests-projected-dpp57, resource: bindings, ignored listing per whitelist
Jan 22 19:38:02.555: INFO: namespace e2e-tests-projected-dpp57 deletion completed in 6.261322402s

• [SLOW TEST:10.513 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:38:02.556: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:38:02.697: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan 22 19:38:02.708: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r5rxm/daemonsets","resourceVersion":"18191"},"items":null}

Jan 22 19:38:02.711: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r5rxm/pods","resourceVersion":"18191"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:38:02.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r5rxm" for this suite.
Jan 22 19:38:08.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:38:08.953: INFO: namespace: e2e-tests-daemonsets-r5rxm, resource: bindings, ignored listing per whitelist
Jan 22 19:38:08.967: INFO: namespace e2e-tests-daemonsets-r5rxm deletion completed in 6.237856899s

S [SKIPPING] [6.411 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 22 19:38:02.697: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:38:08.967: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 22 19:38:09.564: INFO: Number of nodes with available pods: 0
Jan 22 19:38:09.564: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 19:38:10.579: INFO: Number of nodes with available pods: 0
Jan 22 19:38:10.579: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 19:38:11.576: INFO: Number of nodes with available pods: 1
Jan 22 19:38:11.576: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 19:38:12.574: INFO: Number of nodes with available pods: 2
Jan 22 19:38:12.575: INFO: Node aks-nodepool1-25266157-1 is running more than one daemon pod
Jan 22 19:38:13.574: INFO: Number of nodes with available pods: 3
Jan 22 19:38:13.574: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 22 19:38:13.717: INFO: Number of nodes with available pods: 2
Jan 22 19:38:13.717: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:14.728: INFO: Number of nodes with available pods: 2
Jan 22 19:38:14.728: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:15.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:15.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:16.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:16.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:17.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:17.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:18.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:18.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:19.733: INFO: Number of nodes with available pods: 2
Jan 22 19:38:19.733: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:20.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:20.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:21.728: INFO: Number of nodes with available pods: 2
Jan 22 19:38:21.728: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:22.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:22.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:23.731: INFO: Number of nodes with available pods: 2
Jan 22 19:38:23.731: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:24.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:24.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:25.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:25.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:26.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:26.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:27.730: INFO: Number of nodes with available pods: 2
Jan 22 19:38:27.730: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:28.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:28.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:29.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:29.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:30.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:30.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:31.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:31.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:32.729: INFO: Number of nodes with available pods: 2
Jan 22 19:38:32.729: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:33.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:33.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:34.730: INFO: Number of nodes with available pods: 2
Jan 22 19:38:34.730: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:35.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:35.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:36.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:36.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:37.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:37.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:38.730: INFO: Number of nodes with available pods: 2
Jan 22 19:38:38.730: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:39.740: INFO: Number of nodes with available pods: 2
Jan 22 19:38:39.740: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:40.730: INFO: Number of nodes with available pods: 2
Jan 22 19:38:40.730: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:41.731: INFO: Number of nodes with available pods: 2
Jan 22 19:38:41.731: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:42.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:42.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:43.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:43.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:44.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:44.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:45.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:45.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:46.725: INFO: Number of nodes with available pods: 2
Jan 22 19:38:46.725: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:47.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:47.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:48.727: INFO: Number of nodes with available pods: 2
Jan 22 19:38:48.727: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:49.732: INFO: Number of nodes with available pods: 2
Jan 22 19:38:49.733: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:50.726: INFO: Number of nodes with available pods: 2
Jan 22 19:38:50.726: INFO: Node aks-nodepool1-25266157-2 is running more than one daemon pod
Jan 22 19:38:51.726: INFO: Number of nodes with available pods: 3
Jan 22 19:38:51.726: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-6qr6k, will wait for the garbage collector to delete the pods
Jan 22 19:38:51.798: INFO: Deleting {extensions DaemonSet} daemon-set took: 15.333589ms
Jan 22 19:38:51.898: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.2638ms
Jan 22 19:39:34.813: INFO: Number of nodes with available pods: 0
Jan 22 19:39:34.813: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 19:39:34.816: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6qr6k/daemonsets","resourceVersion":"18410"},"items":null}

Jan 22 19:39:34.820: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6qr6k/pods","resourceVersion":"18410"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:39:34.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6qr6k" for this suite.
Jan 22 19:39:40.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:39:40.962: INFO: namespace: e2e-tests-daemonsets-6qr6k, resource: bindings, ignored listing per whitelist
Jan 22 19:39:41.041: INFO: namespace e2e-tests-daemonsets-6qr6k deletion completed in 6.196272482s

• [SLOW TEST:92.074 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:39:41.041: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 22 19:39:42.303: INFO: Waiting up to 5m0s for pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn" in namespace "e2e-tests-svcaccounts-f6t8c" to be "success or failure"
Jan 22 19:39:42.307: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.819722ms
Jan 22 19:39:44.311: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007998053s
Jan 22 19:39:46.316: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012841001s
STEP: Saw pod success
Jan 22 19:39:46.316: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn" satisfied condition "success or failure"
Jan 22 19:39:46.320: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn container token-test: <nil>
STEP: delete the pod
Jan 22 19:39:46.354: INFO: Waiting for pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn to disappear
Jan 22 19:39:46.357: INFO: Pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-c8rgn no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 22 19:39:46.369: INFO: Waiting up to 5m0s for pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m" in namespace "e2e-tests-svcaccounts-f6t8c" to be "success or failure"
Jan 22 19:39:46.374: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m": Phase="Pending", Reason="", readiness=false. Elapsed: 5.242567ms
Jan 22 19:39:48.381: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01131135s
Jan 22 19:39:50.387: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017386428s
STEP: Saw pod success
Jan 22 19:39:50.387: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m" satisfied condition "success or failure"
Jan 22 19:39:50.391: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m container root-ca-test: <nil>
STEP: delete the pod
Jan 22 19:39:50.433: INFO: Waiting for pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m to disappear
Jan 22 19:39:50.437: INFO: Pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-ksj9m no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 22 19:39:50.451: INFO: Waiting up to 5m0s for pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc" in namespace "e2e-tests-svcaccounts-f6t8c" to be "success or failure"
Jan 22 19:39:50.460: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.145691ms
Jan 22 19:39:52.465: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014230633s
Jan 22 19:39:54.471: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020031094s
STEP: Saw pod success
Jan 22 19:39:54.471: INFO: Pod "pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc" satisfied condition "success or failure"
Jan 22 19:39:54.476: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc container namespace-test: <nil>
STEP: delete the pod
Jan 22 19:39:54.544: INFO: Waiting for pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc to disappear
Jan 22 19:39:54.548: INFO: Pod pod-service-account-76615b27-1e7d-11e9-9ccc-2ee9843eaab3-527tc no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:39:54.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-f6t8c" for this suite.
Jan 22 19:40:00.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:40:00.693: INFO: namespace: e2e-tests-svcaccounts-f6t8c, resource: bindings, ignored listing per whitelist
Jan 22 19:40:00.710: INFO: namespace e2e-tests-svcaccounts-f6t8c deletion completed in 6.157362812s

• [SLOW TEST:19.669 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:40:00.711: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 22 19:40:00.902: INFO: Waiting up to 5m0s for pod "pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-qvxf6" to be "success or failure"
Jan 22 19:40:00.906: INFO: Pod "pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.235735ms
Jan 22 19:40:02.911: INFO: Pod "pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00884744s
Jan 22 19:40:04.926: INFO: Pod "pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023947475s
STEP: Saw pod success
Jan 22 19:40:04.926: INFO: Pod "pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:40:04.939: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:40:05.362: INFO: Waiting for pod pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:40:05.374: INFO: Pod pod-81cb0bf6-1e7d-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:40:05.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qvxf6" for this suite.
Jan 22 19:40:11.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:40:11.558: INFO: namespace: e2e-tests-emptydir-qvxf6, resource: bindings, ignored listing per whitelist
Jan 22 19:40:11.621: INFO: namespace e2e-tests-emptydir-qvxf6 deletion completed in 6.241016704s

• [SLOW TEST:10.911 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:40:11.622: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 22 19:40:11.819: INFO: Waiting up to 5m0s for pod "client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-containers-pbmw2" to be "success or failure"
Jan 22 19:40:11.822: INFO: Pod "client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.293205ms
Jan 22 19:40:13.831: INFO: Pod "client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012282326s
Jan 22 19:40:15.835: INFO: Pod "client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016527493s
STEP: Saw pod success
Jan 22 19:40:15.836: INFO: Pod "client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:40:15.840: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:40:15.891: INFO: Waiting for pod client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:40:15.894: INFO: Pod client-containers-884df906-1e7d-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:40:15.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pbmw2" for this suite.
Jan 22 19:40:21.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:40:22.101: INFO: namespace: e2e-tests-containers-pbmw2, resource: bindings, ignored listing per whitelist
Jan 22 19:40:22.104: INFO: namespace e2e-tests-containers-pbmw2 deletion completed in 6.204450173s

• [SLOW TEST:10.483 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:40:22.107: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-v6zpm in namespace e2e-tests-proxy-8zvsx
I0122 19:40:22.323641      15 runners.go:180] Created replication controller with name: proxy-service-v6zpm, namespace: e2e-tests-proxy-8zvsx, replica count: 1
I0122 19:40:23.378102      15 runners.go:180] proxy-service-v6zpm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 19:40:24.378266      15 runners.go:180] proxy-service-v6zpm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 19:40:25.378440      15 runners.go:180] proxy-service-v6zpm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0122 19:40:26.378657      15 runners.go:180] proxy-service-v6zpm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 19:40:27.378811      15 runners.go:180] proxy-service-v6zpm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0122 19:40:28.379040      15 runners.go:180] proxy-service-v6zpm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 22 19:40:28.382: INFO: setup took 6.096102788s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 22 19:40:28.395: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.065515ms)
Jan 22 19:40:28.397: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 14.544562ms)
Jan 22 19:40:28.398: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 15.465592ms)
Jan 22 19:40:28.399: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 16.66403ms)
Jan 22 19:40:28.399: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 16.565427ms)
Jan 22 19:40:28.399: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 16.530226ms)
Jan 22 19:40:28.404: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 21.137373ms)
Jan 22 19:40:28.416: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 33.391962ms)
Jan 22 19:40:28.416: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 33.664671ms)
Jan 22 19:40:28.416: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 33.237457ms)
Jan 22 19:40:28.416: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 33.602268ms)
Jan 22 19:40:28.418: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 35.393726ms)
Jan 22 19:40:28.419: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 36.356456ms)
Jan 22 19:40:28.420: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 37.365988ms)
Jan 22 19:40:28.422: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 39.60286ms)
Jan 22 19:40:28.425: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 42.709458ms)
Jan 22 19:40:28.433: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 7.726946ms)
Jan 22 19:40:28.437: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 12.038083ms)
Jan 22 19:40:28.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 12.223889ms)
Jan 22 19:40:28.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 12.838709ms)
Jan 22 19:40:28.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 12.545899ms)
Jan 22 19:40:28.438: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 12.078784ms)
Jan 22 19:40:28.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 13.089216ms)
Jan 22 19:40:28.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 13.383625ms)
Jan 22 19:40:28.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 12.844508ms)
Jan 22 19:40:28.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 12.5666ms)
Jan 22 19:40:28.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.129918ms)
Jan 22 19:40:28.440: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 13.359025ms)
Jan 22 19:40:28.441: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 15.228984ms)
Jan 22 19:40:28.441: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 15.035579ms)
Jan 22 19:40:28.441: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 14.585964ms)
Jan 22 19:40:28.441: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 14.679267ms)
Jan 22 19:40:28.450: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 9.079989ms)
Jan 22 19:40:28.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 10.952948ms)
Jan 22 19:40:28.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 10.761142ms)
Jan 22 19:40:28.452: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 10.894146ms)
Jan 22 19:40:28.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 11.790275ms)
Jan 22 19:40:28.453: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 11.817776ms)
Jan 22 19:40:28.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 12.507298ms)
Jan 22 19:40:28.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 12.621501ms)
Jan 22 19:40:28.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 12.5794ms)
Jan 22 19:40:28.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 12.494598ms)
Jan 22 19:40:28.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 12.5719ms)
Jan 22 19:40:28.454: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 12.543499ms)
Jan 22 19:40:28.455: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.175819ms)
Jan 22 19:40:28.455: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 13.793938ms)
Jan 22 19:40:28.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 14.375158ms)
Jan 22 19:40:28.456: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 14.722968ms)
Jan 22 19:40:28.463: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 7.089626ms)
Jan 22 19:40:28.466: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.213124ms)
Jan 22 19:40:28.466: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 9.4348ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 11.200156ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 10.855545ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 11.140055ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 11.057452ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 11.690571ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 11.275859ms)
Jan 22 19:40:28.468: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 10.966049ms)
Jan 22 19:40:28.469: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 13.271222ms)
Jan 22 19:40:28.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 14.016845ms)
Jan 22 19:40:28.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 13.489029ms)
Jan 22 19:40:28.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 13.876541ms)
Jan 22 19:40:28.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 14.020346ms)
Jan 22 19:40:28.470: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 13.85814ms)
Jan 22 19:40:28.479: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 8.17386ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 55.205556ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 55.169455ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 55.172455ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 55.053551ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 55.05435ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 55.475264ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 55.537066ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 55.169554ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 55.405462ms)
Jan 22 19:40:28.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 55.243257ms)
Jan 22 19:40:28.547: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 76.827644ms)
Jan 22 19:40:28.547: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 76.990648ms)
Jan 22 19:40:28.547: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 76.871745ms)
Jan 22 19:40:28.547: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 76.673639ms)
Jan 22 19:40:28.548: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 76.769841ms)
Jan 22 19:40:28.558: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 9.4474ms)
Jan 22 19:40:28.558: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 10.137123ms)
Jan 22 19:40:28.558: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 9.4054ms)
Jan 22 19:40:28.558: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 10.203924ms)
Jan 22 19:40:28.558: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 10.138523ms)
Jan 22 19:40:28.562: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 14.131949ms)
Jan 22 19:40:28.562: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 14.053447ms)
Jan 22 19:40:28.562: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 14.807771ms)
Jan 22 19:40:28.562: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.756638ms)
Jan 22 19:40:28.562: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 14.444459ms)
Jan 22 19:40:28.563: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 13.935543ms)
Jan 22 19:40:28.563: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 14.46306ms)
Jan 22 19:40:28.563: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 13.81834ms)
Jan 22 19:40:28.563: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 14.77077ms)
Jan 22 19:40:28.563: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 15.168082ms)
Jan 22 19:40:28.563: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 14.805071ms)
Jan 22 19:40:28.571: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 8.643674ms)
Jan 22 19:40:28.572: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 9.338096ms)
Jan 22 19:40:28.573: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 10.05612ms)
Jan 22 19:40:28.575: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 11.685971ms)
Jan 22 19:40:28.575: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 11.790775ms)
Jan 22 19:40:28.575: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 11.96608ms)
Jan 22 19:40:28.575: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 11.777774ms)
Jan 22 19:40:28.575: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 12.024383ms)
Jan 22 19:40:28.575: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 12.375493ms)
Jan 22 19:40:28.576: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.120817ms)
Jan 22 19:40:28.576: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 13.080216ms)
Jan 22 19:40:28.579: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 15.858604ms)
Jan 22 19:40:28.579: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 15.797902ms)
Jan 22 19:40:28.579: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 15.904806ms)
Jan 22 19:40:28.579: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 16.148913ms)
Jan 22 19:40:28.582: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 19.230012ms)
Jan 22 19:40:28.597: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 14.331156ms)
Jan 22 19:40:28.598: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 15.260985ms)
Jan 22 19:40:28.599: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 16.495424ms)
Jan 22 19:40:28.599: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 15.786102ms)
Jan 22 19:40:28.599: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 16.536526ms)
Jan 22 19:40:28.599: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 16.015509ms)
Jan 22 19:40:28.600: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 17.369053ms)
Jan 22 19:40:28.600: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 17.843468ms)
Jan 22 19:40:28.600: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 17.235549ms)
Jan 22 19:40:28.600: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 18.039074ms)
Jan 22 19:40:28.601: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 17.883869ms)
Jan 22 19:40:28.602: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 18.596691ms)
Jan 22 19:40:28.602: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 19.18211ms)
Jan 22 19:40:28.603: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 19.632424ms)
Jan 22 19:40:28.603: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 19.941134ms)
Jan 22 19:40:28.625: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 42.324346ms)
Jan 22 19:40:28.632: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 6.815616ms)
Jan 22 19:40:28.634: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 8.080557ms)
Jan 22 19:40:28.634: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 7.936552ms)
Jan 22 19:40:28.635: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 8.753179ms)
Jan 22 19:40:28.635: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 9.218393ms)
Jan 22 19:40:28.635: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 9.492902ms)
Jan 22 19:40:28.635: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 9.578905ms)
Jan 22 19:40:28.635: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 10.087021ms)
Jan 22 19:40:28.635: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 9.329197ms)
Jan 22 19:40:28.636: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 9.828413ms)
Jan 22 19:40:28.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 11.64837ms)
Jan 22 19:40:28.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 11.198256ms)
Jan 22 19:40:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 12.019282ms)
Jan 22 19:40:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 12.034983ms)
Jan 22 19:40:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 12.292691ms)
Jan 22 19:40:28.638: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 12.24099ms)
Jan 22 19:40:28.645: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 6.704913ms)
Jan 22 19:40:28.647: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 8.134059ms)
Jan 22 19:40:28.647: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 9.080989ms)
Jan 22 19:40:28.647: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 9.002486ms)
Jan 22 19:40:28.648: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 9.575105ms)
Jan 22 19:40:28.648: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 9.74941ms)
Jan 22 19:40:28.648: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 9.963317ms)
Jan 22 19:40:28.648: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 9.893214ms)
Jan 22 19:40:28.648: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 9.721709ms)
Jan 22 19:40:28.648: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 9.72371ms)
Jan 22 19:40:28.649: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 10.463032ms)
Jan 22 19:40:28.649: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 10.447832ms)
Jan 22 19:40:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 12.023383ms)
Jan 22 19:40:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 11.566268ms)
Jan 22 19:40:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 11.902778ms)
Jan 22 19:40:28.650: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 12.095985ms)
Jan 22 19:40:28.662: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 10.554736ms)
Jan 22 19:40:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 11.93128ms)
Jan 22 19:40:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 12.658603ms)
Jan 22 19:40:28.663: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 11.976981ms)
Jan 22 19:40:28.664: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 13.655935ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 14.035247ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 13.309224ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 13.19752ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.85044ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 13.603033ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 14.001945ms)
Jan 22 19:40:28.665: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 14.14385ms)
Jan 22 19:40:28.666: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 14.838972ms)
Jan 22 19:40:28.668: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 16.280718ms)
Jan 22 19:40:28.668: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 16.640929ms)
Jan 22 19:40:28.668: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 16.801334ms)
Jan 22 19:40:28.726: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 58.309154ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 60.67043ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 60.937738ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 60.852336ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 60.595027ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 60.738931ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 60.904537ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 61.159845ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 60.860335ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 60.776533ms)
Jan 22 19:40:28.729: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 60.929338ms)
Jan 22 19:40:28.751: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 82.235015ms)
Jan 22 19:40:28.751: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 82.957238ms)
Jan 22 19:40:28.751: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 82.659429ms)
Jan 22 19:40:28.751: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 82.890336ms)
Jan 22 19:40:28.751: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 82.866436ms)
Jan 22 19:40:28.761: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 9.963017ms)
Jan 22 19:40:28.762: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.815744ms)
Jan 22 19:40:28.763: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 11.586368ms)
Jan 22 19:40:28.763: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 10.573836ms)
Jan 22 19:40:28.763: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 11.02385ms)
Jan 22 19:40:28.763: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 11.855477ms)
Jan 22 19:40:28.764: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 11.797475ms)
Jan 22 19:40:28.764: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 11.465664ms)
Jan 22 19:40:28.764: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 11.733173ms)
Jan 22 19:40:28.764: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 12.613601ms)
Jan 22 19:40:28.764: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 12.401794ms)
Jan 22 19:40:28.764: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 12.373193ms)
Jan 22 19:40:28.765: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 12.011682ms)
Jan 22 19:40:28.765: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 13.853541ms)
Jan 22 19:40:28.765: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 14.028247ms)
Jan 22 19:40:28.766: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 14.14305ms)
Jan 22 19:40:28.774: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 8.312464ms)
Jan 22 19:40:28.774: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 7.404536ms)
Jan 22 19:40:28.775: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 7.836949ms)
Jan 22 19:40:28.775: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 7.630043ms)
Jan 22 19:40:28.775: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 8.701576ms)
Jan 22 19:40:28.775: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 8.458369ms)
Jan 22 19:40:28.775: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 8.301464ms)
Jan 22 19:40:28.775: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 9.047588ms)
Jan 22 19:40:28.776: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 8.836281ms)
Jan 22 19:40:28.776: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 9.251395ms)
Jan 22 19:40:28.776: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 10.06592ms)
Jan 22 19:40:28.777: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 10.092221ms)
Jan 22 19:40:28.778: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 11.95158ms)
Jan 22 19:40:28.781: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 14.352257ms)
Jan 22 19:40:28.783: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 16.811335ms)
Jan 22 19:40:28.783: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 16.33952ms)
Jan 22 19:40:28.790: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 6.995023ms)
Jan 22 19:40:28.790: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 6.2933ms)
Jan 22 19:40:28.793: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 9.253894ms)
Jan 22 19:40:28.794: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 10.425232ms)
Jan 22 19:40:28.794: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 11.078053ms)
Jan 22 19:40:28.794: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 11.29926ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.915347ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 10.494034ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 11.263758ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 11.544567ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.927648ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 11.593369ms)
Jan 22 19:40:28.795: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 11.366561ms)
Jan 22 19:40:28.796: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 13.153319ms)
Jan 22 19:40:28.797: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 13.236321ms)
Jan 22 19:40:28.825: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 41.096907ms)
Jan 22 19:40:28.832: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 6.806116ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 10.178923ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.869446ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 10.572636ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 10.230926ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 10.507334ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 10.441433ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 10.729441ms)
Jan 22 19:40:28.836: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.432132ms)
Jan 22 19:40:28.837: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 10.99875ms)
Jan 22 19:40:28.879: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 53.551403ms)
Jan 22 19:40:28.879: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 53.398899ms)
Jan 22 19:40:28.879: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 53.459ms)
Jan 22 19:40:28.879: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 53.183591ms)
Jan 22 19:40:28.879: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 53.301895ms)
Jan 22 19:40:28.879: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 53.395898ms)
Jan 22 19:40:28.887: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 7.26173ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 11.768175ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 12.552299ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 12.488497ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 12.391594ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 12.950212ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 12.205788ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 12.518698ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 13.229521ms)
Jan 22 19:40:28.892: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 12.360394ms)
Jan 22 19:40:28.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 13.112917ms)
Jan 22 19:40:28.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 13.329524ms)
Jan 22 19:40:28.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 13.298423ms)
Jan 22 19:40:28.894: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 14.952975ms)
Jan 22 19:40:28.895: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 14.398458ms)
Jan 22 19:40:28.895: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 14.680466ms)
Jan 22 19:40:28.903: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 7.802548ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.404631ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 10.320928ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 10.69014ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 10.298528ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 10.957748ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 11.196456ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 10.743642ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 11.091752ms)
Jan 22 19:40:28.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 10.968249ms)
Jan 22 19:40:28.907: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 12.124286ms)
Jan 22 19:40:28.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 12.531898ms)
Jan 22 19:40:28.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 12.091884ms)
Jan 22 19:40:28.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 54.655338ms)
Jan 22 19:40:28.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 54.780842ms)
Jan 22 19:40:28.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 55.094252ms)
Jan 22 19:40:28.959: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 8.361466ms)
Jan 22 19:40:28.963: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 12.791907ms)
Jan 22 19:40:28.963: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 12.88621ms)
Jan 22 19:40:28.964: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 13.188119ms)
Jan 22 19:40:28.964: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 13.066915ms)
Jan 22 19:40:28.964: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 13.150518ms)
Jan 22 19:40:28.964: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 13.185819ms)
Jan 22 19:40:28.965: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 13.901542ms)
Jan 22 19:40:28.965: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 14.265754ms)
Jan 22 19:40:28.965: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 14.15635ms)
Jan 22 19:40:28.966: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 14.705568ms)
Jan 22 19:40:28.966: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 15.061779ms)
Jan 22 19:40:28.966: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 16.172514ms)
Jan 22 19:40:29.007: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 56.167987ms)
Jan 22 19:40:29.007: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 56.244289ms)
Jan 22 19:40:29.007: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 56.387193ms)
Jan 22 19:40:29.016: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:462/proxy/: tls qux (200; 8.746978ms)
Jan 22 19:40:29.016: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj/proxy/rewriteme"... (200; 8.774379ms)
Jan 22 19:40:29.017: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:1080/proxy/rewri... (200; 8.965085ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 11.529967ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 11.709672ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname2/proxy/: tls qux (200; 11.94938ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:1080/proxy/... (200; 11.838077ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/proxy-service-v6zpm-4rklj:160/proxy/: foo (200; 11.820775ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/http:proxy-service-v6zpm-4rklj:162/proxy/: bar (200; 12.332192ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:443/proxy/... (200; 12.136786ms)
Jan 22 19:40:29.019: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/pods/https:proxy-service-v6zpm-4rklj:460/proxy/: tls baz (200; 11.94828ms)
Jan 22 19:40:29.020: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/https:proxy-service-v6zpm:tlsportname1/proxy/: tls baz (200; 12.045483ms)
Jan 22 19:40:29.021: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname1/proxy/: foo (200; 13.656734ms)
Jan 22 19:40:29.029: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/http:proxy-service-v6zpm:portname2/proxy/: bar (200; 21.315378ms)
Jan 22 19:40:29.029: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname2/proxy/: bar (200; 21.529284ms)
Jan 22 19:40:29.029: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8zvsx/services/proxy-service-v6zpm:portname1/proxy/: foo (200; 21.111172ms)
STEP: deleting { ReplicationController} proxy-service-v6zpm in namespace e2e-tests-proxy-8zvsx, will wait for the garbage collector to delete the pods
Jan 22 19:40:29.092: INFO: Deleting { ReplicationController} proxy-service-v6zpm took: 10.230926ms
Jan 22 19:40:29.193: INFO: Terminating { ReplicationController} proxy-service-v6zpm pods took: 100.182086ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:40:31.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8zvsx" for this suite.
Jan 22 19:40:37.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:40:37.328: INFO: namespace: e2e-tests-proxy-8zvsx, resource: bindings, ignored listing per whitelist
Jan 22 19:40:37.445: INFO: namespace e2e-tests-proxy-8zvsx deletion completed in 6.248065164s

• [SLOW TEST:15.338 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:40:37.446: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-97b2b8de-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Creating configMap with name cm-test-opt-upd-97b2b917-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-97b2b8de-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Updating configmap cm-test-opt-upd-97b2b917-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Creating configMap with name cm-test-opt-create-97b2b92f-1e7d-11e9-9ccc-2ee9843eaab3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:42:10.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-blqz8" for this suite.
Jan 22 19:42:32.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:42:32.965: INFO: namespace: e2e-tests-projected-blqz8, resource: bindings, ignored listing per whitelist
Jan 22 19:42:33.057: INFO: namespace e2e-tests-projected-blqz8 deletion completed in 22.259322935s

• [SLOW TEST:115.611 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:42:33.057: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 22 19:42:33.426: INFO: Number of nodes with available pods: 0
Jan 22 19:42:33.426: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 19:42:34.436: INFO: Number of nodes with available pods: 0
Jan 22 19:42:34.436: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 19:42:35.436: INFO: Number of nodes with available pods: 0
Jan 22 19:42:35.436: INFO: Node aks-nodepool1-25266157-0 is running more than one daemon pod
Jan 22 19:42:36.436: INFO: Number of nodes with available pods: 3
Jan 22 19:42:36.436: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 22 19:42:36.482: INFO: Number of nodes with available pods: 2
Jan 22 19:42:36.482: INFO: Node aks-nodepool1-25266157-1 is running more than one daemon pod
Jan 22 19:42:37.501: INFO: Number of nodes with available pods: 2
Jan 22 19:42:37.501: INFO: Node aks-nodepool1-25266157-1 is running more than one daemon pod
Jan 22 19:42:38.502: INFO: Number of nodes with available pods: 3
Jan 22 19:42:38.502: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-f6fwt, will wait for the garbage collector to delete the pods
Jan 22 19:42:38.579: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.652401ms
Jan 22 19:42:38.679: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.159574ms
Jan 22 19:43:18.484: INFO: Number of nodes with available pods: 0
Jan 22 19:43:18.484: INFO: Number of running nodes: 0, number of available pods: 0
Jan 22 19:43:18.490: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-f6fwt/daemonsets","resourceVersion":"19085"},"items":null}

Jan 22 19:43:18.494: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-f6fwt/pods","resourceVersion":"19085"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:43:18.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-f6fwt" for this suite.
Jan 22 19:43:24.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:43:24.588: INFO: namespace: e2e-tests-daemonsets-f6fwt, resource: bindings, ignored listing per whitelist
Jan 22 19:43:24.655: INFO: namespace e2e-tests-daemonsets-f6fwt deletion completed in 6.141124401s

• [SLOW TEST:51.597 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:43:24.655: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-fb537236-1e7d-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:43:24.804: INFO: Waiting up to 5m0s for pod "pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-tdxz9" to be "success or failure"
Jan 22 19:43:24.813: INFO: Pod "pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.784278ms
Jan 22 19:43:26.823: INFO: Pod "pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018499991s
STEP: Saw pod success
Jan 22 19:43:26.823: INFO: Pod "pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:43:26.827: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:43:26.898: INFO: Waiting for pod pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:43:26.902: INFO: Pod pod-secrets-fb547b0c-1e7d-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:43:26.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tdxz9" for this suite.
Jan 22 19:43:32.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:43:32.997: INFO: namespace: e2e-tests-secrets-tdxz9, resource: bindings, ignored listing per whitelist
Jan 22 19:43:33.095: INFO: namespace e2e-tests-secrets-tdxz9 deletion completed in 6.185384566s

• [SLOW TEST:8.440 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:43:33.097: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 22 19:43:33.258: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:43:35.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2xhl9" for this suite.
Jan 22 19:43:41.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:43:41.954: INFO: namespace: e2e-tests-init-container-2xhl9, resource: bindings, ignored listing per whitelist
Jan 22 19:43:42.131: INFO: namespace e2e-tests-init-container-2xhl9 deletion completed in 6.219754415s

• [SLOW TEST:9.034 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:43:42.131: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 22 19:43:42.898: INFO: created pod pod-service-account-defaultsa
Jan 22 19:43:42.898: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 22 19:43:42.912: INFO: created pod pod-service-account-mountsa
Jan 22 19:43:42.912: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 22 19:43:42.926: INFO: created pod pod-service-account-nomountsa
Jan 22 19:43:42.926: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 22 19:43:42.943: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 22 19:43:42.943: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 22 19:43:42.969: INFO: created pod pod-service-account-mountsa-mountspec
Jan 22 19:43:42.969: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 22 19:43:42.987: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 22 19:43:42.987: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 22 19:43:42.999: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 22 19:43:42.999: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 22 19:43:43.019: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 22 19:43:43.019: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 22 19:43:43.038: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 22 19:43:43.038: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:43:43.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bs7xm" for this suite.
Jan 22 19:44:05.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:44:05.260: INFO: namespace: e2e-tests-svcaccounts-bs7xm, resource: bindings, ignored listing per whitelist
Jan 22 19:44:05.309: INFO: namespace e2e-tests-svcaccounts-bs7xm deletion completed in 22.250281348s

• [SLOW TEST:23.177 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:44:05.309: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 22 19:44:05.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-55trj'
Jan 22 19:44:06.514: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 22 19:44:06.514: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan 22 19:44:08.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-55trj'
Jan 22 19:44:08.673: INFO: stderr: ""
Jan 22 19:44:08.673: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:44:08.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-55trj" for this suite.
Jan 22 19:44:14.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:44:14.863: INFO: namespace: e2e-tests-kubectl-55trj, resource: bindings, ignored listing per whitelist
Jan 22 19:44:14.886: INFO: namespace e2e-tests-kubectl-55trj deletion completed in 6.207973507s

• [SLOW TEST:9.577 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:44:14.886: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 22 19:44:15.397: INFO: Waiting up to 5m0s for pod "pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-lc4xc" to be "success or failure"
Jan 22 19:44:15.418: INFO: Pod "pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.129637ms
Jan 22 19:44:17.423: INFO: Pod "pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025461443s
Jan 22 19:44:19.428: INFO: Pod "pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030305931s
STEP: Saw pod success
Jan 22 19:44:19.428: INFO: Pod "pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:44:19.432: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:44:19.464: INFO: Waiting for pod pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:44:19.467: INFO: Pod pod-19742e38-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:44:19.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lc4xc" for this suite.
Jan 22 19:44:25.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:44:25.534: INFO: namespace: e2e-tests-emptydir-lc4xc, resource: bindings, ignored listing per whitelist
Jan 22 19:44:25.617: INFO: namespace e2e-tests-emptydir-lc4xc deletion completed in 6.145560791s

• [SLOW TEST:10.731 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:44:25.618: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 22 19:44:31.829: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:31.829: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:32.110: INFO: Exec stderr: ""
Jan 22 19:44:32.111: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:32.111: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:32.470: INFO: Exec stderr: ""
Jan 22 19:44:32.470: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:32.470: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:32.788: INFO: Exec stderr: ""
Jan 22 19:44:32.788: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:32.788: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:33.062: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 22 19:44:33.062: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:33.062: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:33.318: INFO: Exec stderr: ""
Jan 22 19:44:33.318: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:33.319: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:33.582: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 22 19:44:33.582: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:33.582: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:33.925: INFO: Exec stderr: ""
Jan 22 19:44:33.925: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:33.925: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:34.158: INFO: Exec stderr: ""
Jan 22 19:44:34.158: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:34.158: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:34.490: INFO: Exec stderr: ""
Jan 22 19:44:34.490: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-24jm6 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:44:34.490: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:44:34.755: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:44:34.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-24jm6" for this suite.
Jan 22 19:45:22.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:45:22.852: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-24jm6, resource: bindings, ignored listing per whitelist
Jan 22 19:45:22.967: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-24jm6 deletion completed in 48.20300797s

• [SLOW TEST:57.349 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:45:22.968: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 22 19:45:29.174: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:29.178: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:31.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:31.187: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:33.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:33.184: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:35.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:35.183: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:37.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:37.226: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:39.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:39.182: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:41.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:41.184: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:43.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:43.184: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:45.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:45.184: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:47.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:47.237: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:49.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:49.225: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:51.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:51.182: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:53.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:53.183: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:55.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:55.185: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:57.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:57.182: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 22 19:45:59.178: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 22 19:45:59.185: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:45:59.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9kfgq" for this suite.
Jan 22 19:46:21.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:46:21.379: INFO: namespace: e2e-tests-container-lifecycle-hook-9kfgq, resource: bindings, ignored listing per whitelist
Jan 22 19:46:21.438: INFO: namespace e2e-tests-container-lifecycle-hook-9kfgq deletion completed in 22.228732496s

• [SLOW TEST:58.471 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:46:21.441: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-64b1ff20-1e7e-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:46:21.582: INFO: Waiting up to 5m0s for pod "pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-76bsn" to be "success or failure"
Jan 22 19:46:21.586: INFO: Pod "pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043827ms
Jan 22 19:46:23.591: INFO: Pod "pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008976677s
Jan 22 19:46:25.598: INFO: Pod "pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015997692s
STEP: Saw pod success
Jan 22 19:46:25.598: INFO: Pod "pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:46:25.601: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3 container secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:46:25.637: INFO: Waiting for pod pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:46:25.640: INFO: Pod pod-secrets-64b3082b-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:46:25.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-76bsn" for this suite.
Jan 22 19:46:31.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:46:31.726: INFO: namespace: e2e-tests-secrets-76bsn, resource: bindings, ignored listing per whitelist
Jan 22 19:46:31.816: INFO: namespace e2e-tests-secrets-76bsn deletion completed in 6.171653081s

• [SLOW TEST:10.376 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:46:31.817: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 22 19:46:31.987: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-545960299 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:46:32.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wpmh8" for this suite.
Jan 22 19:46:38.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:46:38.237: INFO: namespace: e2e-tests-kubectl-wpmh8, resource: bindings, ignored listing per whitelist
Jan 22 19:46:38.354: INFO: namespace e2e-tests-kubectl-wpmh8 deletion completed in 6.240048018s

• [SLOW TEST:6.538 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:46:38.355: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:46:44.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-j7lgj" for this suite.
Jan 22 19:46:50.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:46:50.798: INFO: namespace: e2e-tests-namespaces-j7lgj, resource: bindings, ignored listing per whitelist
Jan 22 19:46:50.884: INFO: namespace e2e-tests-namespaces-j7lgj deletion completed in 6.220382661s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hrnxw" for this suite.
Jan 22 19:46:50.887: INFO: Namespace e2e-tests-nsdeletetest-hrnxw was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-kj54t" for this suite.
Jan 22 19:46:56.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:46:56.957: INFO: namespace: e2e-tests-nsdeletetest-kj54t, resource: bindings, ignored listing per whitelist
Jan 22 19:46:57.069: INFO: namespace e2e-tests-nsdeletetest-kj54t deletion completed in 6.180636389s

• [SLOW TEST:18.715 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:46:57.069: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 22 19:46:57.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19846,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 19:46:57.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19846,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 22 19:47:07.262: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19862,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 22 19:47:07.262: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19862,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 22 19:47:17.277: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19878,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 19:47:17.277: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19878,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 22 19:47:27.289: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19894,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 22 19:47:27.289: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-a,UID:79f6aa80-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19894,Generation:0,CreationTimestamp:2019-01-22 19:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 22 19:47:37.301: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-b,UID:91d5e0ee-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19911,Generation:0,CreationTimestamp:2019-01-22 19:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 19:47:37.301: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-b,UID:91d5e0ee-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19911,Generation:0,CreationTimestamp:2019-01-22 19:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 22 19:47:47.313: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-b,UID:91d5e0ee-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19927,Generation:0,CreationTimestamp:2019-01-22 19:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 22 19:47:47.314: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-jcgfx,SelfLink:/api/v1/namespaces/e2e-tests-watch-jcgfx/configmaps/e2e-watch-test-configmap-b,UID:91d5e0ee-1e7e-11e9-a380-de5a8a93737b,ResourceVersion:19927,Generation:0,CreationTimestamp:2019-01-22 19:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:47:57.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jcgfx" for this suite.
Jan 22 19:48:03.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:48:03.485: INFO: namespace: e2e-tests-watch-jcgfx, resource: bindings, ignored listing per whitelist
Jan 22 19:48:03.506: INFO: namespace e2e-tests-watch-jcgfx deletion completed in 6.18701461s

• [SLOW TEST:66.437 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:48:03.507: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a1a6c282-1e7e-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:48:03.853: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-795mg" to be "success or failure"
Jan 22 19:48:03.862: INFO: Pod "pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.805978ms
Jan 22 19:48:05.867: INFO: Pod "pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013287821s
STEP: Saw pod success
Jan 22 19:48:05.867: INFO: Pod "pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:48:05.870: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:48:05.920: INFO: Waiting for pod pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:48:05.926: INFO: Pod pod-projected-configmaps-a1a7bd13-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:48:05.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-795mg" for this suite.
Jan 22 19:48:11.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:48:12.084: INFO: namespace: e2e-tests-projected-795mg, resource: bindings, ignored listing per whitelist
Jan 22 19:48:12.195: INFO: namespace e2e-tests-projected-795mg deletion completed in 6.263890909s

• [SLOW TEST:8.688 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:48:12.195: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan 22 19:48:12.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:12.698: INFO: stderr: ""
Jan 22 19:48:12.698: INFO: stdout: "pod/pause created\n"
Jan 22 19:48:12.698: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 22 19:48:12.698: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-496jt" to be "running and ready"
Jan 22 19:48:12.706: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.657372ms
Jan 22 19:48:14.711: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012936602s
Jan 22 19:48:16.715: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.017470638s
Jan 22 19:48:16.715: INFO: Pod "pause" satisfied condition "running and ready"
Jan 22 19:48:16.715: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 22 19:48:16.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:16.859: INFO: stderr: ""
Jan 22 19:48:16.859: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 22 19:48:16.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pod pause -L testing-label --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:16.981: INFO: stderr: ""
Jan 22 19:48:16.981: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 22 19:48:16.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 label pods pause testing-label- --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:17.129: INFO: stderr: ""
Jan 22 19:48:17.129: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 22 19:48:17.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pod pause -L testing-label --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:17.255: INFO: stderr: ""
Jan 22 19:48:17.255: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan 22 19:48:17.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:17.395: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 22 19:48:17.395: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 22 19:48:17.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-496jt'
Jan 22 19:48:17.509: INFO: stderr: "No resources found.\n"
Jan 22 19:48:17.509: INFO: stdout: ""
Jan 22 19:48:17.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 get pods -l name=pause --namespace=e2e-tests-kubectl-496jt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 22 19:48:17.620: INFO: stderr: ""
Jan 22 19:48:17.620: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:48:17.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-496jt" for this suite.
Jan 22 19:48:23.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:48:23.697: INFO: namespace: e2e-tests-kubectl-496jt, resource: bindings, ignored listing per whitelist
Jan 22 19:48:23.807: INFO: namespace e2e-tests-kubectl-496jt deletion completed in 6.1819825s

• [SLOW TEST:11.612 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:48:23.807: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 22 19:48:23.962: INFO: Waiting up to 5m0s for pod "pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-zrkcg" to be "success or failure"
Jan 22 19:48:23.966: INFO: Pod "pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.47761ms
Jan 22 19:48:25.974: INFO: Pod "pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011706655s
Jan 22 19:48:27.979: INFO: Pod "pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016492491s
STEP: Saw pod success
Jan 22 19:48:27.979: INFO: Pod "pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:48:27.983: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:48:28.026: INFO: Waiting for pod pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:48:28.029: INFO: Pod pod-ada3b391-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:48:28.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zrkcg" for this suite.
Jan 22 19:48:34.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:48:34.102: INFO: namespace: e2e-tests-emptydir-zrkcg, resource: bindings, ignored listing per whitelist
Jan 22 19:48:34.238: INFO: namespace e2e-tests-emptydir-zrkcg deletion completed in 6.203794262s

• [SLOW TEST:10.431 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:48:34.238: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 22 19:48:34.560: INFO: Waiting up to 5m0s for pod "pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-t7kkw" to be "success or failure"
Jan 22 19:48:34.565: INFO: Pod "pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365038ms
Jan 22 19:48:36.569: INFO: Pod "pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008764154s
Jan 22 19:48:38.574: INFO: Pod "pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013871491s
STEP: Saw pod success
Jan 22 19:48:38.574: INFO: Pod "pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:48:38.580: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:48:38.625: INFO: Waiting for pod pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:48:38.630: INFO: Pod pod-b3f55bbd-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:48:38.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t7kkw" for this suite.
Jan 22 19:48:44.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:48:44.717: INFO: namespace: e2e-tests-emptydir-t7kkw, resource: bindings, ignored listing per whitelist
Jan 22 19:48:44.834: INFO: namespace e2e-tests-emptydir-t7kkw deletion completed in 6.199387498s

• [SLOW TEST:10.596 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:48:44.834: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 22 19:48:45.010: INFO: Waiting up to 5m0s for pod "pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-emptydir-p477s" to be "success or failure"
Jan 22 19:48:45.036: INFO: Pod "pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.451401ms
Jan 22 19:48:47.044: INFO: Pod "pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033131113s
Jan 22 19:48:49.048: INFO: Pod "pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038000235s
STEP: Saw pod success
Jan 22 19:48:49.048: INFO: Pod "pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:48:49.054: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3 container test-container: <nil>
STEP: delete the pod
Jan 22 19:48:49.106: INFO: Waiting for pod pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:48:49.111: INFO: Pod pod-ba2c6f23-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:48:49.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p477s" for this suite.
Jan 22 19:48:55.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:48:55.203: INFO: namespace: e2e-tests-emptydir-p477s, resource: bindings, ignored listing per whitelist
Jan 22 19:48:55.269: INFO: namespace e2e-tests-emptydir-p477s deletion completed in 6.153339524s

• [SLOW TEST:10.435 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:48:55.270: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:48:55.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 version --client'
Jan 22 19:48:55.515: INFO: stderr: ""
Jan 22 19:48:55.515: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 22 19:48:55.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-b7gp4'
Jan 22 19:48:55.893: INFO: stderr: ""
Jan 22 19:48:55.893: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 22 19:48:55.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 create -f - --namespace=e2e-tests-kubectl-b7gp4'
Jan 22 19:48:56.267: INFO: stderr: ""
Jan 22 19:48:56.267: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 22 19:48:57.271: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:48:57.271: INFO: Found 0 / 1
Jan 22 19:48:58.274: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:48:58.274: INFO: Found 1 / 1
Jan 22 19:48:58.274: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 22 19:48:58.277: INFO: Selector matched 1 pods for map[app:redis]
Jan 22 19:48:58.277: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 22 19:48:58.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 describe pod redis-master-z9zdt --namespace=e2e-tests-kubectl-b7gp4'
Jan 22 19:48:58.431: INFO: stderr: ""
Jan 22 19:48:58.431: INFO: stdout: "Name:               redis-master-z9zdt\nNamespace:          e2e-tests-kubectl-b7gp4\nPriority:           0\nPriorityClassName:  <none>\nNode:               aks-nodepool1-25266157-2/10.240.0.4\nStart Time:         Tue, 22 Jan 2019 19:48:55 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.245\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://a1ece8384711976cd5112ddc50e2ae20794ad6f4a6802f3ca7eb55f6ed652ba9\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 22 Jan 2019 19:48:57 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_PORT_443_TCP_ADDR:  levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io\n      KUBERNETES_PORT:               tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443\n      KUBERNETES_PORT_443_TCP:       tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443\n      KUBERNETES_SERVICE_HOST:       levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-k6f5l (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-k6f5l:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-k6f5l\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                               Message\n  ----    ------     ----  ----                               -------\n  Normal  Scheduled  3s    default-scheduler                  Successfully assigned e2e-tests-kubectl-b7gp4/redis-master-z9zdt to aks-nodepool1-25266157-2\n  Normal  Pulled     2s    kubelet, aks-nodepool1-25266157-2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, aks-nodepool1-25266157-2  Created container\n  Normal  Started    1s    kubelet, aks-nodepool1-25266157-2  Started container\n"
Jan 22 19:48:58.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 describe rc redis-master --namespace=e2e-tests-kubectl-b7gp4'
Jan 22 19:48:58.584: INFO: stderr: ""
Jan 22 19:48:58.584: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-b7gp4\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-z9zdt\n"
Jan 22 19:48:58.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 describe service redis-master --namespace=e2e-tests-kubectl-b7gp4'
Jan 22 19:48:58.722: INFO: stderr: ""
Jan 22 19:48:58.722: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-b7gp4\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.149.112\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.245:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 22 19:48:58.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 describe node aks-nodepool1-25266157-0'
Jan 22 19:48:58.876: INFO: stderr: ""
Jan 22 19:48:58.876: INFO: stdout: "Name:               aks-nodepool1-25266157-0\nRoles:              agent\nLabels:             agentpool=nodepool1\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westus2\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.azure.com/cluster=MC_levo-aks-westus2_levo-wus2-1-12-1_westus2\n                    kubernetes.io/hostname=aks-nodepool1-25266157-0\n                    kubernetes.io/role=agent\n                    node-role.kubernetes.io/agent=\n                    storageprofile=managed\n                    storagetier=Premium_LRS\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 22 Jan 2019 18:06:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 22 Jan 2019 18:07:59 +0000   Tue, 22 Jan 2019 18:07:59 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Tue, 22 Jan 2019 19:48:54 +0000   Tue, 22 Jan 2019 18:06:47 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Tue, 22 Jan 2019 19:48:54 +0000   Tue, 22 Jan 2019 18:06:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 22 Jan 2019 19:48:54 +0000   Tue, 22 Jan 2019 18:06:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 22 Jan 2019 19:48:54 +0000   Tue, 22 Jan 2019 18:06:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 22 Jan 2019 19:48:54 +0000   Tue, 22 Jan 2019 18:06:47 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    aks-nodepool1-25266157-0\n  InternalIP:  10.240.0.6\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              30428648Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7137112Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            1931m\n ephemeral-storage:              28043041951\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         5357400Ki\n pods:                           110\nSystem Info:\n Machine ID:                 bc55b8ae04a84bfd8b3c9f0962a4f55a\n System UUID:                34B5120E-9995-A847-B374-F7B38E6AC87E\n Boot ID:                    68d3156f-b5fd-4d95-b595-23d8cb0cdde3\n Kernel Version:             4.15.0-1035-azure\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://3.0.1\n Kubelet Version:            v1.12.4\n Kube-Proxy Version:         v1.12.4\nPodCIDR:                     10.244.0.0/24\nProviderID:                  azure:///subscriptions/01db32b1-e169-43b0-a791-de0e1ca5d8cd/resourceGroups/MC_levo-aks-westus2_levo-wus2-1-12-1_westus2/providers/Microsoft.Compute/virtualMachines/aks-nodepool1-25266157-0\nNon-terminated Pods:         (12 in total)\n  Namespace                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                               ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-vcfbq            0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                addon-http-application-routing-default-http-backend-8cdc9dxj4t8    10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)\n  kube-system                addon-http-application-routing-external-dns-748b5c76c5-6jkzs       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                addon-http-application-routing-nginx-ingress-controller-8fgw98w    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-7d6976d69b-cwx7h                                           100m (5%)     0 (0%)      70Mi (1%)        170Mi (3%)\n  kube-system                coredns-autoscaler-6fcdb7d64-b7f2f                                 20m (1%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                heapster-5fb7488d97-c8mth                                          130m (6%)     130m (6%)   230Mi (4%)       230Mi (4%)\n  kube-system                kube-proxy-2v8rv                                                   100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-svc-redirect-qsqw9                                            10m (0%)      0 (0%)      34Mi (0%)        0 (0%)\n  kube-system                kubernetes-dashboard-847bb4ddc6-d6279                              100m (5%)     100m (5%)   50Mi (0%)        300Mi (5%)\n  kube-system                metrics-server-7b97f9cd9-5m9b9                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                tunnelfront-7d7c8dd874-mmz7c                                       10m (0%)      0 (0%)      64Mi (1%)        0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            480m (24%)  240m (12%)\n  memory                         478Mi (9%)  720Mi (13%)\n  attachable-volumes-azure-disk  0           0\nEvents:                          <none>\n"
Jan 22 19:48:58.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-545960299 describe namespace e2e-tests-kubectl-b7gp4'
Jan 22 19:48:59.009: INFO: stderr: ""
Jan 22 19:48:59.009: INFO: stdout: "Name:         e2e-tests-kubectl-b7gp4\nLabels:       e2e-framework=kubectl\n              e2e-run=00fe3434-1e73-11e9-9ccc-2ee9843eaab3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:48:59.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b7gp4" for this suite.
Jan 22 19:49:11.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:49:11.199: INFO: namespace: e2e-tests-kubectl-b7gp4, resource: bindings, ignored listing per whitelist
Jan 22 19:49:11.226: INFO: namespace e2e-tests-kubectl-b7gp4 deletion completed in 12.210844472s

• [SLOW TEST:15.956 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:49:11.226: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 22 19:49:11.450: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 22 19:49:11.460: INFO: Waiting for terminating namespaces to be deleted...
Jan 22 19:49:11.464: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-0 before test
Jan 22 19:49:11.484: INFO: tunnelfront-7d7c8dd874-mmz7c from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container tunnel-front ready: true, restart count 0
Jan 22 19:49:11.484: INFO: addon-http-application-routing-nginx-ingress-controller-8fgw98w from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container addon-http-application-routing-nginx-ingress-controller ready: true, restart count 0
Jan 22 19:49:11.484: INFO: coredns-7d6976d69b-cwx7h from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container coredns ready: true, restart count 0
Jan 22 19:49:11.484: INFO: addon-http-application-routing-default-http-backend-8cdc9dxj4t8 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container addon-http-application-routing-default-http-backend ready: true, restart count 0
Jan 22 19:49:11.484: INFO: kube-svc-redirect-qsqw9 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 19:49:11.484: INFO: 	Container redirector ready: true, restart count 0
Jan 22 19:49:11.484: INFO: kube-proxy-2v8rv from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 19:49:11.484: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-vcfbq from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 22 19:49:11.484: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 22 19:49:11.484: INFO: coredns-autoscaler-6fcdb7d64-b7f2f from kube-system started at 2019-01-22 18:06:47 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container autoscaler ready: true, restart count 0
Jan 22 19:49:11.484: INFO: metrics-server-7b97f9cd9-5m9b9 from kube-system started at 2019-01-22 18:06:47 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container metrics-server ready: true, restart count 1
Jan 22 19:49:11.484: INFO: heapster-5fb7488d97-c8mth from kube-system started at 2019-01-22 18:06:47 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container heapster ready: true, restart count 0
Jan 22 19:49:11.484: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 22 19:49:11.484: INFO: addon-http-application-routing-external-dns-748b5c76c5-6jkzs from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container addon-http-application-routing-external-dns ready: true, restart count 0
Jan 22 19:49:11.484: INFO: kubernetes-dashboard-847bb4ddc6-d6279 from kube-system started at 2019-01-22 18:06:48 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.484: INFO: 	Container main ready: true, restart count 0
Jan 22 19:49:11.484: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-1 before test
Jan 22 19:49:11.580: INFO: kube-proxy-5t82s from kube-system started at 2019-01-22 18:07:06 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.580: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 19:49:11.580: INFO: coredns-7d6976d69b-bx6qf from kube-system started at 2019-01-22 18:07:18 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.580: INFO: 	Container coredns ready: true, restart count 0
Jan 22 19:49:11.580: INFO: kube-svc-redirect-79xvb from kube-system started at 2019-01-22 18:07:06 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.580: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 19:49:11.580: INFO: 	Container redirector ready: true, restart count 0
Jan 22 19:49:11.580: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z4tt7 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.580: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 22 19:49:11.580: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 22 19:49:11.580: INFO: sonobuoy-e2e-job-28ff8d7933fc4391 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.580: INFO: 	Container e2e ready: true, restart count 0
Jan 22 19:49:11.580: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 22 19:49:11.580: INFO: 
Logging pods the kubelet thinks is on node aks-nodepool1-25266157-2 before test
Jan 22 19:49:11.591: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-22 18:23:38 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.591: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 22 19:49:11.591: INFO: kube-svc-redirect-gzjdx from kube-system started at 2019-01-22 18:07:01 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.591: INFO: 	Container azureproxy ready: true, restart count 0
Jan 22 19:49:11.591: INFO: 	Container redirector ready: true, restart count 0
Jan 22 19:49:11.591: INFO: kube-proxy-8rjdt from kube-system started at 2019-01-22 18:07:01 +0000 UTC (1 container statuses recorded)
Jan 22 19:49:11.591: INFO: 	Container kube-proxy ready: true, restart count 0
Jan 22 19:49:11.591: INFO: sonobuoy-systemd-logs-daemon-set-8131d806dadf43df-z68w9 from heptio-sonobuoy started at 2019-01-22 18:23:44 +0000 UTC (2 container statuses recorded)
Jan 22 19:49:11.591: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 22 19:49:11.591: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157c43774f4a0b9a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:49:12.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-cghfr" for this suite.
Jan 22 19:49:18.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:49:18.771: INFO: namespace: e2e-tests-sched-pred-cghfr, resource: bindings, ignored listing per whitelist
Jan 22 19:49:18.851: INFO: namespace e2e-tests-sched-pred-cghfr deletion completed in 6.212486033s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.625 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:49:18.852: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:49:19.194: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-njrln" to be "success or failure"
Jan 22 19:49:19.197: INFO: Pod "downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.562212ms
Jan 22 19:49:21.203: INFO: Pod "downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008593815s
Jan 22 19:49:23.208: INFO: Pod "downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014334778s
STEP: Saw pod success
Jan 22 19:49:23.208: INFO: Pod "downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:49:23.213: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:49:23.255: INFO: Waiting for pod downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:49:23.259: INFO: Pod downwardapi-volume-ce907c99-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:49:23.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-njrln" for this suite.
Jan 22 19:49:29.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:49:29.410: INFO: namespace: e2e-tests-downward-api-njrln, resource: bindings, ignored listing per whitelist
Jan 22 19:49:29.450: INFO: namespace e2e-tests-downward-api-njrln deletion completed in 6.186000108s

• [SLOW TEST:10.598 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:49:29.450: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:49:29.595: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-9lk2p" to be "success or failure"
Jan 22 19:49:29.599: INFO: Pod "downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.993838ms
Jan 22 19:49:31.626: INFO: Pod "downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030733003s
Jan 22 19:49:33.630: INFO: Pod "downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034977565s
STEP: Saw pod success
Jan 22 19:49:33.630: INFO: Pod "downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:49:33.634: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:49:33.668: INFO: Waiting for pod downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:49:33.671: INFO: Pod downwardapi-volume-d4c30e39-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:49:33.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9lk2p" for this suite.
Jan 22 19:49:39.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:49:39.858: INFO: namespace: e2e-tests-projected-9lk2p, resource: bindings, ignored listing per whitelist
Jan 22 19:49:39.869: INFO: namespace e2e-tests-projected-9lk2p deletion completed in 6.192849274s

• [SLOW TEST:10.419 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:49:39.869: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-dafacf0e-1e7e-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:49:40.033: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-ls44b" to be "success or failure"
Jan 22 19:49:40.044: INFO: Pod "pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.652768ms
Jan 22 19:49:42.048: INFO: Pod "pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014505621s
STEP: Saw pod success
Jan 22 19:49:42.048: INFO: Pod "pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:49:42.052: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 22 19:49:42.134: INFO: Waiting for pod pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:49:42.139: INFO: Pod pod-projected-secrets-dafc2509-1e7e-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:49:42.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ls44b" for this suite.
Jan 22 19:49:48.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:49:48.215: INFO: namespace: e2e-tests-projected-ls44b, resource: bindings, ignored listing per whitelist
Jan 22 19:49:48.327: INFO: namespace e2e-tests-projected-ls44b deletion completed in 6.183553856s

• [SLOW TEST:8.458 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:49:48.331: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-e0042a49-1e7e-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-e0042a49-1e7e-11e9-9ccc-2ee9843eaab3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:49:54.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s7bt4" for this suite.
Jan 22 19:50:16.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:50:16.691: INFO: namespace: e2e-tests-configmap-s7bt4, resource: bindings, ignored listing per whitelist
Jan 22 19:50:16.834: INFO: namespace e2e-tests-configmap-s7bt4 deletion completed in 22.24073281s

• [SLOW TEST:28.502 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:50:16.834: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p4jsb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 22 19:50:17.067: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 22 19:50:39.242: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.253:8080/dial?request=hostName&protocol=udp&host=10.244.1.252&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-p4jsb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:50:39.242: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:50:39.558: INFO: Waiting for endpoints: map[]
Jan 22 19:50:39.624: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.253:8080/dial?request=hostName&protocol=udp&host=10.244.2.64&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-p4jsb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:50:39.624: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:50:39.990: INFO: Waiting for endpoints: map[]
Jan 22 19:50:39.995: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.253:8080/dial?request=hostName&protocol=udp&host=10.244.0.43&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-p4jsb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 22 19:50:39.995: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
Jan 22 19:50:40.258: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:50:40.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p4jsb" for this suite.
Jan 22 19:51:02.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:51:02.357: INFO: namespace: e2e-tests-pod-network-test-p4jsb, resource: bindings, ignored listing per whitelist
Jan 22 19:51:02.506: INFO: namespace e2e-tests-pod-network-test-p4jsb deletion completed in 22.242952057s

• [SLOW TEST:45.673 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:51:02.507: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-2vnb8/secret-test-0c3bfaed-1e7f-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume secrets
Jan 22 19:51:02.670: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-secrets-2vnb8" to be "success or failure"
Jan 22 19:51:02.674: INFO: Pod "pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.886433ms
Jan 22 19:51:04.679: INFO: Pod "pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00857575s
STEP: Saw pod success
Jan 22 19:51:04.679: INFO: Pod "pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:51:04.682: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3 container env-test: <nil>
STEP: delete the pod
Jan 22 19:51:04.725: INFO: Waiting for pod pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:51:04.729: INFO: Pod pod-configmaps-0c3d1494-1e7f-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:51:04.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2vnb8" for this suite.
Jan 22 19:51:10.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:51:10.910: INFO: namespace: e2e-tests-secrets-2vnb8, resource: bindings, ignored listing per whitelist
Jan 22 19:51:10.963: INFO: namespace e2e-tests-secrets-2vnb8 deletion completed in 6.229391077s

• [SLOW TEST:8.456 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:51:10.963: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 22 19:51:11.119: INFO: Waiting up to 5m0s for pod "downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-downward-api-t5nbn" to be "success or failure"
Jan 22 19:51:11.130: INFO: Pod "downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.694798ms
Jan 22 19:51:13.135: INFO: Pod "downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016820649s
Jan 22 19:51:15.142: INFO: Pod "downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02337543s
STEP: Saw pod success
Jan 22 19:51:15.142: INFO: Pod "downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:51:15.146: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3 container dapi-container: <nil>
STEP: delete the pod
Jan 22 19:51:15.201: INFO: Waiting for pod downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:51:15.205: INFO: Pod downward-api-11450879-1e7f-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:51:15.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t5nbn" for this suite.
Jan 22 19:51:21.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:51:21.363: INFO: namespace: e2e-tests-downward-api-t5nbn, resource: bindings, ignored listing per whitelist
Jan 22 19:51:21.445: INFO: namespace e2e-tests-downward-api-t5nbn deletion completed in 6.233795117s

• [SLOW TEST:10.482 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:51:21.445: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-17897d0b-1e7f-11e9-9ccc-2ee9843eaab3
STEP: Creating a pod to test consume configMaps
Jan 22 19:51:21.644: INFO: Waiting up to 5m0s for pod "pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-configmap-gxj8h" to be "success or failure"
Jan 22 19:51:21.651: INFO: Pod "pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.152843ms
Jan 22 19:51:23.655: INFO: Pod "pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011162958s
STEP: Saw pod success
Jan 22 19:51:23.655: INFO: Pod "pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:51:23.658: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 22 19:51:23.693: INFO: Waiting for pod pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:51:23.697: INFO: Pod pod-configmaps-178a9ef7-1e7f-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:51:23.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gxj8h" for this suite.
Jan 22 19:51:29.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:51:29.745: INFO: namespace: e2e-tests-configmap-gxj8h, resource: bindings, ignored listing per whitelist
Jan 22 19:51:29.862: INFO: namespace e2e-tests-configmap-gxj8h deletion completed in 6.160671786s

• [SLOW TEST:8.417 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:51:29.862: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 22 19:51:30.040: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 22 19:51:35.045: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 22 19:51:35.045: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 22 19:51:37.049: INFO: Creating deployment "test-rollover-deployment"
Jan 22 19:51:37.066: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 22 19:51:39.077: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 22 19:51:39.093: INFO: Ensure that both replica sets have 1 created replica
Jan 22 19:51:39.100: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 22 19:51:39.114: INFO: Updating deployment test-rollover-deployment
Jan 22 19:51:39.114: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 22 19:51:41.124: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 22 19:51:41.133: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 22 19:51:41.142: INFO: all replica sets need to contain the pod-template-hash label
Jan 22 19:51:41.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783499, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:51:43.152: INFO: all replica sets need to contain the pod-template-hash label
Jan 22 19:51:43.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783501, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:51:45.154: INFO: all replica sets need to contain the pod-template-hash label
Jan 22 19:51:45.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783501, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:51:47.158: INFO: all replica sets need to contain the pod-template-hash label
Jan 22 19:51:47.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783501, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:51:49.154: INFO: all replica sets need to contain the pod-template-hash label
Jan 22 19:51:49.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783501, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:51:51.150: INFO: all replica sets need to contain the pod-template-hash label
Jan 22 19:51:51.150: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783501, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683783497, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 22 19:51:53.150: INFO: 
Jan 22 19:51:53.150: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 22 19:51:53.164: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-sq75l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sq75l/deployments/test-rollover-deployment,UID:20be31a4-1e7f-11e9-a380-de5a8a93737b,ResourceVersion:20833,Generation:2,CreationTimestamp:2019-01-22 19:51:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-22 19:51:37 +0000 UTC 2019-01-22 19:51:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-22 19:51:51 +0000 UTC 2019-01-22 19:51:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 22 19:51:53.174: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-sq75l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sq75l/replicasets/test-rollover-deployment-5b76ff8c4,UID:21f93451-1e7f-11e9-a380-de5a8a93737b,ResourceVersion:20824,Generation:2,CreationTimestamp:2019-01-22 19:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 20be31a4-1e7f-11e9-a380-de5a8a93737b 0xc421b03ea7 0xc421b03ea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 22 19:51:53.174: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 22 19:51:53.174: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-sq75l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sq75l/replicasets/test-rollover-controller,UID:1c8e8e8f-1e7f-11e9-a380-de5a8a93737b,ResourceVersion:20832,Generation:2,CreationTimestamp:2019-01-22 19:51:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 20be31a4-1e7f-11e9-a380-de5a8a93737b 0xc421b03d5e 0xc421b03d5f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 22 19:51:53.174: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-sq75l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sq75l/replicasets/test-rollover-deployment-6975f4fb87,UID:20c288a4-1e7f-11e9-a380-de5a8a93737b,ResourceVersion:20796,Generation:2,CreationTimestamp:2019-01-22 19:51:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 20be31a4-1e7f-11e9-a380-de5a8a93737b 0xc421b03f67 0xc421b03f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 22 19:51:53.182: INFO: Pod "test-rollover-deployment-5b76ff8c4-4q98t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-4q98t,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-sq75l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-sq75l/pods/test-rollover-deployment-5b76ff8c4-4q98t,UID:2202002f-1e7f-11e9-a380-de5a8a93737b,ResourceVersion:20806,Generation:0,CreationTimestamp:2019-01-22 19:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 21f93451-1e7f-11e9-a380-de5a8a93737b 0xc42162bf20 0xc42162bf21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nrqc4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nrqc4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [{KUBERNETES_PORT_443_TCP_ADDR levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil} {KUBERNETES_PORT tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_PORT_443_TCP tcp://levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io:443 nil} {KUBERNETES_SERVICE_HOST levo-wus2--levo-aks-westus2-01db32-c95441f3.hcp.westus2.azmk8s.io nil}] {map[] map[]} [{default-token-nrqc4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-nodepool1-25266157-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc423228390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc423228410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:51:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:51:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-22 19:51:39 +0000 UTC  }],Message:,Reason:,HostIP:10.240.0.4,PodIP:10.244.1.7,StartTime:2019-01-22 19:51:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-22 19:51:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8d9823756b3639f00a90e87a006d3729f76f73ad3f54b48efc6929b120de4b19}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:51:53.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-sq75l" for this suite.
Jan 22 19:51:59.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:51:59.254: INFO: namespace: e2e-tests-deployment-sq75l, resource: bindings, ignored listing per whitelist
Jan 22 19:51:59.409: INFO: namespace e2e-tests-deployment-sq75l deletion completed in 6.221664039s

• [SLOW TEST:29.546 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:51:59.409: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-52dsx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-52dsx to expose endpoints map[]
Jan 22 19:51:59.549: INFO: Get endpoints failed (4.353648ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 22 19:52:00.553: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-52dsx exposes endpoints map[] (1.00821965s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-52dsx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-52dsx to expose endpoints map[pod1:[80]]
Jan 22 19:52:02.621: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-52dsx exposes endpoints map[pod1:[80]] (2.031759606s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-52dsx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-52dsx to expose endpoints map[pod1:[80] pod2:[80]]
Jan 22 19:52:05.700: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-52dsx exposes endpoints map[pod2:[80] pod1:[80]] (3.061533645s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-52dsx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-52dsx to expose endpoints map[pod2:[80]]
Jan 22 19:52:05.729: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-52dsx exposes endpoints map[pod2:[80]] (14.528592ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-52dsx
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-52dsx to expose endpoints map[]
Jan 22 19:52:05.759: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-52dsx exposes endpoints map[] (9.256713ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:52:05.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-52dsx" for this suite.
Jan 22 19:52:27.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:52:27.997: INFO: namespace: e2e-tests-services-52dsx, resource: bindings, ignored listing per whitelist
Jan 22 19:52:28.009: INFO: namespace e2e-tests-services-52dsx deletion completed in 22.200299179s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.601 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:52:28.010: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 22 19:52:28.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3" in namespace "e2e-tests-projected-kqhgt" to be "success or failure"
Jan 22 19:52:28.152: INFO: Pod "downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471817ms
Jan 22 19:52:30.157: INFO: Pod "downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008537888s
STEP: Saw pod success
Jan 22 19:52:30.157: INFO: Pod "downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3" satisfied condition "success or failure"
Jan 22 19:52:30.161: INFO: Trying to get logs from node aks-nodepool1-25266157-2 pod downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3 container client-container: <nil>
STEP: delete the pod
Jan 22 19:52:30.198: INFO: Waiting for pod downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3 to disappear
Jan 22 19:52:30.202: INFO: Pod downwardapi-volume-3f30827b-1e7f-11e9-9ccc-2ee9843eaab3 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:52:30.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kqhgt" for this suite.
Jan 22 19:52:36.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:52:36.358: INFO: namespace: e2e-tests-projected-kqhgt, resource: bindings, ignored listing per whitelist
Jan 22 19:52:36.363: INFO: namespace e2e-tests-projected-kqhgt deletion completed in 6.153673183s

• [SLOW TEST:8.353 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:52:36.363: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-44316a2d-1e7f-11e9-9ccc-2ee9843eaab3
STEP: Creating secret with name s-test-opt-upd-44316a69-1e7f-11e9-9ccc-2ee9843eaab3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-44316a2d-1e7f-11e9-9ccc-2ee9843eaab3
STEP: Updating secret s-test-opt-upd-44316a69-1e7f-11e9-9ccc-2ee9843eaab3
STEP: Creating secret with name s-test-opt-create-44316a7f-1e7f-11e9-9ccc-2ee9843eaab3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:52:44.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tzwqd" for this suite.
Jan 22 19:53:06.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:53:07.042: INFO: namespace: e2e-tests-secrets-tzwqd, resource: bindings, ignored listing per whitelist
Jan 22 19:53:07.107: INFO: namespace e2e-tests-secrets-tzwqd deletion completed in 22.197322194s

• [SLOW TEST:30.744 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 22 19:53:07.108: INFO: >>> kubeConfig: /tmp/kubeconfig-545960299
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 22 19:53:07.237: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 22 19:53:11.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2bplh" for this suite.
Jan 22 19:53:33.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 22 19:53:33.653: INFO: namespace: e2e-tests-init-container-2bplh, resource: bindings, ignored listing per whitelist
Jan 22 19:53:33.683: INFO: namespace e2e-tests-init-container-2bplh deletion completed in 22.17637297s

• [SLOW TEST:26.575 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSJan 22 19:53:33.683: INFO: Running AfterSuite actions on all node
Jan 22 19:53:33.683: INFO: Running AfterSuite actions on node 1
Jan 22 19:53:33.683: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5323.028 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h28m44.013239427s
Test Suite Passed
