Jan 21 08:45:51.136: INFO: Overriding default scale value of zero to 1
Jan 21 08:45:51.136: INFO: Overriding default milliseconds value of zero to 5000
I0121 08:45:51.541674      16 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-484689981
I0121 08:45:51.541790      16 e2e.go:304] Starting e2e run "f4ab4fb1-1d58-11e9-9c91-0a58ac100282" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1548060350 - Will randomize all specs
Will run 188 of 1814 specs

Jan 21 08:45:51.660: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:45:51.662: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 21 08:45:51.676: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 21 08:45:51.702: INFO: 40 / 40 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 21 08:45:51.702: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Jan 21 08:45:51.702: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 21 08:45:51.709: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cloud-controller-manager' (0 seconds elapsed)
Jan 21 08:45:51.709: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'flexvolume' (0 seconds elapsed)
Jan 21 08:45:51.709: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Jan 21 08:45:51.709: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-master' (0 seconds elapsed)
Jan 21 08:45:51.709: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker' (0 seconds elapsed)
Jan 21 08:45:51.709: INFO: e2e test version: v1.12.1
Jan 21 08:45:51.709: INFO: kube-apiserver version: v1.12.4-aliyun.1
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:45:51.709: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
Jan 21 08:45:51.784: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f5185488-1d58-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 08:45:51.795: INFO: Waiting up to 5m0s for pod "pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-jgl8l" to be "success or failure"
Jan 21 08:45:51.797: INFO: Pod "pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.375561ms
Jan 21 08:45:53.800: INFO: Pod "pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004763585s
Jan 21 08:45:55.802: INFO: Pod "pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00724253s
STEP: Saw pod success
Jan 21 08:45:55.802: INFO: Pod "pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:45:55.804: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 08:45:55.839: INFO: Waiting for pod pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:45:55.840: INFO: Pod pod-secrets-f519060a-1d58-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:45:55.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jgl8l" for this suite.
Jan 21 08:46:01.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:46:01.864: INFO: namespace: e2e-tests-secrets-jgl8l, resource: bindings, ignored listing per whitelist
Jan 21 08:46:01.941: INFO: namespace e2e-tests-secrets-jgl8l deletion completed in 6.098041287s

• [SLOW TEST:10.232 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:46:01.941: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-fb2f0098-1d58-11e9-9c91-0a58ac100282
STEP: Creating configMap with name cm-test-opt-upd-fb2f00f3-1d58-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fb2f0098-1d58-11e9-9c91-0a58ac100282
STEP: Updating configmap cm-test-opt-upd-fb2f00f3-1d58-11e9-9c91-0a58ac100282
STEP: Creating configMap with name cm-test-opt-create-fb2f0106-1d58-11e9-9c91-0a58ac100282
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:46:06.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wb92r" for this suite.
Jan 21 08:46:28.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:46:28.122: INFO: namespace: e2e-tests-projected-wb92r, resource: bindings, ignored listing per whitelist
Jan 21 08:46:28.143: INFO: namespace e2e-tests-projected-wb92r deletion completed in 22.071784464s

• [SLOW TEST:26.202 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:46:28.143: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0121 08:46:34.223698      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 08:46:34.223: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:46:34.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zvhwb" for this suite.
Jan 21 08:46:40.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:46:40.246: INFO: namespace: e2e-tests-gc-zvhwb, resource: bindings, ignored listing per whitelist
Jan 21 08:46:40.320: INFO: namespace e2e-tests-gc-zvhwb deletion completed in 6.093734738s

• [SLOW TEST:12.176 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:46:40.320: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 08:46:40.378: INFO: Waiting up to 5m0s for pod "downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-mr5r4" to be "success or failure"
Jan 21 08:46:40.381: INFO: Pod "downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.480073ms
Jan 21 08:46:42.383: INFO: Pod "downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004733174s
STEP: Saw pod success
Jan 21 08:46:42.383: INFO: Pod "downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:46:42.385: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 08:46:42.399: INFO: Waiting for pod downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:46:42.400: INFO: Pod downwardapi-volume-120e2782-1d59-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:46:42.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mr5r4" for this suite.
Jan 21 08:46:48.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:46:48.443: INFO: namespace: e2e-tests-projected-mr5r4, resource: bindings, ignored listing per whitelist
Jan 21 08:46:48.473: INFO: namespace e2e-tests-projected-mr5r4 deletion completed in 6.069766943s

• [SLOW TEST:8.153 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:46:48.473: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 21 08:46:48.535: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:48.535: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:48.535: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:48.537: INFO: Number of nodes with available pods: 0
Jan 21 08:46:48.537: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 08:46:49.540: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:49.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:49.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:49.543: INFO: Number of nodes with available pods: 0
Jan 21 08:46:49.543: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 08:46:50.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:50.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:50.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:50.543: INFO: Number of nodes with available pods: 0
Jan 21 08:46:50.543: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 08:46:51.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:51.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:51.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:51.543: INFO: Number of nodes with available pods: 0
Jan 21 08:46:51.543: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 08:46:52.540: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:52.540: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:52.540: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:52.543: INFO: Number of nodes with available pods: 1
Jan 21 08:46:52.543: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 08:46:53.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:53.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:53.541: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:53.543: INFO: Number of nodes with available pods: 3
Jan 21 08:46:53.543: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 21 08:46:53.555: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:53.555: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:53.555: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:53.557: INFO: Number of nodes with available pods: 2
Jan 21 08:46:53.557: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:46:54.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:54.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:54.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:54.566: INFO: Number of nodes with available pods: 2
Jan 21 08:46:54.566: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:46:55.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:55.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:55.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:55.563: INFO: Number of nodes with available pods: 2
Jan 21 08:46:55.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:46:56.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:56.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:56.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:56.563: INFO: Number of nodes with available pods: 2
Jan 21 08:46:56.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:46:57.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:57.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:57.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:57.563: INFO: Number of nodes with available pods: 2
Jan 21 08:46:57.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:46:58.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:58.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:58.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:58.563: INFO: Number of nodes with available pods: 2
Jan 21 08:46:58.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:46:59.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:59.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:59.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:46:59.563: INFO: Number of nodes with available pods: 2
Jan 21 08:46:59.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:00.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:00.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:00.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:00.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:00.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:01.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:01.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:01.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:01.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:01.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:02.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:02.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:02.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:02.562: INFO: Number of nodes with available pods: 2
Jan 21 08:47:02.562: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:03.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:03.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:03.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:03.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:03.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:04.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:04.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:04.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:04.562: INFO: Number of nodes with available pods: 2
Jan 21 08:47:04.562: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:05.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:05.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:05.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:05.566: INFO: Number of nodes with available pods: 2
Jan 21 08:47:05.566: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:06.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:06.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:06.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:06.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:06.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:07.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:07.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:07.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:07.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:07.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:08.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:08.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:08.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:08.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:08.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:09.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:09.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:09.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:09.564: INFO: Number of nodes with available pods: 2
Jan 21 08:47:09.564: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:10.562: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:10.562: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:10.562: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:10.564: INFO: Number of nodes with available pods: 2
Jan 21 08:47:10.564: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:11.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:11.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:11.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:11.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:11.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:12.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:12.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:12.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:12.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:12.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:13.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:13.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:13.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:13.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:13.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:14.562: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:14.562: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:14.562: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:14.564: INFO: Number of nodes with available pods: 2
Jan 21 08:47:14.564: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:15.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:15.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:15.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:15.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:15.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:16.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:16.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:16.564: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:16.566: INFO: Number of nodes with available pods: 2
Jan 21 08:47:16.566: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:17.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:17.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:17.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:17.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:17.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:18.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:18.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:18.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:18.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:18.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:19.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:19.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:19.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:19.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:19.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:20.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:20.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:20.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:20.562: INFO: Number of nodes with available pods: 2
Jan 21 08:47:20.562: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:21.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:21.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:21.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:21.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:21.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:22.563: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:22.563: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:22.563: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:22.568: INFO: Number of nodes with available pods: 2
Jan 21 08:47:22.568: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:23.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:23.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:23.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:23.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:23.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:24.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:24.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:24.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:24.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:24.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:25.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:25.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:25.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:25.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:25.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:26.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:26.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:26.560: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:26.563: INFO: Number of nodes with available pods: 2
Jan 21 08:47:26.563: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:27.565: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:27.565: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:27.565: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:27.567: INFO: Number of nodes with available pods: 2
Jan 21 08:47:27.567: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 08:47:28.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:28.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:28.561: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 08:47:28.566: INFO: Number of nodes with available pods: 3
Jan 21 08:47:28.566: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-g544l, will wait for the garbage collector to delete the pods
Jan 21 08:47:28.652: INFO: Deleting {extensions DaemonSet} daemon-set took: 30.268622ms
Jan 21 08:47:28.753: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.181097ms
Jan 21 08:48:10.559: INFO: Number of nodes with available pods: 0
Jan 21 08:48:10.559: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 08:48:10.562: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-g544l/daemonsets","resourceVersion":"7231"},"items":null}

Jan 21 08:48:10.564: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-g544l/pods","resourceVersion":"7231"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:48:10.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-g544l" for this suite.
Jan 21 08:48:16.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:48:16.601: INFO: namespace: e2e-tests-daemonsets-g544l, resource: bindings, ignored listing per whitelist
Jan 21 08:48:16.646: INFO: namespace e2e-tests-daemonsets-g544l deletion completed in 6.070273151s

• [SLOW TEST:88.173 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:48:16.646: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4b77e8f4-1d59-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 08:48:16.705: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-9q54h" to be "success or failure"
Jan 21 08:48:16.707: INFO: Pod "pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.724429ms
Jan 21 08:48:18.709: INFO: Pod "pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004245167s
Jan 21 08:48:20.716: INFO: Pod "pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010746118s
STEP: Saw pod success
Jan 21 08:48:20.716: INFO: Pod "pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:48:20.717: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 08:48:20.741: INFO: Waiting for pod pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:48:20.743: INFO: Pod pod-projected-configmaps-4b788b4a-1d59-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:48:20.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9q54h" for this suite.
Jan 21 08:48:26.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:48:26.763: INFO: namespace: e2e-tests-projected-9q54h, resource: bindings, ignored listing per whitelist
Jan 21 08:48:26.816: INFO: namespace e2e-tests-projected-9q54h deletion completed in 6.070090683s

• [SLOW TEST:10.170 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:48:26.816: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 08:48:26.876: INFO: Waiting up to 5m0s for pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-sx74g" to be "success or failure"
Jan 21 08:48:26.877: INFO: Pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.575286ms
Jan 21 08:48:28.880: INFO: Pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004328531s
Jan 21 08:48:30.887: INFO: Pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010998492s
Jan 21 08:48:32.889: INFO: Pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013570892s
Jan 21 08:48:34.892: INFO: Pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016150365s
STEP: Saw pod success
Jan 21 08:48:34.892: INFO: Pod "downward-api-51885c93-1d59-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:48:34.894: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downward-api-51885c93-1d59-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 08:48:34.908: INFO: Waiting for pod downward-api-51885c93-1d59-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:48:34.910: INFO: Pod downward-api-51885c93-1d59-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:48:34.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sx74g" for this suite.
Jan 21 08:48:40.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:48:40.552: INFO: namespace: e2e-tests-downward-api-sx74g, resource: bindings, ignored listing per whitelist
Jan 21 08:48:40.557: INFO: namespace e2e-tests-downward-api-sx74g deletion completed in 6.076075867s

• [SLOW TEST:14.173 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:48:40.557: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-c8fvr
Jan 21 08:48:44.620: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-c8fvr
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 08:48:44.622: INFO: Initial restart count of pod liveness-http is 0
Jan 21 08:49:06.659: INFO: Restart count of pod e2e-tests-container-probe-c8fvr/liveness-http is now 1 (22.03656322s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:49:06.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c8fvr" for this suite.
Jan 21 08:49:12.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:49:12.726: INFO: namespace: e2e-tests-container-probe-c8fvr, resource: bindings, ignored listing per whitelist
Jan 21 08:49:12.746: INFO: namespace e2e-tests-container-probe-c8fvr deletion completed in 6.07489411s

• [SLOW TEST:32.189 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:49:12.746: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 21 08:49:16.816: INFO: Pod pod-hostip-6ce86fbb-1d59-11e9-9c91-0a58ac100282 has hostIP: 192.168.0.78
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:49:16.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7bpcb" for this suite.
Jan 21 08:49:38.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:49:38.835: INFO: namespace: e2e-tests-pods-7bpcb, resource: bindings, ignored listing per whitelist
Jan 21 08:49:38.888: INFO: namespace e2e-tests-pods-7bpcb deletion completed in 22.069847837s

• [SLOW TEST:26.142 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:49:38.888: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 08:49:38.946: INFO: (0) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 3.953708ms)
Jan 21 08:49:38.948: INFO: (1) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.472997ms)
Jan 21 08:49:38.951: INFO: (2) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.403796ms)
Jan 21 08:49:38.953: INFO: (3) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.467242ms)
Jan 21 08:49:38.955: INFO: (4) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.409737ms)
Jan 21 08:49:38.958: INFO: (5) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.319171ms)
Jan 21 08:49:38.960: INFO: (6) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.588967ms)
Jan 21 08:49:38.963: INFO: (7) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.432462ms)
Jan 21 08:49:38.965: INFO: (8) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.366913ms)
Jan 21 08:49:38.968: INFO: (9) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.376992ms)
Jan 21 08:49:38.970: INFO: (10) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.519139ms)
Jan 21 08:49:38.973: INFO: (11) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.386711ms)
Jan 21 08:49:38.975: INFO: (12) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.502005ms)
Jan 21 08:49:38.978: INFO: (13) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.499222ms)
Jan 21 08:49:38.980: INFO: (14) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.470253ms)
Jan 21 08:49:38.982: INFO: (15) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.349363ms)
Jan 21 08:49:38.985: INFO: (16) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.487225ms)
Jan 21 08:49:38.987: INFO: (17) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.364448ms)
Jan 21 08:49:38.990: INFO: (18) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.292164ms)
Jan 21 08:49:38.992: INFO: (19) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.439009ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:49:38.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nbcq9" for this suite.
Jan 21 08:49:45.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:49:45.047: INFO: namespace: e2e-tests-proxy-nbcq9, resource: bindings, ignored listing per whitelist
Jan 21 08:49:45.070: INFO: namespace e2e-tests-proxy-nbcq9 deletion completed in 6.075431626s

• [SLOW TEST:6.182 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:49:45.070: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pk7r5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 08:49:45.116: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 08:50:05.177: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.2.139:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-pk7r5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 08:50:05.177: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:50:05.352: INFO: Found all expected endpoints: [netserver-0]
Jan 21 08:50:05.354: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.2.14:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-pk7r5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 08:50:05.354: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:50:05.560: INFO: Found all expected endpoints: [netserver-1]
Jan 21 08:50:05.562: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.16.1.140:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-pk7r5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 08:50:05.562: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:50:05.780: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:50:05.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pk7r5" for this suite.
Jan 21 08:50:27.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:50:27.838: INFO: namespace: e2e-tests-pod-network-test-pk7r5, resource: bindings, ignored listing per whitelist
Jan 21 08:50:27.858: INFO: namespace e2e-tests-pod-network-test-pk7r5 deletion completed in 22.074006319s

• [SLOW TEST:42.787 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:50:27.858: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 21 08:50:27.920: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 21 08:50:27.926: INFO: Waiting for terminating namespaces to be deleted...
Jan 21 08:50:27.928: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuht before test
Jan 21 08:50:27.932: INFO: kube-proxy-worker-wtj4k from kube-system started at 2019-01-21 08:17:30 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.932: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 08:50:27.932: INFO: flexvolume-4lfmg from kube-system started at 2019-01-21 08:17:41 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.932: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 08:50:27.932: INFO: sonobuoy-e2e-job-0b58519d2e6c4c07 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.932: INFO: 	Container e2e ready: true, restart count 0
Jan 21 08:50:27.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 08:50:27.932: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-spkt6 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.932: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 08:50:27.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 08:50:27.932: INFO: kube-flannel-ds-g8c6v from kube-system started at 2019-01-21 08:17:30 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.932: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 08:50:27.932: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 21 08:50:27.932: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuhu before test
Jan 21 08:50:27.945: INFO: kube-proxy-worker-86qb8 from kube-system started at 2019-01-21 08:17:28 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 08:50:27.945: INFO: kube-flannel-ds-xxrn6 from kube-system started at 2019-01-21 08:17:28 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 08:50:27.945: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 21 08:50:27.945: INFO: flexvolume-wt6rj from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 08:50:27.945: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-7hhtj from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 08:50:27.945: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 08:50:27.945: INFO: metrics-server-54856586f-wnrsd from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container metrics-server ready: true, restart count 0
Jan 21 08:50:27.945: INFO: nginx-ingress-controller-645744f998-r4xfz from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 21 08:50:27.945: INFO: aliyun-acr-credential-helper-858f46c86d-5n5xg from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container aliyun-acr-credential-helper ready: true, restart count 0
Jan 21 08:50:27.945: INFO: tiller-deploy-57b7c996bc-svpwx from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container tiller ready: true, restart count 0
Jan 21 08:50:27.945: INFO: nginx-ingress-controller-645744f998-8z6m6 from kube-system started at 2019-01-21 08:17:40 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.945: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 21 08:50:27.945: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuhv before test
Jan 21 08:50:27.949: INFO: kube-flannel-ds-cgv55 from kube-system started at 2019-01-21 08:17:29 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.949: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 08:50:27.949: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 21 08:50:27.949: INFO: kube-proxy-worker-gq8p6 from kube-system started at 2019-01-21 08:17:29 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.949: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 08:50:27.949: INFO: flexvolume-59z5z from kube-system started at 2019-01-21 08:17:40 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.949: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 08:50:27.949: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-21 08:45:02 +0000 UTC (1 container statuses recorded)
Jan 21 08:50:27.949: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 21 08:50:27.949: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-6zr44 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 08:50:27.949: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 08:50:27.949: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9c1954a8-1d59-11e9-9c91-0a58ac100282 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9c1954a8-1d59-11e9-9c91-0a58ac100282 off the node cn-hongkong.i-j6c44erhl7eu2z5nuuht
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9c1954a8-1d59-11e9-9c91-0a58ac100282
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:50:34.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jqwj5" for this suite.
Jan 21 08:50:42.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:50:42.035: INFO: namespace: e2e-tests-sched-pred-jqwj5, resource: bindings, ignored listing per whitelist
Jan 21 08:50:42.077: INFO: namespace e2e-tests-sched-pred-jqwj5 deletion completed in 8.070760887s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:14.219 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:50:42.077: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0121 08:50:43.171952      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 08:50:43.171: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:50:43.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2g6nc" for this suite.
Jan 21 08:50:49.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:50:49.226: INFO: namespace: e2e-tests-gc-2g6nc, resource: bindings, ignored listing per whitelist
Jan 21 08:50:49.249: INFO: namespace e2e-tests-gc-2g6nc deletion completed in 6.074621348s

• [SLOW TEST:7.172 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:50:49.249: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 21 08:50:49.301: INFO: Waiting up to 5m0s for pod "var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282" in namespace "e2e-tests-var-expansion-c78bf" to be "success or failure"
Jan 21 08:50:49.303: INFO: Pod "var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.646865ms
Jan 21 08:50:51.305: INFO: Pod "var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004134207s
STEP: Saw pod success
Jan 21 08:50:51.305: INFO: Pod "var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:50:51.307: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 08:50:51.321: INFO: Waiting for pod var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:50:51.323: INFO: Pod var-expansion-a66cd02b-1d59-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:50:51.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-c78bf" for this suite.
Jan 21 08:50:57.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:50:57.351: INFO: namespace: e2e-tests-var-expansion-c78bf, resource: bindings, ignored listing per whitelist
Jan 21 08:50:57.400: INFO: namespace e2e-tests-var-expansion-c78bf deletion completed in 6.074551082s

• [SLOW TEST:8.151 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:50:57.400: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-flp6g
Jan 21 08:51:03.469: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-flp6g
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 08:51:03.471: INFO: Initial restart count of pod liveness-exec is 0
Jan 21 08:51:53.556: INFO: Restart count of pod e2e-tests-container-probe-flp6g/liveness-exec is now 1 (50.084701754s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:51:53.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-flp6g" for this suite.
Jan 21 08:51:59.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:51:59.590: INFO: namespace: e2e-tests-container-probe-flp6g, resource: bindings, ignored listing per whitelist
Jan 21 08:51:59.637: INFO: namespace e2e-tests-container-probe-flp6g deletion completed in 6.071686065s

• [SLOW TEST:62.237 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:51:59.637: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 08:51:59.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gd5d5'
Jan 21 08:51:59.953: INFO: stderr: ""
Jan 21 08:51:59.953: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 21 08:52:05.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gd5d5 -o json'
Jan 21 08:52:05.088: INFO: stderr: ""
Jan 21 08:52:05.088: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-21T08:51:59Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-gd5d5\",\n        \"resourceVersion\": \"8233\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-gd5d5/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d0885f2c-1d59-11e9-9352-00163e04cddc\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zv8dg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"cn-hongkong.i-j6c44erhl7eu2z5nuuht\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zv8dg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zv8dg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T08:51:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T08:52:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T08:52:01Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T08:51:59Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f32da9e9df557aed2c0d9c210fa34d6d66adf61464bd55cad10880fa7b1eb470\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-21T08:52:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.0.76\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.2.145\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-21T08:51:59Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 21 08:52:05.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 replace -f - --namespace=e2e-tests-kubectl-gd5d5'
Jan 21 08:52:05.284: INFO: stderr: ""
Jan 21 08:52:05.284: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan 21 08:52:05.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gd5d5'
Jan 21 08:52:12.205: INFO: stderr: ""
Jan 21 08:52:12.205: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:52:12.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gd5d5" for this suite.
Jan 21 08:52:18.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:52:18.274: INFO: namespace: e2e-tests-kubectl-gd5d5, resource: bindings, ignored listing per whitelist
Jan 21 08:52:18.282: INFO: namespace e2e-tests-kubectl-gd5d5 deletion completed in 6.070468267s

• [SLOW TEST:18.645 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:52:18.282: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 08:52:18.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-d9xnp'
Jan 21 08:52:18.424: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 08:52:18.424: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 21 08:52:18.428: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 21 08:52:18.430: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 21 08:52:18.437: INFO: scanned /root for discovery docs: <nil>
Jan 21 08:52:18.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-d9xnp'
Jan 21 08:52:34.208: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 21 08:52:34.208: INFO: stdout: "Created e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271\nScaling up e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 21 08:52:34.208: INFO: stdout: "Created e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271\nScaling up e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 21 08:52:34.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d9xnp'
Jan 21 08:52:34.288: INFO: stderr: ""
Jan 21 08:52:34.288: INFO: stdout: "e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271-fx68q "
Jan 21 08:52:34.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271-fx68q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d9xnp'
Jan 21 08:52:34.363: INFO: stderr: ""
Jan 21 08:52:34.363: INFO: stdout: "true"
Jan 21 08:52:34.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271-fx68q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d9xnp'
Jan 21 08:52:34.441: INFO: stderr: ""
Jan 21 08:52:34.441: INFO: stdout: "nginx:1.14-alpine"
Jan 21 08:52:34.441: INFO: e2e-test-nginx-rc-8d62396d2c777031dd6dc85b89535271-fx68q is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan 21 08:52:34.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d9xnp'
Jan 21 08:52:34.524: INFO: stderr: ""
Jan 21 08:52:34.524: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:52:34.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d9xnp" for this suite.
Jan 21 08:52:40.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:52:40.596: INFO: namespace: e2e-tests-kubectl-d9xnp, resource: bindings, ignored listing per whitelist
Jan 21 08:52:40.626: INFO: namespace e2e-tests-kubectl-d9xnp deletion completed in 6.098632826s

• [SLOW TEST:22.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:52:40.626: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 08:52:40.681: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 21 08:52:40.688: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 21 08:52:45.695: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 21 08:52:45.695: INFO: Creating deployment "test-rolling-update-deployment"
Jan 21 08:52:45.699: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 21 08:52:45.703: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 21 08:52:47.708: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 21 08:52:47.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 08:52:49.713: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683657565, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 08:52:51.713: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 08:52:51.719: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-njllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-njllp/deployments/test-rolling-update-deployment,UID:ebcd08b6-1d59-11e9-8ca7-00163e00ea4b,ResourceVersion:8510,Generation:1,CreationTimestamp:2019-01-21 08:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-21 08:52:45 +0000 UTC 2019-01-21 08:52:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-21 08:52:49 +0000 UTC 2019-01-21 08:52:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 21 08:52:51.722: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-njllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-njllp/replicasets/test-rolling-update-deployment-65b7695dcf,UID:ebd0924e-1d59-11e9-9352-00163e04cddc,ResourceVersion:8501,Generation:1,CreationTimestamp:2019-01-21 08:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ebcd08b6-1d59-11e9-8ca7-00163e00ea4b 0xc421f952b7 0xc421f952b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 21 08:52:51.722: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 21 08:52:51.722: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-njllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-njllp/replicasets/test-rolling-update-controller,UID:e8cfebbc-1d59-11e9-8ca7-00163e00ea4b,ResourceVersion:8509,Generation:2,CreationTimestamp:2019-01-21 08:52:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ebcd08b6-1d59-11e9-8ca7-00163e00ea4b 0xc421f95207 0xc421f95208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 08:52:51.724: INFO: Pod "test-rolling-update-deployment-65b7695dcf-7wfcp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-7wfcp,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-njllp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-njllp/pods/test-rolling-update-deployment-65b7695dcf-7wfcp,UID:ebd1205a-1d59-11e9-9352-00163e04cddc,ResourceVersion:8500,Generation:0,CreationTimestamp:2019-01-21 08:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf ebd0924e-1d59-11e9-9352-00163e04cddc 0xc42248e0f7 0xc42248e0f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7kl5p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7kl5p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7kl5p true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42248e160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42248e180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:52:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:52:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:52:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:52:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:172.16.2.19,StartTime:2019-01-21 08:52:45 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-21 08:52:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://7149f77198724b04687cd48861e4d31f8939b13065e52107b02dec0d632a3b4b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:52:51.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-njllp" for this suite.
Jan 21 08:52:57.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:52:57.773: INFO: namespace: e2e-tests-deployment-njllp, resource: bindings, ignored listing per whitelist
Jan 21 08:52:57.802: INFO: namespace e2e-tests-deployment-njllp deletion completed in 6.075008123s

• [SLOW TEST:17.176 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:52:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:53:57.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p8fn2" for this suite.
Jan 21 08:54:19.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:54:19.901: INFO: namespace: e2e-tests-container-probe-p8fn2, resource: bindings, ignored listing per whitelist
Jan 21 08:54:19.954: INFO: namespace e2e-tests-container-probe-p8fn2 deletion completed in 22.080873552s

• [SLOW TEST:82.152 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:54:19.954: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 21 08:54:20.063: INFO: Waiting up to 5m0s for pod "pod-240c387a-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-nbb8m" to be "success or failure"
Jan 21 08:54:20.065: INFO: Pod "pod-240c387a-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.65503ms
Jan 21 08:54:22.067: INFO: Pod "pod-240c387a-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004120903s
STEP: Saw pod success
Jan 21 08:54:22.067: INFO: Pod "pod-240c387a-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:54:22.069: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-240c387a-1d5a-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 08:54:22.086: INFO: Waiting for pod pod-240c387a-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:54:22.088: INFO: Pod pod-240c387a-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:54:22.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nbb8m" for this suite.
Jan 21 08:54:28.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:54:28.123: INFO: namespace: e2e-tests-emptydir-nbb8m, resource: bindings, ignored listing per whitelist
Jan 21 08:54:28.165: INFO: namespace e2e-tests-emptydir-nbb8m deletion completed in 6.074655607s

• [SLOW TEST:8.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:54:28.165: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-28e94ec5-1d5a-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 08:54:28.225: INFO: Waiting up to 5m0s for pod "pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-nbgkb" to be "success or failure"
Jan 21 08:54:28.227: INFO: Pod "pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.678737ms
Jan 21 08:54:30.233: INFO: Pod "pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008102532s
Jan 21 08:54:32.236: INFO: Pod "pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010855887s
STEP: Saw pod success
Jan 21 08:54:32.236: INFO: Pod "pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:54:32.238: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 08:54:32.252: INFO: Waiting for pod pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:54:32.254: INFO: Pod pod-configmaps-28ea34da-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:54:32.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nbgkb" for this suite.
Jan 21 08:54:38.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:54:38.316: INFO: namespace: e2e-tests-configmap-nbgkb, resource: bindings, ignored listing per whitelist
Jan 21 08:54:38.328: INFO: namespace e2e-tests-configmap-nbgkb deletion completed in 6.070784078s

• [SLOW TEST:10.163 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:54:38.328: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 21 08:54:38.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:38.556: INFO: stderr: ""
Jan 21 08:54:38.556: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 08:54:38.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:38.639: INFO: stderr: ""
Jan 21 08:54:38.639: INFO: stdout: "update-demo-nautilus-cfwrc update-demo-nautilus-gjpmh "
Jan 21 08:54:38.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-cfwrc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:38.711: INFO: stderr: ""
Jan 21 08:54:38.711: INFO: stdout: ""
Jan 21 08:54:38.711: INFO: update-demo-nautilus-cfwrc is created but not running
Jan 21 08:54:43.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:43.795: INFO: stderr: ""
Jan 21 08:54:43.795: INFO: stdout: "update-demo-nautilus-cfwrc update-demo-nautilus-gjpmh "
Jan 21 08:54:43.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-cfwrc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:43.869: INFO: stderr: ""
Jan 21 08:54:43.869: INFO: stdout: "true"
Jan 21 08:54:43.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-cfwrc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:43.944: INFO: stderr: ""
Jan 21 08:54:43.944: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:54:43.944: INFO: validating pod update-demo-nautilus-cfwrc
Jan 21 08:54:43.947: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:54:43.947: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:54:43.947: INFO: update-demo-nautilus-cfwrc is verified up and running
Jan 21 08:54:43.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-gjpmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:44.021: INFO: stderr: ""
Jan 21 08:54:44.021: INFO: stdout: "true"
Jan 21 08:54:44.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-gjpmh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:44.092: INFO: stderr: ""
Jan 21 08:54:44.092: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:54:44.092: INFO: validating pod update-demo-nautilus-gjpmh
Jan 21 08:54:44.096: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:54:44.096: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:54:44.096: INFO: update-demo-nautilus-gjpmh is verified up and running
STEP: using delete to clean up resources
Jan 21 08:54:44.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:44.176: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 08:54:44.176: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 21 08:54:44.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-ktkp6'
Jan 21 08:54:44.265: INFO: stderr: "No resources found.\n"
Jan 21 08:54:44.265: INFO: stdout: ""
Jan 21 08:54:44.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -l name=update-demo --namespace=e2e-tests-kubectl-ktkp6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 08:54:44.356: INFO: stderr: ""
Jan 21 08:54:44.356: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:54:44.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ktkp6" for this suite.
Jan 21 08:54:50.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:54:50.388: INFO: namespace: e2e-tests-kubectl-ktkp6, resource: bindings, ignored listing per whitelist
Jan 21 08:54:50.430: INFO: namespace e2e-tests-kubectl-ktkp6 deletion completed in 6.070922082s

• [SLOW TEST:12.102 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:54:50.430: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 21 08:54:50.498: INFO: Waiting up to 5m0s for pod "pod-36305836-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-j494b" to be "success or failure"
Jan 21 08:54:50.500: INFO: Pod "pod-36305836-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.735417ms
Jan 21 08:54:52.502: INFO: Pod "pod-36305836-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004276155s
STEP: Saw pod success
Jan 21 08:54:52.502: INFO: Pod "pod-36305836-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:54:52.504: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-36305836-1d5a-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 08:54:52.517: INFO: Waiting for pod pod-36305836-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:54:52.519: INFO: Pod pod-36305836-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:54:52.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j494b" for this suite.
Jan 21 08:54:58.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:54:58.587: INFO: namespace: e2e-tests-emptydir-j494b, resource: bindings, ignored listing per whitelist
Jan 21 08:54:58.593: INFO: namespace e2e-tests-emptydir-j494b deletion completed in 6.07147037s

• [SLOW TEST:8.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:54:58.593: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Jan 21 08:55:07.787: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:55:24.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-j8sjm" for this suite.
Jan 21 08:55:30.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:55:30.810: INFO: namespace: e2e-tests-namespaces-j8sjm, resource: bindings, ignored listing per whitelist
Jan 21 08:55:30.810: INFO: namespace e2e-tests-namespaces-j8sjm deletion completed in 6.070178078s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7tkmj" for this suite.
Jan 21 08:55:30.812: INFO: Namespace e2e-tests-nsdeletetest-7tkmj was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7p8mp" for this suite.
Jan 21 08:55:36.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:55:36.880: INFO: namespace: e2e-tests-nsdeletetest-7p8mp, resource: bindings, ignored listing per whitelist
Jan 21 08:55:36.885: INFO: namespace e2e-tests-nsdeletetest-7p8mp deletion completed in 6.072695662s

• [SLOW TEST:38.292 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:55:36.885: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 21 08:55:36.943: INFO: Waiting up to 5m0s for pod "pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-mn8rt" to be "success or failure"
Jan 21 08:55:36.945: INFO: Pod "pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.739964ms
Jan 21 08:55:38.947: INFO: Pod "pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004229386s
STEP: Saw pod success
Jan 21 08:55:38.947: INFO: Pod "pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:55:38.949: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 08:55:38.965: INFO: Waiting for pod pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:55:38.967: INFO: Pod pod-51df5ec3-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:55:38.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mn8rt" for this suite.
Jan 21 08:55:44.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:55:45.034: INFO: namespace: e2e-tests-emptydir-mn8rt, resource: bindings, ignored listing per whitelist
Jan 21 08:55:45.041: INFO: namespace e2e-tests-emptydir-mn8rt deletion completed in 6.071642614s

• [SLOW TEST:8.156 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:55:45.041: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zcgqv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 08:55:45.089: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 08:56:07.153: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.2.153 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zcgqv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 08:56:07.153: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:56:08.310: INFO: Found all expected endpoints: [netserver-0]
Jan 21 08:56:08.312: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.1.141 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zcgqv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 08:56:08.312: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:56:09.545: INFO: Found all expected endpoints: [netserver-1]
Jan 21 08:56:09.551: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.16.2.26 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zcgqv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 08:56:09.551: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 08:56:10.746: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:56:10.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zcgqv" for this suite.
Jan 21 08:56:32.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:56:32.815: INFO: namespace: e2e-tests-pod-network-test-zcgqv, resource: bindings, ignored listing per whitelist
Jan 21 08:56:32.834: INFO: namespace e2e-tests-pod-network-test-zcgqv deletion completed in 22.082759869s

• [SLOW TEST:47.793 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:56:32.835: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 08:56:32.896: INFO: Waiting up to 5m0s for pod "downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-qhjq6" to be "success or failure"
Jan 21 08:56:32.898: INFO: Pod "downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637377ms
Jan 21 08:56:34.901: INFO: Pod "downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004147799s
STEP: Saw pod success
Jan 21 08:56:34.901: INFO: Pod "downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:56:34.902: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 08:56:34.916: INFO: Waiting for pod downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:56:34.918: INFO: Pod downward-api-733940d1-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:56:34.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qhjq6" for this suite.
Jan 21 08:56:40.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:56:40.936: INFO: namespace: e2e-tests-downward-api-qhjq6, resource: bindings, ignored listing per whitelist
Jan 21 08:56:40.995: INFO: namespace e2e-tests-downward-api-qhjq6 deletion completed in 6.074186227s

• [SLOW TEST:8.161 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:56:40.995: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 21 08:56:41.062: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zjg5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-zjg5l/configmaps/e2e-watch-test-label-changed,UID:78151660-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9465,Generation:0,CreationTimestamp:2019-01-21 08:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 08:56:41.062: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zjg5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-zjg5l/configmaps/e2e-watch-test-label-changed,UID:78151660-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9466,Generation:0,CreationTimestamp:2019-01-21 08:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 21 08:56:41.062: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zjg5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-zjg5l/configmaps/e2e-watch-test-label-changed,UID:78151660-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9467,Generation:0,CreationTimestamp:2019-01-21 08:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 21 08:56:51.087: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zjg5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-zjg5l/configmaps/e2e-watch-test-label-changed,UID:78151660-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9495,Generation:0,CreationTimestamp:2019-01-21 08:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 08:56:51.087: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zjg5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-zjg5l/configmaps/e2e-watch-test-label-changed,UID:78151660-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9496,Generation:0,CreationTimestamp:2019-01-21 08:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 21 08:56:51.087: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zjg5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-zjg5l/configmaps/e2e-watch-test-label-changed,UID:78151660-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9497,Generation:0,CreationTimestamp:2019-01-21 08:56:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:56:51.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zjg5l" for this suite.
Jan 21 08:56:57.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:56:57.132: INFO: namespace: e2e-tests-watch-zjg5l, resource: bindings, ignored listing per whitelist
Jan 21 08:56:57.160: INFO: namespace e2e-tests-watch-zjg5l deletion completed in 6.070229091s

• [SLOW TEST:16.165 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:56:57.160: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 21 08:56:59.226: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-81b85c99-1d5a-11e9-9c91-0a58ac100282,GenerateName:,Namespace:e2e-tests-events-wgzf4,SelfLink:/api/v1/namespaces/e2e-tests-events-wgzf4/pods/send-events-81b85c99-1d5a-11e9-9c91-0a58ac100282,UID:81b7e86e-1d5a-11e9-8ca7-00163e00ea4b,ResourceVersion:9536,Generation:0,CreationTimestamp:2019-01-21 08:56:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 211617162,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2bk8q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2bk8q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-2bk8q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42117bf60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42117bf80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:56:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:56:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:56:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 08:56:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:172.16.2.28,StartTime:2019-01-21 08:56:57 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-21 08:56:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://21403697c0b0d7827ed8082e05a6fb5371d8c634e87841728bb7093a841b4d1b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 21 08:57:01.232: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 21 08:57:03.236: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:57:03.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-wgzf4" for this suite.
Jan 21 08:57:43.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:57:43.285: INFO: namespace: e2e-tests-events-wgzf4, resource: bindings, ignored listing per whitelist
Jan 21 08:57:43.314: INFO: namespace e2e-tests-events-wgzf4 deletion completed in 40.069750858s

• [SLOW TEST:46.154 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:57:43.314: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 08:57:43.397: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9d3cee17-1d5a-11e9-8ca7-00163e00ea4b", Controller:(*bool)(0xc42248f146), BlockOwnerDeletion:(*bool)(0xc42248f147)}}
Jan 21 08:57:43.413: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"9d3b7f95-1d5a-11e9-8ca7-00163e00ea4b", Controller:(*bool)(0xc422252a36), BlockOwnerDeletion:(*bool)(0xc422252a37)}}
Jan 21 08:57:43.418: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9d3c3b41-1d5a-11e9-8ca7-00163e00ea4b", Controller:(*bool)(0xc42254257e), BlockOwnerDeletion:(*bool)(0xc42254257f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:57:48.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-djbgd" for this suite.
Jan 21 08:57:54.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:57:54.497: INFO: namespace: e2e-tests-gc-djbgd, resource: bindings, ignored listing per whitelist
Jan 21 08:57:54.503: INFO: namespace e2e-tests-gc-djbgd deletion completed in 6.069310752s

• [SLOW TEST:11.189 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:57:54.503: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-a3e94a67-1d5a-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 08:57:54.586: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-f4g6n" to be "success or failure"
Jan 21 08:57:54.588: INFO: Pod "pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.763893ms
Jan 21 08:57:56.590: INFO: Pod "pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004065276s
STEP: Saw pod success
Jan 21 08:57:56.590: INFO: Pod "pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:57:56.592: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 08:57:56.606: INFO: Waiting for pod pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:57:56.608: INFO: Pod pod-projected-secrets-a3ea33b8-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:57:56.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f4g6n" for this suite.
Jan 21 08:58:02.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:58:02.642: INFO: namespace: e2e-tests-projected-f4g6n, resource: bindings, ignored listing per whitelist
Jan 21 08:58:02.692: INFO: namespace e2e-tests-projected-f4g6n deletion completed in 6.081703955s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:58:02.692: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 21 08:58:06.778: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:06.780: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:08.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:08.786: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:10.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:10.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:12.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:12.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:14.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:14.783: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:16.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:16.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:18.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:18.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:20.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:20.787: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:22.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:22.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:24.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:24.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:26.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:26.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:28.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:28.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:30.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:30.782: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 08:58:32.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 08:58:32.786: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:58:32.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fw8zt" for this suite.
Jan 21 08:58:54.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:58:54.836: INFO: namespace: e2e-tests-container-lifecycle-hook-fw8zt, resource: bindings, ignored listing per whitelist
Jan 21 08:58:54.868: INFO: namespace e2e-tests-container-lifecycle-hook-fw8zt deletion completed in 22.078753418s

• [SLOW TEST:52.175 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:58:54.868: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 21 08:58:54.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:58:55.098: INFO: stderr: ""
Jan 21 08:58:55.098: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 08:58:55.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:58:55.182: INFO: stderr: ""
Jan 21 08:58:55.182: INFO: stdout: "update-demo-nautilus-5s29g update-demo-nautilus-7qql8 "
Jan 21 08:58:55.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:58:55.261: INFO: stderr: ""
Jan 21 08:58:55.261: INFO: stdout: ""
Jan 21 08:58:55.261: INFO: update-demo-nautilus-5s29g is created but not running
Jan 21 08:59:00.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:00.340: INFO: stderr: ""
Jan 21 08:59:00.340: INFO: stdout: "update-demo-nautilus-5s29g update-demo-nautilus-7qql8 "
Jan 21 08:59:00.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:00.418: INFO: stderr: ""
Jan 21 08:59:00.418: INFO: stdout: "true"
Jan 21 08:59:00.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:00.496: INFO: stderr: ""
Jan 21 08:59:00.496: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:59:00.496: INFO: validating pod update-demo-nautilus-5s29g
Jan 21 08:59:00.499: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:59:00.499: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:59:00.499: INFO: update-demo-nautilus-5s29g is verified up and running
Jan 21 08:59:00.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-7qql8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:00.573: INFO: stderr: ""
Jan 21 08:59:00.573: INFO: stdout: "true"
Jan 21 08:59:00.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-7qql8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:00.647: INFO: stderr: ""
Jan 21 08:59:00.647: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:59:00.647: INFO: validating pod update-demo-nautilus-7qql8
Jan 21 08:59:00.650: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:59:00.650: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:59:00.650: INFO: update-demo-nautilus-7qql8 is verified up and running
STEP: scaling down the replication controller
Jan 21 08:59:00.651: INFO: scanned /root for discovery docs: <nil>
Jan 21 08:59:00.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:01.747: INFO: stderr: ""
Jan 21 08:59:01.747: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 08:59:01.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:01.826: INFO: stderr: ""
Jan 21 08:59:01.826: INFO: stdout: "update-demo-nautilus-5s29g update-demo-nautilus-7qql8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 21 08:59:06.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:06.908: INFO: stderr: ""
Jan 21 08:59:06.908: INFO: stdout: "update-demo-nautilus-5s29g "
Jan 21 08:59:06.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:06.983: INFO: stderr: ""
Jan 21 08:59:06.983: INFO: stdout: "true"
Jan 21 08:59:06.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:07.059: INFO: stderr: ""
Jan 21 08:59:07.059: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:59:07.059: INFO: validating pod update-demo-nautilus-5s29g
Jan 21 08:59:07.065: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:59:07.065: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:59:07.065: INFO: update-demo-nautilus-5s29g is verified up and running
STEP: scaling up the replication controller
Jan 21 08:59:07.066: INFO: scanned /root for discovery docs: <nil>
Jan 21 08:59:07.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:08.163: INFO: stderr: ""
Jan 21 08:59:08.163: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 08:59:08.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:08.242: INFO: stderr: ""
Jan 21 08:59:08.242: INFO: stdout: "update-demo-nautilus-5s29g update-demo-nautilus-x4j7g "
Jan 21 08:59:08.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:08.315: INFO: stderr: ""
Jan 21 08:59:08.315: INFO: stdout: "true"
Jan 21 08:59:08.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:08.389: INFO: stderr: ""
Jan 21 08:59:08.389: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:59:08.389: INFO: validating pod update-demo-nautilus-5s29g
Jan 21 08:59:08.391: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:59:08.391: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:59:08.391: INFO: update-demo-nautilus-5s29g is verified up and running
Jan 21 08:59:08.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-x4j7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:08.464: INFO: stderr: ""
Jan 21 08:59:08.464: INFO: stdout: ""
Jan 21 08:59:08.464: INFO: update-demo-nautilus-x4j7g is created but not running
Jan 21 08:59:13.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:13.551: INFO: stderr: ""
Jan 21 08:59:13.551: INFO: stdout: "update-demo-nautilus-5s29g update-demo-nautilus-x4j7g "
Jan 21 08:59:13.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:13.627: INFO: stderr: ""
Jan 21 08:59:13.627: INFO: stdout: "true"
Jan 21 08:59:13.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-5s29g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:13.702: INFO: stderr: ""
Jan 21 08:59:13.702: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:59:13.702: INFO: validating pod update-demo-nautilus-5s29g
Jan 21 08:59:13.705: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:59:13.705: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:59:13.705: INFO: update-demo-nautilus-5s29g is verified up and running
Jan 21 08:59:13.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-x4j7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:13.779: INFO: stderr: ""
Jan 21 08:59:13.779: INFO: stdout: "true"
Jan 21 08:59:13.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-x4j7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:13.854: INFO: stderr: ""
Jan 21 08:59:13.854: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 08:59:13.854: INFO: validating pod update-demo-nautilus-x4j7g
Jan 21 08:59:13.857: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 08:59:13.857: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 08:59:13.857: INFO: update-demo-nautilus-x4j7g is verified up and running
STEP: using delete to clean up resources
Jan 21 08:59:13.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:13.935: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 08:59:13.935: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 21 08:59:13.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-cnswc'
Jan 21 08:59:14.024: INFO: stderr: "No resources found.\n"
Jan 21 08:59:14.024: INFO: stdout: ""
Jan 21 08:59:14.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -l name=update-demo --namespace=e2e-tests-kubectl-cnswc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 08:59:14.112: INFO: stderr: ""
Jan 21 08:59:14.112: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:59:14.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cnswc" for this suite.
Jan 21 08:59:36.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:59:36.137: INFO: namespace: e2e-tests-kubectl-cnswc, resource: bindings, ignored listing per whitelist
Jan 21 08:59:36.185: INFO: namespace e2e-tests-kubectl-cnswc deletion completed in 22.069837054s

• [SLOW TEST:41.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:59:36.185: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e0821b37-1d5a-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 08:59:36.249: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-5glbs" to be "success or failure"
Jan 21 08:59:36.251: INFO: Pod "pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.860512ms
Jan 21 08:59:38.254: INFO: Pod "pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004390709s
STEP: Saw pod success
Jan 21 08:59:38.254: INFO: Pod "pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 08:59:38.256: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 08:59:38.279: INFO: Waiting for pod pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282 to disappear
Jan 21 08:59:38.281: INFO: Pod pod-projected-configmaps-e082d077-1d5a-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:59:38.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5glbs" for this suite.
Jan 21 08:59:44.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 08:59:44.306: INFO: namespace: e2e-tests-projected-5glbs, resource: bindings, ignored listing per whitelist
Jan 21 08:59:44.354: INFO: namespace e2e-tests-projected-5glbs deletion completed in 6.069887674s

• [SLOW TEST:8.169 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 08:59:44.354: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 08:59:46.935: INFO: Successfully updated pod "labelsupdatee56026ec-1d5a-11e9-9c91-0a58ac100282"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 08:59:50.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qpt7q" for this suite.
Jan 21 09:00:12.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:00:13.019: INFO: namespace: e2e-tests-downward-api-qpt7q, resource: bindings, ignored listing per whitelist
Jan 21 09:00:13.041: INFO: namespace e2e-tests-downward-api-qpt7q deletion completed in 22.079457587s

• [SLOW TEST:28.688 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:00:13.042: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 21 09:00:19.117: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:19.117: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:19.283: INFO: Exec stderr: ""
Jan 21 09:00:19.283: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:19.283: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:19.479: INFO: Exec stderr: ""
Jan 21 09:00:19.480: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:19.480: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:19.659: INFO: Exec stderr: ""
Jan 21 09:00:19.659: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:19.659: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:19.868: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 21 09:00:19.868: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:19.868: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:20.054: INFO: Exec stderr: ""
Jan 21 09:00:20.054: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:20.054: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:20.236: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 21 09:00:20.236: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:20.236: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:20.400: INFO: Exec stderr: ""
Jan 21 09:00:20.400: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:20.400: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:20.603: INFO: Exec stderr: ""
Jan 21 09:00:20.603: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:20.603: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:20.791: INFO: Exec stderr: ""
Jan 21 09:00:20.791: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jr4t2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:00:20.791: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:00:20.997: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:00:20.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-jr4t2" for this suite.
Jan 21 09:00:59.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:00:59.052: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-jr4t2, resource: bindings, ignored listing per whitelist
Jan 21 09:00:59.073: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-jr4t2 deletion completed in 38.073065759s

• [SLOW TEST:46.032 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:00:59.074: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-11e97f68-1d5b-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:00:59.136: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-7bqk6" to be "success or failure"
Jan 21 09:00:59.137: INFO: Pod "pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.753612ms
Jan 21 09:01:01.140: INFO: Pod "pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004260564s
STEP: Saw pod success
Jan 21 09:01:01.140: INFO: Pod "pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:01:01.142: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:01:01.154: INFO: Waiting for pod pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:01:01.156: INFO: Pod pod-projected-secrets-11ea2919-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:01:01.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7bqk6" for this suite.
Jan 21 09:01:07.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:01:07.201: INFO: namespace: e2e-tests-projected-7bqk6, resource: bindings, ignored listing per whitelist
Jan 21 09:01:07.230: INFO: namespace e2e-tests-projected-7bqk6 deletion completed in 6.070855872s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:01:07.231: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 21 09:01:07.815: INFO: created pod pod-service-account-defaultsa
Jan 21 09:01:07.815: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 21 09:01:07.818: INFO: created pod pod-service-account-mountsa
Jan 21 09:01:07.818: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 21 09:01:07.822: INFO: created pod pod-service-account-nomountsa
Jan 21 09:01:07.822: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 21 09:01:07.827: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 21 09:01:07.827: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 21 09:01:07.831: INFO: created pod pod-service-account-mountsa-mountspec
Jan 21 09:01:07.831: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 21 09:01:07.836: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 21 09:01:07.836: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 21 09:01:07.840: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 21 09:01:07.840: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 21 09:01:07.846: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 21 09:01:07.846: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 21 09:01:07.852: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 21 09:01:07.852: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:01:07.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-trfqk" for this suite.
Jan 21 09:01:13.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:01:13.892: INFO: namespace: e2e-tests-svcaccounts-trfqk, resource: bindings, ignored listing per whitelist
Jan 21 09:01:13.929: INFO: namespace e2e-tests-svcaccounts-trfqk deletion completed in 6.0725655s

• [SLOW TEST:6.699 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:01:13.929: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:01:13.988: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-jdgkr" to be "success or failure"
Jan 21 09:01:13.990: INFO: Pod "downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.639533ms
Jan 21 09:01:15.993: INFO: Pod "downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004207821s
STEP: Saw pod success
Jan 21 09:01:15.993: INFO: Pod "downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:01:15.995: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:01:16.012: INFO: Waiting for pod downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:01:16.014: INFO: Pod downwardapi-volume-1ac45a14-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:01:16.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jdgkr" for this suite.
Jan 21 09:01:22.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:01:22.040: INFO: namespace: e2e-tests-projected-jdgkr, resource: bindings, ignored listing per whitelist
Jan 21 09:01:22.086: INFO: namespace e2e-tests-projected-jdgkr deletion completed in 6.068645115s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:01:22.086: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1fa02a0f-1d5b-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:01:22.144: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-6nkkc" to be "success or failure"
Jan 21 09:01:22.146: INFO: Pod "pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.75549ms
Jan 21 09:01:24.149: INFO: Pod "pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004322518s
STEP: Saw pod success
Jan 21 09:01:24.149: INFO: Pod "pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:01:24.151: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:01:24.165: INFO: Waiting for pod pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:01:24.167: INFO: Pod pod-projected-configmaps-1fa1476b-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:01:24.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6nkkc" for this suite.
Jan 21 09:01:30.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:01:30.235: INFO: namespace: e2e-tests-projected-6nkkc, resource: bindings, ignored listing per whitelist
Jan 21 09:01:30.243: INFO: namespace e2e-tests-projected-6nkkc deletion completed in 6.073027097s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:01:30.243: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:01:30.301: INFO: Waiting up to 5m0s for pod "downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-w9n64" to be "success or failure"
Jan 21 09:01:30.304: INFO: Pod "downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.375411ms
Jan 21 09:01:32.306: INFO: Pod "downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005101792s
STEP: Saw pod success
Jan 21 09:01:32.307: INFO: Pod "downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:01:32.309: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:01:32.323: INFO: Waiting for pod downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:01:32.324: INFO: Pod downwardapi-volume-247d7e88-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:01:32.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w9n64" for this suite.
Jan 21 09:01:38.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:01:38.367: INFO: namespace: e2e-tests-downward-api-w9n64, resource: bindings, ignored listing per whitelist
Jan 21 09:01:38.396: INFO: namespace e2e-tests-downward-api-w9n64 deletion completed in 6.069171181s

• [SLOW TEST:8.153 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:01:38.397: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-gpt2f
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-gpt2f
STEP: Deleting pre-stop pod
Jan 21 09:01:49.472: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:01:49.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-gpt2f" for this suite.
Jan 21 09:02:27.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:02:27.531: INFO: namespace: e2e-tests-prestop-gpt2f, resource: bindings, ignored listing per whitelist
Jan 21 09:02:27.569: INFO: namespace e2e-tests-prestop-gpt2f deletion completed in 38.088762857s

• [SLOW TEST:49.172 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:02:27.569: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 21 09:02:27.636: INFO: Waiting up to 5m0s for pod "pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-9z67z" to be "success or failure"
Jan 21 09:02:27.638: INFO: Pod "pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.661197ms
Jan 21 09:02:29.640: INFO: Pod "pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004153786s
Jan 21 09:02:31.643: INFO: Pod "pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006581051s
STEP: Saw pod success
Jan 21 09:02:31.643: INFO: Pod "pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:02:31.644: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:02:31.658: INFO: Waiting for pod pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:02:31.659: INFO: Pod pod-46a9f7f1-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:02:31.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9z67z" for this suite.
Jan 21 09:02:37.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:02:37.690: INFO: namespace: e2e-tests-emptydir-9z67z, resource: bindings, ignored listing per whitelist
Jan 21 09:02:37.740: INFO: namespace e2e-tests-emptydir-9z67z deletion completed in 6.076848905s

• [SLOW TEST:10.171 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:02:37.740: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4cb8cd87-1d5b-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:02:37.801: INFO: Waiting up to 5m0s for pod "pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-wp9xl" to be "success or failure"
Jan 21 09:02:37.803: INFO: Pod "pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.71927ms
Jan 21 09:02:39.805: INFO: Pod "pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003951589s
STEP: Saw pod success
Jan 21 09:02:39.805: INFO: Pod "pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:02:39.807: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:02:39.821: INFO: Waiting for pod pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:02:39.822: INFO: Pod pod-configmaps-4cb98b75-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:02:39.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wp9xl" for this suite.
Jan 21 09:02:45.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:02:45.849: INFO: namespace: e2e-tests-configmap-wp9xl, resource: bindings, ignored listing per whitelist
Jan 21 09:02:45.898: INFO: namespace e2e-tests-configmap-wp9xl deletion completed in 6.073113026s

• [SLOW TEST:8.158 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:02:45.898: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 21 09:02:49.974: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:02:49.976: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:02:51.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:02:51.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:02:53.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:02:53.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:02:55.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:02:55.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:02:57.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:02:57.982: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:02:59.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:02:59.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:03:01.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:03:01.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:03:03.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:03:03.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:03:05.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:03:05.978: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:03:07.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:03:07.979: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 09:03:09.976: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 09:03:09.982: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:03:09.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dtsvr" for this suite.
Jan 21 09:03:32.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:03:32.053: INFO: namespace: e2e-tests-container-lifecycle-hook-dtsvr, resource: bindings, ignored listing per whitelist
Jan 21 09:03:32.067: INFO: namespace e2e-tests-container-lifecycle-hook-dtsvr deletion completed in 22.074850666s

• [SLOW TEST:46.169 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:03:32.067: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:03:32.118: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:03:38.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-d7c9h" for this suite.
Jan 21 09:03:44.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:03:44.175: INFO: namespace: e2e-tests-custom-resource-definition-d7c9h, resource: bindings, ignored listing per whitelist
Jan 21 09:03:44.231: INFO: namespace e2e-tests-custom-resource-definition-d7c9h deletion completed in 6.071012533s

• [SLOW TEST:12.164 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:03:44.231: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 09:03:44.303: INFO: Waiting up to 5m0s for pod "downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-pkjtk" to be "success or failure"
Jan 21 09:03:44.305: INFO: Pod "downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.685379ms
Jan 21 09:03:46.307: INFO: Pod "downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004247472s
STEP: Saw pod success
Jan 21 09:03:46.307: INFO: Pod "downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:03:46.309: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 09:03:46.324: INFO: Waiting for pod downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:03:46.325: INFO: Pod downward-api-745cb2ee-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:03:46.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pkjtk" for this suite.
Jan 21 09:03:52.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:03:52.352: INFO: namespace: e2e-tests-downward-api-pkjtk, resource: bindings, ignored listing per whitelist
Jan 21 09:03:52.402: INFO: namespace e2e-tests-downward-api-pkjtk deletion completed in 6.073469637s

• [SLOW TEST:8.171 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:03:52.402: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zmtbl
Jan 21 09:03:54.466: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zmtbl
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 09:03:54.467: INFO: Initial restart count of pod liveness-http is 0
Jan 21 09:04:10.493: INFO: Restart count of pod e2e-tests-container-probe-zmtbl/liveness-http is now 1 (16.025367392s elapsed)
Jan 21 09:04:30.531: INFO: Restart count of pod e2e-tests-container-probe-zmtbl/liveness-http is now 2 (36.063235645s elapsed)
Jan 21 09:04:50.565: INFO: Restart count of pod e2e-tests-container-probe-zmtbl/liveness-http is now 3 (56.097403971s elapsed)
Jan 21 09:05:10.598: INFO: Restart count of pod e2e-tests-container-probe-zmtbl/liveness-http is now 4 (1m16.13050192s elapsed)
Jan 21 09:06:10.699: INFO: Restart count of pod e2e-tests-container-probe-zmtbl/liveness-http is now 5 (2m16.231251295s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:06:10.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zmtbl" for this suite.
Jan 21 09:06:16.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:06:16.725: INFO: namespace: e2e-tests-container-probe-zmtbl, resource: bindings, ignored listing per whitelist
Jan 21 09:06:16.783: INFO: namespace e2e-tests-container-probe-zmtbl deletion completed in 6.07350855s

• [SLOW TEST:144.381 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:06:16.783: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hzgfn
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-hzgfn
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-hzgfn
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-hzgfn
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-hzgfn
Jan 21 09:06:20.861: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-hzgfn, name: ss-0, uid: d15446c9-1d5b-11e9-9352-00163e04cddc, status phase: Failed. Waiting for statefulset controller to delete.
Jan 21 09:06:20.864: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-hzgfn
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-hzgfn
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-hzgfn and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 09:06:24.886: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hzgfn
Jan 21 09:06:24.888: INFO: Scaling statefulset ss to 0
Jan 21 09:06:34.904: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:06:34.906: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:06:34.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hzgfn" for this suite.
Jan 21 09:06:40.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:06:40.932: INFO: namespace: e2e-tests-statefulset-hzgfn, resource: bindings, ignored listing per whitelist
Jan 21 09:06:40.989: INFO: namespace e2e-tests-statefulset-hzgfn deletion completed in 6.07052144s

• [SLOW TEST:24.206 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:06:40.989: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ddb60d55-1d5b-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:06:41.063: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-dmt9v" to be "success or failure"
Jan 21 09:06:41.065: INFO: Pod "pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.755186ms
Jan 21 09:06:43.067: INFO: Pod "pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004035665s
STEP: Saw pod success
Jan 21 09:06:43.067: INFO: Pod "pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:06:43.069: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:06:43.083: INFO: Waiting for pod pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:06:43.084: INFO: Pod pod-projected-secrets-ddb81287-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:06:43.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dmt9v" for this suite.
Jan 21 09:06:49.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:06:49.135: INFO: namespace: e2e-tests-projected-dmt9v, resource: bindings, ignored listing per whitelist
Jan 21 09:06:49.161: INFO: namespace e2e-tests-projected-dmt9v deletion completed in 6.073697409s

• [SLOW TEST:8.171 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:06:49.161: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:06:49.209: INFO: Creating deployment "nginx-deployment"
Jan 21 09:06:49.214: INFO: Waiting for observed generation 1
Jan 21 09:06:51.219: INFO: Waiting for all required pods to come up
Jan 21 09:06:51.221: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 21 09:06:53.228: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 21 09:06:53.232: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 21 09:06:53.238: INFO: Updating deployment nginx-deployment
Jan 21 09:06:53.238: INFO: Waiting for observed generation 2
Jan 21 09:06:55.246: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 21 09:06:55.248: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 21 09:06:55.250: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 21 09:06:55.255: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 21 09:06:55.255: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 21 09:06:55.257: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 21 09:06:55.260: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 21 09:06:55.260: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 21 09:06:55.265: INFO: Updating deployment nginx-deployment
Jan 21 09:06:55.265: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 21 09:06:55.269: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 21 09:06:57.273: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 09:06:57.277: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gw2qq/deployments/nginx-deployment,UID:e293bf8e-1d5b-11e9-8ca7-00163e00ea4b,ResourceVersion:12205,Generation:3,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-01-21 09:06:55 +0000 UTC 2019-01-21 09:06:55 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-21 09:06:55 +0000 UTC 2019-01-21 09:06:49 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 21 09:06:57.280: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gw2qq/replicasets/nginx-deployment-7dc8f79789,UID:e4fb56b8-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12200,Generation:3,CreationTimestamp:2019-01-21 09:06:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e293bf8e-1d5b-11e9-8ca7-00163e00ea4b 0xc4213a4b07 0xc4213a4b08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 09:06:57.280: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 21 09:06:57.280: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gw2qq/replicasets/nginx-deployment-7f9675fb8b,UID:e295dcf8-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12196,Generation:3,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e293bf8e-1d5b-11e9-8ca7-00163e00ea4b 0xc4213a4c67 0xc4213a4c68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-58mgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-58mgk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-58mgk,UID:e4fcdc1e-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12086,Generation:0,CreationTimestamp:2019-01-21 09:06:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed0917 0xc420ed0918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed09f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed0a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-844zd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-844zd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-844zd,UID:e6364ab5-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12204,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed0ad0 0xc420ed0ad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed0bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed0bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-bmdsl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bmdsl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-bmdsl,UID:e507307b-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12112,Generation:0,CreationTimestamp:2019-01-21 09:06:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed0cb0 0xc420ed0cb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed0e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed0e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-hfhkt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hfhkt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-hfhkt,UID:e63284a3-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12179,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed0f40 0xc420ed0f41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed1080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed10a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-nffsj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nffsj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-nffsj,UID:e4fc1aa4-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12085,Generation:0,CreationTimestamp:2019-01-21 09:06:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed1160 0xc420ed1161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed11d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed11f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-p854b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-p854b,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-p854b,UID:e633f9ce-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12178,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed12b0 0xc420ed12b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed1320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed1340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.284: INFO: Pod "nginx-deployment-7dc8f79789-pftxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-pftxc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-pftxc,UID:e636690f-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12250,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed1400 0xc420ed1401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed1470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed1490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7dc8f79789-s7vp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s7vp9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-s7vp9,UID:e6365a75-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12215,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc420ed17b0 0xc420ed17b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420ed1820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420ed1840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7dc8f79789-sdqdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sdqdj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-sdqdj,UID:e4fce72f-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12091,Generation:0,CreationTimestamp:2019-01-21 09:06:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc4215321e0 0xc4215321e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421532270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7dc8f79789-vxplf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vxplf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-vxplf,UID:e639001d-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12249,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc4215324c0 0xc4215324c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215325b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215325d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7dc8f79789-w87zc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-w87zc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-w87zc,UID:e5080fb8-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12116,Generation:0,CreationTimestamp:2019-01-21 09:06:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc4215326e0 0xc4215326e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215327e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:53 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7dc8f79789-x76mf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-x76mf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-x76mf,UID:e6362656-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12214,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc4215328f0 0xc4215328f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421532960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7dc8f79789-zn8hn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zn8hn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7dc8f79789-zn8hn,UID:e63431da-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12203,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 e4fb56b8-1d5b-11e9-9352-00163e04cddc 0xc421532a60 0xc421532a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421532ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7f9675fb8b-25h6l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-25h6l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-25h6l,UID:e636a70c-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12238,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421532bb0 0xc421532bb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421532c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.285: INFO: Pod "nginx-deployment-7f9675fb8b-2g8zv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2g8zv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-2g8zv,UID:e29a285f-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12062,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421532d07 0xc421532d08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421532d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:172.16.1.145,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://ef06d96f5992bbe66fe1831f6592d530de4d5c21bf12627130bf6ae11d9623ce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-5hwfw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5hwfw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-5hwfw,UID:e6328294-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12158,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421532e57 0xc421532e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421532ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421532ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-65cn4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-65cn4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-65cn4,UID:e6342c98-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12193,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421532f97 0xc421532f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421533000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421533020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-9xx8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9xx8g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-9xx8g,UID:e6342f8b-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12199,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4215330d7 0xc4215330d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421533140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421533160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-dz465" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dz465,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-dz465,UID:e29a1110-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12052,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421533217 0xc421533218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421533280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215332a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:172.16.2.179,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://605daa3e83ff524b552626462a2a4d095b82a58029e59d8e768ca3cb4b809359}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-f2vxl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f2vxl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-f2vxl,UID:e63184e9-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12157,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421533367 0xc421533368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215333d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215333f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-fztsf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fztsf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-fztsf,UID:e29b7f6c-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12045,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4215334a7 0xc4215334a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421533510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421533530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:172.16.2.46,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f3cc3be6f7e1dcfca15e20260f35fd8c16fab451a9b6482ab3d93a9e38714b94}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-h6p6d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h6p6d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-h6p6d,UID:e636c142-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12240,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4215335f0 0xc4215335f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421533650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421533670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-h9shw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h9shw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-h9shw,UID:e63291d3-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12195,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421533737 0xc421533738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215337a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215337c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.286: INFO: Pod "nginx-deployment-7f9675fb8b-jcbx4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jcbx4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-jcbx4,UID:e636cea5-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12221,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc421533877 0xc421533878}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-m4c4t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m4c4t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-m4c4t,UID:e29a1cdd-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12040,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2227 0xc4217e2228}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e22b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:172.16.2.48,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://933037fc284689622e2af7d6b0e70e2b481bd49ba4f649767ff7747e186fb9ab}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-mjxtp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mjxtp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-mjxtp,UID:e636c6f9-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12239,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e24c0 0xc4217e24c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-ms4kr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ms4kr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-ms4kr,UID:e6343fd9-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12211,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2677 0xc4217e2678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e26e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-nbjvh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nbjvh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-nbjvh,UID:e298965c-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12023,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2827 0xc4217e2828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e28b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:172.16.1.144,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://530219e4d38ff59d99a489889d7fee2471f0ac0d42e0e53da2c5df439794721e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-p29wj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p29wj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-p29wj,UID:e29891b4-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12058,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e29e7 0xc4217e29e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:172.16.2.180,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://760550023b759b433bdc96a2d756e86605228cc56faded61f3af0c248b74efe6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-qcls6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qcls6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-qcls6,UID:e29a2704-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12043,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2b87 0xc4217e2b88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:172.16.2.49,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://fd1791591b8df66c3d7aa1a52322adc69f08c9c774cc7dc49322374abc4420d7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-vzbtm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vzbtm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-vzbtm,UID:e636de37-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12213,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2d00 0xc4217e2d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhu,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.77,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-xjczs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xjczs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-xjczs,UID:e6343a8b-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12208,Generation:0,CreationTimestamp:2019-01-21 09:06:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2e57 0xc4217e2e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e2ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e2ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:55 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:,StartTime:2019-01-21 09:06:55 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 09:06:57.287: INFO: Pod "nginx-deployment-7f9675fb8b-zcgn8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zcgn8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-gw2qq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gw2qq/pods/nginx-deployment-7f9675fb8b-zcgn8,UID:e29b622b-1d5b-11e9-9352-00163e04cddc,ResourceVersion:12055,Generation:0,CreationTimestamp:2019-01-21 09:06:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b e295dcf8-1d5b-11e9-9352-00163e04cddc 0xc4217e2fb7 0xc4217e2fb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xgj9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xgj9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6xgj9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217e3020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217e3040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:06:49 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:172.16.2.181,StartTime:2019-01-21 09:06:49 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 09:06:50 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://039d78059d4fd08f90982bb609d41426217a14422e6c40e31aea63bbdd02c2bf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:06:57.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gw2qq" for this suite.
Jan 21 09:07:03.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:07:03.353: INFO: namespace: e2e-tests-deployment-gw2qq, resource: bindings, ignored listing per whitelist
Jan 21 09:07:03.367: INFO: namespace e2e-tests-deployment-gw2qq deletion completed in 6.07706193s

• [SLOW TEST:14.207 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:07:03.367: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-eb0ce6dc-1d5b-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:07:03.433: INFO: Waiting up to 5m0s for pod "pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-vcsnp" to be "success or failure"
Jan 21 09:07:03.434: INFO: Pod "pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.699909ms
Jan 21 09:07:05.440: INFO: Pod "pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00779981s
Jan 21 09:07:07.443: INFO: Pod "pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010392401s
STEP: Saw pod success
Jan 21 09:07:07.443: INFO: Pod "pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:07:07.445: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:07:07.459: INFO: Waiting for pod pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:07:07.460: INFO: Pod pod-secrets-eb0d96ed-1d5b-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:07:07.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vcsnp" for this suite.
Jan 21 09:07:13.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:07:13.496: INFO: namespace: e2e-tests-secrets-vcsnp, resource: bindings, ignored listing per whitelist
Jan 21 09:07:13.542: INFO: namespace e2e-tests-secrets-vcsnp deletion completed in 6.078606643s

• [SLOW TEST:10.174 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:07:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 21 09:07:17.637: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 21 09:07:17.639: INFO: Pod pod-with-prestop-http-hook still exists
Jan 21 09:07:19.639: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 21 09:07:19.642: INFO: Pod pod-with-prestop-http-hook still exists
Jan 21 09:07:21.639: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 21 09:07:21.643: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:07:21.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xzbxm" for this suite.
Jan 21 09:07:43.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:07:43.691: INFO: namespace: e2e-tests-container-lifecycle-hook-xzbxm, resource: bindings, ignored listing per whitelist
Jan 21 09:07:43.740: INFO: namespace e2e-tests-container-lifecycle-hook-xzbxm deletion completed in 22.078011138s

• [SLOW TEST:30.198 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:07:43.740: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 21 09:07:43.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:44.188: INFO: stderr: ""
Jan 21 09:07:44.188: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 09:07:44.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:44.276: INFO: stderr: ""
Jan 21 09:07:44.276: INFO: stdout: "update-demo-nautilus-782xl update-demo-nautilus-mzsgl "
Jan 21 09:07:44.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-782xl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:44.351: INFO: stderr: ""
Jan 21 09:07:44.351: INFO: stdout: ""
Jan 21 09:07:44.351: INFO: update-demo-nautilus-782xl is created but not running
Jan 21 09:07:49.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:49.431: INFO: stderr: ""
Jan 21 09:07:49.431: INFO: stdout: "update-demo-nautilus-782xl update-demo-nautilus-mzsgl "
Jan 21 09:07:49.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-782xl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:49.507: INFO: stderr: ""
Jan 21 09:07:49.507: INFO: stdout: "true"
Jan 21 09:07:49.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-782xl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:49.581: INFO: stderr: ""
Jan 21 09:07:49.581: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 09:07:49.581: INFO: validating pod update-demo-nautilus-782xl
Jan 21 09:07:49.588: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 09:07:49.588: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 09:07:49.588: INFO: update-demo-nautilus-782xl is verified up and running
Jan 21 09:07:49.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-mzsgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:49.661: INFO: stderr: ""
Jan 21 09:07:49.661: INFO: stdout: "true"
Jan 21 09:07:49.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-nautilus-mzsgl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:07:49.734: INFO: stderr: ""
Jan 21 09:07:49.734: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 09:07:49.734: INFO: validating pod update-demo-nautilus-mzsgl
Jan 21 09:07:49.737: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 09:07:49.737: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 09:07:49.737: INFO: update-demo-nautilus-mzsgl is verified up and running
STEP: rolling-update to new replication controller
Jan 21 09:07:49.738: INFO: scanned /root for discovery docs: <nil>
Jan 21 09:07:49.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:12.058: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 21 09:08:12.058: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 09:08:12.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:12.147: INFO: stderr: ""
Jan 21 09:08:12.148: INFO: stdout: "update-demo-kitten-psmqc update-demo-kitten-z6qxr update-demo-nautilus-782xl "
STEP: Replicas for name=update-demo: expected=2 actual=3
Jan 21 09:08:17.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:17.234: INFO: stderr: ""
Jan 21 09:08:17.234: INFO: stdout: "update-demo-kitten-psmqc update-demo-kitten-z6qxr "
Jan 21 09:08:17.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-kitten-psmqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:17.310: INFO: stderr: ""
Jan 21 09:08:17.310: INFO: stdout: "true"
Jan 21 09:08:17.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-kitten-psmqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:17.383: INFO: stderr: ""
Jan 21 09:08:17.383: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 21 09:08:17.383: INFO: validating pod update-demo-kitten-psmqc
Jan 21 09:08:17.387: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 21 09:08:17.387: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 21 09:08:17.387: INFO: update-demo-kitten-psmqc is verified up and running
Jan 21 09:08:17.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-kitten-z6qxr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:17.461: INFO: stderr: ""
Jan 21 09:08:17.461: INFO: stdout: "true"
Jan 21 09:08:17.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods update-demo-kitten-z6qxr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vf776'
Jan 21 09:08:17.535: INFO: stderr: ""
Jan 21 09:08:17.535: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 21 09:08:17.535: INFO: validating pod update-demo-kitten-z6qxr
Jan 21 09:08:17.538: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 21 09:08:17.538: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 21 09:08:17.538: INFO: update-demo-kitten-z6qxr is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:08:17.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vf776" for this suite.
Jan 21 09:08:39.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:08:39.608: INFO: namespace: e2e-tests-kubectl-vf776, resource: bindings, ignored listing per whitelist
Jan 21 09:08:39.611: INFO: namespace e2e-tests-kubectl-vf776 deletion completed in 22.069892963s

• [SLOW TEST:55.871 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:08:39.611: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-5clr
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 09:08:39.679: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5clr" in namespace "e2e-tests-subpath-6pt4c" to be "success or failure"
Jan 21 09:08:39.682: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.553411ms
Jan 21 09:08:41.684: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005172031s
Jan 21 09:08:43.687: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 4.007836035s
Jan 21 09:08:45.693: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 6.014287985s
Jan 21 09:08:47.696: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 8.016886097s
Jan 21 09:08:49.699: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 10.019695539s
Jan 21 09:08:51.702: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 12.022449509s
Jan 21 09:08:53.705: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 14.02561293s
Jan 21 09:08:55.713: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 16.033998483s
Jan 21 09:08:57.716: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 18.0367619s
Jan 21 09:08:59.719: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 20.039551863s
Jan 21 09:09:01.721: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Running", Reason="", readiness=false. Elapsed: 22.042149418s
Jan 21 09:09:03.724: INFO: Pod "pod-subpath-test-configmap-5clr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044573121s
STEP: Saw pod success
Jan 21 09:09:03.724: INFO: Pod "pod-subpath-test-configmap-5clr" satisfied condition "success or failure"
Jan 21 09:09:03.726: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-subpath-test-configmap-5clr container test-container-subpath-configmap-5clr: <nil>
STEP: delete the pod
Jan 21 09:09:03.740: INFO: Waiting for pod pod-subpath-test-configmap-5clr to disappear
Jan 21 09:09:03.742: INFO: Pod pod-subpath-test-configmap-5clr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5clr
Jan 21 09:09:03.742: INFO: Deleting pod "pod-subpath-test-configmap-5clr" in namespace "e2e-tests-subpath-6pt4c"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:09:03.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6pt4c" for this suite.
Jan 21 09:09:09.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:09:09.769: INFO: namespace: e2e-tests-subpath-6pt4c, resource: bindings, ignored listing per whitelist
Jan 21 09:09:09.816: INFO: namespace e2e-tests-subpath-6pt4c deletion completed in 6.069406065s

• [SLOW TEST:30.205 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:09:09.816: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tgs8f.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tgs8f.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tgs8f.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tgs8f.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tgs8f.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tgs8f.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 21 09:09:35.927: INFO: DNS probes using e2e-tests-dns-tgs8f/dns-test-366aaed5-1d5c-11e9-9c91-0a58ac100282 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:09:35.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tgs8f" for this suite.
Jan 21 09:09:41.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:09:41.961: INFO: namespace: e2e-tests-dns-tgs8f, resource: bindings, ignored listing per whitelist
Jan 21 09:09:42.007: INFO: namespace e2e-tests-dns-tgs8f deletion completed in 6.069901608s

• [SLOW TEST:32.191 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:09:42.007: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0121 09:10:12.598904      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 09:10:12.598: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:10:12.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7hgm4" for this suite.
Jan 21 09:10:18.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:10:18.647: INFO: namespace: e2e-tests-gc-7hgm4, resource: bindings, ignored listing per whitelist
Jan 21 09:10:18.669: INFO: namespace e2e-tests-gc-7hgm4 deletion completed in 6.067792724s

• [SLOW TEST:36.662 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:10:18.669: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 09:10:18.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4z7gw'
Jan 21 09:10:18.809: INFO: stderr: ""
Jan 21 09:10:18.809: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan 21 09:10:18.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-4z7gw'
Jan 21 09:10:31.807: INFO: stderr: ""
Jan 21 09:10:31.807: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:10:31.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4z7gw" for this suite.
Jan 21 09:10:37.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:10:37.848: INFO: namespace: e2e-tests-kubectl-4z7gw, resource: bindings, ignored listing per whitelist
Jan 21 09:10:37.885: INFO: namespace e2e-tests-kubectl-4z7gw deletion completed in 6.071373331s

• [SLOW TEST:19.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:10:37.885: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kn5gv
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-kn5gv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-kn5gv
Jan 21 09:10:37.945: INFO: Found 0 stateful pods, waiting for 1
Jan 21 09:10:47.952: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 21 09:10:47.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:10:48.204: INFO: stderr: ""
Jan 21 09:10:48.204: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:10:48.204: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:10:48.207: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 21 09:10:58.213: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:10:58.213: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:10:58.224: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:10:58.224: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:10:58.224: INFO: 
Jan 21 09:10:58.224: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 21 09:10:59.227: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997711997s
Jan 21 09:11:00.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994794987s
Jan 21 09:11:01.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992346318s
Jan 21 09:11:02.235: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989418133s
Jan 21 09:11:03.238: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986414047s
Jan 21 09:11:04.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.983582341s
Jan 21 09:11:05.244: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.980668265s
Jan 21 09:11:06.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.977622011s
Jan 21 09:11:07.250: INFO: Verifying statefulset ss doesn't scale past 3 for another 974.313954ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-kn5gv
Jan 21 09:11:08.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:11:08.513: INFO: stderr: ""
Jan 21 09:11:08.513: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:11:08.513: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:11:08.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:11:08.758: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 21 09:11:08.758: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:11:08.758: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:11:08.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:11:08.998: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 21 09:11:08.998: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:11:08.998: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:11:09.001: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:11:09.001: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:11:09.001: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 21 09:11:09.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:11:09.242: INFO: stderr: ""
Jan 21 09:11:09.242: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:11:09.242: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:11:09.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:11:09.514: INFO: stderr: ""
Jan 21 09:11:09.514: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:11:09.514: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:11:09.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:11:09.763: INFO: stderr: ""
Jan 21 09:11:09.763: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:11:09.763: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:11:09.763: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:11:09.767: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 21 09:11:19.776: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:11:19.776: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:11:19.776: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:11:19.786: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:19.786: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:19.786: INFO: ss-1  cn-hongkong.i-j6c44erhl7eu2z5nuuhv  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:19.786: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:19.786: INFO: 
Jan 21 09:11:19.786: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 21 09:11:20.789: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:20.789: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:20.789: INFO: ss-1  cn-hongkong.i-j6c44erhl7eu2z5nuuhv  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:20.789: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:20.789: INFO: 
Jan 21 09:11:20.789: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 21 09:11:21.792: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:21.792: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:21.792: INFO: ss-1  cn-hongkong.i-j6c44erhl7eu2z5nuuhv  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:21.792: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:21.792: INFO: 
Jan 21 09:11:21.792: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 21 09:11:22.795: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:22.795: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:22.795: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:22.795: INFO: 
Jan 21 09:11:22.795: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 09:11:23.798: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:23.798: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:23.798: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:23.798: INFO: 
Jan 21 09:11:23.798: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 09:11:24.801: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:24.801: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:24.801: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:24.801: INFO: 
Jan 21 09:11:24.801: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 09:11:25.804: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:25.804: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:25.804: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:25.804: INFO: 
Jan 21 09:11:25.804: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 09:11:26.807: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:26.807: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:26.807: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:26.807: INFO: 
Jan 21 09:11:26.807: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 09:11:27.809: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:27.809: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:27.809: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:27.809: INFO: 
Jan 21 09:11:27.809: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 09:11:28.812: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Jan 21 09:11:28.812: INFO: ss-0  cn-hongkong.i-j6c44erhl7eu2z5nuuht  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:37 +0000 UTC  }]
Jan 21 09:11:28.812: INFO: ss-2  cn-hongkong.i-j6c44erhl7eu2z5nuuhu  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:11:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:10:58 +0000 UTC  }]
Jan 21 09:11:28.812: INFO: 
Jan 21 09:11:28.812: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-kn5gv
Jan 21 09:11:29.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:11:29.917: INFO: rc: 1
Jan 21 09:11:29.917: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4206d7200 exit status 1 <nil> <nil> true [0xc42000fc30 0xc42000fca8 0xc42000fd18] [0xc42000fc30 0xc42000fca8 0xc42000fd18] [0xc42000fc98 0xc42000fd00] [0x8fd520 0x8fd520] 0xc421b3bb60 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jan 21 09:11:39.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:11:39.993: INFO: rc: 1
Jan 21 09:11:39.993: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213fc7e0 exit status 1 <nil> <nil> true [0xc4214fe4e8 0xc4214fe510 0xc4214fe558] [0xc4214fe4e8 0xc4214fe510 0xc4214fe558] [0xc4214fe508 0xc4214fe540] [0x8fd520 0x8fd520] 0xc421057440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:11:49.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:11:50.066: INFO: rc: 1
Jan 21 09:11:50.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d38b40 exit status 1 <nil> <nil> true [0xc420df3218 0xc420df3250 0xc420df3298] [0xc420df3218 0xc420df3250 0xc420df3298] [0xc420df3240 0xc420df3288] [0x8fd520 0x8fd520] 0xc420ed5ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:12:00.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:12:00.138: INFO: rc: 1
Jan 21 09:12:00.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4206d7740 exit status 1 <nil> <nil> true [0xc42000fd38 0xc42000fd90 0xc42000fde0] [0xc42000fd38 0xc42000fd90 0xc42000fde0] [0xc42000fd68 0xc42000fdd8] [0x8fd520 0x8fd520] 0xc421b3bc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:12:10.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:12:10.213: INFO: rc: 1
Jan 21 09:12:10.213: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213fcc90 exit status 1 <nil> <nil> true [0xc4214fe578 0xc4214fe5c8 0xc4214fe5e0] [0xc4214fe578 0xc4214fe5c8 0xc4214fe5e0] [0xc4214fe5b0 0xc4214fe5d8] [0x8fd520 0x8fd520] 0xc4215b8c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:12:20.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:12:20.291: INFO: rc: 1
Jan 21 09:12:20.291: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213fd140 exit status 1 <nil> <nil> true [0xc4214fe5f0 0xc4214fe608 0xc4214fe640] [0xc4214fe5f0 0xc4214fe608 0xc4214fe640] [0xc4214fe600 0xc4214fe628] [0x8fd520 0x8fd520] 0xc4215b9c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:12:30.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:12:30.369: INFO: rc: 1
Jan 21 09:12:30.369: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4207003c0 exit status 1 <nil> <nil> true [0xc4200ea000 0xc4200ea280 0xc4200ea330] [0xc4200ea000 0xc4200ea280 0xc4200ea330] [0xc4200ea258 0xc4200ea2d8] [0x8fd520 0x8fd520] 0xc4215b8c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:12:40.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:12:40.448: INFO: rc: 1
Jan 21 09:12:40.448: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420ebc450 exit status 1 <nil> <nil> true [0xc420a020e8 0xc420a50f68 0xc420a51028] [0xc420a020e8 0xc420a50f68 0xc420a51028] [0xc420a50f20 0xc420a50fa0] [0x8fd520 0x8fd520] 0xc420ffdc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:12:50.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:12:50.521: INFO: rc: 1
Jan 21 09:12:50.522: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420700780 exit status 1 <nil> <nil> true [0xc4200ea360 0xc4200ea478 0xc4200ea510] [0xc4200ea360 0xc4200ea478 0xc4200ea510] [0xc4200ea428 0xc4200ea500] [0x8fd520 0x8fd520] 0xc420eff6e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:13:00.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:13:00.595: INFO: rc: 1
Jan 21 09:13:00.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420700ba0 exit status 1 <nil> <nil> true [0xc4200ea580 0xc4200ea658 0xc4200ea7d0] [0xc4200ea580 0xc4200ea658 0xc4200ea7d0] [0xc4200ea618 0xc4200ea6f0] [0x8fd520 0x8fd520] 0xc421066d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:13:10.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:13:10.672: INFO: rc: 1
Jan 21 09:13:10.672: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420ebc840 exit status 1 <nil> <nil> true [0xc420a51058 0xc420a510a8 0xc420a51160] [0xc420a51058 0xc420a510a8 0xc420a51160] [0xc420a51098 0xc420a51140] [0x8fd520 0x8fd520] 0xc421585080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:13:20.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:13:20.744: INFO: rc: 1
Jan 21 09:13:20.744: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d02390 exit status 1 <nil> <nil> true [0xc4211a6000 0xc4211a6018 0xc4211a6030] [0xc4211a6000 0xc4211a6018 0xc4211a6030] [0xc4211a6010 0xc4211a6028] [0x8fd520 0x8fd520] 0xc420fcb800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:13:30.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:13:30.816: INFO: rc: 1
Jan 21 09:13:30.816: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420700fc0 exit status 1 <nil> <nil> true [0xc4200eab60 0xc4200eac70 0xc4200ead78] [0xc4200eab60 0xc4200eac70 0xc4200ead78] [0xc4200eabd0 0xc4200ead50] [0x8fd520 0x8fd520] 0xc4219945a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:13:40.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:13:40.894: INFO: rc: 1
Jan 21 09:13:40.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420ebcd50 exit status 1 <nil> <nil> true [0xc420a511b8 0xc420a51288 0xc420a512e8] [0xc420a511b8 0xc420a51288 0xc420a512e8] [0xc420a51240 0xc420a512b8] [0x8fd520 0x8fd520] 0xc421c18060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:13:50.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:13:50.966: INFO: rc: 1
Jan 21 09:13:50.966: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420701380 exit status 1 <nil> <nil> true [0xc4200eadd0 0xc4200eae60 0xc4200eaee8] [0xc4200eadd0 0xc4200eae60 0xc4200eaee8] [0xc4200eae30 0xc4200eaed0] [0x8fd520 0x8fd520] 0xc421995320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:14:00.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:14:01.043: INFO: rc: 1
Jan 21 09:14:01.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420701800 exit status 1 <nil> <nil> true [0xc4200eaf58 0xc4200eaf88 0xc4200eb0b0] [0xc4200eaf58 0xc4200eaf88 0xc4200eb0b0] [0xc4200eaf80 0xc4200eb048] [0x8fd520 0x8fd520] 0xc4210d6000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:14:11.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:14:11.120: INFO: rc: 1
Jan 21 09:14:11.120: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d02840 exit status 1 <nil> <nil> true [0xc4211a6038 0xc4211a6050 0xc4211a6068] [0xc4211a6038 0xc4211a6050 0xc4211a6068] [0xc4211a6048 0xc4211a6060] [0x8fd520 0x8fd520] 0xc421763020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:14:21.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:14:21.195: INFO: rc: 1
Jan 21 09:14:21.195: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421132390 exit status 1 <nil> <nil> true [0xc4211a6000 0xc4211a6018 0xc4211a6030] [0xc4211a6000 0xc4211a6018 0xc4211a6030] [0xc4211a6010 0xc4211a6028] [0x8fd520 0x8fd520] 0xc4219945a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:14:31.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:14:31.271: INFO: rc: 1
Jan 21 09:14:31.271: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420ebc420 exit status 1 <nil> <nil> true [0xc420a50ea0 0xc420a50f70 0xc420a51058] [0xc420a50ea0 0xc420a50f70 0xc420a51058] [0xc420a50f68 0xc420a51028] [0x8fd520 0x8fd520] 0xc420fcb800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:14:41.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:14:41.347: INFO: rc: 1
Jan 21 09:14:41.348: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211328a0 exit status 1 <nil> <nil> true [0xc4211a6038 0xc4211a6050 0xc4211a6068] [0xc4211a6038 0xc4211a6050 0xc4211a6068] [0xc4211a6048 0xc4211a6060] [0x8fd520 0x8fd520] 0xc421995320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:14:51.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:14:51.423: INFO: rc: 1
Jan 21 09:14:51.424: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d023c0 exit status 1 <nil> <nil> true [0xc4200ea000 0xc4200ea280 0xc4200ea330] [0xc4200ea000 0xc4200ea280 0xc4200ea330] [0xc4200ea258 0xc4200ea2d8] [0x8fd520 0x8fd520] 0xc4210675c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:15:01.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:15:01.498: INFO: rc: 1
Jan 21 09:15:01.498: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421132c90 exit status 1 <nil> <nil> true [0xc4211a6070 0xc4211a6088 0xc4211a60f0] [0xc4211a6070 0xc4211a6088 0xc4211a60f0] [0xc4211a6080 0xc4211a60e8] [0x8fd520 0x8fd520] 0xc421080fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:15:11.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:15:11.572: INFO: rc: 1
Jan 21 09:15:11.572: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4207003f0 exit status 1 <nil> <nil> true [0xc420df2000 0xc420df2030 0xc420df2048] [0xc420df2000 0xc420df2030 0xc420df2048] [0xc420df2028 0xc420df2040] [0x8fd520 0x8fd520] 0xc4216f2ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:15:21.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:15:21.655: INFO: rc: 1
Jan 21 09:15:21.655: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d02810 exit status 1 <nil> <nil> true [0xc4200ea360 0xc4200ea478 0xc4200ea510] [0xc4200ea360 0xc4200ea478 0xc4200ea510] [0xc4200ea428 0xc4200ea500] [0x8fd520 0x8fd520] 0xc4215b8900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:15:31.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:15:31.733: INFO: rc: 1
Jan 21 09:15:31.733: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4207007b0 exit status 1 <nil> <nil> true [0xc420df2050 0xc420df2088 0xc420df20b0] [0xc420df2050 0xc420df2088 0xc420df20b0] [0xc420df2080 0xc420df20a8] [0x8fd520 0x8fd520] 0xc4217628a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:15:41.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:15:41.810: INFO: rc: 1
Jan 21 09:15:41.810: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421133080 exit status 1 <nil> <nil> true [0xc4211a60f8 0xc4211a6110 0xc4211a6128] [0xc4211a60f8 0xc4211a6110 0xc4211a6128] [0xc4211a6108 0xc4211a6120] [0x8fd520 0x8fd520] 0xc421c180c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:15:51.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:15:51.887: INFO: rc: 1
Jan 21 09:15:51.887: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d02cf0 exit status 1 <nil> <nil> true [0xc4200ea580 0xc4200ea658 0xc4200ea7d0] [0xc4200ea580 0xc4200ea658 0xc4200ea7d0] [0xc4200ea618 0xc4200ea6f0] [0x8fd520 0x8fd520] 0xc4215b9920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:16:01.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:16:01.960: INFO: rc: 1
Jan 21 09:16:01.960: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421133410 exit status 1 <nil> <nil> true [0xc4211a6130 0xc4211a6148 0xc4211a6160] [0xc4211a6130 0xc4211a6148 0xc4211a6160] [0xc4211a6140 0xc4211a6158] [0x8fd520 0x8fd520] 0xc421c18480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:16:11.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:16:12.036: INFO: rc: 1
Jan 21 09:16:12.036: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420ebc900 exit status 1 <nil> <nil> true [0xc420a51078 0xc420a510e0 0xc420a511b8] [0xc420a51078 0xc420a510e0 0xc420a511b8] [0xc420a510a8 0xc420a51160] [0x8fd520 0x8fd520] 0xc421585740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:16:22.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:16:22.108: INFO: rc: 1
Jan 21 09:16:22.108: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4207003c0 exit status 1 <nil> <nil> true [0xc420df2000 0xc420df2030 0xc420df2048] [0xc420df2000 0xc420df2030 0xc420df2048] [0xc420df2028 0xc420df2040] [0x8fd520 0x8fd520] 0xc420ffdc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 21 09:16:32.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-kn5gv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:16:32.184: INFO: rc: 1
Jan 21 09:16:32.184: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Jan 21 09:16:32.184: INFO: Scaling statefulset ss to 0
Jan 21 09:16:32.191: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 09:16:32.193: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kn5gv
Jan 21 09:16:32.195: INFO: Scaling statefulset ss to 0
Jan 21 09:16:32.201: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:16:32.203: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:16:32.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kn5gv" for this suite.
Jan 21 09:16:38.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:16:38.262: INFO: namespace: e2e-tests-statefulset-kn5gv, resource: bindings, ignored listing per whitelist
Jan 21 09:16:38.295: INFO: namespace e2e-tests-statefulset-kn5gv deletion completed in 6.070692063s

• [SLOW TEST:360.410 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:16:38.295: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 21 09:16:38.365: INFO: Waiting up to 5m0s for pod "pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-lcn4q" to be "success or failure"
Jan 21 09:16:38.367: INFO: Pod "pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.828037ms
Jan 21 09:16:40.370: INFO: Pod "pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004423403s
Jan 21 09:16:42.376: INFO: Pod "pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010646045s
STEP: Saw pod success
Jan 21 09:16:42.376: INFO: Pod "pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:16:42.378: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:16:42.395: INFO: Waiting for pod pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:16:42.397: INFO: Pod pod-41bbb8a1-1d5d-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:16:42.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lcn4q" for this suite.
Jan 21 09:16:48.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:16:48.445: INFO: namespace: e2e-tests-emptydir-lcn4q, resource: bindings, ignored listing per whitelist
Jan 21 09:16:48.469: INFO: namespace e2e-tests-emptydir-lcn4q deletion completed in 6.068714078s

• [SLOW TEST:10.173 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:16:48.469: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-47cb998b-1d5d-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:16:48.530: INFO: Waiting up to 5m0s for pod "pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-4ptch" to be "success or failure"
Jan 21 09:16:48.531: INFO: Pod "pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.820797ms
Jan 21 09:16:50.534: INFO: Pod "pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004342151s
STEP: Saw pod success
Jan 21 09:16:50.534: INFO: Pod "pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:16:50.536: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:16:50.551: INFO: Waiting for pod pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:16:50.553: INFO: Pod pod-configmaps-47cc45b2-1d5d-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:16:50.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4ptch" for this suite.
Jan 21 09:16:56.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:16:56.583: INFO: namespace: e2e-tests-configmap-4ptch, resource: bindings, ignored listing per whitelist
Jan 21 09:16:56.628: INFO: namespace e2e-tests-configmap-4ptch deletion completed in 6.071665855s

• [SLOW TEST:8.159 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:16:56.628: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 21 09:16:56.681: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-dzvgh" to be "success or failure"
Jan 21 09:16:56.683: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.65391ms
Jan 21 09:16:58.686: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004735105s
STEP: Saw pod success
Jan 21 09:16:58.686: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 21 09:16:58.688: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 21 09:16:58.702: INFO: Waiting for pod pod-host-path-test to disappear
Jan 21 09:16:58.704: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:16:58.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-dzvgh" for this suite.
Jan 21 09:17:04.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:17:04.745: INFO: namespace: e2e-tests-hostpath-dzvgh, resource: bindings, ignored listing per whitelist
Jan 21 09:17:04.778: INFO: namespace e2e-tests-hostpath-dzvgh deletion completed in 6.071995406s

• [SLOW TEST:8.150 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:17:04.778: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:17:10.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-g7px5" for this suite.
Jan 21 09:17:16.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:17:16.935: INFO: namespace: e2e-tests-namespaces-g7px5, resource: bindings, ignored listing per whitelist
Jan 21 09:17:16.964: INFO: namespace e2e-tests-namespaces-g7px5 deletion completed in 6.072027247s
STEP: Destroying namespace "e2e-tests-nsdeletetest-969r4" for this suite.
Jan 21 09:17:16.966: INFO: Namespace e2e-tests-nsdeletetest-969r4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-wqrgr" for this suite.
Jan 21 09:17:22.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:17:22.992: INFO: namespace: e2e-tests-nsdeletetest-wqrgr, resource: bindings, ignored listing per whitelist
Jan 21 09:17:23.070: INFO: namespace e2e-tests-nsdeletetest-wqrgr deletion completed in 6.104049823s

• [SLOW TEST:18.292 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:17:23.070: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:17:23.130: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-q7fv8" to be "success or failure"
Jan 21 09:17:23.132: INFO: Pod "downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.788868ms
Jan 21 09:17:25.134: INFO: Pod "downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00459451s
STEP: Saw pod success
Jan 21 09:17:25.134: INFO: Pod "downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:17:25.136: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:17:25.151: INFO: Waiting for pod downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:17:25.153: INFO: Pod downwardapi-volume-5c6b7cf3-1d5d-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:17:25.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q7fv8" for this suite.
Jan 21 09:17:31.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:17:31.228: INFO: namespace: e2e-tests-projected-q7fv8, resource: bindings, ignored listing per whitelist
Jan 21 09:17:31.232: INFO: namespace e2e-tests-projected-q7fv8 deletion completed in 6.076339344s

• [SLOW TEST:8.162 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:17:31.232: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 21 09:17:31.284: INFO: Waiting up to 5m0s for pod "client-containers-61480473-1d5d-11e9-9c91-0a58ac100282" in namespace "e2e-tests-containers-p5xw6" to be "success or failure"
Jan 21 09:17:31.286: INFO: Pod "client-containers-61480473-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.669294ms
Jan 21 09:17:33.292: INFO: Pod "client-containers-61480473-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007797065s
Jan 21 09:17:35.294: INFO: Pod "client-containers-61480473-1d5d-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010338866s
STEP: Saw pod success
Jan 21 09:17:35.294: INFO: Pod "client-containers-61480473-1d5d-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:17:35.296: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod client-containers-61480473-1d5d-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:17:35.309: INFO: Waiting for pod client-containers-61480473-1d5d-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:17:35.310: INFO: Pod client-containers-61480473-1d5d-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:17:35.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-p5xw6" for this suite.
Jan 21 09:17:41.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:17:41.364: INFO: namespace: e2e-tests-containers-p5xw6, resource: bindings, ignored listing per whitelist
Jan 21 09:17:41.385: INFO: namespace e2e-tests-containers-p5xw6 deletion completed in 6.071858528s

• [SLOW TEST:10.152 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:17:41.385: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 09:17:41.439: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:17:44.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-l9jkf" for this suite.
Jan 21 09:17:50.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:17:50.360: INFO: namespace: e2e-tests-init-container-l9jkf, resource: bindings, ignored listing per whitelist
Jan 21 09:17:50.395: INFO: namespace e2e-tests-init-container-l9jkf deletion completed in 6.071030208s

• [SLOW TEST:9.010 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:17:50.395: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 09:17:52.969: INFO: Successfully updated pod "annotationupdate6cb4348d-1d5d-11e9-9c91-0a58ac100282"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:17:56.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cwrjc" for this suite.
Jan 21 09:18:19.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:18:19.014: INFO: namespace: e2e-tests-projected-cwrjc, resource: bindings, ignored listing per whitelist
Jan 21 09:18:19.063: INFO: namespace e2e-tests-projected-cwrjc deletion completed in 22.069832494s

• [SLOW TEST:28.668 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:18:19.063: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 21 09:18:19.117: INFO: namespace e2e-tests-kubectl-hz6gf
Jan 21 09:18:19.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-hz6gf'
Jan 21 09:18:19.451: INFO: stderr: ""
Jan 21 09:18:19.451: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 21 09:18:20.454: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:18:20.454: INFO: Found 0 / 1
Jan 21 09:18:21.454: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:18:21.454: INFO: Found 0 / 1
Jan 21 09:18:22.454: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:18:22.454: INFO: Found 0 / 1
Jan 21 09:18:23.454: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:18:23.454: INFO: Found 1 / 1
Jan 21 09:18:23.454: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 21 09:18:23.456: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:18:23.456: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 21 09:18:23.456: INFO: wait on redis-master startup in e2e-tests-kubectl-hz6gf 
Jan 21 09:18:23.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 logs redis-master-t56rq redis-master --namespace=e2e-tests-kubectl-hz6gf'
Jan 21 09:18:23.555: INFO: stderr: ""
Jan 21 09:18:23.555: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jan 09:18:21.886 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jan 09:18:21.886 # Server started, Redis version 3.2.12\n1:M 21 Jan 09:18:21.886 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jan 09:18:21.886 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 21 09:18:23.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hz6gf'
Jan 21 09:18:23.687: INFO: stderr: ""
Jan 21 09:18:23.687: INFO: stdout: "service/rm2 exposed\n"
Jan 21 09:18:23.690: INFO: Service rm2 in namespace e2e-tests-kubectl-hz6gf found.
STEP: exposing service
Jan 21 09:18:25.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hz6gf'
Jan 21 09:18:25.783: INFO: stderr: ""
Jan 21 09:18:25.783: INFO: stdout: "service/rm3 exposed\n"
Jan 21 09:18:25.785: INFO: Service rm3 in namespace e2e-tests-kubectl-hz6gf found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:18:27.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hz6gf" for this suite.
Jan 21 09:18:49.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:18:49.821: INFO: namespace: e2e-tests-kubectl-hz6gf, resource: bindings, ignored listing per whitelist
Jan 21 09:18:49.872: INFO: namespace e2e-tests-kubectl-hz6gf deletion completed in 22.077119291s

• [SLOW TEST:30.809 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:18:49.873: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 21 09:18:49.938: INFO: Waiting up to 5m0s for pod "client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282" in namespace "e2e-tests-containers-gzxvp" to be "success or failure"
Jan 21 09:18:49.940: INFO: Pod "client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472868ms
Jan 21 09:18:51.943: INFO: Pod "client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005173546s
Jan 21 09:18:53.945: INFO: Pod "client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007609773s
STEP: Saw pod success
Jan 21 09:18:53.945: INFO: Pod "client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:18:53.947: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:18:53.961: INFO: Waiting for pod client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:18:53.963: INFO: Pod client-containers-902999ae-1d5d-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:18:53.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gzxvp" for this suite.
Jan 21 09:18:59.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:18:59.994: INFO: namespace: e2e-tests-containers-gzxvp, resource: bindings, ignored listing per whitelist
Jan 21 09:19:00.037: INFO: namespace e2e-tests-containers-gzxvp deletion completed in 6.071838923s

• [SLOW TEST:10.165 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:19:00.038: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xpd6n
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 21 09:19:00.117: INFO: Found 0 stateful pods, waiting for 3
Jan 21 09:19:10.123: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:19:10.123: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:19:10.123: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:19:10.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-xpd6n ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:19:10.373: INFO: stderr: ""
Jan 21 09:19:10.373: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:19:10.373: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 21 09:19:20.414: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 21 09:19:30.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-xpd6n ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:19:30.677: INFO: stderr: ""
Jan 21 09:19:30.677: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:19:30.677: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:19:40.694: INFO: Waiting for StatefulSet e2e-tests-statefulset-xpd6n/ss2 to complete update
Jan 21 09:19:40.694: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 09:19:40.694: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 09:19:50.703: INFO: Waiting for StatefulSet e2e-tests-statefulset-xpd6n/ss2 to complete update
Jan 21 09:19:50.703: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 09:20:00.700: INFO: Waiting for StatefulSet e2e-tests-statefulset-xpd6n/ss2 to complete update
Jan 21 09:20:00.700: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan 21 09:20:10.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-xpd6n ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:20:10.939: INFO: stderr: ""
Jan 21 09:20:10.939: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:20:10.939: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:20:20.968: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 21 09:20:30.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-xpd6n ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:20:31.228: INFO: stderr: ""
Jan 21 09:20:31.228: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:20:31.228: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:20:41.245: INFO: Waiting for StatefulSet e2e-tests-statefulset-xpd6n/ss2 to complete update
Jan 21 09:20:41.245: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 21 09:20:41.245: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 21 09:20:51.254: INFO: Waiting for StatefulSet e2e-tests-statefulset-xpd6n/ss2 to complete update
Jan 21 09:20:51.254: INFO: Waiting for Pod e2e-tests-statefulset-xpd6n/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 09:21:01.250: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xpd6n
Jan 21 09:21:01.256: INFO: Scaling statefulset ss2 to 0
Jan 21 09:21:41.268: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:21:41.270: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:21:41.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xpd6n" for this suite.
Jan 21 09:21:47.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:21:47.322: INFO: namespace: e2e-tests-statefulset-xpd6n, resource: bindings, ignored listing per whitelist
Jan 21 09:21:47.361: INFO: namespace e2e-tests-statefulset-xpd6n deletion completed in 6.071471717s

• [SLOW TEST:167.324 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:21:47.362: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 21 09:21:47.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 api-versions'
Jan 21 09:21:47.494: INFO: stderr: ""
Jan 21 09:21:47.494: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\nalicloud.com/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:21:47.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4qw74" for this suite.
Jan 21 09:21:53.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:21:53.538: INFO: namespace: e2e-tests-kubectl-4qw74, resource: bindings, ignored listing per whitelist
Jan 21 09:21:53.569: INFO: namespace e2e-tests-kubectl-4qw74 deletion completed in 6.07107933s

• [SLOW TEST:6.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:21:53.569: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:21:53.628: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan 21 09:21:53.632: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bb26s/daemonsets","resourceVersion":"16018"},"items":null}

Jan 21 09:21:53.633: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bb26s/pods","resourceVersion":"16018"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:21:53.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bb26s" for this suite.
Jan 21 09:21:59.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:21:59.687: INFO: namespace: e2e-tests-daemonsets-bb26s, resource: bindings, ignored listing per whitelist
Jan 21 09:21:59.714: INFO: namespace e2e-tests-daemonsets-bb26s deletion completed in 6.06931724s

S [SKIPPING] [6.145 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 21 09:21:53.628: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:21:59.714: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-014fc72f-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:21:59.775: INFO: Waiting up to 5m0s for pod "pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-lkjfl" to be "success or failure"
Jan 21 09:21:59.777: INFO: Pod "pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.618233ms
Jan 21 09:22:01.782: INFO: Pod "pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007184184s
STEP: Saw pod success
Jan 21 09:22:01.782: INFO: Pod "pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:22:01.784: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:22:01.798: INFO: Waiting for pod pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:22:01.800: INFO: Pod pod-configmaps-015075f0-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:22:01.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lkjfl" for this suite.
Jan 21 09:22:07.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:22:07.844: INFO: namespace: e2e-tests-configmap-lkjfl, resource: bindings, ignored listing per whitelist
Jan 21 09:22:07.877: INFO: namespace e2e-tests-configmap-lkjfl deletion completed in 6.073884249s

• [SLOW TEST:8.163 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:22:07.877: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 21 09:22:07.934: INFO: Waiting up to 5m0s for pod "client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-containers-g669t" to be "success or failure"
Jan 21 09:22:07.936: INFO: Pod "client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.621291ms
Jan 21 09:22:09.938: INFO: Pod "client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004052811s
STEP: Saw pod success
Jan 21 09:22:09.938: INFO: Pod "client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:22:09.940: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:22:09.955: INFO: Waiting for pod client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:22:09.957: INFO: Pod client-containers-062d7414-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:22:09.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-g669t" for this suite.
Jan 21 09:22:15.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:22:16.008: INFO: namespace: e2e-tests-containers-g669t, resource: bindings, ignored listing per whitelist
Jan 21 09:22:16.029: INFO: namespace e2e-tests-containers-g669t deletion completed in 6.068692604s

• [SLOW TEST:8.152 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:22:16.029: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 09:22:16.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4lm7b'
Jan 21 09:22:16.184: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 09:22:16.184: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan 21 09:22:16.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-4lm7b'
Jan 21 09:22:16.297: INFO: stderr: ""
Jan 21 09:22:16.297: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:22:16.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4lm7b" for this suite.
Jan 21 09:22:38.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:22:38.358: INFO: namespace: e2e-tests-kubectl-4lm7b, resource: bindings, ignored listing per whitelist
Jan 21 09:22:38.372: INFO: namespace e2e-tests-kubectl-4lm7b deletion completed in 22.071188258s

• [SLOW TEST:22.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:22:38.372: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 21 09:22:38.440: INFO: Waiting up to 5m0s for pod "pod-185c4f04-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-89f5b" to be "success or failure"
Jan 21 09:22:38.442: INFO: Pod "pod-185c4f04-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.790691ms
Jan 21 09:22:40.445: INFO: Pod "pod-185c4f04-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004548373s
STEP: Saw pod success
Jan 21 09:22:40.445: INFO: Pod "pod-185c4f04-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:22:40.447: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-185c4f04-1d5e-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:22:40.461: INFO: Waiting for pod pod-185c4f04-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:22:40.463: INFO: Pod pod-185c4f04-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:22:40.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-89f5b" for this suite.
Jan 21 09:22:46.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:22:46.538: INFO: namespace: e2e-tests-emptydir-89f5b, resource: bindings, ignored listing per whitelist
Jan 21 09:22:46.538: INFO: namespace e2e-tests-emptydir-89f5b deletion completed in 6.07224491s

• [SLOW TEST:8.166 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:22:46.538: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:22:46.606: INFO: (0) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 3.777002ms)
Jan 21 09:22:46.608: INFO: (1) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.458778ms)
Jan 21 09:22:46.611: INFO: (2) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.575291ms)
Jan 21 09:22:46.613: INFO: (3) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.442189ms)
Jan 21 09:22:46.616: INFO: (4) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.49237ms)
Jan 21 09:22:46.618: INFO: (5) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.379149ms)
Jan 21 09:22:46.620: INFO: (6) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.394336ms)
Jan 21 09:22:46.623: INFO: (7) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.481632ms)
Jan 21 09:22:46.625: INFO: (8) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.451091ms)
Jan 21 09:22:46.628: INFO: (9) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.418385ms)
Jan 21 09:22:46.630: INFO: (10) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.382997ms)
Jan 21 09:22:46.633: INFO: (11) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.436526ms)
Jan 21 09:22:46.636: INFO: (12) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.96179ms)
Jan 21 09:22:46.643: INFO: (13) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 7.012335ms)
Jan 21 09:22:46.645: INFO: (14) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.423012ms)
Jan 21 09:22:46.648: INFO: (15) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.583922ms)
Jan 21 09:22:46.650: INFO: (16) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.690009ms)
Jan 21 09:22:46.657: INFO: (17) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 6.080603ms)
Jan 21 09:22:46.659: INFO: (18) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.55326ms)
Jan 21 09:22:46.662: INFO: (19) /api/v1/nodes/cn-hongkong.i-j6c44erhl7eu2z5nuuht:10250/proxy/logs/: <pre>
<a href="alicloud/">alicloud/</a>
<a href="anaconda/">anaconda/</a>
<a href="at.log">at.log... (200; 2.487649ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:22:46.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-d5k8k" for this suite.
Jan 21 09:22:52.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:22:52.704: INFO: namespace: e2e-tests-proxy-d5k8k, resource: bindings, ignored listing per whitelist
Jan 21 09:22:52.736: INFO: namespace e2e-tests-proxy-d5k8k deletion completed in 6.071367778s

• [SLOW TEST:6.198 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:22:52.737: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 21 09:22:55.313: INFO: Successfully updated pod "pod-update-20ea9316-1d5e-11e9-9c91-0a58ac100282"
STEP: verifying the updated pod is in kubernetes
Jan 21 09:22:55.317: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:22:55.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7sd2v" for this suite.
Jan 21 09:23:17.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:23:17.349: INFO: namespace: e2e-tests-pods-7sd2v, resource: bindings, ignored listing per whitelist
Jan 21 09:23:17.403: INFO: namespace e2e-tests-pods-7sd2v deletion completed in 22.082733879s

• [SLOW TEST:24.666 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:23:17.403: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 21 09:23:21.490: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:21.492: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 09:23:23.492: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:23.495: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 09:23:25.492: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:25.495: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 09:23:27.492: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:27.499: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 09:23:29.492: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:29.495: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 09:23:31.492: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:31.495: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 09:23:33.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 09:23:33.495: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:23:33.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7k58r" for this suite.
Jan 21 09:23:55.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:23:55.525: INFO: namespace: e2e-tests-container-lifecycle-hook-7k58r, resource: bindings, ignored listing per whitelist
Jan 21 09:23:55.568: INFO: namespace e2e-tests-container-lifecycle-hook-7k58r deletion completed in 22.070204042s

• [SLOW TEST:38.165 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:23:55.569: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-wtr2
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 09:23:55.632: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wtr2" in namespace "e2e-tests-subpath-v765n" to be "success or failure"
Jan 21 09:23:55.634: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.825526ms
Jan 21 09:23:57.637: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004414643s
Jan 21 09:23:59.659: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 4.027085983s
Jan 21 09:24:01.662: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 6.029993672s
Jan 21 09:24:03.665: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 8.032667492s
Jan 21 09:24:05.667: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 10.034903928s
Jan 21 09:24:07.670: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 12.037691613s
Jan 21 09:24:09.677: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 14.044471731s
Jan 21 09:24:11.680: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 16.047233669s
Jan 21 09:24:13.682: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 18.049791948s
Jan 21 09:24:15.685: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 20.052566285s
Jan 21 09:24:17.688: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Running", Reason="", readiness=false. Elapsed: 22.055409348s
Jan 21 09:24:19.694: INFO: Pod "pod-subpath-test-downwardapi-wtr2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061901064s
STEP: Saw pod success
Jan 21 09:24:19.694: INFO: Pod "pod-subpath-test-downwardapi-wtr2" satisfied condition "success or failure"
Jan 21 09:24:19.696: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-subpath-test-downwardapi-wtr2 container test-container-subpath-downwardapi-wtr2: <nil>
STEP: delete the pod
Jan 21 09:24:19.710: INFO: Waiting for pod pod-subpath-test-downwardapi-wtr2 to disappear
Jan 21 09:24:19.712: INFO: Pod pod-subpath-test-downwardapi-wtr2 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wtr2
Jan 21 09:24:19.712: INFO: Deleting pod "pod-subpath-test-downwardapi-wtr2" in namespace "e2e-tests-subpath-v765n"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:24:19.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v765n" for this suite.
Jan 21 09:24:25.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:24:25.761: INFO: namespace: e2e-tests-subpath-v765n, resource: bindings, ignored listing per whitelist
Jan 21 09:24:25.786: INFO: namespace e2e-tests-subpath-v765n deletion completed in 6.06948885s

• [SLOW TEST:30.217 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:24:25.786: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-58612a22-1d5e-11e9-9c91-0a58ac100282
STEP: Creating secret with name secret-projected-all-test-volume-586129e6-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 21 09:24:25.853: INFO: Waiting up to 5m0s for pod "projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-k6mkc" to be "success or failure"
Jan 21 09:24:25.855: INFO: Pod "projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.788863ms
Jan 21 09:24:27.857: INFO: Pod "projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004402544s
STEP: Saw pod success
Jan 21 09:24:27.857: INFO: Pod "projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:24:27.859: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 21 09:24:27.873: INFO: Waiting for pod projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:24:27.875: INFO: Pod projected-volume-586129ac-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:24:27.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k6mkc" for this suite.
Jan 21 09:24:33.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:24:33.951: INFO: namespace: e2e-tests-projected-k6mkc, resource: bindings, ignored listing per whitelist
Jan 21 09:24:33.955: INFO: namespace e2e-tests-projected-k6mkc deletion completed in 6.077235644s

• [SLOW TEST:8.169 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:24:33.955: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 21 09:24:34.007: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 21 09:24:34.012: INFO: Waiting for terminating namespaces to be deleted...
Jan 21 09:24:34.014: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuht before test
Jan 21 09:24:34.017: INFO: kube-proxy-worker-wtj4k from kube-system started at 2019-01-21 08:17:30 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.017: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 09:24:34.017: INFO: sonobuoy-e2e-job-0b58519d2e6c4c07 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.017: INFO: 	Container e2e ready: true, restart count 0
Jan 21 09:24:34.018: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:24:34.018: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-spkt6 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.018: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 09:24:34.018: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:24:34.018: INFO: kube-flannel-ds-g8c6v from kube-system started at 2019-01-21 08:17:30 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.018: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 09:24:34.018: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 21 09:24:34.018: INFO: flexvolume-4lfmg from kube-system started at 2019-01-21 08:17:41 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.018: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 09:24:34.018: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuhu before test
Jan 21 09:24:34.023: INFO: kube-flannel-ds-xxrn6 from kube-system started at 2019-01-21 08:17:28 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 09:24:34.023: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 21 09:24:34.023: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-7hhtj from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 09:24:34.023: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:24:34.023: INFO: metrics-server-54856586f-wnrsd from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container metrics-server ready: true, restart count 0
Jan 21 09:24:34.023: INFO: aliyun-acr-credential-helper-858f46c86d-5n5xg from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container aliyun-acr-credential-helper ready: true, restart count 0
Jan 21 09:24:34.023: INFO: tiller-deploy-57b7c996bc-svpwx from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container tiller ready: true, restart count 0
Jan 21 09:24:34.023: INFO: kube-proxy-worker-86qb8 from kube-system started at 2019-01-21 08:17:28 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 09:24:34.023: INFO: flexvolume-wt6rj from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 09:24:34.023: INFO: nginx-ingress-controller-645744f998-r4xfz from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 21 09:24:34.023: INFO: nginx-ingress-controller-645744f998-8z6m6 from kube-system started at 2019-01-21 08:17:40 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.023: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 21 09:24:34.023: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuhv before test
Jan 21 09:24:34.027: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-21 08:45:02 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.027: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 21 09:24:34.027: INFO: kube-flannel-ds-cgv55 from kube-system started at 2019-01-21 08:17:29 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.027: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 09:24:34.027: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 21 09:24:34.027: INFO: flexvolume-59z5z from kube-system started at 2019-01-21 08:17:40 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.027: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 09:24:34.027: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-6zr44 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:24:34.027: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 09:24:34.027: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:24:34.027: INFO: kube-proxy-worker-gq8p6 from kube-system started at 2019-01-21 08:17:29 +0000 UTC (1 container statuses recorded)
Jan 21 09:24:34.027: INFO: 	Container kube-proxy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node cn-hongkong.i-j6c44erhl7eu2z5nuuht
STEP: verifying the node has the label node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
STEP: verifying the node has the label node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
Jan 21 09:24:34.064: INFO: Pod sonobuoy requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
Jan 21 09:24:34.064: INFO: Pod sonobuoy-e2e-job-0b58519d2e6c4c07 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuht
Jan 21 09:24:34.064: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0800c708c434388-6zr44 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
Jan 21 09:24:34.064: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0800c708c434388-7hhtj requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0800c708c434388-spkt6 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuht
Jan 21 09:24:34.064: INFO: Pod aliyun-acr-credential-helper-858f46c86d-5n5xg requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod flexvolume-4lfmg requesting resource cpu=100m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuht
Jan 21 09:24:34.064: INFO: Pod flexvolume-59z5z requesting resource cpu=100m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
Jan 21 09:24:34.064: INFO: Pod flexvolume-wt6rj requesting resource cpu=100m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod kube-flannel-ds-cgv55 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
Jan 21 09:24:34.064: INFO: Pod kube-flannel-ds-g8c6v requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuht
Jan 21 09:24:34.064: INFO: Pod kube-flannel-ds-xxrn6 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod kube-proxy-worker-86qb8 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod kube-proxy-worker-gq8p6 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
Jan 21 09:24:34.064: INFO: Pod kube-proxy-worker-wtj4k requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuht
Jan 21 09:24:34.064: INFO: Pod metrics-server-54856586f-wnrsd requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod nginx-ingress-controller-645744f998-8z6m6 requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod nginx-ingress-controller-645744f998-r4xfz requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
Jan 21 09:24:34.064: INFO: Pod tiller-deploy-57b7c996bc-svpwx requesting resource cpu=0m on Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d480cd5-1d5e-11e9-9c91-0a58ac100282.157bd2ccd307ac55], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-ffcrq/filler-pod-5d480cd5-1d5e-11e9-9c91-0a58ac100282 to cn-hongkong.i-j6c44erhl7eu2z5nuuhv]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d480cd5-1d5e-11e9-9c91-0a58ac100282.157bd2ccfc0cdaaa], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d480cd5-1d5e-11e9-9c91-0a58ac100282.157bd2ccfdbb099d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d480cd5-1d5e-11e9-9c91-0a58ac100282.157bd2cd0a51acfd], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d48fdfb-1d5e-11e9-9c91-0a58ac100282.157bd2ccd3664cf2], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-ffcrq/filler-pod-5d48fdfb-1d5e-11e9-9c91-0a58ac100282 to cn-hongkong.i-j6c44erhl7eu2z5nuuht]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d48fdfb-1d5e-11e9-9c91-0a58ac100282.157bd2ccfed00e2f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d48fdfb-1d5e-11e9-9c91-0a58ac100282.157bd2cd021715ac], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d48fdfb-1d5e-11e9-9c91-0a58ac100282.157bd2cd0ec8ef70], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d4994a1-1d5e-11e9-9c91-0a58ac100282.157bd2ccd3607181], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-ffcrq/filler-pod-5d4994a1-1d5e-11e9-9c91-0a58ac100282 to cn-hongkong.i-j6c44erhl7eu2z5nuuhu]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d4994a1-1d5e-11e9-9c91-0a58ac100282.157bd2ccfd736c52], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d4994a1-1d5e-11e9-9c91-0a58ac100282.157bd2cd37496e86], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d4994a1-1d5e-11e9-9c91-0a58ac100282.157bd2cd39378430], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d4994a1-1d5e-11e9-9c91-0a58ac100282.157bd2cd46345f5a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157bd2cdc1f03f4a], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node cn-hongkong.i-j6c44erhl7eu2z5nuuht
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node cn-hongkong.i-j6c44erhl7eu2z5nuuhu
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node cn-hongkong.i-j6c44erhl7eu2z5nuuhv
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:24:39.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ffcrq" for this suite.
Jan 21 09:24:45.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:24:45.202: INFO: namespace: e2e-tests-sched-pred-ffcrq, resource: bindings, ignored listing per whitelist
Jan 21 09:24:45.215: INFO: namespace e2e-tests-sched-pred-ffcrq deletion completed in 6.075343942s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.260 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:24:45.216: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-63f577b9-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:24:45.276: INFO: Waiting up to 5m0s for pod "pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-2z6d9" to be "success or failure"
Jan 21 09:24:45.277: INFO: Pod "pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.529082ms
Jan 21 09:24:47.279: INFO: Pod "pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003846917s
STEP: Saw pod success
Jan 21 09:24:47.279: INFO: Pod "pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:24:47.281: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:24:47.297: INFO: Waiting for pod pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:24:47.298: INFO: Pod pod-secrets-63f61e36-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:24:47.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2z6d9" for this suite.
Jan 21 09:24:53.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:24:53.325: INFO: namespace: e2e-tests-secrets-2z6d9, resource: bindings, ignored listing per whitelist
Jan 21 09:24:53.372: INFO: namespace e2e-tests-secrets-2z6d9 deletion completed in 6.070992115s

• [SLOW TEST:8.156 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:24:53.372: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-68d20057-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:24:53.433: INFO: Waiting up to 5m0s for pod "pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-gbw9p" to be "success or failure"
Jan 21 09:24:53.435: INFO: Pod "pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.805208ms
Jan 21 09:24:55.438: INFO: Pod "pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004397369s
STEP: Saw pod success
Jan 21 09:24:55.438: INFO: Pod "pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:24:55.439: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:24:55.456: INFO: Waiting for pod pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:24:55.458: INFO: Pod pod-configmaps-68d2aef6-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:24:55.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gbw9p" for this suite.
Jan 21 09:25:01.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:25:01.498: INFO: namespace: e2e-tests-configmap-gbw9p, resource: bindings, ignored listing per whitelist
Jan 21 09:25:01.533: INFO: namespace e2e-tests-configmap-gbw9p deletion completed in 6.073177499s

• [SLOW TEST:8.161 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:25:01.534: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 09:25:01.585: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:25:05.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-66wbg" for this suite.
Jan 21 09:25:27.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:25:27.466: INFO: namespace: e2e-tests-init-container-66wbg, resource: bindings, ignored listing per whitelist
Jan 21 09:25:27.512: INFO: namespace e2e-tests-init-container-66wbg deletion completed in 22.072897148s

• [SLOW TEST:25.978 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:25:27.512: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 21 09:25:27.572: INFO: Waiting up to 5m0s for pod "pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-rvftk" to be "success or failure"
Jan 21 09:25:27.574: INFO: Pod "pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.949201ms
Jan 21 09:25:29.577: INFO: Pod "pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004498367s
STEP: Saw pod success
Jan 21 09:25:29.577: INFO: Pod "pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:25:29.579: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:25:29.593: INFO: Waiting for pod pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:25:29.595: INFO: Pod pod-7d2bcce7-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:25:29.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rvftk" for this suite.
Jan 21 09:25:35.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:25:35.653: INFO: namespace: e2e-tests-emptydir-rvftk, resource: bindings, ignored listing per whitelist
Jan 21 09:25:35.676: INFO: namespace e2e-tests-emptydir-rvftk deletion completed in 6.078591044s

• [SLOW TEST:8.164 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:25:35.676: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-82085aec-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:25:35.734: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-fwpjj" to be "success or failure"
Jan 21 09:25:35.735: INFO: Pod "pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.701014ms
Jan 21 09:25:37.738: INFO: Pod "pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004215688s
STEP: Saw pod success
Jan 21 09:25:37.738: INFO: Pod "pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:25:37.740: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:25:37.754: INFO: Waiting for pod pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:25:37.756: INFO: Pod pod-projected-configmaps-82094daf-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:25:37.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fwpjj" for this suite.
Jan 21 09:25:43.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:25:43.823: INFO: namespace: e2e-tests-projected-fwpjj, resource: bindings, ignored listing per whitelist
Jan 21 09:25:43.830: INFO: namespace e2e-tests-projected-fwpjj deletion completed in 6.071250984s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:25:43.830: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 21 09:25:43.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-nqjj6'
Jan 21 09:25:44.069: INFO: stderr: ""
Jan 21 09:25:44.069: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 21 09:25:45.072: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:25:45.072: INFO: Found 0 / 1
Jan 21 09:25:46.076: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:25:46.076: INFO: Found 1 / 1
Jan 21 09:25:46.076: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 21 09:25:46.078: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:25:46.078: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 21 09:25:46.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 patch pod redis-master-kvnmd --namespace=e2e-tests-kubectl-nqjj6 -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 21 09:25:46.161: INFO: stderr: ""
Jan 21 09:25:46.161: INFO: stdout: "pod/redis-master-kvnmd patched\n"
STEP: checking annotations
Jan 21 09:25:46.163: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:25:46.163: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:25:46.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nqjj6" for this suite.
Jan 21 09:26:08.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:26:08.222: INFO: namespace: e2e-tests-kubectl-nqjj6, resource: bindings, ignored listing per whitelist
Jan 21 09:26:08.239: INFO: namespace e2e-tests-kubectl-nqjj6 deletion completed in 22.072796341s

• [SLOW TEST:24.408 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:26:08.239: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-7fpsv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7fpsv to expose endpoints map[]
Jan 21 09:26:08.311: INFO: Get endpoints failed (2.272515ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 21 09:26:09.313: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7fpsv exposes endpoints map[] (1.004697655s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7fpsv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7fpsv to expose endpoints map[pod1:[100]]
Jan 21 09:26:11.332: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7fpsv exposes endpoints map[pod1:[100]] (2.011967063s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7fpsv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7fpsv to expose endpoints map[pod2:[101] pod1:[100]]
Jan 21 09:26:13.354: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7fpsv exposes endpoints map[pod1:[100] pod2:[101]] (2.017462688s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7fpsv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7fpsv to expose endpoints map[pod2:[101]]
Jan 21 09:26:14.368: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7fpsv exposes endpoints map[pod2:[101]] (1.009486815s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7fpsv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-7fpsv to expose endpoints map[]
Jan 21 09:26:15.379: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-7fpsv exposes endpoints map[] (1.004504698s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:26:15.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7fpsv" for this suite.
Jan 21 09:26:37.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:26:37.461: INFO: namespace: e2e-tests-services-7fpsv, resource: bindings, ignored listing per whitelist
Jan 21 09:26:37.467: INFO: namespace e2e-tests-services-7fpsv deletion completed in 22.071197434s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.229 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:26:37.468: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:26:37.519: INFO: Creating ReplicaSet my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282
Jan 21 09:26:37.526: INFO: Pod name my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282: Found 0 pods out of 1
Jan 21 09:26:42.533: INFO: Pod name my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282: Found 1 pods out of 1
Jan 21 09:26:42.533: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282" is running
Jan 21 09:26:42.534: INFO: Pod "my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282-rlws2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:26:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:26:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:26:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:26:37 +0000 UTC Reason: Message:}])
Jan 21 09:26:42.534: INFO: Trying to dial the pod
Jan 21 09:26:47.542: INFO: Controller my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282: Got expected result from replica 1 [my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282-rlws2]: "my-hostname-basic-a6ddce82-1d5e-11e9-9c91-0a58ac100282-rlws2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:26:47.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9szm5" for this suite.
Jan 21 09:26:53.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:26:53.590: INFO: namespace: e2e-tests-replicaset-9szm5, resource: bindings, ignored listing per whitelist
Jan 21 09:26:53.618: INFO: namespace e2e-tests-replicaset-9szm5 deletion completed in 6.072290846s

• [SLOW TEST:16.150 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:26:53.618: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b07db348-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:26:53.676: INFO: Waiting up to 5m0s for pod "pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-8nxft" to be "success or failure"
Jan 21 09:26:53.678: INFO: Pod "pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.64108ms
Jan 21 09:26:55.680: INFO: Pod "pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004214313s
STEP: Saw pod success
Jan 21 09:26:55.680: INFO: Pod "pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:26:55.682: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:26:55.697: INFO: Waiting for pod pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:26:55.701: INFO: Pod pod-secrets-b07e7436-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:26:55.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8nxft" for this suite.
Jan 21 09:27:01.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:27:01.731: INFO: namespace: e2e-tests-secrets-8nxft, resource: bindings, ignored listing per whitelist
Jan 21 09:27:01.780: INFO: namespace e2e-tests-secrets-8nxft deletion completed in 6.076227396s

• [SLOW TEST:8.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:27:01.780: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-2tt5z/secret-test-b55b6f29-1d5e-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:27:01.840: INFO: Waiting up to 5m0s for pod "pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-2tt5z" to be "success or failure"
Jan 21 09:27:01.842: INFO: Pod "pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002785ms
Jan 21 09:27:03.848: INFO: Pod "pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008142912s
STEP: Saw pod success
Jan 21 09:27:03.848: INFO: Pod "pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:27:03.850: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282 container env-test: <nil>
STEP: delete the pod
Jan 21 09:27:03.865: INFO: Waiting for pod pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:27:03.868: INFO: Pod pod-configmaps-b55c24b2-1d5e-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:27:03.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2tt5z" for this suite.
Jan 21 09:27:09.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:27:09.905: INFO: namespace: e2e-tests-secrets-2tt5z, resource: bindings, ignored listing per whitelist
Jan 21 09:27:09.941: INFO: namespace e2e-tests-secrets-2tt5z deletion completed in 6.070263949s

• [SLOW TEST:8.160 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:27:09.941: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 21 09:27:10.010: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:10.010: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:10.010: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:10.012: INFO: Number of nodes with available pods: 0
Jan 21 09:27:10.012: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:27:11.015: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:11.015: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:11.015: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:11.018: INFO: Number of nodes with available pods: 0
Jan 21 09:27:11.018: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:27:12.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:12.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:12.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:12.022: INFO: Number of nodes with available pods: 3
Jan 21 09:27:12.022: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 21 09:27:12.035: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:12.035: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:12.035: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:27:12.039: INFO: Number of nodes with available pods: 3
Jan 21 09:27:12.039: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-7slf8, will wait for the garbage collector to delete the pods
Jan 21 09:27:13.102: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.213927ms
Jan 21 09:27:13.202: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.166934ms
Jan 21 09:28:56.409: INFO: Number of nodes with available pods: 0
Jan 21 09:28:56.409: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 09:28:56.410: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7slf8/daemonsets","resourceVersion":"17797"},"items":null}

Jan 21 09:28:56.412: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7slf8/pods","resourceVersion":"17797"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:28:56.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7slf8" for this suite.
Jan 21 09:29:02.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:29:02.471: INFO: namespace: e2e-tests-daemonsets-7slf8, resource: bindings, ignored listing per whitelist
Jan 21 09:29:02.500: INFO: namespace e2e-tests-daemonsets-7slf8 deletion completed in 6.076805058s

• [SLOW TEST:112.559 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:29:02.500: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:29:02.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9cwbc" for this suite.
Jan 21 09:29:08.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:29:08.621: INFO: namespace: e2e-tests-services-9cwbc, resource: bindings, ignored listing per whitelist
Jan 21 09:29:08.625: INFO: namespace e2e-tests-services-9cwbc deletion completed in 6.069321608s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.124 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:29:08.625: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:29:08.676: INFO: Creating deployment "test-recreate-deployment"
Jan 21 09:29:08.682: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 21 09:29:08.686: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 21 09:29:10.691: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 21 09:29:10.693: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 21 09:29:10.700: INFO: Updating deployment test-recreate-deployment
Jan 21 09:29:10.700: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 09:29:10.758: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-xtzhd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xtzhd/deployments/test-recreate-deployment,UID:00f662a8-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:17922,Generation:2,CreationTimestamp:2019-01-21 09:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-21 09:29:10 +0000 UTC 2019-01-21 09:29:10 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-21 09:29:10 +0000 UTC 2019-01-21 09:29:08 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 21 09:29:10.761: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-xtzhd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xtzhd/replicasets/test-recreate-deployment-7cf749666b,UID:022e84b2-1d5f-11e9-9352-00163e04cddc,ResourceVersion:17921,Generation:1,CreationTimestamp:2019-01-21 09:29:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 00f662a8-1d5f-11e9-8ca7-00163e00ea4b 0xc4221959d7 0xc4221959d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 09:29:10.761: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 21 09:29:10.761: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-xtzhd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xtzhd/replicasets/test-recreate-deployment-79f694ff59,UID:00f7b656-1d5f-11e9-9352-00163e04cddc,ResourceVersion:17910,Generation:2,CreationTimestamp:2019-01-21 09:29:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 00f662a8-1d5f-11e9-8ca7-00163e00ea4b 0xc4221958d7 0xc4221958d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 09:29:10.763: INFO: Pod "test-recreate-deployment-7cf749666b-kksj8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-kksj8,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-xtzhd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xtzhd/pods/test-recreate-deployment-7cf749666b-kksj8,UID:022f2d8c-1d5f-11e9-9352-00163e04cddc,ResourceVersion:17920,Generation:0,CreationTimestamp:2019-01-21 09:29:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 022e84b2-1d5f-11e9-9352-00163e04cddc 0xc421b7a357 0xc421b7a358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xkmrv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xkmrv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xkmrv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuht,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b7a3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b7a3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:29:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:29:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:29:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:29:10 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.76,PodIP:,StartTime:2019-01-21 09:29:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:29:10.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xtzhd" for this suite.
Jan 21 09:29:16.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:29:16.809: INFO: namespace: e2e-tests-deployment-xtzhd, resource: bindings, ignored listing per whitelist
Jan 21 09:29:16.838: INFO: namespace e2e-tests-deployment-xtzhd deletion completed in 6.072732211s

• [SLOW TEST:8.214 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:29:16.838: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-05dbce25-1d5f-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:29:16.925: INFO: Waiting up to 5m0s for pod "pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-v6t67" to be "success or failure"
Jan 21 09:29:16.928: INFO: Pod "pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.620706ms
Jan 21 09:29:18.930: INFO: Pod "pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005146805s
STEP: Saw pod success
Jan 21 09:29:18.930: INFO: Pod "pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:29:18.932: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:29:18.947: INFO: Waiting for pod pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:29:18.949: INFO: Pod pod-secrets-05e08987-1d5f-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:29:18.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v6t67" for this suite.
Jan 21 09:29:24.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:29:24.969: INFO: namespace: e2e-tests-secrets-v6t67, resource: bindings, ignored listing per whitelist
Jan 21 09:29:25.025: INFO: namespace e2e-tests-secrets-v6t67 deletion completed in 6.073712306s
STEP: Destroying namespace "e2e-tests-secret-namespace-dnb8k" for this suite.
Jan 21 09:29:31.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:29:31.082: INFO: namespace: e2e-tests-secret-namespace-dnb8k, resource: bindings, ignored listing per whitelist
Jan 21 09:29:31.096: INFO: namespace e2e-tests-secret-namespace-dnb8k deletion completed in 6.071315623s

• [SLOW TEST:14.258 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:29:31.097: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 21 09:29:31.163: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18042,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 09:29:31.163: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18042,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 21 09:29:41.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18068,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 21 09:29:41.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18068,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 21 09:29:51.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18095,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 09:29:51.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18095,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 21 09:30:01.196: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18121,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 09:30:01.196: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-a,UID:0e5cec37-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18121,Generation:0,CreationTimestamp:2019-01-21 09:29:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 21 09:30:11.205: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-b,UID:263aedeb-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18147,Generation:0,CreationTimestamp:2019-01-21 09:30:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 09:30:11.205: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-b,UID:263aedeb-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18147,Generation:0,CreationTimestamp:2019-01-21 09:30:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 21 09:30:21.215: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-b,UID:263aedeb-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18174,Generation:0,CreationTimestamp:2019-01-21 09:30:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 09:30:21.215: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-97lrb,SelfLink:/api/v1/namespaces/e2e-tests-watch-97lrb/configmaps/e2e-watch-test-configmap-b,UID:263aedeb-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18174,Generation:0,CreationTimestamp:2019-01-21 09:30:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:30:31.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-97lrb" for this suite.
Jan 21 09:30:37.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:30:37.278: INFO: namespace: e2e-tests-watch-97lrb, resource: bindings, ignored listing per whitelist
Jan 21 09:30:37.297: INFO: namespace e2e-tests-watch-97lrb deletion completed in 6.07329375s

• [SLOW TEST:66.200 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:30:37.297: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:30:37.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xrd84" for this suite.
Jan 21 09:30:59.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:30:59.450: INFO: namespace: e2e-tests-pods-xrd84, resource: bindings, ignored listing per whitelist
Jan 21 09:30:59.457: INFO: namespace e2e-tests-pods-xrd84 deletion completed in 22.082262266s

• [SLOW TEST:22.160 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:30:59.457: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-mt7l
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 09:30:59.533: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mt7l" in namespace "e2e-tests-subpath-pnpwc" to be "success or failure"
Jan 21 09:30:59.535: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Pending", Reason="", readiness=false. Elapsed: 1.643538ms
Jan 21 09:31:01.537: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003899995s
Jan 21 09:31:03.543: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 4.009510734s
Jan 21 09:31:05.546: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 6.012712282s
Jan 21 09:31:07.548: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 8.014959121s
Jan 21 09:31:09.552: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 10.018338608s
Jan 21 09:31:11.554: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 12.021010165s
Jan 21 09:31:13.561: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 14.027352604s
Jan 21 09:31:15.563: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 16.030058451s
Jan 21 09:31:17.566: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 18.032591s
Jan 21 09:31:19.569: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 20.035291458s
Jan 21 09:31:21.571: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Running", Reason="", readiness=false. Elapsed: 22.038051236s
Jan 21 09:31:23.578: INFO: Pod "pod-subpath-test-configmap-mt7l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044319723s
STEP: Saw pod success
Jan 21 09:31:23.578: INFO: Pod "pod-subpath-test-configmap-mt7l" satisfied condition "success or failure"
Jan 21 09:31:23.580: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-subpath-test-configmap-mt7l container test-container-subpath-configmap-mt7l: <nil>
STEP: delete the pod
Jan 21 09:31:23.594: INFO: Waiting for pod pod-subpath-test-configmap-mt7l to disappear
Jan 21 09:31:23.596: INFO: Pod pod-subpath-test-configmap-mt7l no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mt7l
Jan 21 09:31:23.596: INFO: Deleting pod "pod-subpath-test-configmap-mt7l" in namespace "e2e-tests-subpath-pnpwc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:31:23.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-pnpwc" for this suite.
Jan 21 09:31:29.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:31:29.625: INFO: namespace: e2e-tests-subpath-pnpwc, resource: bindings, ignored listing per whitelist
Jan 21 09:31:29.673: INFO: namespace e2e-tests-subpath-pnpwc deletion completed in 6.070630294s

• [SLOW TEST:30.216 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:31:29.674: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 09:31:29.732: INFO: Waiting up to 5m0s for pod "downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-sm2vc" to be "success or failure"
Jan 21 09:31:29.734: INFO: Pod "downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.886402ms
Jan 21 09:31:31.736: INFO: Pod "downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004668018s
STEP: Saw pod success
Jan 21 09:31:31.736: INFO: Pod "downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:31:31.738: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 09:31:31.754: INFO: Waiting for pod downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:31:31.755: INFO: Pod downward-api-5508c858-1d5f-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:31:31.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sm2vc" for this suite.
Jan 21 09:31:37.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:31:37.825: INFO: namespace: e2e-tests-downward-api-sm2vc, resource: bindings, ignored listing per whitelist
Jan 21 09:31:37.828: INFO: namespace e2e-tests-downward-api-sm2vc deletion completed in 6.069961928s

• [SLOW TEST:8.155 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:31:37.829: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 21 09:31:37.884: INFO: Waiting up to 5m0s for pod "var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282" in namespace "e2e-tests-var-expansion-dknqc" to be "success or failure"
Jan 21 09:31:37.886: INFO: Pod "var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.7574ms
Jan 21 09:31:39.889: INFO: Pod "var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004278702s
STEP: Saw pod success
Jan 21 09:31:39.889: INFO: Pod "var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:31:39.890: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 09:31:39.904: INFO: Waiting for pod var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:31:39.906: INFO: Pod var-expansion-59e4c834-1d5f-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:31:39.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-dknqc" for this suite.
Jan 21 09:31:45.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:31:45.962: INFO: namespace: e2e-tests-var-expansion-dknqc, resource: bindings, ignored listing per whitelist
Jan 21 09:31:45.978: INFO: namespace e2e-tests-var-expansion-dknqc deletion completed in 6.069063896s

• [SLOW TEST:8.149 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:31:45.978: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:31:46.035: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-vfkwk" to be "success or failure"
Jan 21 09:31:46.037: INFO: Pod "downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266062ms
Jan 21 09:31:48.040: INFO: Pod "downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004938481s
STEP: Saw pod success
Jan 21 09:31:48.040: INFO: Pod "downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:31:48.042: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:31:48.056: INFO: Waiting for pod downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:31:48.058: INFO: Pod downwardapi-volume-5ec0733e-1d5f-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:31:48.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vfkwk" for this suite.
Jan 21 09:31:54.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:31:54.095: INFO: namespace: e2e-tests-downward-api-vfkwk, resource: bindings, ignored listing per whitelist
Jan 21 09:31:54.138: INFO: namespace e2e-tests-downward-api-vfkwk deletion completed in 6.076983986s

• [SLOW TEST:8.160 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:31:54.138: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 21 09:31:54.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hzz4g,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzz4g/configmaps/e2e-watch-test-watch-closed,UID:63a01cba-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18548,Generation:0,CreationTimestamp:2019-01-21 09:31:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 09:31:54.213: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hzz4g,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzz4g/configmaps/e2e-watch-test-watch-closed,UID:63a01cba-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18549,Generation:0,CreationTimestamp:2019-01-21 09:31:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 21 09:31:54.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hzz4g,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzz4g/configmaps/e2e-watch-test-watch-closed,UID:63a01cba-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18550,Generation:0,CreationTimestamp:2019-01-21 09:31:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 09:31:54.223: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-hzz4g,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzz4g/configmaps/e2e-watch-test-watch-closed,UID:63a01cba-1d5f-11e9-8ca7-00163e00ea4b,ResourceVersion:18551,Generation:0,CreationTimestamp:2019-01-21 09:31:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:31:54.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hzz4g" for this suite.
Jan 21 09:32:00.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:32:00.240: INFO: namespace: e2e-tests-watch-hzz4g, resource: bindings, ignored listing per whitelist
Jan 21 09:32:00.299: INFO: namespace e2e-tests-watch-hzz4g deletion completed in 6.072432995s

• [SLOW TEST:6.161 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:32:00.299: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t7vrf
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-t7vrf
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-t7vrf
Jan 21 09:32:00.388: INFO: Found 0 stateful pods, waiting for 1
Jan 21 09:32:10.394: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 21 09:32:10.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:32:10.648: INFO: stderr: ""
Jan 21 09:32:10.648: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:32:10.648: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:32:10.650: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:32:10.650: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:32:10.655: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 21 09:32:20.670: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999954s
Jan 21 09:32:21.673: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997699605s
Jan 21 09:32:22.675: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995014647s
Jan 21 09:32:23.678: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.99247413s
Jan 21 09:32:24.681: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989644026s
Jan 21 09:32:25.684: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986779716s
Jan 21 09:32:26.686: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.98410962s
Jan 21 09:32:27.689: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.981298423s
Jan 21 09:32:28.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.978442161s
Jan 21 09:32:29.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 975.593744ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-t7vrf
Jan 21 09:32:30.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:32:30.941: INFO: stderr: ""
Jan 21 09:32:30.941: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:32:30.941: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:32:30.943: INFO: Found 1 stateful pods, waiting for 3
Jan 21 09:32:40.950: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:32:40.950: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:32:40.950: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 21 09:32:40.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:32:41.197: INFO: stderr: ""
Jan 21 09:32:41.197: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:32:41.197: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:32:41.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:32:41.441: INFO: stderr: ""
Jan 21 09:32:41.441: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:32:41.441: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:32:41.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 09:32:41.703: INFO: stderr: ""
Jan 21 09:32:41.703: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 09:32:41.703: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 09:32:41.703: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:32:41.706: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 21 09:32:51.714: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:32:51.714: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:32:51.714: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 09:32:51.723: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999524s
Jan 21 09:32:52.726: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997699309s
Jan 21 09:32:53.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99478021s
Jan 21 09:32:54.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991612461s
Jan 21 09:32:55.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988725968s
Jan 21 09:32:56.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985740492s
Jan 21 09:32:57.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982898367s
Jan 21 09:32:58.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979066403s
Jan 21 09:32:59.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976276983s
Jan 21 09:33:00.750: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.128175ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-t7vrf
Jan 21 09:33:01.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:33:01.986: INFO: stderr: ""
Jan 21 09:33:01.986: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:33:01.986: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:33:01.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:33:02.241: INFO: stderr: ""
Jan 21 09:33:02.241: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:33:02.241: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:33:02.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 exec --namespace=e2e-tests-statefulset-t7vrf ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 09:33:02.494: INFO: stderr: ""
Jan 21 09:33:02.494: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 09:33:02.494: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 09:33:02.494: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 09:33:12.521: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t7vrf
Jan 21 09:33:12.523: INFO: Scaling statefulset ss to 0
Jan 21 09:33:12.530: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:33:12.532: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:33:12.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t7vrf" for this suite.
Jan 21 09:33:18.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:33:18.587: INFO: namespace: e2e-tests-statefulset-t7vrf, resource: bindings, ignored listing per whitelist
Jan 21 09:33:18.623: INFO: namespace e2e-tests-statefulset-t7vrf deletion completed in 6.072413974s

• [SLOW TEST:78.324 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:33:18.623: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-95f9878b-1d5f-11e9-9c91-0a58ac100282
STEP: Creating secret with name s-test-opt-upd-95f987ce-1d5f-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-95f9878b-1d5f-11e9-9c91-0a58ac100282
STEP: Updating secret s-test-opt-upd-95f987ce-1d5f-11e9-9c91-0a58ac100282
STEP: Creating secret with name s-test-opt-create-95f987e7-1d5f-11e9-9c91-0a58ac100282
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:33:22.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fdt4k" for this suite.
Jan 21 09:33:44.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:33:44.803: INFO: namespace: e2e-tests-projected-fdt4k, resource: bindings, ignored listing per whitelist
Jan 21 09:33:44.821: INFO: namespace e2e-tests-projected-fdt4k deletion completed in 22.072640301s

• [SLOW TEST:26.197 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:33:44.821: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 21 09:33:44.880: INFO: Waiting up to 5m0s for pod "pod-a596d037-1d5f-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-qqpws" to be "success or failure"
Jan 21 09:33:44.882: INFO: Pod "pod-a596d037-1d5f-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.689304ms
Jan 21 09:33:46.884: INFO: Pod "pod-a596d037-1d5f-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004029884s
STEP: Saw pod success
Jan 21 09:33:46.884: INFO: Pod "pod-a596d037-1d5f-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:33:46.886: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-a596d037-1d5f-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:33:46.906: INFO: Waiting for pod pod-a596d037-1d5f-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:33:46.908: INFO: Pod pod-a596d037-1d5f-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:33:46.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qqpws" for this suite.
Jan 21 09:33:52.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:33:52.952: INFO: namespace: e2e-tests-emptydir-qqpws, resource: bindings, ignored listing per whitelist
Jan 21 09:33:52.983: INFO: namespace e2e-tests-emptydir-qqpws deletion completed in 6.072230369s

• [SLOW TEST:8.162 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:33:52.983: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-wrvhw
Jan 21 09:33:55.050: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-wrvhw
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 09:33:55.052: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:37:55.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wrvhw" for this suite.
Jan 21 09:38:01.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:38:01.541: INFO: namespace: e2e-tests-container-probe-wrvhw, resource: bindings, ignored listing per whitelist
Jan 21 09:38:01.547: INFO: namespace e2e-tests-container-probe-wrvhw deletion completed in 6.069944933s

• [SLOW TEST:248.564 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:38:01.547: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 21 09:38:01.613: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 21 09:38:01.619: INFO: Waiting for terminating namespaces to be deleted...
Jan 21 09:38:01.620: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuht before test
Jan 21 09:38:01.625: INFO: kube-proxy-worker-wtj4k from kube-system started at 2019-01-21 08:17:30 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.625: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 09:38:01.625: INFO: sonobuoy-e2e-job-0b58519d2e6c4c07 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.625: INFO: 	Container e2e ready: true, restart count 0
Jan 21 09:38:01.625: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:38:01.625: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-spkt6 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.625: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 09:38:01.625: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:38:01.625: INFO: kube-flannel-ds-g8c6v from kube-system started at 2019-01-21 08:17:30 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.625: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 09:38:01.625: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 21 09:38:01.625: INFO: flexvolume-4lfmg from kube-system started at 2019-01-21 08:17:41 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.625: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 09:38:01.625: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuhu before test
Jan 21 09:38:01.631: INFO: nginx-ingress-controller-645744f998-r4xfz from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 21 09:38:01.631: INFO: nginx-ingress-controller-645744f998-8z6m6 from kube-system started at 2019-01-21 08:17:40 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 21 09:38:01.631: INFO: kube-flannel-ds-xxrn6 from kube-system started at 2019-01-21 08:17:28 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 09:38:01.631: INFO: 	Container kube-flannel ready: true, restart count 0
Jan 21 09:38:01.631: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-7hhtj from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 09:38:01.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:38:01.631: INFO: metrics-server-54856586f-wnrsd from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container metrics-server ready: true, restart count 0
Jan 21 09:38:01.631: INFO: aliyun-acr-credential-helper-858f46c86d-5n5xg from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container aliyun-acr-credential-helper ready: true, restart count 0
Jan 21 09:38:01.631: INFO: tiller-deploy-57b7c996bc-svpwx from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container tiller ready: true, restart count 0
Jan 21 09:38:01.631: INFO: kube-proxy-worker-86qb8 from kube-system started at 2019-01-21 08:17:28 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 09:38:01.631: INFO: flexvolume-wt6rj from kube-system started at 2019-01-21 08:17:39 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.631: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 09:38:01.631: INFO: 
Logging pods the kubelet thinks is on node cn-hongkong.i-j6c44erhl7eu2z5nuuhv before test
Jan 21 09:38:01.636: INFO: kube-flannel-ds-cgv55 from kube-system started at 2019-01-21 08:17:29 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.636: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 09:38:01.636: INFO: 	Container kube-flannel ready: true, restart count 1
Jan 21 09:38:01.636: INFO: flexvolume-59z5z from kube-system started at 2019-01-21 08:17:40 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.636: INFO: 	Container acs-flexvolume ready: true, restart count 0
Jan 21 09:38:01.636: INFO: sonobuoy-systemd-logs-daemon-set-a0800c708c434388-6zr44 from heptio-sonobuoy started at 2019-01-21 08:45:06 +0000 UTC (2 container statuses recorded)
Jan 21 09:38:01.636: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 09:38:01.636: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 09:38:01.636: INFO: kube-proxy-worker-gq8p6 from kube-system started at 2019-01-21 08:17:29 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.636: INFO: 	Container kube-proxy-worker ready: true, restart count 0
Jan 21 09:38:01.636: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-21 08:45:02 +0000 UTC (1 container statuses recorded)
Jan 21 09:38:01.636: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157bd388d95efa24], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:38:02.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-js6r6" for this suite.
Jan 21 09:38:08.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:38:08.699: INFO: namespace: e2e-tests-sched-pred-js6r6, resource: bindings, ignored listing per whitelist
Jan 21 09:38:08.728: INFO: namespace e2e-tests-sched-pred-js6r6 deletion completed in 6.071533768s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.181 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:38:08.728: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-42e3b52c-1d60-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:38:08.789: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-92gxh" to be "success or failure"
Jan 21 09:38:08.791: INFO: Pod "pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.664944ms
Jan 21 09:38:10.793: INFO: Pod "pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004135761s
STEP: Saw pod success
Jan 21 09:38:10.793: INFO: Pod "pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:38:10.795: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:38:10.809: INFO: Waiting for pod pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:38:10.811: INFO: Pod pod-projected-configmaps-42e46491-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:38:10.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-92gxh" for this suite.
Jan 21 09:38:16.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:38:16.856: INFO: namespace: e2e-tests-projected-92gxh, resource: bindings, ignored listing per whitelist
Jan 21 09:38:16.885: INFO: namespace e2e-tests-projected-92gxh deletion completed in 6.071578692s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:38:16.886: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 21 09:38:19.461: INFO: Successfully updated pod "pod-update-activedeadlineseconds-47c0fe52-1d60-11e9-9c91-0a58ac100282"
Jan 21 09:38:19.462: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-47c0fe52-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-pods-kmkzf" to be "terminated due to deadline exceeded"
Jan 21 09:38:19.463: INFO: Pod "pod-update-activedeadlineseconds-47c0fe52-1d60-11e9-9c91-0a58ac100282": Phase="Running", Reason="", readiness=true. Elapsed: 1.799033ms
Jan 21 09:38:21.466: INFO: Pod "pod-update-activedeadlineseconds-47c0fe52-1d60-11e9-9c91-0a58ac100282": Phase="Running", Reason="", readiness=true. Elapsed: 2.004471751s
Jan 21 09:38:23.469: INFO: Pod "pod-update-activedeadlineseconds-47c0fe52-1d60-11e9-9c91-0a58ac100282": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007198354s
Jan 21 09:38:23.469: INFO: Pod "pod-update-activedeadlineseconds-47c0fe52-1d60-11e9-9c91-0a58ac100282" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:38:23.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kmkzf" for this suite.
Jan 21 09:38:29.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:38:29.510: INFO: namespace: e2e-tests-pods-kmkzf, resource: bindings, ignored listing per whitelist
Jan 21 09:38:29.547: INFO: namespace e2e-tests-pods-kmkzf deletion completed in 6.07551714s

• [SLOW TEST:12.662 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:38:29.548: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:38:31.642: INFO: Waiting up to 5m0s for pod "client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-pods-txvlc" to be "success or failure"
Jan 21 09:38:31.644: INFO: Pod "client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079606ms
Jan 21 09:38:33.647: INFO: Pod "client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004969924s
STEP: Saw pod success
Jan 21 09:38:33.647: INFO: Pod "client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:38:33.649: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282 container env3cont: <nil>
STEP: delete the pod
Jan 21 09:38:33.663: INFO: Waiting for pod client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:38:33.665: INFO: Pod client-envvars-5083a822-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:38:33.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-txvlc" for this suite.
Jan 21 09:39:23.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:39:23.732: INFO: namespace: e2e-tests-pods-txvlc, resource: bindings, ignored listing per whitelist
Jan 21 09:39:23.753: INFO: namespace e2e-tests-pods-txvlc deletion completed in 50.084108768s

• [SLOW TEST:54.205 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:39:23.753: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 09:39:23.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zshdz'
Jan 21 09:39:24.153: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 09:39:24.153: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan 21 09:39:26.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-zshdz'
Jan 21 09:39:26.252: INFO: stderr: ""
Jan 21 09:39:26.252: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:39:26.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zshdz" for this suite.
Jan 21 09:39:32.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:39:32.302: INFO: namespace: e2e-tests-kubectl-zshdz, resource: bindings, ignored listing per whitelist
Jan 21 09:39:32.350: INFO: namespace e2e-tests-kubectl-zshdz deletion completed in 6.089003413s

• [SLOW TEST:8.597 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:39:32.350: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 21 09:39:34.424: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-74bbd334-1d60-11e9-9c91-0a58ac100282", GenerateName:"", Namespace:"e2e-tests-pods-tw4x2", SelfLink:"/api/v1/namespaces/e2e-tests-pods-tw4x2/pods/pod-submit-remove-74bbd334-1d60-11e9-9c91-0a58ac100282", UID:"74bce99f-1d60-11e9-8ca7-00163e00ea4b", ResourceVersion:"20183", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683660372, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"404311837"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-mxgvg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42187f480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mxgvg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421371278), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cn-hongkong.i-j6c44erhl7eu2z5nuuht", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422567c20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4213712e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421371300)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421371308), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660372, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660374, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660374, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660372, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.76", PodIP:"172.16.2.225", StartTime:(*v1.Time)(0xc420b3d520), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420b3d5c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://b85102c2638b90b67ffe84c7e8a3b1dddec819aa764591b5a4fce02e5418179a"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 21 09:39:39.436: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:39:39.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tw4x2" for this suite.
Jan 21 09:39:45.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:39:45.486: INFO: namespace: e2e-tests-pods-tw4x2, resource: bindings, ignored listing per whitelist
Jan 21 09:39:45.517: INFO: namespace e2e-tests-pods-tw4x2 deletion completed in 6.075113783s

• [SLOW TEST:13.167 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:39:45.517: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 21 09:39:45.583: INFO: Waiting up to 5m0s for pod "pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-w92q5" to be "success or failure"
Jan 21 09:39:45.584: INFO: Pod "pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.571497ms
Jan 21 09:39:47.587: INFO: Pod "pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004165722s
STEP: Saw pod success
Jan 21 09:39:47.587: INFO: Pod "pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:39:47.589: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:39:47.603: INFO: Waiting for pod pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:39:47.605: INFO: Pod pod-7c95d0e6-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:39:47.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w92q5" for this suite.
Jan 21 09:39:53.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:39:53.646: INFO: namespace: e2e-tests-emptydir-w92q5, resource: bindings, ignored listing per whitelist
Jan 21 09:39:53.680: INFO: namespace e2e-tests-emptydir-w92q5 deletion completed in 6.07250063s

• [SLOW TEST:8.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:39:53.681: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-bp8r
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 09:39:53.743: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bp8r" in namespace "e2e-tests-subpath-t5788" to be "success or failure"
Jan 21 09:39:53.745: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Pending", Reason="", readiness=false. Elapsed: 1.862545ms
Jan 21 09:39:55.751: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008172791s
Jan 21 09:39:57.754: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 4.01093307s
Jan 21 09:39:59.757: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 6.013590747s
Jan 21 09:40:01.760: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 8.01639742s
Jan 21 09:40:03.762: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 10.019238083s
Jan 21 09:40:05.769: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 12.025558932s
Jan 21 09:40:07.772: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 14.028558913s
Jan 21 09:40:09.774: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 16.031105593s
Jan 21 09:40:11.777: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 18.033703004s
Jan 21 09:40:13.780: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 20.036447077s
Jan 21 09:40:15.786: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Running", Reason="", readiness=false. Elapsed: 22.042646234s
Jan 21 09:40:17.789: INFO: Pod "pod-subpath-test-projected-bp8r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.045604427s
STEP: Saw pod success
Jan 21 09:40:17.789: INFO: Pod "pod-subpath-test-projected-bp8r" satisfied condition "success or failure"
Jan 21 09:40:17.791: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-subpath-test-projected-bp8r container test-container-subpath-projected-bp8r: <nil>
STEP: delete the pod
Jan 21 09:40:17.808: INFO: Waiting for pod pod-subpath-test-projected-bp8r to disappear
Jan 21 09:40:17.810: INFO: Pod pod-subpath-test-projected-bp8r no longer exists
STEP: Deleting pod pod-subpath-test-projected-bp8r
Jan 21 09:40:17.810: INFO: Deleting pod "pod-subpath-test-projected-bp8r" in namespace "e2e-tests-subpath-t5788"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:40:17.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-t5788" for this suite.
Jan 21 09:40:23.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:40:23.841: INFO: namespace: e2e-tests-subpath-t5788, resource: bindings, ignored listing per whitelist
Jan 21 09:40:23.886: INFO: namespace e2e-tests-subpath-t5788 deletion completed in 6.071613995s

• [SLOW TEST:30.205 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:40:23.886: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 21 09:40:23.943: INFO: Waiting up to 5m0s for pod "pod-9373314d-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-wdsjq" to be "success or failure"
Jan 21 09:40:23.946: INFO: Pod "pod-9373314d-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.313333ms
Jan 21 09:40:25.951: INFO: Pod "pod-9373314d-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00797638s
STEP: Saw pod success
Jan 21 09:40:25.951: INFO: Pod "pod-9373314d-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:40:25.953: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-9373314d-1d60-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:40:25.967: INFO: Waiting for pod pod-9373314d-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:40:25.969: INFO: Pod pod-9373314d-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:40:25.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wdsjq" for this suite.
Jan 21 09:40:31.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:40:31.992: INFO: namespace: e2e-tests-emptydir-wdsjq, resource: bindings, ignored listing per whitelist
Jan 21 09:40:32.046: INFO: namespace e2e-tests-emptydir-wdsjq deletion completed in 6.074763646s

• [SLOW TEST:8.160 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:40:32.046: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 21 09:40:32.112: INFO: Waiting up to 5m0s for pod "pod-985178c0-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-lhfjp" to be "success or failure"
Jan 21 09:40:32.114: INFO: Pod "pod-985178c0-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.92316ms
Jan 21 09:40:34.117: INFO: Pod "pod-985178c0-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004514751s
STEP: Saw pod success
Jan 21 09:40:34.117: INFO: Pod "pod-985178c0-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:40:34.119: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-985178c0-1d60-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:40:34.132: INFO: Waiting for pod pod-985178c0-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:40:34.134: INFO: Pod pod-985178c0-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:40:34.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lhfjp" for this suite.
Jan 21 09:40:40.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:40:40.150: INFO: namespace: e2e-tests-emptydir-lhfjp, resource: bindings, ignored listing per whitelist
Jan 21 09:40:40.208: INFO: namespace e2e-tests-emptydir-lhfjp deletion completed in 6.070773919s

• [SLOW TEST:8.161 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:40:40.208: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 21 09:40:40.258: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-484689981 proxy --unix-socket=/tmp/kubectl-proxy-unix731746936/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:40:40.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jdkmf" for this suite.
Jan 21 09:40:46.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:40:46.397: INFO: namespace: e2e-tests-kubectl-jdkmf, resource: bindings, ignored listing per whitelist
Jan 21 09:40:46.400: INFO: namespace e2e-tests-kubectl-jdkmf deletion completed in 6.077503332s

• [SLOW TEST:6.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:40:46.400: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:40:46.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-tx4v8" to be "success or failure"
Jan 21 09:40:46.457: INFO: Pod "downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.992569ms
Jan 21 09:40:48.460: INFO: Pod "downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005953128s
STEP: Saw pod success
Jan 21 09:40:48.460: INFO: Pod "downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:40:48.462: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:40:48.475: INFO: Waiting for pod downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:40:48.477: INFO: Pod downwardapi-volume-a0de0bba-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:40:48.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tx4v8" for this suite.
Jan 21 09:40:54.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:40:54.524: INFO: namespace: e2e-tests-projected-tx4v8, resource: bindings, ignored listing per whitelist
Jan 21 09:40:54.550: INFO: namespace e2e-tests-projected-tx4v8 deletion completed in 6.069422994s

• [SLOW TEST:8.149 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:40:54.550: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a5bb32f8-1d60-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a5bb32f8-1d60-11e9-9c91-0a58ac100282
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:40:58.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c9vjd" for this suite.
Jan 21 09:41:20.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:41:20.699: INFO: namespace: e2e-tests-projected-c9vjd, resource: bindings, ignored listing per whitelist
Jan 21 09:41:20.730: INFO: namespace e2e-tests-projected-c9vjd deletion completed in 22.076356355s

• [SLOW TEST:26.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:41:20.730: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:41:20.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 version'
Jan 21 09:41:20.859: INFO: stderr: ""
Jan 21 09:41:20.859: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.4-aliyun.1\", GitCommit:\"e417a8a\", GitTreeState:\"\", BuildDate:\"2019-01-16T06:03:23Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:41:20.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xhw7g" for this suite.
Jan 21 09:41:26.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:41:26.919: INFO: namespace: e2e-tests-kubectl-xhw7g, resource: bindings, ignored listing per whitelist
Jan 21 09:41:26.933: INFO: namespace e2e-tests-kubectl-xhw7g deletion completed in 6.0712772s

• [SLOW TEST:6.203 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:41:26.934: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b9077b93-1d60-11e9-9c91-0a58ac100282
STEP: Creating configMap with name cm-test-opt-upd-b9077bcd-1d60-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b9077b93-1d60-11e9-9c91-0a58ac100282
STEP: Updating configmap cm-test-opt-upd-b9077bcd-1d60-11e9-9c91-0a58ac100282
STEP: Creating configMap with name cm-test-opt-create-b9077be3-1d60-11e9-9c91-0a58ac100282
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:42:55.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-npk8c" for this suite.
Jan 21 09:43:17.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:43:17.379: INFO: namespace: e2e-tests-configmap-npk8c, resource: bindings, ignored listing per whitelist
Jan 21 09:43:17.434: INFO: namespace e2e-tests-configmap-npk8c deletion completed in 22.071742063s

• [SLOW TEST:110.501 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:43:17.435: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:43:17.495: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-f6qt4" to be "success or failure"
Jan 21 09:43:17.497: INFO: Pod "downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.601947ms
Jan 21 09:43:19.499: INFO: Pod "downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003950787s
STEP: Saw pod success
Jan 21 09:43:19.499: INFO: Pod "downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:43:19.501: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:43:19.516: INFO: Waiting for pod downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:43:19.517: INFO: Pod downwardapi-volume-fae4daf1-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:43:19.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f6qt4" for this suite.
Jan 21 09:43:25.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:43:25.576: INFO: namespace: e2e-tests-downward-api-f6qt4, resource: bindings, ignored listing per whitelist
Jan 21 09:43:25.592: INFO: namespace e2e-tests-downward-api-f6qt4 deletion completed in 6.072192256s

• [SLOW TEST:8.158 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:43:25.592: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ffc320d9-1d60-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:43:25.665: INFO: Waiting up to 5m0s for pod "pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-vlfgz" to be "success or failure"
Jan 21 09:43:25.667: INFO: Pod "pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.701804ms
Jan 21 09:43:27.670: INFO: Pod "pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004265738s
STEP: Saw pod success
Jan 21 09:43:27.670: INFO: Pod "pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:43:27.671: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:43:27.684: INFO: Waiting for pod pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:43:27.686: INFO: Pod pod-secrets-ffc3d742-1d60-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:43:27.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vlfgz" for this suite.
Jan 21 09:43:33.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:43:33.722: INFO: namespace: e2e-tests-secrets-vlfgz, resource: bindings, ignored listing per whitelist
Jan 21 09:43:33.760: INFO: namespace e2e-tests-secrets-vlfgz deletion completed in 6.071150478s

• [SLOW TEST:8.167 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:43:33.760: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 21 09:43:33.817: INFO: Waiting up to 5m0s for pod "pod-049f95f1-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-qlhkp" to be "success or failure"
Jan 21 09:43:33.819: INFO: Pod "pod-049f95f1-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.774638ms
Jan 21 09:43:35.821: INFO: Pod "pod-049f95f1-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004285709s
STEP: Saw pod success
Jan 21 09:43:35.821: INFO: Pod "pod-049f95f1-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:43:35.823: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-049f95f1-1d61-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 09:43:35.838: INFO: Waiting for pod pod-049f95f1-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:43:35.840: INFO: Pod pod-049f95f1-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:43:35.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qlhkp" for this suite.
Jan 21 09:43:41.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:43:41.895: INFO: namespace: e2e-tests-emptydir-qlhkp, resource: bindings, ignored listing per whitelist
Jan 21 09:43:41.919: INFO: namespace e2e-tests-emptydir-qlhkp deletion completed in 6.075860256s

• [SLOW TEST:8.159 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:43:41.919: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:43:41.974: INFO: Waiting up to 5m0s for pod "downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-9pnll" to be "success or failure"
Jan 21 09:43:41.975: INFO: Pod "downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.754405ms
Jan 21 09:43:43.978: INFO: Pod "downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004203658s
STEP: Saw pod success
Jan 21 09:43:43.978: INFO: Pod "downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:43:43.980: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:43:43.995: INFO: Waiting for pod downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:43:43.997: INFO: Pod downwardapi-volume-097bea9b-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:43:43.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9pnll" for this suite.
Jan 21 09:43:50.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:43:50.057: INFO: namespace: e2e-tests-projected-9pnll, resource: bindings, ignored listing per whitelist
Jan 21 09:43:50.085: INFO: namespace e2e-tests-projected-9pnll deletion completed in 6.086071257s

• [SLOW TEST:8.166 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:43:50.086: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:43:50.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-lxd7h" to be "success or failure"
Jan 21 09:43:50.156: INFO: Pod "downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.873482ms
Jan 21 09:43:52.162: INFO: Pod "downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008070697s
STEP: Saw pod success
Jan 21 09:43:52.162: INFO: Pod "downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:43:52.164: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:43:52.177: INFO: Waiting for pod downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:43:52.179: INFO: Pod downwardapi-volume-0e5c4784-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:43:52.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lxd7h" for this suite.
Jan 21 09:43:58.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:43:58.199: INFO: namespace: e2e-tests-projected-lxd7h, resource: bindings, ignored listing per whitelist
Jan 21 09:43:58.253: INFO: namespace e2e-tests-projected-lxd7h deletion completed in 6.070515063s

• [SLOW TEST:8.167 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:43:58.253: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-13390f03-1d61-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:43:58.316: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-hdf29" to be "success or failure"
Jan 21 09:43:58.317: INFO: Pod "pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.769376ms
Jan 21 09:44:00.320: INFO: Pod "pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004086711s
STEP: Saw pod success
Jan 21 09:44:00.320: INFO: Pod "pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:44:00.321: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:44:00.335: INFO: Waiting for pod pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:44:00.338: INFO: Pod pod-projected-secrets-133a0823-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:44:00.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hdf29" for this suite.
Jan 21 09:44:06.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:44:06.410: INFO: namespace: e2e-tests-projected-hdf29, resource: bindings, ignored listing per whitelist
Jan 21 09:44:06.416: INFO: namespace e2e-tests-projected-hdf29 deletion completed in 6.06985795s

• [SLOW TEST:8.164 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:44:06.416: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0121 09:44:16.517781      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 09:44:16.517: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:44:16.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-x9l9b" for this suite.
Jan 21 09:44:22.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:44:22.570: INFO: namespace: e2e-tests-gc-x9l9b, resource: bindings, ignored listing per whitelist
Jan 21 09:44:22.590: INFO: namespace e2e-tests-gc-x9l9b deletion completed in 6.069376058s

• [SLOW TEST:16.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:44:22.590: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:44:42.662: INFO: Container started at 2019-01-21 09:44:23 +0000 UTC, pod became ready at 2019-01-21 09:44:40 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:44:42.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-r5x96" for this suite.
Jan 21 09:45:04.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:45:04.706: INFO: namespace: e2e-tests-container-probe-r5x96, resource: bindings, ignored listing per whitelist
Jan 21 09:45:04.740: INFO: namespace e2e-tests-container-probe-r5x96 deletion completed in 22.074543497s

• [SLOW TEST:42.150 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:45:04.740: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 09:45:04.791: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:45:08.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xxjrw" for this suite.
Jan 21 09:45:14.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:45:14.844: INFO: namespace: e2e-tests-init-container-xxjrw, resource: bindings, ignored listing per whitelist
Jan 21 09:45:14.883: INFO: namespace e2e-tests-init-container-xxjrw deletion completed in 6.071958284s

• [SLOW TEST:10.143 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:45:14.883: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:45:14.945: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-bvvpf" to be "success or failure"
Jan 21 09:45:14.947: INFO: Pod "downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.767623ms
Jan 21 09:45:16.949: INFO: Pod "downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004261608s
STEP: Saw pod success
Jan 21 09:45:16.949: INFO: Pod "downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:45:16.951: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:45:16.967: INFO: Waiting for pod downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:45:16.969: INFO: Pod downwardapi-volume-40e65553-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:45:16.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bvvpf" for this suite.
Jan 21 09:45:22.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:45:23.041: INFO: namespace: e2e-tests-downward-api-bvvpf, resource: bindings, ignored listing per whitelist
Jan 21 09:45:23.044: INFO: namespace e2e-tests-downward-api-bvvpf deletion completed in 6.072367763s

• [SLOW TEST:8.161 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:45:23.044: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:45:23.115: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-rgmg8" to be "success or failure"
Jan 21 09:45:23.117: INFO: Pod "downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.845737ms
Jan 21 09:45:25.119: INFO: Pod "downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004125165s
STEP: Saw pod success
Jan 21 09:45:25.119: INFO: Pod "downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:45:25.121: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:45:25.134: INFO: Waiting for pod downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:45:25.136: INFO: Pod downwardapi-volume-45c5218f-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:45:25.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rgmg8" for this suite.
Jan 21 09:45:31.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:45:31.157: INFO: namespace: e2e-tests-downward-api-rgmg8, resource: bindings, ignored listing per whitelist
Jan 21 09:45:31.213: INFO: namespace e2e-tests-downward-api-rgmg8 deletion completed in 6.074502019s

• [SLOW TEST:8.169 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:45:31.214: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 21 09:45:31.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 cluster-info'
Jan 21 09:45:31.354: INFO: stderr: ""
Jan 21 09:45:31.354: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.19.0.1:443\x1b[0m\n\x1b[0;32mmetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.19.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.19.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:45:31.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l7t54" for this suite.
Jan 21 09:45:37.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:45:37.404: INFO: namespace: e2e-tests-kubectl-l7t54, resource: bindings, ignored listing per whitelist
Jan 21 09:45:37.439: INFO: namespace e2e-tests-kubectl-l7t54 deletion completed in 6.081464917s

• [SLOW TEST:6.225 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:45:37.439: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:45:37.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-69kkd" to be "success or failure"
Jan 21 09:45:37.495: INFO: Pod "downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.699809ms
Jan 21 09:45:39.497: INFO: Pod "downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004266468s
STEP: Saw pod success
Jan 21 09:45:39.497: INFO: Pod "downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:45:39.499: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:45:39.513: INFO: Waiting for pod downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:45:39.515: INFO: Pod downwardapi-volume-4e56c83d-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:45:39.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-69kkd" for this suite.
Jan 21 09:45:45.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:45:45.589: INFO: namespace: e2e-tests-projected-69kkd, resource: bindings, ignored listing per whitelist
Jan 21 09:45:45.590: INFO: namespace e2e-tests-projected-69kkd deletion completed in 6.073103461s

• [SLOW TEST:8.152 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:45:45.591: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:45:45.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 version --client'
Jan 21 09:45:45.704: INFO: stderr: ""
Jan 21 09:45:45.704: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 21 09:45:45.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-9q62k'
Jan 21 09:45:45.875: INFO: stderr: ""
Jan 21 09:45:45.875: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 21 09:45:45.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-9q62k'
Jan 21 09:45:46.054: INFO: stderr: ""
Jan 21 09:45:46.054: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 21 09:45:47.057: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:45:47.057: INFO: Found 0 / 1
Jan 21 09:45:48.056: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:45:48.057: INFO: Found 1 / 1
Jan 21 09:45:48.057: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 21 09:45:48.059: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 09:45:48.059: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 21 09:45:48.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 describe pod redis-master-8zppk --namespace=e2e-tests-kubectl-9q62k'
Jan 21 09:45:48.148: INFO: stderr: ""
Jan 21 09:45:48.148: INFO: stdout: "Name:               redis-master-8zppk\nNamespace:          e2e-tests-kubectl-9q62k\nPriority:           0\nPriorityClassName:  <none>\nNode:               cn-hongkong.i-j6c44erhl7eu2z5nuuhv/192.168.0.78\nStart Time:         Mon, 21 Jan 2019 09:45:45 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.16.2.8\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6a7a9c1ca843c17295db45cc351157746296a3896ada09e007a645c0aa8febba\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Jan 2019 09:45:46 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4vfxz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-4vfxz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-4vfxz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                         Message\n  ----    ------     ----  ----                                         -------\n  Normal  Scheduled  3s    default-scheduler                            Successfully assigned e2e-tests-kubectl-9q62k/redis-master-8zppk to cn-hongkong.i-j6c44erhl7eu2z5nuuhv\n  Normal  Pulled     2s    kubelet, cn-hongkong.i-j6c44erhl7eu2z5nuuhv  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, cn-hongkong.i-j6c44erhl7eu2z5nuuhv  Created container\n  Normal  Started    2s    kubelet, cn-hongkong.i-j6c44erhl7eu2z5nuuhv  Started container\n"
Jan 21 09:45:48.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 describe rc redis-master --namespace=e2e-tests-kubectl-9q62k'
Jan 21 09:45:48.244: INFO: stderr: ""
Jan 21 09:45:48.244: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-9q62k\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-8zppk\n"
Jan 21 09:45:48.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 describe service redis-master --namespace=e2e-tests-kubectl-9q62k'
Jan 21 09:45:48.325: INFO: stderr: ""
Jan 21 09:45:48.325: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-9q62k\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.19.11.161\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.16.2.8:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 21 09:45:48.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 describe node cn-hongkong.i-j6c44erhl7eu2z5nuuht'
Jan 21 09:45:48.419: INFO: stderr: ""
Jan 21 09:45:48.419: INFO: stdout: "Name:               cn-hongkong.i-j6c44erhl7eu2z5nuuht\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecs.c5.xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=cn-hongkong\n                    failure-domain.beta.kubernetes.io/zone=cn-hongkong-b\n                    kubernetes.io/hostname=cn-hongkong.i-j6c44erhl7eu2z5nuuht\nAnnotations:        flannel.alpha.coreos.com/backend-data: null\n                    flannel.alpha.coreos.com/backend-type: \n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.0.76\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\nCreationTimestamp:  Mon, 21 Jan 2019 08:17:32 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 21 Jan 2019 08:18:24 +0000   Mon, 21 Jan 2019 08:18:24 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Mon, 21 Jan 2019 09:45:38 +0000   Mon, 21 Jan 2019 08:17:30 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Mon, 21 Jan 2019 09:45:38 +0000   Mon, 21 Jan 2019 08:17:30 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 21 Jan 2019 09:45:38 +0000   Mon, 21 Jan 2019 08:17:30 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 21 Jan 2019 09:45:38 +0000   Mon, 21 Jan 2019 08:17:30 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 21 Jan 2019 09:45:38 +0000   Mon, 21 Jan 2019 08:17:40 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.0.76\nCapacity:\n cpu:                4\n ephemeral-storage:  101441464Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8010192Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  93488453068\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6986192Ki\n pods:               110\nSystem Info:\n Machine ID:                 f0f31005fb5a436d88e3c6cbf54e25aa\n System UUID:                57B9766B-B1FF-4648-991B-A30183D224DE\n Boot ID:                    4677747a-760f-410e-a4d6-9d7e51bc5c20\n Kernel Version:             3.10.0-693.2.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.12.4-aliyun.1\n Kube-Proxy Version:         v1.12.4-aliyun.1\nPodCIDR:                     172.16.2.128/25\nProviderID:                  cn-hongkong.i-j6c44erhl7eu2z5nuuht\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-0b58519d2e6c4c07                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-a0800c708c434388-spkt6    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                flexvolume-4lfmg                                           100m (2%)     0 (0%)      200Mi (2%)       200Mi (2%)\n  kube-system                kube-flannel-ds-g8c6v                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-worker-wtj4k                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       100m (2%)   0 (0%)\n  memory    200Mi (2%)  200Mi (2%)\nEvents:     <none>\n"
Jan 21 09:45:48.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 describe namespace e2e-tests-kubectl-9q62k'
Jan 21 09:45:48.505: INFO: stderr: ""
Jan 21 09:45:48.505: INFO: stdout: "Name:         e2e-tests-kubectl-9q62k\nLabels:       e2e-framework=kubectl\n              e2e-run=f4ab4fb1-1d58-11e9-9c91-0a58ac100282\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:45:48.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9q62k" for this suite.
Jan 21 09:46:10.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:46:10.532: INFO: namespace: e2e-tests-kubectl-9q62k, resource: bindings, ignored listing per whitelist
Jan 21 09:46:10.581: INFO: namespace e2e-tests-kubectl-9q62k deletion completed in 22.07293919s

• [SLOW TEST:24.990 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:46:10.581: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-621850a0-1d61-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:46:10.640: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-rtbs4" to be "success or failure"
Jan 21 09:46:10.642: INFO: Pod "pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.808995ms
Jan 21 09:46:12.644: INFO: Pod "pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004267482s
STEP: Saw pod success
Jan 21 09:46:12.645: INFO: Pod "pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:46:12.646: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:46:12.661: INFO: Waiting for pod pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:46:12.663: INFO: Pod pod-projected-secrets-6218f39e-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:46:12.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rtbs4" for this suite.
Jan 21 09:46:18.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:46:18.684: INFO: namespace: e2e-tests-projected-rtbs4, resource: bindings, ignored listing per whitelist
Jan 21 09:46:18.735: INFO: namespace e2e-tests-projected-rtbs4 deletion completed in 6.07003221s

• [SLOW TEST:8.155 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:46:18.735: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 09:46:18.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-pm6d4'
Jan 21 09:46:18.869: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 09:46:18.869: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 21 09:46:18.874: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-tbtt8]
Jan 21 09:46:18.874: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-tbtt8" in namespace "e2e-tests-kubectl-pm6d4" to be "running and ready"
Jan 21 09:46:18.878: INFO: Pod "e2e-test-nginx-rc-tbtt8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.683004ms
Jan 21 09:46:20.881: INFO: Pod "e2e-test-nginx-rc-tbtt8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00615827s
Jan 21 09:46:20.881: INFO: Pod "e2e-test-nginx-rc-tbtt8" satisfied condition "running and ready"
Jan 21 09:46:20.881: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-tbtt8]
Jan 21 09:46:20.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pm6d4'
Jan 21 09:46:20.974: INFO: stderr: ""
Jan 21 09:46:20.974: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan 21 09:46:20.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pm6d4'
Jan 21 09:46:21.054: INFO: stderr: ""
Jan 21 09:46:21.054: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:46:21.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pm6d4" for this suite.
Jan 21 09:46:43.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:46:43.114: INFO: namespace: e2e-tests-kubectl-pm6d4, resource: bindings, ignored listing per whitelist
Jan 21 09:46:43.129: INFO: namespace e2e-tests-kubectl-pm6d4 deletion completed in 22.071424478s

• [SLOW TEST:24.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:46:43.129: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 21 09:46:43.182: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 21 09:46:43.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:46:43.364: INFO: stderr: ""
Jan 21 09:46:43.364: INFO: stdout: "service/redis-slave created\n"
Jan 21 09:46:43.364: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 21 09:46:43.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:46:43.538: INFO: stderr: ""
Jan 21 09:46:43.538: INFO: stdout: "service/redis-master created\n"
Jan 21 09:46:43.539: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 21 09:46:43.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:46:43.719: INFO: stderr: ""
Jan 21 09:46:43.719: INFO: stdout: "service/frontend created\n"
Jan 21 09:46:43.719: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 21 09:46:43.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:46:43.897: INFO: stderr: ""
Jan 21 09:46:43.897: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 21 09:46:43.898: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 21 09:46:43.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:46:44.079: INFO: stderr: ""
Jan 21 09:46:44.080: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 21 09:46:44.080: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 21 09:46:44.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:46:44.252: INFO: stderr: ""
Jan 21 09:46:44.252: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 21 09:46:44.253: INFO: Waiting for all frontend pods to be Running.
Jan 21 09:47:14.304: INFO: Waiting for frontend to serve content.
Jan 21 09:47:14.318: INFO: Trying to add a new entry to the guestbook.
Jan 21 09:47:14.328: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 21 09:47:14.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:47:14.426: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 09:47:14.426: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 09:47:14.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:47:14.522: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 09:47:14.522: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 09:47:14.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:47:14.614: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 09:47:14.614: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 09:47:14.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:47:14.712: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 09:47:14.712: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 09:47:14.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:47:14.844: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 09:47:14.844: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 09:47:14.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sp8jz'
Jan 21 09:47:14.930: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 09:47:14.930: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:47:14.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sp8jz" for this suite.
Jan 21 09:47:52.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:47:52.958: INFO: namespace: e2e-tests-kubectl-sp8jz, resource: bindings, ignored listing per whitelist
Jan 21 09:47:53.003: INFO: namespace e2e-tests-kubectl-sp8jz deletion completed in 38.070455661s

• [SLOW TEST:69.874 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:47:53.004: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-9f26eba1-1d61-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:47:53.081: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-n888r" to be "success or failure"
Jan 21 09:47:53.083: INFO: Pod "pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.650075ms
Jan 21 09:47:55.086: INFO: Pod "pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004320879s
STEP: Saw pod success
Jan 21 09:47:55.086: INFO: Pod "pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:47:55.088: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:47:55.102: INFO: Waiting for pod pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:47:55.104: INFO: Pod pod-projected-secrets-9f28765d-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:47:55.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n888r" for this suite.
Jan 21 09:48:01.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:48:01.140: INFO: namespace: e2e-tests-projected-n888r, resource: bindings, ignored listing per whitelist
Jan 21 09:48:01.183: INFO: namespace e2e-tests-projected-n888r deletion completed in 6.07561091s

• [SLOW TEST:8.179 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:48:01.183: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-z6wws
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 09:48:01.229: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 09:48:25.285: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.2.14:8080/dial?request=hostName&protocol=udp&host=172.16.1.165&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-z6wws PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:48:25.285: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:48:25.457: INFO: Waiting for endpoints: map[]
Jan 21 09:48:25.459: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.2.14:8080/dial?request=hostName&protocol=udp&host=172.16.2.13&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-z6wws PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:48:25.459: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:48:25.667: INFO: Waiting for endpoints: map[]
Jan 21 09:48:25.669: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.2.14:8080/dial?request=hostName&protocol=udp&host=172.16.2.245&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-z6wws PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:48:25.669: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:48:25.916: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:48:25.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-z6wws" for this suite.
Jan 21 09:48:47.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:48:47.970: INFO: namespace: e2e-tests-pod-network-test-z6wws, resource: bindings, ignored listing per whitelist
Jan 21 09:48:47.992: INFO: namespace e2e-tests-pod-network-test-z6wws deletion completed in 22.072944547s

• [SLOW TEST:46.809 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:48:47.992: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:48:48.063: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-gjhlh" to be "success or failure"
Jan 21 09:48:48.065: INFO: Pod "downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.706201ms
Jan 21 09:48:50.067: INFO: Pod "downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004293971s
STEP: Saw pod success
Jan 21 09:48:50.068: INFO: Pod "downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:48:50.070: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:48:50.086: INFO: Waiting for pod downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:48:50.088: INFO: Pod downwardapi-volume-bfed7d1b-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:48:50.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gjhlh" for this suite.
Jan 21 09:48:56.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:48:56.130: INFO: namespace: e2e-tests-downward-api-gjhlh, resource: bindings, ignored listing per whitelist
Jan 21 09:48:56.161: INFO: namespace e2e-tests-downward-api-gjhlh deletion completed in 6.070419648s

• [SLOW TEST:8.169 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:48:56.161: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c4c96caa-1d61-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:48:56.217: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-x69lh" to be "success or failure"
Jan 21 09:48:56.219: INFO: Pod "pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021914ms
Jan 21 09:48:58.222: INFO: Pod "pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004654197s
STEP: Saw pod success
Jan 21 09:48:58.222: INFO: Pod "pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:48:58.224: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:48:58.239: INFO: Waiting for pod pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:48:58.241: INFO: Pod pod-projected-configmaps-c4ca3e03-1d61-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:48:58.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x69lh" for this suite.
Jan 21 09:49:04.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:49:04.309: INFO: namespace: e2e-tests-projected-x69lh, resource: bindings, ignored listing per whitelist
Jan 21 09:49:04.319: INFO: namespace e2e-tests-projected-x69lh deletion completed in 6.07519186s

• [SLOW TEST:8.158 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:49:04.319: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c9a88444-1d61-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c9a88444-1d61-11e9-9c91-0a58ac100282
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:49:08.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5tx8g" for this suite.
Jan 21 09:49:30.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:49:30.459: INFO: namespace: e2e-tests-configmap-5tx8g, resource: bindings, ignored listing per whitelist
Jan 21 09:49:30.492: INFO: namespace e2e-tests-configmap-5tx8g deletion completed in 22.071310413s

• [SLOW TEST:26.173 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:49:30.492: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 09:49:30.557: INFO: PodSpec: initContainers in spec.initContainers
Jan 21 09:50:15.154: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d942cef8-1d61-11e9-9c91-0a58ac100282", GenerateName:"", Namespace:"e2e-tests-init-container-dcz4l", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-dcz4l/pods/pod-init-d942cef8-1d61-11e9-9c91-0a58ac100282", UID:"d94428d9-1d61-11e9-8ca7-00163e00ea4b", ResourceVersion:"23162", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683660970, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"557836345"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vcxh7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4227c4ec0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vcxh7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vcxh7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vcxh7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422252938), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"cn-hongkong.i-j6c44erhl7eu2z5nuuht", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42294d920), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4222529b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4222529d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4222529d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660970, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660970, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660970, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683660970, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.76", PodIP:"172.16.2.248", StartTime:(*v1.Time)(0xc421106400), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42033f0a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42033f110)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://e4d59927f02d7b9efc7e6beb2777efbf4efaf11e00137ebbcbb6f94932e7d64f"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421106480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421106440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:50:15.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dcz4l" for this suite.
Jan 21 09:50:37.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:50:37.198: INFO: namespace: e2e-tests-init-container-dcz4l, resource: bindings, ignored listing per whitelist
Jan 21 09:50:37.237: INFO: namespace e2e-tests-init-container-dcz4l deletion completed in 22.076241606s

• [SLOW TEST:66.745 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:50:37.237: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:50:37.295: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-g2s2x" to be "success or failure"
Jan 21 09:50:37.296: INFO: Pod "downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.784335ms
Jan 21 09:50:39.299: INFO: Pod "downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004388342s
STEP: Saw pod success
Jan 21 09:50:39.299: INFO: Pod "downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:50:39.301: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:50:39.314: INFO: Waiting for pod downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:50:39.315: INFO: Pod downwardapi-volume-01091dee-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:50:39.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g2s2x" for this suite.
Jan 21 09:50:45.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:50:45.358: INFO: namespace: e2e-tests-projected-g2s2x, resource: bindings, ignored listing per whitelist
Jan 21 09:50:45.394: INFO: namespace e2e-tests-projected-g2s2x deletion completed in 6.075513576s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:50:45.394: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:50:45.448: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 21 09:50:50.455: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 21 09:50:50.455: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 09:50:50.468: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-5z56g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5z56g/deployments/test-cleanup-deployment,UID:08e3c2eb-1d62-11e9-8ca7-00163e00ea4b,ResourceVersion:23312,Generation:1,CreationTimestamp:2019-01-21 09:50:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 21 09:50:50.470: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:50:50.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5z56g" for this suite.
Jan 21 09:50:56.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:50:56.518: INFO: namespace: e2e-tests-deployment-5z56g, resource: bindings, ignored listing per whitelist
Jan 21 09:50:56.550: INFO: namespace e2e-tests-deployment-5z56g deletion completed in 6.07389463s

• [SLOW TEST:11.156 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:50:56.551: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0c8d5f3d-1d62-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:50:56.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-gwlcj" to be "success or failure"
Jan 21 09:50:56.621: INFO: Pod "pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.826373ms
Jan 21 09:50:58.623: INFO: Pod "pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004112905s
STEP: Saw pod success
Jan 21 09:50:58.623: INFO: Pod "pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:50:58.625: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:50:58.640: INFO: Waiting for pod pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:50:58.641: INFO: Pod pod-configmaps-0c8e0c16-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:50:58.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gwlcj" for this suite.
Jan 21 09:51:04.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:51:04.691: INFO: namespace: e2e-tests-configmap-gwlcj, resource: bindings, ignored listing per whitelist
Jan 21 09:51:04.719: INFO: namespace e2e-tests-configmap-gwlcj deletion completed in 6.0749822s

• [SLOW TEST:8.168 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:51:04.719: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 21 09:51:04.781: INFO: Waiting up to 5m0s for pod "var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-var-expansion-nbs55" to be "success or failure"
Jan 21 09:51:04.787: INFO: Pod "var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 5.965008ms
Jan 21 09:51:06.792: INFO: Pod "var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010574269s
STEP: Saw pod success
Jan 21 09:51:06.792: INFO: Pod "var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:51:06.795: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 09:51:06.809: INFO: Waiting for pod var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:51:06.810: INFO: Pod var-expansion-116b48f5-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:51:06.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nbs55" for this suite.
Jan 21 09:51:12.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:51:12.827: INFO: namespace: e2e-tests-var-expansion-nbs55, resource: bindings, ignored listing per whitelist
Jan 21 09:51:12.889: INFO: namespace e2e-tests-var-expansion-nbs55 deletion completed in 6.075479863s

• [SLOW TEST:8.170 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:51:12.889: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-kgq6n/configmap-test-164902fc-1d62-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:51:12.949: INFO: Waiting up to 5m0s for pod "pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-kgq6n" to be "success or failure"
Jan 21 09:51:12.951: INFO: Pod "pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.820029ms
Jan 21 09:51:14.954: INFO: Pod "pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004291272s
STEP: Saw pod success
Jan 21 09:51:14.954: INFO: Pod "pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:51:14.955: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282 container env-test: <nil>
STEP: delete the pod
Jan 21 09:51:14.971: INFO: Waiting for pod pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:51:14.973: INFO: Pod pod-configmaps-1649b396-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:51:14.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kgq6n" for this suite.
Jan 21 09:51:20.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:51:21.028: INFO: namespace: e2e-tests-configmap-kgq6n, resource: bindings, ignored listing per whitelist
Jan 21 09:51:21.050: INFO: namespace e2e-tests-configmap-kgq6n deletion completed in 6.074199445s

• [SLOW TEST:8.161 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:51:21.050: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1b260d37-1d62-11e9-9c91-0a58ac100282
STEP: Creating secret with name s-test-opt-upd-1b260d79-1d62-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1b260d37-1d62-11e9-9c91-0a58ac100282
STEP: Updating secret s-test-opt-upd-1b260d79-1d62-11e9-9c91-0a58ac100282
STEP: Creating secret with name s-test-opt-create-1b260d92-1d62-11e9-9c91-0a58ac100282
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:51:25.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9gw99" for this suite.
Jan 21 09:51:47.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:51:47.222: INFO: namespace: e2e-tests-secrets-9gw99, resource: bindings, ignored listing per whitelist
Jan 21 09:51:47.238: INFO: namespace e2e-tests-secrets-9gw99 deletion completed in 22.069857284s

• [SLOW TEST:26.188 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:51:47.238: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 09:51:49.817: INFO: Successfully updated pod "annotationupdate2ac27dcf-1d62-11e9-9c91-0a58ac100282"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:51:53.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c92wq" for this suite.
Jan 21 09:52:15.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:52:15.886: INFO: namespace: e2e-tests-downward-api-c92wq, resource: bindings, ignored listing per whitelist
Jan 21 09:52:15.915: INFO: namespace e2e-tests-downward-api-c92wq deletion completed in 22.072849298s

• [SLOW TEST:28.676 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:52:15.915: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3bda7a9f-1d62-11e9-9c91-0a58ac100282
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:52:17.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r8ztq" for this suite.
Jan 21 09:52:40.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:52:40.054: INFO: namespace: e2e-tests-configmap-r8ztq, resource: bindings, ignored listing per whitelist
Jan 21 09:52:40.068: INFO: namespace e2e-tests-configmap-r8ztq deletion completed in 22.070818528s

• [SLOW TEST:24.154 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:52:40.069: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q4xqc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 80.1.19.172.in-addr.arpa. PTR)" && echo OK > /results/172.19.1.80_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 80.1.19.172.in-addr.arpa. PTR)" && echo OK > /results/172.19.1.80_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-q4xqc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q4xqc.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-q4xqc.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q4xqc.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 80.1.19.172.in-addr.arpa. PTR)" && echo OK > /results/172.19.1.80_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 80.1.19.172.in-addr.arpa. PTR)" && echo OK > /results/172.19.1.80_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 21 09:52:52.156: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.161: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.163: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.165: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.167: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.169: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.171: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.186: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.188: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.190: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.192: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.194: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.196: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.198: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.200: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:52:52.213: INFO: Lookups using e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc.svc wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q4xqc jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc jessie_udp@dns-test-service.e2e-tests-dns-q4xqc.svc jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc]

Jan 21 09:53:02.152: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.155: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.161: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.163: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.165: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.167: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.169: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.171: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.186: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.188: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.190: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.192: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.194: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.197: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.199: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.201: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:02.213: INFO: Lookups using e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc wheezy_udp@dns-test-service.e2e-tests-dns-q4xqc.svc wheezy_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q4xqc jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc jessie_udp@dns-test-service.e2e-tests-dns-q4xqc.svc jessie_tcp@dns-test-service.e2e-tests-dns-q4xqc.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc]

Jan 21 09:53:12.187: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:12.197: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:12.199: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc from pod e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282: the server could not find the requested resource (get pods dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282)
Jan 21 09:53:12.211: INFO: Lookups using e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282 failed for: [jessie_tcp@dns-test-service jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q4xqc.svc]

Jan 21 09:53:22.216: INFO: DNS probes using e2e-tests-dns-q4xqc/dns-test-4a41fff5-1d62-11e9-9c91-0a58ac100282 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:53:22.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-q4xqc" for this suite.
Jan 21 09:53:28.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:53:28.305: INFO: namespace: e2e-tests-dns-q4xqc, resource: bindings, ignored listing per whitelist
Jan 21 09:53:28.329: INFO: namespace e2e-tests-dns-q4xqc deletion completed in 6.076785244s

• [SLOW TEST:48.260 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:53:28.329: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t9fpn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 09:53:28.380: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 09:53:50.440: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.2.252:8080/dial?request=hostName&protocol=http&host=172.16.1.166&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t9fpn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:53:50.440: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:53:50.606: INFO: Waiting for endpoints: map[]
Jan 21 09:53:50.609: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.2.252:8080/dial?request=hostName&protocol=http&host=172.16.2.251&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t9fpn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:53:50.609: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:53:50.809: INFO: Waiting for endpoints: map[]
Jan 21 09:53:50.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.2.252:8080/dial?request=hostName&protocol=http&host=172.16.2.24&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t9fpn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 09:53:50.811: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
Jan 21 09:53:51.036: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:53:51.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t9fpn" for this suite.
Jan 21 09:54:13.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:54:13.072: INFO: namespace: e2e-tests-pod-network-test-t9fpn, resource: bindings, ignored listing per whitelist
Jan 21 09:54:13.118: INFO: namespace e2e-tests-pod-network-test-t9fpn deletion completed in 22.071179846s

• [SLOW TEST:44.789 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:54:13.119: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-rtlln/configmap-test-81b6724b-1d62-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:54:13.183: INFO: Waiting up to 5m0s for pod "pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-rtlln" to be "success or failure"
Jan 21 09:54:13.184: INFO: Pod "pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.643904ms
Jan 21 09:54:15.187: INFO: Pod "pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004279408s
STEP: Saw pod success
Jan 21 09:54:15.187: INFO: Pod "pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:54:15.189: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282 container env-test: <nil>
STEP: delete the pod
Jan 21 09:54:15.205: INFO: Waiting for pod pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:54:15.207: INFO: Pod pod-configmaps-81b71fb3-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:54:15.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rtlln" for this suite.
Jan 21 09:54:21.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:54:21.259: INFO: namespace: e2e-tests-configmap-rtlln, resource: bindings, ignored listing per whitelist
Jan 21 09:54:21.287: INFO: namespace e2e-tests-configmap-rtlln deletion completed in 6.076998463s

• [SLOW TEST:8.168 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:54:21.287: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:54:21.341: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 21 09:54:26.344: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 21 09:54:26.344: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 21 09:54:28.350: INFO: Creating deployment "test-rollover-deployment"
Jan 21 09:54:28.357: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 21 09:54:30.362: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 21 09:54:30.366: INFO: Ensure that both replica sets have 1 created replica
Jan 21 09:54:30.369: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 21 09:54:30.376: INFO: Updating deployment test-rollover-deployment
Jan 21 09:54:30.376: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 21 09:54:32.381: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 21 09:54:32.385: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 21 09:54:32.389: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 09:54:32.389: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661272, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 09:54:34.394: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 09:54:34.394: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661272, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 09:54:36.395: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 09:54:36.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661272, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 09:54:38.398: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 09:54:38.398: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661272, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 09:54:40.395: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 09:54:40.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661272, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683661268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 09:54:42.395: INFO: 
Jan 21 09:54:42.395: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 09:54:42.401: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-qt9wh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qt9wh/deployments/test-rollover-deployment,UID:8ac3fb34-1d62-11e9-8ca7-00163e00ea4b,ResourceVersion:24347,Generation:2,CreationTimestamp:2019-01-21 09:54:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-21 09:54:28 +0000 UTC 2019-01-21 09:54:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-21 09:54:42 +0000 UTC 2019-01-21 09:54:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 21 09:54:42.403: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-qt9wh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qt9wh/replicasets/test-rollover-deployment-5b76ff8c4,UID:8bf8123c-1d62-11e9-9352-00163e04cddc,ResourceVersion:24338,Generation:2,CreationTimestamp:2019-01-21 09:54:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 8ac3fb34-1d62-11e9-8ca7-00163e00ea4b 0xc42240cce7 0xc42240cce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 21 09:54:42.403: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 21 09:54:42.403: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-qt9wh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qt9wh/replicasets/test-rollover-controller,UID:86957c1e-1d62-11e9-8ca7-00163e00ea4b,ResourceVersion:24346,Generation:2,CreationTimestamp:2019-01-21 09:54:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 8ac3fb34-1d62-11e9-8ca7-00163e00ea4b 0xc42240cc1e 0xc42240cc1f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 09:54:42.403: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-qt9wh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qt9wh/replicasets/test-rollover-deployment-6975f4fb87,UID:8ac52f63-1d62-11e9-9352-00163e04cddc,ResourceVersion:24302,Generation:2,CreationTimestamp:2019-01-21 09:54:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 8ac3fb34-1d62-11e9-8ca7-00163e00ea4b 0xc42240cda7 0xc42240cda8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 09:54:42.405: INFO: Pod "test-rollover-deployment-5b76ff8c4-5mwnz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-5mwnz,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-qt9wh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qt9wh/pods/test-rollover-deployment-5b76ff8c4-5mwnz,UID:8bfbe759-1d62-11e9-9352-00163e04cddc,ResourceVersion:24310,Generation:0,CreationTimestamp:2019-01-21 09:54:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 8bf8123c-1d62-11e9-9352-00163e04cddc 0xc42240dbd0 0xc42240dbd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rzfjp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rzfjp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rzfjp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:cn-hongkong.i-j6c44erhl7eu2z5nuuhv,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42240dc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42240dc60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:54:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:54:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:54:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 09:54:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.78,PodIP:172.16.2.26,StartTime:2019-01-21 09:54:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-21 09:54:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b3f909951e97d45e4ec16d1cde34bb01000585527362b03e3e6086b087ad2708}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:54:42.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qt9wh" for this suite.
Jan 21 09:54:48.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:54:48.462: INFO: namespace: e2e-tests-deployment-qt9wh, resource: bindings, ignored listing per whitelist
Jan 21 09:54:48.482: INFO: namespace e2e-tests-deployment-qt9wh deletion completed in 6.074061684s

• [SLOW TEST:27.195 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:54:48.482: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 09:54:51.065: INFO: Successfully updated pod "labelsupdate96ca90cf-1d62-11e9-9c91-0a58ac100282"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:54:53.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sxmk6" for this suite.
Jan 21 09:55:15.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:55:15.146: INFO: namespace: e2e-tests-projected-sxmk6, resource: bindings, ignored listing per whitelist
Jan 21 09:55:15.151: INFO: namespace e2e-tests-projected-sxmk6 deletion completed in 22.070127429s

• [SLOW TEST:26.669 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:55:15.151: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 21 09:55:15.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-2mc6h,SelfLink:/api/v1/namespaces/e2e-tests-watch-2mc6h/configmaps/e2e-watch-test-resource-version,UID:a6b12528-1d62-11e9-8ca7-00163e00ea4b,ResourceVersion:24502,Generation:0,CreationTimestamp:2019-01-21 09:55:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 09:55:15.228: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-2mc6h,SelfLink:/api/v1/namespaces/e2e-tests-watch-2mc6h/configmaps/e2e-watch-test-resource-version,UID:a6b12528-1d62-11e9-8ca7-00163e00ea4b,ResourceVersion:24503,Generation:0,CreationTimestamp:2019-01-21 09:55:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:55:15.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-2mc6h" for this suite.
Jan 21 09:55:21.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:55:21.253: INFO: namespace: e2e-tests-watch-2mc6h, resource: bindings, ignored listing per whitelist
Jan 21 09:55:21.313: INFO: namespace e2e-tests-watch-2mc6h deletion completed in 6.081910957s

• [SLOW TEST:6.162 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:55:21.313: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-aa5ad429-1d62-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 09:55:21.369: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-fgqwg" to be "success or failure"
Jan 21 09:55:21.370: INFO: Pod "pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.581262ms
Jan 21 09:55:23.373: INFO: Pod "pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004048075s
STEP: Saw pod success
Jan 21 09:55:23.373: INFO: Pod "pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:55:23.374: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 09:55:23.388: INFO: Waiting for pod pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:55:23.390: INFO: Pod pod-projected-configmaps-aa5b7f70-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:55:23.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fgqwg" for this suite.
Jan 21 09:55:29.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:55:29.450: INFO: namespace: e2e-tests-projected-fgqwg, resource: bindings, ignored listing per whitelist
Jan 21 09:55:29.465: INFO: namespace e2e-tests-projected-fgqwg deletion completed in 6.071241651s

• [SLOW TEST:8.151 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:55:29.465: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 09:55:29.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-projected-r57xc" to be "success or failure"
Jan 21 09:55:29.524: INFO: Pod "downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.758845ms
Jan 21 09:55:31.533: INFO: Pod "downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010760553s
STEP: Saw pod success
Jan 21 09:55:31.533: INFO: Pod "downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:55:31.535: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 09:55:31.549: INFO: Waiting for pod downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:55:31.550: INFO: Pod downwardapi-volume-af374bd3-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:55:31.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r57xc" for this suite.
Jan 21 09:55:37.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:55:37.568: INFO: namespace: e2e-tests-projected-r57xc, resource: bindings, ignored listing per whitelist
Jan 21 09:55:37.625: INFO: namespace e2e-tests-projected-r57xc deletion completed in 6.072290498s

• [SLOW TEST:8.161 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:55:37.626: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 21 09:55:37.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 --namespace=e2e-tests-kubectl-v9dvr run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 21 09:55:39.876: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 21 09:55:39.876: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:55:41.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v9dvr" for this suite.
Jan 21 09:55:53.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:55:53.954: INFO: namespace: e2e-tests-kubectl-v9dvr, resource: bindings, ignored listing per whitelist
Jan 21 09:55:53.957: INFO: namespace e2e-tests-kubectl-v9dvr deletion completed in 12.070059785s

• [SLOW TEST:16.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:55:53.957: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 21 09:55:54.522: INFO: Waiting up to 5m0s for pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v" in namespace "e2e-tests-svcaccounts-wcdnn" to be "success or failure"
Jan 21 09:55:54.524: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v": Phase="Pending", Reason="", readiness=false. Elapsed: 1.782596ms
Jan 21 09:55:56.527: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004383151s
Jan 21 09:55:58.529: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007015919s
STEP: Saw pod success
Jan 21 09:55:58.529: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v" satisfied condition "success or failure"
Jan 21 09:55:58.531: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v container token-test: <nil>
STEP: delete the pod
Jan 21 09:55:58.546: INFO: Waiting for pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v to disappear
Jan 21 09:55:58.549: INFO: Pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gj58v no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 21 09:55:58.553: INFO: Waiting up to 5m0s for pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx" in namespace "e2e-tests-svcaccounts-wcdnn" to be "success or failure"
Jan 21 09:55:58.556: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.830604ms
Jan 21 09:56:00.559: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005687558s
STEP: Saw pod success
Jan 21 09:56:00.559: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx" satisfied condition "success or failure"
Jan 21 09:56:00.561: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx container root-ca-test: <nil>
STEP: delete the pod
Jan 21 09:56:00.577: INFO: Waiting for pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx to disappear
Jan 21 09:56:00.579: INFO: Pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-gsjhx no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 21 09:56:00.583: INFO: Waiting up to 5m0s for pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924" in namespace "e2e-tests-svcaccounts-wcdnn" to be "success or failure"
Jan 21 09:56:00.585: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924": Phase="Pending", Reason="", readiness=false. Elapsed: 1.720626ms
Jan 21 09:56:02.590: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007349318s
STEP: Saw pod success
Jan 21 09:56:02.591: INFO: Pod "pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924" satisfied condition "success or failure"
Jan 21 09:56:02.592: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924 container namespace-test: <nil>
STEP: delete the pod
Jan 21 09:56:02.606: INFO: Waiting for pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924 to disappear
Jan 21 09:56:02.607: INFO: Pod pod-service-account-be1dfdad-1d62-11e9-9c91-0a58ac100282-d4924 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:56:02.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-wcdnn" for this suite.
Jan 21 09:56:08.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:56:08.666: INFO: namespace: e2e-tests-svcaccounts-wcdnn, resource: bindings, ignored listing per whitelist
Jan 21 09:56:08.681: INFO: namespace e2e-tests-svcaccounts-wcdnn deletion completed in 6.071035764s

• [SLOW TEST:14.724 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:56:08.682: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:56:08.746: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 21 09:56:08.754: INFO: Number of nodes with available pods: 0
Jan 21 09:56:08.754: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 21 09:56:08.768: INFO: Number of nodes with available pods: 0
Jan 21 09:56:08.768: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:09.771: INFO: Number of nodes with available pods: 0
Jan 21 09:56:09.771: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:10.771: INFO: Number of nodes with available pods: 1
Jan 21 09:56:10.771: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 21 09:56:10.785: INFO: Number of nodes with available pods: 1
Jan 21 09:56:10.785: INFO: Number of running nodes: 0, number of available pods: 1
Jan 21 09:56:11.787: INFO: Number of nodes with available pods: 0
Jan 21 09:56:11.787: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 21 09:56:11.795: INFO: Number of nodes with available pods: 0
Jan 21 09:56:11.795: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:12.802: INFO: Number of nodes with available pods: 0
Jan 21 09:56:12.802: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:13.799: INFO: Number of nodes with available pods: 0
Jan 21 09:56:13.799: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:14.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:14.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:15.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:15.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:16.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:16.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:17.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:17.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:18.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:18.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:19.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:19.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:20.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:20.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:21.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:21.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:22.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:22.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:23.802: INFO: Number of nodes with available pods: 0
Jan 21 09:56:23.802: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:24.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:24.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:25.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:25.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:26.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:26.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:27.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:27.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:28.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:28.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:29.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:29.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:30.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:30.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:31.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:31.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:32.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:32.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:33.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:33.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:34.802: INFO: Number of nodes with available pods: 0
Jan 21 09:56:34.802: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:35.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:35.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:36.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:36.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:37.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:37.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:38.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:38.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:39.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:39.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:40.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:40.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:41.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:41.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:42.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:42.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:43.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:43.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:44.798: INFO: Number of nodes with available pods: 0
Jan 21 09:56:44.798: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:56:45.802: INFO: Number of nodes with available pods: 1
Jan 21 09:56:45.802: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-dldb8, will wait for the garbage collector to delete the pods
Jan 21 09:56:45.862: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.370521ms
Jan 21 09:56:45.962: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.15145ms
Jan 21 09:57:22.269: INFO: Number of nodes with available pods: 0
Jan 21 09:57:22.269: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 09:57:22.270: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dldb8/daemonsets","resourceVersion":"25054"},"items":null}

Jan 21 09:57:22.272: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dldb8/pods","resourceVersion":"25054"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:57:22.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dldb8" for this suite.
Jan 21 09:57:28.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:57:28.341: INFO: namespace: e2e-tests-daemonsets-dldb8, resource: bindings, ignored listing per whitelist
Jan 21 09:57:28.360: INFO: namespace e2e-tests-daemonsets-dldb8 deletion completed in 6.070338725s

• [SLOW TEST:79.679 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:57:28.360: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f61560c9-1d62-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 09:57:28.419: INFO: Waiting up to 5m0s for pod "pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-f8qz7" to be "success or failure"
Jan 21 09:57:28.421: INFO: Pod "pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.779284ms
Jan 21 09:57:30.424: INFO: Pod "pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004362978s
STEP: Saw pod success
Jan 21 09:57:30.424: INFO: Pod "pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 09:57:30.426: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 09:57:30.439: INFO: Waiting for pod pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282 to disappear
Jan 21 09:57:30.441: INFO: Pod pod-secrets-f6160b43-1d62-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:57:30.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f8qz7" for this suite.
Jan 21 09:57:36.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:57:36.479: INFO: namespace: e2e-tests-secrets-f8qz7, resource: bindings, ignored listing per whitelist
Jan 21 09:57:36.514: INFO: namespace e2e-tests-secrets-f8qz7 deletion completed in 6.069428348s

• [SLOW TEST:8.153 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:57:36.514: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qg26x
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 21 09:57:36.574: INFO: Found 0 stateful pods, waiting for 3
Jan 21 09:57:46.581: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:57:46.581: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:57:46.581: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 21 09:57:46.608: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 21 09:57:56.643: INFO: Updating stateful set ss2
Jan 21 09:57:56.652: INFO: Waiting for Pod e2e-tests-statefulset-qg26x/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 21 09:58:06.688: INFO: Found 1 stateful pods, waiting for 3
Jan 21 09:58:16.695: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:58:16.695: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 09:58:16.695: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 21 09:58:16.716: INFO: Updating stateful set ss2
Jan 21 09:58:16.720: INFO: Waiting for Pod e2e-tests-statefulset-qg26x/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 09:58:26.754: INFO: Updating stateful set ss2
Jan 21 09:58:26.758: INFO: Waiting for StatefulSet e2e-tests-statefulset-qg26x/ss2 to complete update
Jan 21 09:58:26.758: INFO: Waiting for Pod e2e-tests-statefulset-qg26x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 09:58:36.767: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qg26x
Jan 21 09:58:36.769: INFO: Scaling statefulset ss2 to 0
Jan 21 09:58:56.790: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 09:58:56.793: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:58:56.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qg26x" for this suite.
Jan 21 09:59:02.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:59:02.862: INFO: namespace: e2e-tests-statefulset-qg26x, resource: bindings, ignored listing per whitelist
Jan 21 09:59:02.883: INFO: namespace e2e-tests-statefulset-qg26x deletion completed in 6.070740227s

• [SLOW TEST:86.369 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:59:02.883: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282
Jan 21 09:59:02.948: INFO: Pod name my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282: Found 0 pods out of 1
Jan 21 09:59:07.958: INFO: Pod name my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282: Found 1 pods out of 1
Jan 21 09:59:07.958: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282" are running
Jan 21 09:59:07.960: INFO: Pod "my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282-47f9f" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:59:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:59:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:59:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 09:59:02 +0000 UTC Reason: Message:}])
Jan 21 09:59:07.960: INFO: Trying to dial the pod
Jan 21 09:59:12.967: INFO: Controller my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282: Got expected result from replica 1 [my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282-47f9f]: "my-hostname-basic-2e6da254-1d63-11e9-9c91-0a58ac100282-47f9f", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:59:12.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-r4clz" for this suite.
Jan 21 09:59:18.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:59:19.046: INFO: namespace: e2e-tests-replication-controller-r4clz, resource: bindings, ignored listing per whitelist
Jan 21 09:59:19.046: INFO: namespace e2e-tests-replication-controller-r4clz deletion completed in 6.075792498s

• [SLOW TEST:16.163 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:59:19.046: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-gv5n8
I0121 09:59:19.104571      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-gv5n8, replica count: 1
I0121 09:59:20.154904      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 09:59:21.155083      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 21 09:59:21.262: INFO: Created: latency-svc-4ngvd
Jan 21 09:59:21.271: INFO: Got endpoints: latency-svc-4ngvd [15.820832ms]
Jan 21 09:59:21.279: INFO: Created: latency-svc-fstz6
Jan 21 09:59:21.283: INFO: Got endpoints: latency-svc-fstz6 [11.865566ms]
Jan 21 09:59:21.284: INFO: Created: latency-svc-ftqkg
Jan 21 09:59:21.289: INFO: Got endpoints: latency-svc-ftqkg [17.481808ms]
Jan 21 09:59:21.292: INFO: Created: latency-svc-bg5n7
Jan 21 09:59:21.296: INFO: Created: latency-svc-qpghp
Jan 21 09:59:21.297: INFO: Got endpoints: latency-svc-bg5n7 [25.679337ms]
Jan 21 09:59:21.305: INFO: Created: latency-svc-27r9g
Jan 21 09:59:21.305: INFO: Got endpoints: latency-svc-qpghp [34.131621ms]
Jan 21 09:59:21.310: INFO: Created: latency-svc-k6dh5
Jan 21 09:59:21.318: INFO: Got endpoints: latency-svc-27r9g [46.57573ms]
Jan 21 09:59:21.324: INFO: Got endpoints: latency-svc-k6dh5 [52.285204ms]
Jan 21 09:59:21.335: INFO: Created: latency-svc-r59cb
Jan 21 09:59:21.335: INFO: Created: latency-svc-xsszx
Jan 21 09:59:21.336: INFO: Got endpoints: latency-svc-r59cb [64.789492ms]
Jan 21 09:59:21.339: INFO: Got endpoints: latency-svc-xsszx [67.54038ms]
Jan 21 09:59:21.342: INFO: Created: latency-svc-4vbhx
Jan 21 09:59:21.345: INFO: Got endpoints: latency-svc-4vbhx [73.040651ms]
Jan 21 09:59:21.348: INFO: Created: latency-svc-f22h5
Jan 21 09:59:21.351: INFO: Created: latency-svc-vl9zl
Jan 21 09:59:21.355: INFO: Got endpoints: latency-svc-f22h5 [82.903499ms]
Jan 21 09:59:21.356: INFO: Got endpoints: latency-svc-vl9zl [83.991051ms]
Jan 21 09:59:21.356: INFO: Created: latency-svc-c85zb
Jan 21 09:59:21.361: INFO: Created: latency-svc-zkjht
Jan 21 09:59:21.364: INFO: Got endpoints: latency-svc-c85zb [92.323555ms]
Jan 21 09:59:21.367: INFO: Got endpoints: latency-svc-zkjht [95.517291ms]
Jan 21 09:59:21.368: INFO: Created: latency-svc-ncsmj
Jan 21 09:59:21.372: INFO: Got endpoints: latency-svc-ncsmj [99.809899ms]
Jan 21 09:59:21.373: INFO: Created: latency-svc-5qt8h
Jan 21 09:59:21.378: INFO: Got endpoints: latency-svc-5qt8h [105.782513ms]
Jan 21 09:59:21.379: INFO: Created: latency-svc-42vq8
Jan 21 09:59:21.383: INFO: Created: latency-svc-7w7fq
Jan 21 09:59:21.384: INFO: Got endpoints: latency-svc-42vq8 [100.903531ms]
Jan 21 09:59:21.388: INFO: Got endpoints: latency-svc-7w7fq [99.791849ms]
Jan 21 09:59:21.389: INFO: Created: latency-svc-7pzf5
Jan 21 09:59:21.393: INFO: Created: latency-svc-dqllr
Jan 21 09:59:21.394: INFO: Got endpoints: latency-svc-7pzf5 [97.312429ms]
Jan 21 09:59:21.397: INFO: Got endpoints: latency-svc-dqllr [91.403007ms]
Jan 21 09:59:21.399: INFO: Created: latency-svc-p27b2
Jan 21 09:59:21.402: INFO: Got endpoints: latency-svc-p27b2 [84.144284ms]
Jan 21 09:59:21.404: INFO: Created: latency-svc-tlbgt
Jan 21 09:59:21.408: INFO: Got endpoints: latency-svc-tlbgt [83.827749ms]
Jan 21 09:59:21.409: INFO: Created: latency-svc-7xdc4
Jan 21 09:59:21.413: INFO: Got endpoints: latency-svc-7xdc4 [76.943091ms]
Jan 21 09:59:21.414: INFO: Created: latency-svc-tsvvm
Jan 21 09:59:21.423: INFO: Got endpoints: latency-svc-tsvvm [83.63119ms]
Jan 21 09:59:21.424: INFO: Created: latency-svc-tpn6s
Jan 21 09:59:21.429: INFO: Got endpoints: latency-svc-tpn6s [83.921776ms]
Jan 21 09:59:21.429: INFO: Created: latency-svc-qggh7
Jan 21 09:59:21.434: INFO: Created: latency-svc-5lwbw
Jan 21 09:59:21.435: INFO: Got endpoints: latency-svc-qggh7 [80.167757ms]
Jan 21 09:59:21.438: INFO: Got endpoints: latency-svc-5lwbw [81.979918ms]
Jan 21 09:59:21.440: INFO: Created: latency-svc-7f744
Jan 21 09:59:21.443: INFO: Got endpoints: latency-svc-7f744 [78.598356ms]
Jan 21 09:59:21.446: INFO: Created: latency-svc-mjp9g
Jan 21 09:59:21.452: INFO: Got endpoints: latency-svc-mjp9g [85.191187ms]
Jan 21 09:59:21.453: INFO: Created: latency-svc-k7rrm
Jan 21 09:59:21.456: INFO: Got endpoints: latency-svc-k7rrm [83.976047ms]
Jan 21 09:59:21.459: INFO: Created: latency-svc-qdjft
Jan 21 09:59:21.463: INFO: Got endpoints: latency-svc-qdjft [84.95444ms]
Jan 21 09:59:21.465: INFO: Created: latency-svc-wmgnf
Jan 21 09:59:21.470: INFO: Got endpoints: latency-svc-wmgnf [86.50848ms]
Jan 21 09:59:21.471: INFO: Created: latency-svc-bfr8h
Jan 21 09:59:21.475: INFO: Got endpoints: latency-svc-bfr8h [86.624239ms]
Jan 21 09:59:21.475: INFO: Created: latency-svc-pvdgn
Jan 21 09:59:21.481: INFO: Got endpoints: latency-svc-pvdgn [86.3746ms]
Jan 21 09:59:21.481: INFO: Created: latency-svc-zs7r2
Jan 21 09:59:21.486: INFO: Created: latency-svc-zwtfm
Jan 21 09:59:21.490: INFO: Created: latency-svc-tk478
Jan 21 09:59:21.494: INFO: Created: latency-svc-89g9v
Jan 21 09:59:21.497: INFO: Created: latency-svc-5wvql
Jan 21 09:59:21.501: INFO: Created: latency-svc-x427m
Jan 21 09:59:21.505: INFO: Created: latency-svc-qzss2
Jan 21 09:59:21.509: INFO: Created: latency-svc-l5xxj
Jan 21 09:59:21.515: INFO: Created: latency-svc-86q4x
Jan 21 09:59:21.517: INFO: Got endpoints: latency-svc-zs7r2 [120.329398ms]
Jan 21 09:59:21.520: INFO: Created: latency-svc-5j88l
Jan 21 09:59:21.524: INFO: Created: latency-svc-69fnm
Jan 21 09:59:21.531: INFO: Created: latency-svc-zk2kp
Jan 21 09:59:21.534: INFO: Created: latency-svc-257gz
Jan 21 09:59:21.537: INFO: Created: latency-svc-2ww84
Jan 21 09:59:21.542: INFO: Created: latency-svc-chgcv
Jan 21 09:59:21.549: INFO: Created: latency-svc-qg6z2
Jan 21 09:59:21.566: INFO: Got endpoints: latency-svc-zwtfm [163.696028ms]
Jan 21 09:59:21.575: INFO: Created: latency-svc-llz65
Jan 21 09:59:21.615: INFO: Got endpoints: latency-svc-tk478 [207.777133ms]
Jan 21 09:59:21.623: INFO: Created: latency-svc-bjntw
Jan 21 09:59:21.667: INFO: Got endpoints: latency-svc-89g9v [253.484972ms]
Jan 21 09:59:21.675: INFO: Created: latency-svc-wvr5t
Jan 21 09:59:21.716: INFO: Got endpoints: latency-svc-5wvql [292.944564ms]
Jan 21 09:59:21.723: INFO: Created: latency-svc-2hlgf
Jan 21 09:59:21.765: INFO: Got endpoints: latency-svc-x427m [336.817613ms]
Jan 21 09:59:21.773: INFO: Created: latency-svc-9t56z
Jan 21 09:59:21.817: INFO: Got endpoints: latency-svc-qzss2 [382.23198ms]
Jan 21 09:59:21.825: INFO: Created: latency-svc-btvrs
Jan 21 09:59:21.865: INFO: Got endpoints: latency-svc-l5xxj [427.66654ms]
Jan 21 09:59:21.871: INFO: Created: latency-svc-rx2jz
Jan 21 09:59:21.917: INFO: Got endpoints: latency-svc-86q4x [473.879701ms]
Jan 21 09:59:21.924: INFO: Created: latency-svc-zdm5j
Jan 21 09:59:21.966: INFO: Got endpoints: latency-svc-5j88l [513.537489ms]
Jan 21 09:59:21.972: INFO: Created: latency-svc-g7pl9
Jan 21 09:59:22.015: INFO: Got endpoints: latency-svc-69fnm [559.769816ms]
Jan 21 09:59:22.023: INFO: Created: latency-svc-mbpf2
Jan 21 09:59:22.067: INFO: Got endpoints: latency-svc-zk2kp [604.253448ms]
Jan 21 09:59:22.073: INFO: Created: latency-svc-rr7gl
Jan 21 09:59:22.116: INFO: Got endpoints: latency-svc-257gz [645.488697ms]
Jan 21 09:59:22.123: INFO: Created: latency-svc-h5fss
Jan 21 09:59:22.167: INFO: Got endpoints: latency-svc-2ww84 [691.526379ms]
Jan 21 09:59:22.173: INFO: Created: latency-svc-4sb4s
Jan 21 09:59:22.215: INFO: Got endpoints: latency-svc-chgcv [734.777741ms]
Jan 21 09:59:22.221: INFO: Created: latency-svc-h6fqg
Jan 21 09:59:22.266: INFO: Got endpoints: latency-svc-qg6z2 [749.15829ms]
Jan 21 09:59:22.274: INFO: Created: latency-svc-kzk98
Jan 21 09:59:22.315: INFO: Got endpoints: latency-svc-llz65 [749.429048ms]
Jan 21 09:59:22.323: INFO: Created: latency-svc-f2vjq
Jan 21 09:59:22.365: INFO: Got endpoints: latency-svc-bjntw [749.746671ms]
Jan 21 09:59:22.373: INFO: Created: latency-svc-87tpg
Jan 21 09:59:22.415: INFO: Got endpoints: latency-svc-wvr5t [748.733559ms]
Jan 21 09:59:22.421: INFO: Created: latency-svc-j7njh
Jan 21 09:59:22.466: INFO: Got endpoints: latency-svc-2hlgf [749.86426ms]
Jan 21 09:59:22.473: INFO: Created: latency-svc-jlr5d
Jan 21 09:59:22.515: INFO: Got endpoints: latency-svc-9t56z [749.824171ms]
Jan 21 09:59:22.522: INFO: Created: latency-svc-nb5dd
Jan 21 09:59:22.565: INFO: Got endpoints: latency-svc-btvrs [748.120004ms]
Jan 21 09:59:22.573: INFO: Created: latency-svc-5gl6p
Jan 21 09:59:22.616: INFO: Got endpoints: latency-svc-rx2jz [750.126526ms]
Jan 21 09:59:22.622: INFO: Created: latency-svc-z9fg5
Jan 21 09:59:22.666: INFO: Got endpoints: latency-svc-zdm5j [749.086457ms]
Jan 21 09:59:22.674: INFO: Created: latency-svc-fsg6h
Jan 21 09:59:22.715: INFO: Got endpoints: latency-svc-g7pl9 [749.342205ms]
Jan 21 09:59:22.721: INFO: Created: latency-svc-624hr
Jan 21 09:59:22.765: INFO: Got endpoints: latency-svc-mbpf2 [749.944275ms]
Jan 21 09:59:22.777: INFO: Created: latency-svc-wqjcl
Jan 21 09:59:22.815: INFO: Got endpoints: latency-svc-rr7gl [748.49133ms]
Jan 21 09:59:22.822: INFO: Created: latency-svc-kptv2
Jan 21 09:59:22.865: INFO: Got endpoints: latency-svc-h5fss [749.453979ms]
Jan 21 09:59:22.874: INFO: Created: latency-svc-rlp82
Jan 21 09:59:22.916: INFO: Got endpoints: latency-svc-4sb4s [749.528872ms]
Jan 21 09:59:22.922: INFO: Created: latency-svc-wl2f6
Jan 21 09:59:22.965: INFO: Got endpoints: latency-svc-h6fqg [749.81591ms]
Jan 21 09:59:22.979: INFO: Created: latency-svc-8qrqx
Jan 21 09:59:23.016: INFO: Got endpoints: latency-svc-kzk98 [749.320601ms]
Jan 21 09:59:23.024: INFO: Created: latency-svc-4kmz7
Jan 21 09:59:23.065: INFO: Got endpoints: latency-svc-f2vjq [750.06235ms]
Jan 21 09:59:23.074: INFO: Created: latency-svc-jlxjc
Jan 21 09:59:23.115: INFO: Got endpoints: latency-svc-87tpg [750.134863ms]
Jan 21 09:59:23.122: INFO: Created: latency-svc-948fv
Jan 21 09:59:23.165: INFO: Got endpoints: latency-svc-j7njh [749.945988ms]
Jan 21 09:59:23.172: INFO: Created: latency-svc-47z57
Jan 21 09:59:23.215: INFO: Got endpoints: latency-svc-jlr5d [749.690431ms]
Jan 21 09:59:23.223: INFO: Created: latency-svc-vnvwl
Jan 21 09:59:23.266: INFO: Got endpoints: latency-svc-nb5dd [750.233539ms]
Jan 21 09:59:23.272: INFO: Created: latency-svc-k48gv
Jan 21 09:59:23.316: INFO: Got endpoints: latency-svc-5gl6p [750.867187ms]
Jan 21 09:59:23.322: INFO: Created: latency-svc-sqb6b
Jan 21 09:59:23.365: INFO: Got endpoints: latency-svc-z9fg5 [749.784338ms]
Jan 21 09:59:23.373: INFO: Created: latency-svc-nkhxf
Jan 21 09:59:23.416: INFO: Got endpoints: latency-svc-fsg6h [750.014894ms]
Jan 21 09:59:23.425: INFO: Created: latency-svc-wxgvx
Jan 21 09:59:23.465: INFO: Got endpoints: latency-svc-624hr [749.940721ms]
Jan 21 09:59:23.479: INFO: Created: latency-svc-tb5lv
Jan 21 09:59:23.533: INFO: Got endpoints: latency-svc-wqjcl [767.186099ms]
Jan 21 09:59:23.540: INFO: Created: latency-svc-8jrqh
Jan 21 09:59:23.565: INFO: Got endpoints: latency-svc-kptv2 [749.942609ms]
Jan 21 09:59:23.571: INFO: Created: latency-svc-nb6tk
Jan 21 09:59:23.616: INFO: Got endpoints: latency-svc-rlp82 [750.430805ms]
Jan 21 09:59:23.623: INFO: Created: latency-svc-r9n4l
Jan 21 09:59:23.665: INFO: Got endpoints: latency-svc-wl2f6 [749.125815ms]
Jan 21 09:59:23.673: INFO: Created: latency-svc-qkwqh
Jan 21 09:59:23.715: INFO: Got endpoints: latency-svc-8qrqx [750.136515ms]
Jan 21 09:59:23.723: INFO: Created: latency-svc-jgzdr
Jan 21 09:59:23.766: INFO: Got endpoints: latency-svc-4kmz7 [750.469312ms]
Jan 21 09:59:23.772: INFO: Created: latency-svc-v6tc8
Jan 21 09:59:23.815: INFO: Got endpoints: latency-svc-jlxjc [749.588411ms]
Jan 21 09:59:23.823: INFO: Created: latency-svc-sws5g
Jan 21 09:59:23.865: INFO: Got endpoints: latency-svc-948fv [749.872438ms]
Jan 21 09:59:23.872: INFO: Created: latency-svc-82474
Jan 21 09:59:23.916: INFO: Got endpoints: latency-svc-47z57 [750.312857ms]
Jan 21 09:59:23.923: INFO: Created: latency-svc-l88z2
Jan 21 09:59:23.965: INFO: Got endpoints: latency-svc-vnvwl [749.994861ms]
Jan 21 09:59:23.972: INFO: Created: latency-svc-8gv64
Jan 21 09:59:24.020: INFO: Got endpoints: latency-svc-k48gv [754.601887ms]
Jan 21 09:59:24.027: INFO: Created: latency-svc-d9mld
Jan 21 09:59:24.066: INFO: Got endpoints: latency-svc-sqb6b [750.302254ms]
Jan 21 09:59:24.073: INFO: Created: latency-svc-5sjl7
Jan 21 09:59:24.116: INFO: Got endpoints: latency-svc-nkhxf [750.133001ms]
Jan 21 09:59:24.123: INFO: Created: latency-svc-md6dc
Jan 21 09:59:24.166: INFO: Got endpoints: latency-svc-wxgvx [750.620821ms]
Jan 21 09:59:24.172: INFO: Created: latency-svc-fr4kl
Jan 21 09:59:24.216: INFO: Got endpoints: latency-svc-tb5lv [750.253408ms]
Jan 21 09:59:24.223: INFO: Created: latency-svc-7j9hp
Jan 21 09:59:24.270: INFO: Got endpoints: latency-svc-8jrqh [737.201244ms]
Jan 21 09:59:24.336: INFO: Got endpoints: latency-svc-nb6tk [770.786769ms]
Jan 21 09:59:24.337: INFO: Created: latency-svc-x4fd5
Jan 21 09:59:24.343: INFO: Created: latency-svc-fzqpv
Jan 21 09:59:24.365: INFO: Got endpoints: latency-svc-r9n4l [749.605839ms]
Jan 21 09:59:24.372: INFO: Created: latency-svc-22hvm
Jan 21 09:59:24.416: INFO: Got endpoints: latency-svc-qkwqh [750.310169ms]
Jan 21 09:59:24.422: INFO: Created: latency-svc-m8fj8
Jan 21 09:59:24.467: INFO: Got endpoints: latency-svc-jgzdr [751.22311ms]
Jan 21 09:59:24.475: INFO: Created: latency-svc-d7xsk
Jan 21 09:59:24.518: INFO: Got endpoints: latency-svc-v6tc8 [751.801903ms]
Jan 21 09:59:24.535: INFO: Created: latency-svc-c7nww
Jan 21 09:59:24.565: INFO: Got endpoints: latency-svc-sws5g [750.129805ms]
Jan 21 09:59:24.573: INFO: Created: latency-svc-2tx9s
Jan 21 09:59:24.616: INFO: Got endpoints: latency-svc-82474 [750.380668ms]
Jan 21 09:59:24.622: INFO: Created: latency-svc-9bjf9
Jan 21 09:59:24.668: INFO: Got endpoints: latency-svc-l88z2 [751.906204ms]
Jan 21 09:59:24.675: INFO: Created: latency-svc-vcfws
Jan 21 09:59:24.717: INFO: Got endpoints: latency-svc-8gv64 [751.912371ms]
Jan 21 09:59:24.724: INFO: Created: latency-svc-vtbx9
Jan 21 09:59:24.765: INFO: Got endpoints: latency-svc-d9mld [745.051229ms]
Jan 21 09:59:24.771: INFO: Created: latency-svc-97lpx
Jan 21 09:59:24.816: INFO: Got endpoints: latency-svc-5sjl7 [749.948319ms]
Jan 21 09:59:24.823: INFO: Created: latency-svc-k9cn5
Jan 21 09:59:24.867: INFO: Got endpoints: latency-svc-md6dc [751.229221ms]
Jan 21 09:59:24.873: INFO: Created: latency-svc-2jbdx
Jan 21 09:59:24.916: INFO: Got endpoints: latency-svc-fr4kl [749.236195ms]
Jan 21 09:59:24.923: INFO: Created: latency-svc-lprhb
Jan 21 09:59:24.966: INFO: Got endpoints: latency-svc-7j9hp [750.154034ms]
Jan 21 09:59:24.973: INFO: Created: latency-svc-w2jqg
Jan 21 09:59:25.016: INFO: Got endpoints: latency-svc-x4fd5 [745.716299ms]
Jan 21 09:59:25.024: INFO: Created: latency-svc-qdx84
Jan 21 09:59:25.066: INFO: Got endpoints: latency-svc-fzqpv [729.542221ms]
Jan 21 09:59:25.073: INFO: Created: latency-svc-bkzvw
Jan 21 09:59:25.117: INFO: Got endpoints: latency-svc-22hvm [751.435601ms]
Jan 21 09:59:25.124: INFO: Created: latency-svc-fck4h
Jan 21 09:59:25.165: INFO: Got endpoints: latency-svc-m8fj8 [749.702149ms]
Jan 21 09:59:25.173: INFO: Created: latency-svc-psdxz
Jan 21 09:59:25.215: INFO: Got endpoints: latency-svc-d7xsk [748.261959ms]
Jan 21 09:59:25.223: INFO: Created: latency-svc-zzskh
Jan 21 09:59:25.267: INFO: Got endpoints: latency-svc-c7nww [748.568556ms]
Jan 21 09:59:25.273: INFO: Created: latency-svc-6299f
Jan 21 09:59:25.316: INFO: Got endpoints: latency-svc-2tx9s [751.157769ms]
Jan 21 09:59:25.324: INFO: Created: latency-svc-nv9j4
Jan 21 09:59:25.365: INFO: Got endpoints: latency-svc-9bjf9 [749.703004ms]
Jan 21 09:59:25.374: INFO: Created: latency-svc-5ct9f
Jan 21 09:59:25.417: INFO: Got endpoints: latency-svc-vcfws [749.070329ms]
Jan 21 09:59:25.424: INFO: Created: latency-svc-4r82q
Jan 21 09:59:25.466: INFO: Got endpoints: latency-svc-vtbx9 [748.257455ms]
Jan 21 09:59:25.473: INFO: Created: latency-svc-7mtmb
Jan 21 09:59:25.517: INFO: Got endpoints: latency-svc-97lpx [751.311086ms]
Jan 21 09:59:25.524: INFO: Created: latency-svc-wz2xk
Jan 21 09:59:25.566: INFO: Got endpoints: latency-svc-k9cn5 [749.213154ms]
Jan 21 09:59:25.574: INFO: Created: latency-svc-l4jhq
Jan 21 09:59:25.615: INFO: Got endpoints: latency-svc-2jbdx [748.610492ms]
Jan 21 09:59:25.623: INFO: Created: latency-svc-7v6th
Jan 21 09:59:25.665: INFO: Got endpoints: latency-svc-lprhb [749.659641ms]
Jan 21 09:59:25.672: INFO: Created: latency-svc-4dcm9
Jan 21 09:59:25.717: INFO: Got endpoints: latency-svc-w2jqg [750.799063ms]
Jan 21 09:59:25.735: INFO: Created: latency-svc-2zc8n
Jan 21 09:59:25.765: INFO: Got endpoints: latency-svc-qdx84 [749.704472ms]
Jan 21 09:59:25.772: INFO: Created: latency-svc-7hffx
Jan 21 09:59:25.817: INFO: Got endpoints: latency-svc-bkzvw [750.950006ms]
Jan 21 09:59:25.824: INFO: Created: latency-svc-f26rv
Jan 21 09:59:25.865: INFO: Got endpoints: latency-svc-fck4h [748.499769ms]
Jan 21 09:59:25.871: INFO: Created: latency-svc-mwg7d
Jan 21 09:59:25.915: INFO: Got endpoints: latency-svc-psdxz [750.103563ms]
Jan 21 09:59:25.923: INFO: Created: latency-svc-kq4w8
Jan 21 09:59:25.967: INFO: Got endpoints: latency-svc-zzskh [751.569965ms]
Jan 21 09:59:25.973: INFO: Created: latency-svc-zf5wk
Jan 21 09:59:26.016: INFO: Got endpoints: latency-svc-6299f [749.029868ms]
Jan 21 09:59:26.023: INFO: Created: latency-svc-f6g5d
Jan 21 09:59:26.066: INFO: Got endpoints: latency-svc-nv9j4 [749.960003ms]
Jan 21 09:59:26.073: INFO: Created: latency-svc-5mrnq
Jan 21 09:59:26.116: INFO: Got endpoints: latency-svc-5ct9f [750.438439ms]
Jan 21 09:59:26.123: INFO: Created: latency-svc-lwkcs
Jan 21 09:59:26.166: INFO: Got endpoints: latency-svc-4r82q [749.107754ms]
Jan 21 09:59:26.173: INFO: Created: latency-svc-89lgz
Jan 21 09:59:26.217: INFO: Got endpoints: latency-svc-7mtmb [751.039572ms]
Jan 21 09:59:26.225: INFO: Created: latency-svc-8h2gp
Jan 21 09:59:26.265: INFO: Got endpoints: latency-svc-wz2xk [748.637728ms]
Jan 21 09:59:26.273: INFO: Created: latency-svc-rsszh
Jan 21 09:59:26.316: INFO: Got endpoints: latency-svc-l4jhq [749.92486ms]
Jan 21 09:59:26.322: INFO: Created: latency-svc-sw6rd
Jan 21 09:59:26.365: INFO: Got endpoints: latency-svc-7v6th [749.908384ms]
Jan 21 09:59:26.373: INFO: Created: latency-svc-c5qtb
Jan 21 09:59:26.417: INFO: Got endpoints: latency-svc-4dcm9 [751.254394ms]
Jan 21 09:59:26.423: INFO: Created: latency-svc-kbhz5
Jan 21 09:59:26.466: INFO: Got endpoints: latency-svc-2zc8n [748.762462ms]
Jan 21 09:59:26.474: INFO: Created: latency-svc-wd2vk
Jan 21 09:59:26.516: INFO: Got endpoints: latency-svc-7hffx [750.223857ms]
Jan 21 09:59:26.522: INFO: Created: latency-svc-lvxrk
Jan 21 09:59:26.566: INFO: Got endpoints: latency-svc-f26rv [748.752397ms]
Jan 21 09:59:26.571: INFO: Created: latency-svc-85srv
Jan 21 09:59:26.616: INFO: Got endpoints: latency-svc-mwg7d [751.174643ms]
Jan 21 09:59:26.623: INFO: Created: latency-svc-zdwwf
Jan 21 09:59:26.666: INFO: Got endpoints: latency-svc-kq4w8 [750.528822ms]
Jan 21 09:59:26.674: INFO: Created: latency-svc-br5t6
Jan 21 09:59:26.715: INFO: Got endpoints: latency-svc-zf5wk [748.82125ms]
Jan 21 09:59:26.722: INFO: Created: latency-svc-qr8jt
Jan 21 09:59:26.765: INFO: Got endpoints: latency-svc-f6g5d [749.625522ms]
Jan 21 09:59:26.773: INFO: Created: latency-svc-6tsk5
Jan 21 09:59:26.816: INFO: Got endpoints: latency-svc-5mrnq [749.22773ms]
Jan 21 09:59:26.823: INFO: Created: latency-svc-l2qgg
Jan 21 09:59:26.866: INFO: Got endpoints: latency-svc-lwkcs [749.547131ms]
Jan 21 09:59:26.871: INFO: Created: latency-svc-szgbm
Jan 21 09:59:26.917: INFO: Got endpoints: latency-svc-89lgz [751.003379ms]
Jan 21 09:59:26.924: INFO: Created: latency-svc-mbhrr
Jan 21 09:59:26.966: INFO: Got endpoints: latency-svc-8h2gp [748.90971ms]
Jan 21 09:59:26.974: INFO: Created: latency-svc-5cnqs
Jan 21 09:59:27.015: INFO: Got endpoints: latency-svc-rsszh [749.933464ms]
Jan 21 09:59:27.024: INFO: Created: latency-svc-4l8b6
Jan 21 09:59:27.065: INFO: Got endpoints: latency-svc-sw6rd [749.784963ms]
Jan 21 09:59:27.072: INFO: Created: latency-svc-pbj8w
Jan 21 09:59:27.115: INFO: Got endpoints: latency-svc-c5qtb [750.103203ms]
Jan 21 09:59:27.122: INFO: Created: latency-svc-4lp79
Jan 21 09:59:27.166: INFO: Got endpoints: latency-svc-kbhz5 [749.181085ms]
Jan 21 09:59:27.172: INFO: Created: latency-svc-79dcf
Jan 21 09:59:27.216: INFO: Got endpoints: latency-svc-wd2vk [750.0493ms]
Jan 21 09:59:27.224: INFO: Created: latency-svc-kfvjg
Jan 21 09:59:27.267: INFO: Got endpoints: latency-svc-lvxrk [751.16188ms]
Jan 21 09:59:27.274: INFO: Created: latency-svc-mbvbd
Jan 21 09:59:27.317: INFO: Got endpoints: latency-svc-85srv [750.963208ms]
Jan 21 09:59:27.325: INFO: Created: latency-svc-4r59h
Jan 21 09:59:27.365: INFO: Got endpoints: latency-svc-zdwwf [748.843105ms]
Jan 21 09:59:27.373: INFO: Created: latency-svc-96lwz
Jan 21 09:59:27.424: INFO: Got endpoints: latency-svc-br5t6 [757.900876ms]
Jan 21 09:59:27.438: INFO: Created: latency-svc-g9p7d
Jan 21 09:59:27.465: INFO: Got endpoints: latency-svc-qr8jt [750.032114ms]
Jan 21 09:59:27.472: INFO: Created: latency-svc-xxzlp
Jan 21 09:59:27.516: INFO: Got endpoints: latency-svc-6tsk5 [750.726613ms]
Jan 21 09:59:27.526: INFO: Created: latency-svc-kc92d
Jan 21 09:59:27.567: INFO: Got endpoints: latency-svc-l2qgg [750.948167ms]
Jan 21 09:59:27.573: INFO: Created: latency-svc-n95p2
Jan 21 09:59:27.615: INFO: Got endpoints: latency-svc-szgbm [749.789549ms]
Jan 21 09:59:27.623: INFO: Created: latency-svc-6b8xt
Jan 21 09:59:27.666: INFO: Got endpoints: latency-svc-mbhrr [749.523772ms]
Jan 21 09:59:27.673: INFO: Created: latency-svc-wq7km
Jan 21 09:59:27.715: INFO: Got endpoints: latency-svc-5cnqs [749.793593ms]
Jan 21 09:59:27.724: INFO: Created: latency-svc-jh69j
Jan 21 09:59:27.766: INFO: Got endpoints: latency-svc-4l8b6 [750.299776ms]
Jan 21 09:59:27.773: INFO: Created: latency-svc-42np8
Jan 21 09:59:27.816: INFO: Got endpoints: latency-svc-pbj8w [750.049531ms]
Jan 21 09:59:27.822: INFO: Created: latency-svc-g6bjt
Jan 21 09:59:27.868: INFO: Got endpoints: latency-svc-4lp79 [752.204882ms]
Jan 21 09:59:27.875: INFO: Created: latency-svc-h6j6g
Jan 21 09:59:27.916: INFO: Got endpoints: latency-svc-79dcf [749.929328ms]
Jan 21 09:59:27.922: INFO: Created: latency-svc-dfpxl
Jan 21 09:59:27.967: INFO: Got endpoints: latency-svc-kfvjg [750.992335ms]
Jan 21 09:59:27.974: INFO: Created: latency-svc-vts77
Jan 21 09:59:28.015: INFO: Got endpoints: latency-svc-mbvbd [748.619656ms]
Jan 21 09:59:28.022: INFO: Created: latency-svc-6t2qv
Jan 21 09:59:28.065: INFO: Got endpoints: latency-svc-4r59h [748.694978ms]
Jan 21 09:59:28.073: INFO: Created: latency-svc-dhcrq
Jan 21 09:59:28.117: INFO: Got endpoints: latency-svc-96lwz [751.590684ms]
Jan 21 09:59:28.123: INFO: Created: latency-svc-psmnw
Jan 21 09:59:28.165: INFO: Got endpoints: latency-svc-g9p7d [741.324193ms]
Jan 21 09:59:28.173: INFO: Created: latency-svc-sr8dn
Jan 21 09:59:28.217: INFO: Got endpoints: latency-svc-xxzlp [751.769359ms]
Jan 21 09:59:28.224: INFO: Created: latency-svc-4pv8s
Jan 21 09:59:28.265: INFO: Got endpoints: latency-svc-kc92d [749.172223ms]
Jan 21 09:59:28.272: INFO: Created: latency-svc-8c7fn
Jan 21 09:59:28.315: INFO: Got endpoints: latency-svc-n95p2 [748.689725ms]
Jan 21 09:59:28.322: INFO: Created: latency-svc-khh7m
Jan 21 09:59:28.365: INFO: Got endpoints: latency-svc-6b8xt [749.829309ms]
Jan 21 09:59:28.374: INFO: Created: latency-svc-jzd6j
Jan 21 09:59:28.416: INFO: Got endpoints: latency-svc-wq7km [749.384424ms]
Jan 21 09:59:28.423: INFO: Created: latency-svc-whxxn
Jan 21 09:59:28.465: INFO: Got endpoints: latency-svc-jh69j [749.934918ms]
Jan 21 09:59:28.472: INFO: Created: latency-svc-92c2p
Jan 21 09:59:28.517: INFO: Got endpoints: latency-svc-42np8 [750.877046ms]
Jan 21 09:59:28.524: INFO: Created: latency-svc-xrdff
Jan 21 09:59:28.565: INFO: Got endpoints: latency-svc-g6bjt [749.805801ms]
Jan 21 09:59:28.572: INFO: Created: latency-svc-8sr9c
Jan 21 09:59:28.616: INFO: Got endpoints: latency-svc-h6j6g [747.882851ms]
Jan 21 09:59:28.622: INFO: Created: latency-svc-bsdtm
Jan 21 09:59:28.667: INFO: Got endpoints: latency-svc-dfpxl [750.745603ms]
Jan 21 09:59:28.676: INFO: Created: latency-svc-nx6tl
Jan 21 09:59:28.716: INFO: Got endpoints: latency-svc-vts77 [749.008489ms]
Jan 21 09:59:28.722: INFO: Created: latency-svc-s9cjg
Jan 21 09:59:28.765: INFO: Got endpoints: latency-svc-6t2qv [749.641652ms]
Jan 21 09:59:28.773: INFO: Created: latency-svc-ss2sl
Jan 21 09:59:28.816: INFO: Got endpoints: latency-svc-dhcrq [750.890464ms]
Jan 21 09:59:28.822: INFO: Created: latency-svc-mvfh9
Jan 21 09:59:28.866: INFO: Got endpoints: latency-svc-psmnw [748.533136ms]
Jan 21 09:59:28.872: INFO: Created: latency-svc-h76n6
Jan 21 09:59:28.917: INFO: Got endpoints: latency-svc-sr8dn [751.484389ms]
Jan 21 09:59:28.923: INFO: Created: latency-svc-pd6dj
Jan 21 09:59:28.965: INFO: Got endpoints: latency-svc-4pv8s [747.915913ms]
Jan 21 09:59:28.971: INFO: Created: latency-svc-kr9nn
Jan 21 09:59:29.015: INFO: Got endpoints: latency-svc-8c7fn [750.10532ms]
Jan 21 09:59:29.026: INFO: Created: latency-svc-jhwf4
Jan 21 09:59:29.066: INFO: Got endpoints: latency-svc-khh7m [750.131197ms]
Jan 21 09:59:29.072: INFO: Created: latency-svc-vwljl
Jan 21 09:59:29.117: INFO: Got endpoints: latency-svc-jzd6j [751.378484ms]
Jan 21 09:59:29.166: INFO: Got endpoints: latency-svc-whxxn [749.644146ms]
Jan 21 09:59:29.216: INFO: Got endpoints: latency-svc-92c2p [750.559462ms]
Jan 21 09:59:29.265: INFO: Got endpoints: latency-svc-xrdff [748.675715ms]
Jan 21 09:59:29.316: INFO: Got endpoints: latency-svc-8sr9c [750.225118ms]
Jan 21 09:59:29.365: INFO: Got endpoints: latency-svc-bsdtm [749.581271ms]
Jan 21 09:59:29.415: INFO: Got endpoints: latency-svc-nx6tl [748.499644ms]
Jan 21 09:59:29.465: INFO: Got endpoints: latency-svc-s9cjg [749.633953ms]
Jan 21 09:59:29.515: INFO: Got endpoints: latency-svc-ss2sl [750.298962ms]
Jan 21 09:59:29.565: INFO: Got endpoints: latency-svc-mvfh9 [748.989632ms]
Jan 21 09:59:29.616: INFO: Got endpoints: latency-svc-h76n6 [750.132365ms]
Jan 21 09:59:29.667: INFO: Got endpoints: latency-svc-pd6dj [749.7569ms]
Jan 21 09:59:29.716: INFO: Got endpoints: latency-svc-kr9nn [751.168664ms]
Jan 21 09:59:29.769: INFO: Got endpoints: latency-svc-jhwf4 [753.198692ms]
Jan 21 09:59:29.815: INFO: Got endpoints: latency-svc-vwljl [749.596387ms]
Jan 21 09:59:29.815: INFO: Latencies: [11.865566ms 17.481808ms 25.679337ms 34.131621ms 46.57573ms 52.285204ms 64.789492ms 67.54038ms 73.040651ms 76.943091ms 78.598356ms 80.167757ms 81.979918ms 82.903499ms 83.63119ms 83.827749ms 83.921776ms 83.976047ms 83.991051ms 84.144284ms 84.95444ms 85.191187ms 86.3746ms 86.50848ms 86.624239ms 91.403007ms 92.323555ms 95.517291ms 97.312429ms 99.791849ms 99.809899ms 100.903531ms 105.782513ms 120.329398ms 163.696028ms 207.777133ms 253.484972ms 292.944564ms 336.817613ms 382.23198ms 427.66654ms 473.879701ms 513.537489ms 559.769816ms 604.253448ms 645.488697ms 691.526379ms 729.542221ms 734.777741ms 737.201244ms 741.324193ms 745.051229ms 745.716299ms 747.882851ms 747.915913ms 748.120004ms 748.257455ms 748.261959ms 748.49133ms 748.499644ms 748.499769ms 748.533136ms 748.568556ms 748.610492ms 748.619656ms 748.637728ms 748.675715ms 748.689725ms 748.694978ms 748.733559ms 748.752397ms 748.762462ms 748.82125ms 748.843105ms 748.90971ms 748.989632ms 749.008489ms 749.029868ms 749.070329ms 749.086457ms 749.107754ms 749.125815ms 749.15829ms 749.172223ms 749.181085ms 749.213154ms 749.22773ms 749.236195ms 749.320601ms 749.342205ms 749.384424ms 749.429048ms 749.453979ms 749.523772ms 749.528872ms 749.547131ms 749.581271ms 749.588411ms 749.596387ms 749.605839ms 749.625522ms 749.633953ms 749.641652ms 749.644146ms 749.659641ms 749.690431ms 749.702149ms 749.703004ms 749.704472ms 749.746671ms 749.7569ms 749.784338ms 749.784963ms 749.789549ms 749.793593ms 749.805801ms 749.81591ms 749.824171ms 749.829309ms 749.86426ms 749.872438ms 749.908384ms 749.92486ms 749.929328ms 749.933464ms 749.934918ms 749.940721ms 749.942609ms 749.944275ms 749.945988ms 749.948319ms 749.960003ms 749.994861ms 750.014894ms 750.032114ms 750.0493ms 750.049531ms 750.06235ms 750.103203ms 750.103563ms 750.10532ms 750.126526ms 750.129805ms 750.131197ms 750.132365ms 750.133001ms 750.134863ms 750.136515ms 750.154034ms 750.223857ms 750.225118ms 750.233539ms 750.253408ms 750.298962ms 750.299776ms 750.302254ms 750.310169ms 750.312857ms 750.380668ms 750.430805ms 750.438439ms 750.469312ms 750.528822ms 750.559462ms 750.620821ms 750.726613ms 750.745603ms 750.799063ms 750.867187ms 750.877046ms 750.890464ms 750.948167ms 750.950006ms 750.963208ms 750.992335ms 751.003379ms 751.039572ms 751.157769ms 751.16188ms 751.168664ms 751.174643ms 751.22311ms 751.229221ms 751.254394ms 751.311086ms 751.378484ms 751.435601ms 751.484389ms 751.569965ms 751.590684ms 751.769359ms 751.801903ms 751.906204ms 751.912371ms 752.204882ms 753.198692ms 754.601887ms 757.900876ms 767.186099ms 770.786769ms]
Jan 21 09:59:29.815: INFO: 50 %ile: 749.625522ms
Jan 21 09:59:29.815: INFO: 90 %ile: 751.174643ms
Jan 21 09:59:29.815: INFO: 99 %ile: 767.186099ms
Jan 21 09:59:29.815: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 09:59:29.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-gv5n8" for this suite.
Jan 21 09:59:43.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 09:59:43.893: INFO: namespace: e2e-tests-svc-latency-gv5n8, resource: bindings, ignored listing per whitelist
Jan 21 09:59:43.895: INFO: namespace e2e-tests-svc-latency-gv5n8 deletion completed in 14.075847526s

• [SLOW TEST:24.848 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 09:59:43.895: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 09:59:43.966: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 21 09:59:43.975: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:43.975: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:43.975: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:43.977: INFO: Number of nodes with available pods: 0
Jan 21 09:59:43.977: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuht is running more than one daemon pod
Jan 21 09:59:44.980: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:44.980: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:44.980: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:44.982: INFO: Number of nodes with available pods: 1
Jan 21 09:59:44.982: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhu is running more than one daemon pod
Jan 21 09:59:45.980: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:45.981: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:45.981: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:45.983: INFO: Number of nodes with available pods: 3
Jan 21 09:59:45.983: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 21 09:59:46.004: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:46.004: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:46.004: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:46.007: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:46.007: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:46.007: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:47.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:47.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:47.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:47.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:47.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:47.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:48.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:48.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:48.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:48.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:48.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:48.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:49.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:49.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:49.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:49.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:49.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:49.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:50.014: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:50.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:50.014: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:50.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:50.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:50.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:51.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:51.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:51.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:51.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:51.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:51.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:52.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:52.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:52.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:52.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:52.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:52.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:53.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:53.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:53.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:53.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:53.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:53.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:54.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:54.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:54.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:54.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:54.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:54.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:55.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:55.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:55.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:55.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:55.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:55.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:56.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:56.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:56.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:56.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:56.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:56.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:57.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:57.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:57.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:57.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:57.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:57.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:58.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:58.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:58.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:58.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:58.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:58.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:59.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:59.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:59.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 09:59:59.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:59.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 09:59:59.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:00.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:00.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:00.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:00.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:00.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:00.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:01.014: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:01.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:01.014: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:01.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:01.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:01.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:02.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:02.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:02.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:02.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:02.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:02.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:03.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:03.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:03.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:03.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:03.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:03.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:04.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:04.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:04.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:04.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:04.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:04.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:05.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:05.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:05.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:05.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:05.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:05.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:06.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:06.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:06.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:06.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:06.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:06.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:07.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:07.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:07.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:07.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:07.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:07.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:08.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:08.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:08.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:08.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:08.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:08.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:09.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:09.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:09.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:09.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:09.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:09.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:10.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:10.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:10.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:10.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:10.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:10.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:11.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:11.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:11.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:11.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:11.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:11.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:12.013: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:12.013: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:12.013: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:12.018: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:12.018: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:12.018: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:13.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:13.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:13.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:13.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:13.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:13.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:14.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:14.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:14.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:14.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:14.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:14.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:15.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:15.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:15.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:15.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:15.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:15.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:16.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:16.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:16.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:16.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:16.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:16.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:17.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:17.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:17.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:17.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:17.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:17.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:18.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:18.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:18.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:18.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:18.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:18.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:19.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:19.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:19.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:19.010: INFO: Pod daemon-set-stvzz is not available
Jan 21 10:00:19.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:19.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:19.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:20.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:20.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:20.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:20.010: INFO: Pod daemon-set-stvzz is not available
Jan 21 10:00:20.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:20.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:20.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:21.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:21.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:21.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:21.010: INFO: Pod daemon-set-stvzz is not available
Jan 21 10:00:21.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:21.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:21.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:22.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:22.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:22.010: INFO: Wrong image for pod: daemon-set-stvzz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:22.010: INFO: Pod daemon-set-stvzz is not available
Jan 21 10:00:22.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:22.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:22.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:23.013: INFO: Pod daemon-set-4h5cb is not available
Jan 21 10:00:23.013: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:23.013: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:23.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:23.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:23.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:24.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:24.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:24.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:24.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:24.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:25.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:25.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:25.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:25.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:25.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:26.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:26.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:26.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:26.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:26.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:27.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:27.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:27.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:27.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:27.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:28.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:28.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:28.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:28.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:28.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:29.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:29.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:29.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:29.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:29.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:30.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:30.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:30.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:30.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:30.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:31.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:31.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:31.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:31.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:31.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:32.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:32.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:32.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:32.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:32.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:33.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:33.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:33.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:33.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:33.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:34.014: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:34.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:34.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:34.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:34.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:35.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:35.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:35.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:35.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:35.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:36.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:36.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:36.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:36.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:36.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:37.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:37.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:37.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:37.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:37.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:38.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:38.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:38.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:38.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:38.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:39.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:39.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:39.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:39.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:39.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:40.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:40.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:40.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:40.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:40.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:41.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:41.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:41.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:41.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:41.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:42.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:42.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:42.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:42.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:42.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:43.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:43.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:43.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:43.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:43.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:44.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:44.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:44.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:44.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:44.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:45.014: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:45.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:45.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:45.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:45.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:46.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:46.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:46.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:46.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:46.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:47.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:47.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:47.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:47.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:47.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:48.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:48.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:48.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:48.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:48.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:49.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:49.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:49.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:49.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:49.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:50.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:50.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:50.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:50.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:50.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:51.011: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:51.011: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:51.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:51.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:51.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:52.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:52.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:52.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:52.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:52.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:53.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:53.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:53.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:53.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:53.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:54.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:54.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:54.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:54.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:54.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:55.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:55.010: INFO: Pod daemon-set-cjfxc is not available
Jan 21 10:00:55.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:55.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:55.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:55.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:56.014: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:56.014: INFO: Pod daemon-set-cjfxc is not available
Jan 21 10:00:56.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:56.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:56.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:56.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:57.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:57.010: INFO: Pod daemon-set-cjfxc is not available
Jan 21 10:00:57.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:57.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:57.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:57.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:58.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:58.010: INFO: Pod daemon-set-cjfxc is not available
Jan 21 10:00:58.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:58.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:58.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:58.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:59.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:59.010: INFO: Pod daemon-set-cjfxc is not available
Jan 21 10:00:59.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:00:59.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:59.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:00:59.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:00.010: INFO: Wrong image for pod: daemon-set-cjfxc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:00.010: INFO: Pod daemon-set-cjfxc is not available
Jan 21 10:01:00.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:00.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:00.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:00.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:01.010: INFO: Pod daemon-set-8rsb2 is not available
Jan 21 10:01:01.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:01.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:01.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:01.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:02.010: INFO: Pod daemon-set-8rsb2 is not available
Jan 21 10:01:02.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:02.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:02.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:02.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:03.010: INFO: Pod daemon-set-8rsb2 is not available
Jan 21 10:01:03.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:03.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:03.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:03.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:04.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:04.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:04.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:04.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:05.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:05.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:05.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:05.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:06.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:06.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:06.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:06.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:07.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:07.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:07.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:07.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:08.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:08.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:08.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:08.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:09.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:09.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:09.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:09.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:10.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:10.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:10.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:10.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:11.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:11.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:11.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:11.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:12.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:12.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:12.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:12.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:13.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:13.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:13.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:13.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:14.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:14.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:14.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:14.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:15.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:15.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:15.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:15.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:16.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:16.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:16.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:16.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:17.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:17.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:17.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:17.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:18.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:18.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:18.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:18.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:19.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:19.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:19.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:19.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:20.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:20.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:20.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:20.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:21.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:21.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:21.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:21.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:22.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:22.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:22.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:22.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:23.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:23.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:23.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:23.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:24.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:24.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:24.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:24.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:25.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:25.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:25.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:25.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:26.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:26.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:26.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:26.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:27.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:27.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:27.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:27.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:28.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:28.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:28.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:28.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:29.014: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:29.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:29.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:29.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:30.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:30.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:30.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:30.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:31.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:31.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:31.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:31.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:32.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:32.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:32.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:32.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:33.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:33.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:33.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:33.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:34.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:34.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:34.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:34.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:35.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:35.010: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:35.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:35.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:35.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:36.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:36.010: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:36.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:36.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:36.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:37.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:37.010: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:37.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:37.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:37.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:38.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:38.010: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:38.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:38.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:38.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:39.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:39.011: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:39.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:39.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:39.014: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:40.013: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:40.013: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:40.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:40.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:40.017: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:41.010: INFO: Wrong image for pod: daemon-set-s4zx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 10:01:41.010: INFO: Pod daemon-set-s4zx7 is not available
Jan 21 10:01:41.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:41.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:41.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:42.010: INFO: Pod daemon-set-h2z95 is not available
Jan 21 10:01:42.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:42.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:42.013: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 21 10:01:42.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:42.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:42.016: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:42.018: INFO: Number of nodes with available pods: 2
Jan 21 10:01:42.018: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv is running more than one daemon pod
Jan 21 10:01:43.022: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:43.022: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:43.022: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:43.024: INFO: Number of nodes with available pods: 2
Jan 21 10:01:43.024: INFO: Node cn-hongkong.i-j6c44erhl7eu2z5nuuhv is running more than one daemon pod
Jan 21 10:01:44.022: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6c85s3rq7ziwc8yojiy with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:44.022: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6ccxsiaf8qoq1v5zbq6 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:44.022: INFO: DaemonSet pods can't tolerate node cn-hongkong.i-j6cftl2bwabxau78vigk with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 21 10:01:44.024: INFO: Number of nodes with available pods: 3
Jan 21 10:01:44.024: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-l2xb6, will wait for the garbage collector to delete the pods
Jan 21 10:01:44.091: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.36929ms
Jan 21 10:01:44.191: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.164779ms
Jan 21 10:01:52.297: INFO: Number of nodes with available pods: 0
Jan 21 10:01:52.297: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 10:01:52.299: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-l2xb6/daemonsets","resourceVersion":"27459"},"items":null}

Jan 21 10:01:52.300: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-l2xb6/pods","resourceVersion":"27459"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:01:52.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-l2xb6" for this suite.
Jan 21 10:01:58.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:01:58.380: INFO: namespace: e2e-tests-daemonsets-l2xb6, resource: bindings, ignored listing per whitelist
Jan 21 10:01:58.383: INFO: namespace e2e-tests-daemonsets-l2xb6 deletion completed in 6.071067419s

• [SLOW TEST:134.489 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:01:58.384: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9708e07e-1d63-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume secrets
Jan 21 10:01:58.453: INFO: Waiting up to 5m0s for pod "pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282" in namespace "e2e-tests-secrets-8bkxx" to be "success or failure"
Jan 21 10:01:58.454: INFO: Pod "pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.647866ms
Jan 21 10:02:00.457: INFO: Pod "pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004005546s
STEP: Saw pod success
Jan 21 10:02:00.457: INFO: Pod "pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:02:00.458: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282 container secret-env-test: <nil>
STEP: delete the pod
Jan 21 10:02:00.473: INFO: Waiting for pod pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:02:00.475: INFO: Pod pod-secrets-9709be4e-1d63-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:02:00.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8bkxx" for this suite.
Jan 21 10:02:06.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:02:06.516: INFO: namespace: e2e-tests-secrets-8bkxx, resource: bindings, ignored listing per whitelist
Jan 21 10:02:06.549: INFO: namespace e2e-tests-secrets-8bkxx deletion completed in 6.071727838s

• [SLOW TEST:8.166 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:02:06.550: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 10:02:06.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-rgz6v" to be "success or failure"
Jan 21 10:02:06.620: INFO: Pod "downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.788016ms
Jan 21 10:02:08.622: INFO: Pod "downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004466296s
STEP: Saw pod success
Jan 21 10:02:08.622: INFO: Pod "downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:02:08.624: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 10:02:08.646: INFO: Waiting for pod downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:02:08.647: INFO: Pod downwardapi-volume-9be74a3d-1d63-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:02:08.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rgz6v" for this suite.
Jan 21 10:02:14.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:02:14.676: INFO: namespace: e2e-tests-downward-api-rgz6v, resource: bindings, ignored listing per whitelist
Jan 21 10:02:14.721: INFO: namespace e2e-tests-downward-api-rgz6v deletion completed in 6.0704858s

• [SLOW TEST:8.171 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:02:14.721: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-s5tc
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 10:02:14.799: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-s5tc" in namespace "e2e-tests-subpath-mdcjd" to be "success or failure"
Jan 21 10:02:14.800: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.741868ms
Jan 21 10:02:16.803: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00419691s
Jan 21 10:02:18.805: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 4.006763535s
Jan 21 10:02:20.814: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 6.015223108s
Jan 21 10:02:22.821: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 8.021961721s
Jan 21 10:02:24.823: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 10.024607588s
Jan 21 10:02:26.826: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 12.027080534s
Jan 21 10:02:28.829: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 14.029950712s
Jan 21 10:02:30.831: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 16.032569145s
Jan 21 10:02:32.838: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 18.039325589s
Jan 21 10:02:34.841: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 20.04208366s
Jan 21 10:02:36.843: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Running", Reason="", readiness=false. Elapsed: 22.044620505s
Jan 21 10:02:38.846: INFO: Pod "pod-subpath-test-secret-s5tc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.047160047s
STEP: Saw pod success
Jan 21 10:02:38.846: INFO: Pod "pod-subpath-test-secret-s5tc" satisfied condition "success or failure"
Jan 21 10:02:38.848: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-subpath-test-secret-s5tc container test-container-subpath-secret-s5tc: <nil>
STEP: delete the pod
Jan 21 10:02:38.863: INFO: Waiting for pod pod-subpath-test-secret-s5tc to disappear
Jan 21 10:02:38.865: INFO: Pod pod-subpath-test-secret-s5tc no longer exists
STEP: Deleting pod pod-subpath-test-secret-s5tc
Jan 21 10:02:38.865: INFO: Deleting pod "pod-subpath-test-secret-s5tc" in namespace "e2e-tests-subpath-mdcjd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:02:38.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mdcjd" for this suite.
Jan 21 10:02:44.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:02:44.901: INFO: namespace: e2e-tests-subpath-mdcjd, resource: bindings, ignored listing per whitelist
Jan 21 10:02:44.946: INFO: namespace e2e-tests-subpath-mdcjd deletion completed in 6.077012247s

• [SLOW TEST:30.225 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:02:44.946: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan 21 10:02:44.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:45.181: INFO: stderr: ""
Jan 21 10:02:45.181: INFO: stdout: "pod/pause created\n"
Jan 21 10:02:45.181: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 21 10:02:45.181: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-zdgpt" to be "running and ready"
Jan 21 10:02:45.185: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.699819ms
Jan 21 10:02:47.188: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006415233s
Jan 21 10:02:47.188: INFO: Pod "pause" satisfied condition "running and ready"
Jan 21 10:02:47.188: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 21 10:02:47.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:47.282: INFO: stderr: ""
Jan 21 10:02:47.282: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 21 10:02:47.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pod pause -L testing-label --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:47.357: INFO: stderr: ""
Jan 21 10:02:47.358: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 21 10:02:47.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 label pods pause testing-label- --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:47.440: INFO: stderr: ""
Jan 21 10:02:47.440: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 21 10:02:47.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pod pause -L testing-label --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:47.517: INFO: stderr: ""
Jan 21 10:02:47.517: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan 21 10:02:47.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:47.604: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 10:02:47.604: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 21 10:02:47.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-zdgpt'
Jan 21 10:02:47.683: INFO: stderr: "No resources found.\n"
Jan 21 10:02:47.683: INFO: stdout: ""
Jan 21 10:02:47.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -l name=pause --namespace=e2e-tests-kubectl-zdgpt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 10:02:47.757: INFO: stderr: ""
Jan 21 10:02:47.757: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:02:47.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zdgpt" for this suite.
Jan 21 10:02:53.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:02:53.797: INFO: namespace: e2e-tests-kubectl-zdgpt, resource: bindings, ignored listing per whitelist
Jan 21 10:02:53.843: INFO: namespace e2e-tests-kubectl-zdgpt deletion completed in 6.08251816s

• [SLOW TEST:8.897 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:02:53.843: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 10:02:53.906: INFO: Waiting up to 5m0s for pod "downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-7jkd7" to be "success or failure"
Jan 21 10:02:53.907: INFO: Pod "downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.731787ms
Jan 21 10:02:55.910: INFO: Pod "downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004236816s
STEP: Saw pod success
Jan 21 10:02:55.910: INFO: Pod "downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:02:55.912: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282 container dapi-container: <nil>
STEP: delete the pod
Jan 21 10:02:55.926: INFO: Waiting for pod downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:02:55.927: INFO: Pod downward-api-b816f1e3-1d63-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:02:55.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7jkd7" for this suite.
Jan 21 10:03:01.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:03:01.977: INFO: namespace: e2e-tests-downward-api-7jkd7, resource: bindings, ignored listing per whitelist
Jan 21 10:03:02.002: INFO: namespace e2e-tests-downward-api-7jkd7 deletion completed in 6.071727655s

• [SLOW TEST:8.159 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:03:02.002: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-n9hdj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-n9hdj to expose endpoints map[]
Jan 21 10:03:02.080: INFO: Get endpoints failed (1.850755ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 21 10:03:03.083: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-n9hdj exposes endpoints map[] (1.004391417s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-n9hdj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-n9hdj to expose endpoints map[pod1:[80]]
Jan 21 10:03:05.106: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-n9hdj exposes endpoints map[pod1:[80]] (2.017692951s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-n9hdj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-n9hdj to expose endpoints map[pod1:[80] pod2:[80]]
Jan 21 10:03:07.129: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-n9hdj exposes endpoints map[pod1:[80] pod2:[80]] (2.019022711s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-n9hdj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-n9hdj to expose endpoints map[pod2:[80]]
Jan 21 10:03:08.143: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-n9hdj exposes endpoints map[pod2:[80]] (1.009662415s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-n9hdj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-n9hdj to expose endpoints map[]
Jan 21 10:03:09.151: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-n9hdj exposes endpoints map[] (1.003980859s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:03:09.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-n9hdj" for this suite.
Jan 21 10:03:31.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:03:31.234: INFO: namespace: e2e-tests-services-n9hdj, resource: bindings, ignored listing per whitelist
Jan 21 10:03:31.245: INFO: namespace e2e-tests-services-n9hdj deletion completed in 22.070806461s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.243 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:03:31.245: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 21 10:03:31.306: INFO: Waiting up to 5m0s for pod "pod-ce615e09-1d63-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-bgzwt" to be "success or failure"
Jan 21 10:03:31.308: INFO: Pod "pod-ce615e09-1d63-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.17616ms
Jan 21 10:03:33.311: INFO: Pod "pod-ce615e09-1d63-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004654712s
STEP: Saw pod success
Jan 21 10:03:33.311: INFO: Pod "pod-ce615e09-1d63-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:03:33.313: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-ce615e09-1d63-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 10:03:33.326: INFO: Waiting for pod pod-ce615e09-1d63-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:03:33.328: INFO: Pod pod-ce615e09-1d63-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:03:33.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bgzwt" for this suite.
Jan 21 10:03:39.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:03:39.392: INFO: namespace: e2e-tests-emptydir-bgzwt, resource: bindings, ignored listing per whitelist
Jan 21 10:03:39.403: INFO: namespace e2e-tests-emptydir-bgzwt deletion completed in 6.072265482s

• [SLOW TEST:8.158 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:03:39.403: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 10:03:39.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-zjfhr" to be "success or failure"
Jan 21 10:03:39.457: INFO: Pod "downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.700039ms
Jan 21 10:03:41.460: INFO: Pod "downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004400404s
STEP: Saw pod success
Jan 21 10:03:41.460: INFO: Pod "downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:03:41.462: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 10:03:41.476: INFO: Waiting for pod downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:03:41.478: INFO: Pod downwardapi-volume-d33d44c2-1d63-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:03:41.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zjfhr" for this suite.
Jan 21 10:03:47.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:03:47.500: INFO: namespace: e2e-tests-downward-api-zjfhr, resource: bindings, ignored listing per whitelist
Jan 21 10:03:47.554: INFO: namespace e2e-tests-downward-api-zjfhr deletion completed in 6.072915511s

• [SLOW TEST:8.151 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:03:47.554: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 10:03:47.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282" in namespace "e2e-tests-downward-api-cntsf" to be "success or failure"
Jan 21 10:03:47.616: INFO: Pod "downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.921134ms
Jan 21 10:03:49.618: INFO: Pod "downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004565441s
STEP: Saw pod success
Jan 21 10:03:49.618: INFO: Pod "downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:03:49.620: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282 container client-container: <nil>
STEP: delete the pod
Jan 21 10:03:49.635: INFO: Waiting for pod downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:03:49.637: INFO: Pod downwardapi-volume-d819efde-1d63-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:03:49.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cntsf" for this suite.
Jan 21 10:03:55.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:03:55.683: INFO: namespace: e2e-tests-downward-api-cntsf, resource: bindings, ignored listing per whitelist
Jan 21 10:03:55.717: INFO: namespace e2e-tests-downward-api-cntsf deletion completed in 6.077382727s

• [SLOW TEST:8.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:03:55.717: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0121 10:04:35.796490      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 10:04:35.796: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:04:35.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6cgtz" for this suite.
Jan 21 10:04:41.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:04:41.869: INFO: namespace: e2e-tests-gc-6cgtz, resource: bindings, ignored listing per whitelist
Jan 21 10:04:41.873: INFO: namespace e2e-tests-gc-6cgtz deletion completed in 6.073234596s

• [SLOW TEST:46.156 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:04:41.873: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jp9m4
Jan 21 10:04:45.950: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jp9m4
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 10:04:45.952: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:08:46.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jp9m4" for this suite.
Jan 21 10:08:52.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:08:52.416: INFO: namespace: e2e-tests-container-probe-jp9m4, resource: bindings, ignored listing per whitelist
Jan 21 10:08:52.442: INFO: namespace e2e-tests-container-probe-jp9m4 deletion completed in 6.071808251s

• [SLOW TEST:250.569 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:08:52.442: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 21 10:08:52.499: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-484689981 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:08:52.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vf9z9" for this suite.
Jan 21 10:08:58.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:08:58.588: INFO: namespace: e2e-tests-kubectl-vf9z9, resource: bindings, ignored listing per whitelist
Jan 21 10:08:58.643: INFO: namespace e2e-tests-kubectl-vf9z9 deletion completed in 6.073672231s

• [SLOW TEST:6.201 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:08:58.643: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 10:08:58.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-58552'
Jan 21 10:08:58.960: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 10:08:58.960: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan 21 10:09:00.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-58552'
Jan 21 10:09:01.077: INFO: stderr: ""
Jan 21 10:09:01.077: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:09:01.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-58552" for this suite.
Jan 21 10:09:07.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:09:07.148: INFO: namespace: e2e-tests-kubectl-58552, resource: bindings, ignored listing per whitelist
Jan 21 10:09:07.156: INFO: namespace e2e-tests-kubectl-58552 deletion completed in 6.074643316s

• [SLOW TEST:8.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:09:07.156: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 21 10:09:07.220: INFO: Waiting up to 5m0s for pod "pod-969a1c03-1d64-11e9-9c91-0a58ac100282" in namespace "e2e-tests-emptydir-rm7zn" to be "success or failure"
Jan 21 10:09:07.222: INFO: Pod "pod-969a1c03-1d64-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.916778ms
Jan 21 10:09:09.225: INFO: Pod "pod-969a1c03-1d64-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00490217s
Jan 21 10:09:11.228: INFO: Pod "pod-969a1c03-1d64-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007662995s
STEP: Saw pod success
Jan 21 10:09:11.228: INFO: Pod "pod-969a1c03-1d64-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:09:11.230: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod pod-969a1c03-1d64-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 10:09:11.254: INFO: Waiting for pod pod-969a1c03-1d64-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:09:11.256: INFO: Pod pod-969a1c03-1d64-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:09:11.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rm7zn" for this suite.
Jan 21 10:09:17.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:09:17.316: INFO: namespace: e2e-tests-emptydir-rm7zn, resource: bindings, ignored listing per whitelist
Jan 21 10:09:17.333: INFO: namespace e2e-tests-emptydir-rm7zn deletion completed in 6.074088572s

• [SLOW TEST:10.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:09:17.334: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan 21 10:09:17.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 create -f - --namespace=e2e-tests-kubectl-27p7l'
Jan 21 10:09:17.564: INFO: stderr: ""
Jan 21 10:09:17.564: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 21 10:09:18.566: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 10:09:18.567: INFO: Found 0 / 1
Jan 21 10:09:19.566: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 10:09:19.566: INFO: Found 1 / 1
Jan 21 10:09:19.566: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 21 10:09:19.568: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 10:09:19.568: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 21 10:09:19.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 logs redis-master-rw98w redis-master --namespace=e2e-tests-kubectl-27p7l'
Jan 21 10:09:19.660: INFO: stderr: ""
Jan 21 10:09:19.660: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jan 10:09:18.466 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jan 10:09:18.466 # Server started, Redis version 3.2.12\n1:M 21 Jan 10:09:18.466 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jan 10:09:18.466 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 21 10:09:19.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 log redis-master-rw98w redis-master --namespace=e2e-tests-kubectl-27p7l --tail=1'
Jan 21 10:09:19.745: INFO: stderr: ""
Jan 21 10:09:19.745: INFO: stdout: "1:M 21 Jan 10:09:18.466 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 21 10:09:19.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 log redis-master-rw98w redis-master --namespace=e2e-tests-kubectl-27p7l --limit-bytes=1'
Jan 21 10:09:19.840: INFO: stderr: ""
Jan 21 10:09:19.840: INFO: stdout: " "
STEP: exposing timestamps
Jan 21 10:09:19.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 log redis-master-rw98w redis-master --namespace=e2e-tests-kubectl-27p7l --tail=1 --timestamps'
Jan 21 10:09:19.934: INFO: stderr: ""
Jan 21 10:09:19.934: INFO: stdout: "2019-01-21T10:09:18.467050801Z 1:M 21 Jan 10:09:18.466 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 21 10:09:22.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 log redis-master-rw98w redis-master --namespace=e2e-tests-kubectl-27p7l --since=1s'
Jan 21 10:09:22.520: INFO: stderr: ""
Jan 21 10:09:22.520: INFO: stdout: ""
Jan 21 10:09:22.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 log redis-master-rw98w redis-master --namespace=e2e-tests-kubectl-27p7l --since=24h'
Jan 21 10:09:22.606: INFO: stderr: ""
Jan 21 10:09:22.606: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jan 10:09:18.466 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jan 10:09:18.466 # Server started, Redis version 3.2.12\n1:M 21 Jan 10:09:18.466 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jan 10:09:18.466 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan 21 10:09:22.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27p7l'
Jan 21 10:09:22.686: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 10:09:22.686: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 21 10:09:22.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-27p7l'
Jan 21 10:09:22.770: INFO: stderr: "No resources found.\n"
Jan 21 10:09:22.770: INFO: stdout: ""
Jan 21 10:09:22.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-484689981 get pods -l name=nginx --namespace=e2e-tests-kubectl-27p7l -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 10:09:22.856: INFO: stderr: ""
Jan 21 10:09:22.856: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:09:22.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-27p7l" for this suite.
Jan 21 10:09:44.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:09:44.919: INFO: namespace: e2e-tests-kubectl-27p7l, resource: bindings, ignored listing per whitelist
Jan 21 10:09:44.934: INFO: namespace e2e-tests-kubectl-27p7l deletion completed in 22.074543296s

• [SLOW TEST:27.600 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:09:44.934: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 21 10:09:44.994: INFO: Waiting up to 5m0s for pod "client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282" in namespace "e2e-tests-containers-mshq5" to be "success or failure"
Jan 21 10:09:44.996: INFO: Pod "client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.69646ms
Jan 21 10:09:46.999: INFO: Pod "client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0042793s
STEP: Saw pod success
Jan 21 10:09:46.999: INFO: Pod "client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:09:47.000: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuht pod client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282 container test-container: <nil>
STEP: delete the pod
Jan 21 10:09:47.015: INFO: Waiting for pod client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:09:47.016: INFO: Pod client-containers-ad1e053f-1d64-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:09:47.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mshq5" for this suite.
Jan 21 10:09:53.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:09:53.055: INFO: namespace: e2e-tests-containers-mshq5, resource: bindings, ignored listing per whitelist
Jan 21 10:09:53.089: INFO: namespace e2e-tests-containers-mshq5 deletion completed in 6.069652606s

• [SLOW TEST:8.155 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:09:53.089: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b1fa881f-1d64-11e9-9c91-0a58ac100282
STEP: Creating a pod to test consume configMaps
Jan 21 10:09:53.158: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282" in namespace "e2e-tests-configmap-4ct8t" to be "success or failure"
Jan 21 10:09:53.160: INFO: Pod "pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282": Phase="Pending", Reason="", readiness=false. Elapsed: 1.706517ms
Jan 21 10:09:55.162: INFO: Pod "pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004305523s
STEP: Saw pod success
Jan 21 10:09:55.163: INFO: Pod "pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282" satisfied condition "success or failure"
Jan 21 10:09:55.164: INFO: Trying to get logs from node cn-hongkong.i-j6c44erhl7eu2z5nuuhv pod pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 10:09:55.178: INFO: Waiting for pod pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282 to disappear
Jan 21 10:09:55.179: INFO: Pod pod-configmaps-b1fc1add-1d64-11e9-9c91-0a58ac100282 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:09:55.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4ct8t" for this suite.
Jan 21 10:10:01.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:10:01.255: INFO: namespace: e2e-tests-configmap-4ct8t, resource: bindings, ignored listing per whitelist
Jan 21 10:10:01.258: INFO: namespace e2e-tests-configmap-4ct8t deletion completed in 6.075277275s

• [SLOW TEST:8.168 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:10:01.258: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0121 10:10:11.333159      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 10:10:11.333: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:10:11.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-x42fp" for this suite.
Jan 21 10:10:17.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:10:17.400: INFO: namespace: e2e-tests-gc-x42fp, resource: bindings, ignored listing per whitelist
Jan 21 10:10:17.407: INFO: namespace e2e-tests-gc-x42fp deletion completed in 6.071100713s

• [SLOW TEST:16.149 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 10:10:17.407: INFO: >>> kubeConfig: /tmp/kubeconfig-484689981
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9wfnw in namespace e2e-tests-proxy-rscrd
I0121 10:10:17.476589      16 runners.go:180] Created replication controller with name: proxy-service-9wfnw, namespace: e2e-tests-proxy-rscrd, replica count: 1
I0121 10:10:18.526962      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 10:10:19.527121      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 10:10:20.527302      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 10:10:21.527502      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 10:10:22.527700      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 10:10:23.527862      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 10:10:24.528048      16 runners.go:180] proxy-service-9wfnw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 21 10:10:24.533: INFO: setup took 7.070530159s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 21 10:10:24.538: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.106783ms)
Jan 21 10:10:24.538: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.410782ms)
Jan 21 10:10:24.538: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.562713ms)
Jan 21 10:10:24.542: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 8.386608ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 12.181856ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 12.021113ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 12.257759ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 12.161465ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 12.273577ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 12.25495ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 12.103733ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 12.115573ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 12.194054ms)
Jan 21 10:10:24.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 12.584716ms)
Jan 21 10:10:24.547: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 13.509975ms)
Jan 21 10:10:24.549: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 15.318915ms)
Jan 21 10:10:24.552: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.010262ms)
Jan 21 10:10:24.552: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.057013ms)
Jan 21 10:10:24.552: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 3.127341ms)
Jan 21 10:10:24.552: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.134053ms)
Jan 21 10:10:24.552: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.300971ms)
Jan 21 10:10:24.553: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.590958ms)
Jan 21 10:10:24.553: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.950828ms)
Jan 21 10:10:24.553: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.993774ms)
Jan 21 10:10:24.553: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.234633ms)
Jan 21 10:10:24.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.284782ms)
Jan 21 10:10:24.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.669429ms)
Jan 21 10:10:24.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.452633ms)
Jan 21 10:10:24.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.112793ms)
Jan 21 10:10:24.555: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.460775ms)
Jan 21 10:10:24.555: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 5.436791ms)
Jan 21 10:10:24.555: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 5.430682ms)
Jan 21 10:10:24.557: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.745501ms)
Jan 21 10:10:24.558: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.283988ms)
Jan 21 10:10:24.558: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.164458ms)
Jan 21 10:10:24.559: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.757087ms)
Jan 21 10:10:24.559: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.52349ms)
Jan 21 10:10:24.559: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.579838ms)
Jan 21 10:10:24.559: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.004143ms)
Jan 21 10:10:24.559: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.411017ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.803403ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.604679ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.904834ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.558419ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.657587ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 4.81774ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.1389ms)
Jan 21 10:10:24.560: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.179336ms)
Jan 21 10:10:24.563: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 2.704859ms)
Jan 21 10:10:24.563: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 2.730984ms)
Jan 21 10:10:24.564: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.335828ms)
Jan 21 10:10:24.564: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.438824ms)
Jan 21 10:10:24.564: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.987153ms)
Jan 21 10:10:24.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.001693ms)
Jan 21 10:10:24.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.292484ms)
Jan 21 10:10:24.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 4.256942ms)
Jan 21 10:10:24.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 4.517869ms)
Jan 21 10:10:24.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.524855ms)
Jan 21 10:10:24.565: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.755131ms)
Jan 21 10:10:24.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.875305ms)
Jan 21 10:10:24.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 4.939289ms)
Jan 21 10:10:24.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 5.278568ms)
Jan 21 10:10:24.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.304533ms)
Jan 21 10:10:24.566: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 5.606081ms)
Jan 21 10:10:24.568: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 2.432841ms)
Jan 21 10:10:24.569: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 2.568075ms)
Jan 21 10:10:24.569: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 2.623938ms)
Jan 21 10:10:24.569: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.722134ms)
Jan 21 10:10:24.569: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.714042ms)
Jan 21 10:10:24.570: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.065121ms)
Jan 21 10:10:24.570: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 3.778053ms)
Jan 21 10:10:24.570: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.503701ms)
Jan 21 10:10:24.570: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.819351ms)
Jan 21 10:10:24.570: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.053112ms)
Jan 21 10:10:24.570: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.704986ms)
Jan 21 10:10:24.571: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.35835ms)
Jan 21 10:10:24.571: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.132399ms)
Jan 21 10:10:24.571: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 4.236679ms)
Jan 21 10:10:24.571: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.333593ms)
Jan 21 10:10:24.571: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.730556ms)
Jan 21 10:10:24.574: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.524753ms)
Jan 21 10:10:24.574: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.870208ms)
Jan 21 10:10:24.574: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 2.748717ms)
Jan 21 10:10:24.575: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.160332ms)
Jan 21 10:10:24.575: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 3.436576ms)
Jan 21 10:10:24.575: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.461402ms)
Jan 21 10:10:24.575: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.004645ms)
Jan 21 10:10:24.575: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.862314ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.078953ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.410904ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.548787ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.67139ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.636233ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.70423ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.897017ms)
Jan 21 10:10:24.576: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.90159ms)
Jan 21 10:10:24.579: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.675482ms)
Jan 21 10:10:24.580: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.053963ms)
Jan 21 10:10:24.580: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.08483ms)
Jan 21 10:10:24.580: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.436574ms)
Jan 21 10:10:24.580: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.594379ms)
Jan 21 10:10:24.580: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 3.889068ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.956617ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.257323ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.309595ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.228265ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.33591ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 4.642179ms)
Jan 21 10:10:24.581: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 4.57892ms)
Jan 21 10:10:24.582: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.816933ms)
Jan 21 10:10:24.582: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.775298ms)
Jan 21 10:10:24.582: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.056466ms)
Jan 21 10:10:24.585: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.085054ms)
Jan 21 10:10:24.585: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.100644ms)
Jan 21 10:10:24.585: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.871572ms)
Jan 21 10:10:24.585: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.139263ms)
Jan 21 10:10:24.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.413582ms)
Jan 21 10:10:24.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.453358ms)
Jan 21 10:10:24.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.796646ms)
Jan 21 10:10:24.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.1287ms)
Jan 21 10:10:24.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 4.1926ms)
Jan 21 10:10:24.587: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.596828ms)
Jan 21 10:10:24.587: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.53366ms)
Jan 21 10:10:24.587: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.721584ms)
Jan 21 10:10:24.587: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 4.695122ms)
Jan 21 10:10:24.587: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.68113ms)
Jan 21 10:10:24.588: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.53563ms)
Jan 21 10:10:24.588: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.589614ms)
Jan 21 10:10:24.591: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.95429ms)
Jan 21 10:10:24.591: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.161908ms)
Jan 21 10:10:24.591: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.408798ms)
Jan 21 10:10:24.591: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.352974ms)
Jan 21 10:10:24.591: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.31883ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.675553ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 4.015898ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.21332ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.261666ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.390726ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.53702ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.590889ms)
Jan 21 10:10:24.592: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 4.475561ms)
Jan 21 10:10:24.593: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.679538ms)
Jan 21 10:10:24.593: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.972822ms)
Jan 21 10:10:24.593: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 5.187477ms)
Jan 21 10:10:24.600: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 6.313748ms)
Jan 21 10:10:24.600: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 6.564064ms)
Jan 21 10:10:24.600: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 6.88433ms)
Jan 21 10:10:24.601: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 7.907499ms)
Jan 21 10:10:24.601: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 7.689683ms)
Jan 21 10:10:24.601: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 8.338702ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 8.50669ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 8.15021ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 8.425754ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 8.337498ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 8.780161ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 9.092376ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 9.442599ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 8.822854ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 9.31434ms)
Jan 21 10:10:24.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 9.528417ms)
Jan 21 10:10:24.605: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 2.571434ms)
Jan 21 10:10:24.605: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 2.844694ms)
Jan 21 10:10:24.606: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.109531ms)
Jan 21 10:10:24.606: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.509088ms)
Jan 21 10:10:24.606: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 3.390098ms)
Jan 21 10:10:24.606: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.432214ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.677239ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.413684ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.422222ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.389847ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 4.760128ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.651995ms)
Jan 21 10:10:24.607: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.814025ms)
Jan 21 10:10:24.608: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.811108ms)
Jan 21 10:10:24.608: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.857692ms)
Jan 21 10:10:24.608: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.105327ms)
Jan 21 10:10:24.611: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 2.673716ms)
Jan 21 10:10:24.611: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 2.599163ms)
Jan 21 10:10:24.611: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.219983ms)
Jan 21 10:10:24.611: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.26674ms)
Jan 21 10:10:24.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.517661ms)
Jan 21 10:10:24.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.7991ms)
Jan 21 10:10:24.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.821958ms)
Jan 21 10:10:24.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 4.310741ms)
Jan 21 10:10:24.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.306637ms)
Jan 21 10:10:24.612: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.18344ms)
Jan 21 10:10:24.613: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.603523ms)
Jan 21 10:10:24.613: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.60334ms)
Jan 21 10:10:24.613: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.589325ms)
Jan 21 10:10:24.613: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.773136ms)
Jan 21 10:10:24.613: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.791975ms)
Jan 21 10:10:24.613: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.914211ms)
Jan 21 10:10:24.616: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 2.716253ms)
Jan 21 10:10:24.616: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.183955ms)
Jan 21 10:10:24.617: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.289546ms)
Jan 21 10:10:24.617: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.677066ms)
Jan 21 10:10:24.617: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.182751ms)
Jan 21 10:10:24.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.596933ms)
Jan 21 10:10:24.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.549738ms)
Jan 21 10:10:24.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.583818ms)
Jan 21 10:10:24.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 4.727792ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 5.407167ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.532304ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 5.164111ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 5.345907ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 5.658621ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 6.084918ms)
Jan 21 10:10:24.619: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 5.656072ms)
Jan 21 10:10:24.622: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.829386ms)
Jan 21 10:10:24.622: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.721086ms)
Jan 21 10:10:24.622: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 2.991456ms)
Jan 21 10:10:24.622: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.041811ms)
Jan 21 10:10:24.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.469495ms)
Jan 21 10:10:24.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.594996ms)
Jan 21 10:10:24.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.456733ms)
Jan 21 10:10:24.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 3.838627ms)
Jan 21 10:10:24.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.801861ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.304323ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.569617ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.485717ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.604909ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.873238ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.828401ms)
Jan 21 10:10:24.624: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 4.722911ms)
Jan 21 10:10:24.627: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.477052ms)
Jan 21 10:10:24.627: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 2.820822ms)
Jan 21 10:10:24.627: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.726254ms)
Jan 21 10:10:24.628: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.346365ms)
Jan 21 10:10:24.628: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.947018ms)
Jan 21 10:10:24.628: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.941156ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.330873ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.38983ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.823345ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.769478ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.619798ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.730022ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.7205ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 5.057251ms)
Jan 21 10:10:24.629: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.725543ms)
Jan 21 10:10:24.630: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.243863ms)
Jan 21 10:10:24.632: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 2.440963ms)
Jan 21 10:10:24.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.585709ms)
Jan 21 10:10:24.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.101536ms)
Jan 21 10:10:24.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 2.740297ms)
Jan 21 10:10:24.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.278859ms)
Jan 21 10:10:24.633: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.093988ms)
Jan 21 10:10:24.634: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.795015ms)
Jan 21 10:10:24.634: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.173219ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 4.329633ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.485528ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.86577ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.521666ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.68268ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 4.756917ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.968013ms)
Jan 21 10:10:24.635: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.159709ms)
Jan 21 10:10:24.637: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 2.263097ms)
Jan 21 10:10:24.638: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.56833ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.052375ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.617585ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.865526ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.736872ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.861605ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.98489ms)
Jan 21 10:10:24.639: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.257972ms)
Jan 21 10:10:24.640: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.06939ms)
Jan 21 10:10:24.640: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.781179ms)
Jan 21 10:10:24.640: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.441713ms)
Jan 21 10:10:24.640: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.5552ms)
Jan 21 10:10:24.640: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.690163ms)
Jan 21 10:10:24.640: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.823838ms)
Jan 21 10:10:24.641: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.964944ms)
Jan 21 10:10:24.643: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 2.455744ms)
Jan 21 10:10:24.644: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.039639ms)
Jan 21 10:10:24.644: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 3.201075ms)
Jan 21 10:10:24.644: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.212773ms)
Jan 21 10:10:24.644: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.432182ms)
Jan 21 10:10:24.644: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.774498ms)
Jan 21 10:10:24.645: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.903956ms)
Jan 21 10:10:24.645: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.430556ms)
Jan 21 10:10:24.645: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 4.541412ms)
Jan 21 10:10:24.645: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.55487ms)
Jan 21 10:10:24.645: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.839203ms)
Jan 21 10:10:24.646: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 4.99954ms)
Jan 21 10:10:24.646: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 5.053613ms)
Jan 21 10:10:24.646: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.206721ms)
Jan 21 10:10:24.646: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 5.430135ms)
Jan 21 10:10:24.646: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 5.644233ms)
Jan 21 10:10:24.649: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.897629ms)
Jan 21 10:10:24.649: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 3.04924ms)
Jan 21 10:10:24.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.221859ms)
Jan 21 10:10:24.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 3.178435ms)
Jan 21 10:10:24.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 3.194207ms)
Jan 21 10:10:24.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.286426ms)
Jan 21 10:10:24.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 3.48047ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 3.923456ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 4.095384ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 3.773273ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 3.952114ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 4.373813ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 4.310257ms)
Jan 21 10:10:24.651: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 4.461431ms)
Jan 21 10:10:24.652: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 4.897073ms)
Jan 21 10:10:24.652: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.866143ms)
Jan 21 10:10:24.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:460/proxy/: tls baz (200; 2.679252ms)
Jan 21 10:10:24.654: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:1080/proxy/... (200; 2.545688ms)
Jan 21 10:10:24.656: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:462/proxy/: tls qux (200; 4.291915ms)
Jan 21 10:10:24.656: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.334311ms)
Jan 21 10:10:24.657: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname2/proxy/: tls qux (200; 4.62048ms)
Jan 21 10:10:24.657: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:162/proxy/: bar (200; 4.723613ms)
Jan 21 10:10:24.657: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname2/proxy/: bar (200; 5.199616ms)
Jan 21 10:10:24.657: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname1/proxy/: foo (200; 5.500576ms)
Jan 21 10:10:24.657: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:1080/proxy/rewri... (200; 5.490151ms)
Jan 21 10:10:24.657: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/https:proxy-service-9wfnw:tlsportname1/proxy/: tls baz (200; 5.596016ms)
Jan 21 10:10:24.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/http:proxy-service-9wfnw:portname1/proxy/: foo (200; 5.859011ms)
Jan 21 10:10:24.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 5.904111ms)
Jan 21 10:10:24.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/http:proxy-service-9wfnw-q87jr:160/proxy/: foo (200; 6.122262ms)
Jan 21 10:10:24.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/proxy-service-9wfnw-q87jr/proxy/rewriteme"... (200; 6.067642ms)
Jan 21 10:10:24.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-rscrd/pods/https:proxy-service-9wfnw-q87jr:443/proxy/... (200; 6.231593ms)
Jan 21 10:10:24.658: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-rscrd/services/proxy-service-9wfnw:portname2/proxy/: bar (200; 6.32694ms)
STEP: deleting { ReplicationController} proxy-service-9wfnw in namespace e2e-tests-proxy-rscrd, will wait for the garbage collector to delete the pods
Jan 21 10:10:24.715: INFO: Deleting { ReplicationController} proxy-service-9wfnw took: 5.254065ms
Jan 21 10:10:24.815: INFO: Terminating { ReplicationController} proxy-service-9wfnw pods took: 100.1879ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 10:10:26.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-rscrd" for this suite.
Jan 21 10:10:32.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 10:10:32.352: INFO: namespace: e2e-tests-proxy-rscrd, resource: bindings, ignored listing per whitelist
Jan 21 10:10:32.390: INFO: namespace e2e-tests-proxy-rscrd deletion completed in 6.071263505s

• [SLOW TEST:14.984 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSJan 21 10:10:32.391: INFO: Running AfterSuite actions on all node
Jan 21 10:10:32.391: INFO: Running AfterSuite actions on node 1
Jan 21 10:10:32.391: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5081.163 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h24m41.862474739s
Test Suite Passed
