Mar  9 15:53:20.843: INFO: Overriding default scale value of zero to 1
Mar  9 15:53:20.843: INFO: Overriding default milliseconds value of zero to 5000
I0309 15:53:21.228816      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-182708018
I0309 15:53:21.228888      15 e2e.go:304] Starting e2e run "767ef7fc-4283-11e9-923b-2eb43f2b540f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1552146800 - Will randomize all specs
Will run 188 of 1814 specs

Mar  9 15:53:21.401: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 15:53:21.403: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  9 15:53:21.410: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  9 15:53:21.431: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  9 15:53:21.431: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Mar  9 15:53:21.431: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  9 15:53:21.439: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar  9 15:53:21.439: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Mar  9 15:53:21.439: INFO: e2e test version: v1.12.1
Mar  9 15:53:21.439: INFO: kube-apiserver version: v1.12.2
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 15:53:21.439: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 15:53:21.471735      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
Mar  9 15:53:21.531: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 15:53:21.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-wh9kg" to be "success or failure"
Mar  9 15:53:21.547: INFO: Pod "downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.447347ms
Mar  9 15:53:23.550: INFO: Pod "downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005069774s
Mar  9 15:53:25.551: INFO: Pod "downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006816355s
STEP: Saw pod success
Mar  9 15:53:25.551: INFO: Pod "downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 15:53:25.553: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 15:53:25.581: INFO: Waiting for pod downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f to disappear
Mar  9 15:53:25.582: INFO: Pod downwardapi-volume-76f361a1-4283-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 15:53:25.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wh9kg" for this suite.
Mar  9 15:53:31.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 15:53:31.607: INFO: namespace: e2e-tests-projected-wh9kg, resource: bindings, ignored listing per whitelist
Mar  9 15:53:31.633: INFO: namespace e2e-tests-projected-wh9kg deletion completed in 6.048603414s

• [SLOW TEST:10.193 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 15:53:31.633: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 15:53:31.650166      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-4clms
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4clms to expose endpoints map[]
Mar  9 15:53:31.677: INFO: Get endpoints failed (4.490391ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar  9 15:53:32.678: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4clms exposes endpoints map[] (1.006050474s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-4clms
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4clms to expose endpoints map[pod1:[80]]
Mar  9 15:53:34.694: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4clms exposes endpoints map[pod1:[80]] (2.011574753s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-4clms
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4clms to expose endpoints map[pod1:[80] pod2:[80]]
Mar  9 15:53:35.714: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4clms exposes endpoints map[pod1:[80] pod2:[80]] (1.017038961s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-4clms
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4clms to expose endpoints map[pod2:[80]]
Mar  9 15:53:35.728: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4clms exposes endpoints map[pod2:[80]] (7.411076ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-4clms
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-4clms to expose endpoints map[]
Mar  9 15:53:35.735: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-4clms exposes endpoints map[] (1.052998ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 15:53:35.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-4clms" for this suite.
Mar  9 15:53:57.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 15:53:57.767: INFO: namespace: e2e-tests-services-4clms, resource: bindings, ignored listing per whitelist
Mar  9 15:53:57.799: INFO: namespace e2e-tests-services-4clms deletion completed in 22.050765333s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:26.166 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 15:53:57.799: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 15:53:57.817038      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jxc22
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jxc22
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jxc22
Mar  9 15:53:57.860: INFO: Found 0 stateful pods, waiting for 1
Mar  9 15:54:07.862: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  9 15:54:07.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 15:54:08.023: INFO: stderr: ""
Mar  9 15:54:08.023: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 15:54:08.023: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 15:54:08.024: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  9 15:54:18.026: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 15:54:18.026: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 15:54:18.033: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:18.033: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:18.033: INFO: 
Mar  9 15:54:18.033: INFO: StatefulSet ss has not reached scale 3, at 1
Mar  9 15:54:19.035: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997928186s
Mar  9 15:54:20.037: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.996076286s
Mar  9 15:54:21.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.994032282s
Mar  9 15:54:22.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.991900929s
Mar  9 15:54:23.043: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.989876715s
Mar  9 15:54:24.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.987693906s
Mar  9 15:54:25.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.985869848s
Mar  9 15:54:26.049: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.983169561s
Mar  9 15:54:27.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 981.398914ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jxc22
Mar  9 15:54:28.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:54:28.207: INFO: stderr: ""
Mar  9 15:54:28.207: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 15:54:28.207: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 15:54:28.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:54:28.351: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  9 15:54:28.351: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 15:54:28.351: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 15:54:28.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:54:28.512: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  9 15:54:28.512: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 15:54:28.512: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 15:54:28.513: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Mar  9 15:54:38.515: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 15:54:38.515: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 15:54:38.515: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  9 15:54:38.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 15:54:38.664: INFO: stderr: ""
Mar  9 15:54:38.664: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 15:54:38.664: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 15:54:38.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 15:54:38.814: INFO: stderr: ""
Mar  9 15:54:38.814: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 15:54:38.814: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 15:54:38.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 15:54:38.966: INFO: stderr: ""
Mar  9 15:54:38.966: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 15:54:38.966: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 15:54:38.966: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 15:54:38.968: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar  9 15:54:48.971: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 15:54:48.971: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 15:54:48.971: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 15:54:48.979: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:48.979: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:48.979: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:48.979: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:48.979: INFO: 
Mar  9 15:54:48.979: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:49.981: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:49.981: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:49.981: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:49.981: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:49.981: INFO: 
Mar  9 15:54:49.981: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:50.983: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:50.983: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:50.983: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:50.983: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:50.983: INFO: 
Mar  9 15:54:50.983: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:51.985: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:51.985: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:51.985: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:51.985: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:51.985: INFO: 
Mar  9 15:54:51.985: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:52.987: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:52.987: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:52.987: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:52.987: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:52.987: INFO: 
Mar  9 15:54:52.987: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:53.990: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:53.990: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:53.990: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:53.990: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:53.990: INFO: 
Mar  9 15:54:53.990: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:54.992: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:54.992: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:54.992: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:54.992: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:54.992: INFO: 
Mar  9 15:54:54.992: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:55.994: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:55.994: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:55.994: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:55.994: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:55.994: INFO: 
Mar  9 15:54:55.994: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:56.996: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:56.996: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:56.996: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:56.996: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:56.996: INFO: 
Mar  9 15:54:56.996: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 15:54:57.998: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Mar  9 15:54:57.998: INFO: ss-0  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:53:57 +0000 UTC  }]
Mar  9 15:54:57.998: INFO: ss-1  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:57.998: INFO: ss-2  ip-192-168-70-73.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 15:54:18 +0000 UTC  }]
Mar  9 15:54:57.998: INFO: 
Mar  9 15:54:57.998: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jxc22
Mar  9 15:54:59.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:54:59.076: INFO: rc: 1
Mar  9 15:54:59.076: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42219c480 exit status 1 <nil> <nil> true [0xc4216b6438 0xc4216b6450 0xc4216b6468] [0xc4216b6438 0xc4216b6450 0xc4216b6468] [0xc4216b6448 0xc4216b6460] [0x8fd520 0x8fd520] 0xc421350c60 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar  9 15:55:09.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:55:09.138: INFO: rc: 1
Mar  9 15:55:09.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4221b0c90 exit status 1 <nil> <nil> true [0xc4215b3fd0 0xc4215b3fe8 0xc4221a2000] [0xc4215b3fd0 0xc4215b3fe8 0xc4221a2000] [0xc4215b3fe0 0xc4215b3ff8] [0x8fd520 0x8fd520] 0xc421ce2960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:55:19.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:55:19.198: INFO: rc: 1
Mar  9 15:55:19.198: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4221b1050 exit status 1 <nil> <nil> true [0xc4221a2008 0xc4221a2020 0xc4221a2038] [0xc4221a2008 0xc4221a2020 0xc4221a2038] [0xc4221a2018 0xc4221a2030] [0x8fd520 0x8fd520] 0xc421ce2a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:55:29.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:55:29.259: INFO: rc: 1
Mar  9 15:55:29.259: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154e3c0 exit status 1 <nil> <nil> true [0xc4215b2008 0xc4215b2020 0xc4215b2038] [0xc4215b2008 0xc4215b2020 0xc4215b2038] [0xc4215b2018 0xc4215b2030] [0x8fd520 0x8fd520] 0xc420f7c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:55:39.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:55:39.320: INFO: rc: 1
Mar  9 15:55:39.320: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154e780 exit status 1 <nil> <nil> true [0xc4215b2040 0xc4215b2058 0xc4215b2070] [0xc4215b2040 0xc4215b2058 0xc4215b2070] [0xc4215b2050 0xc4215b2068] [0x8fd520 0x8fd520] 0xc420f7c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:55:49.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:55:49.380: INFO: rc: 1
Mar  9 15:55:49.380: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154eb70 exit status 1 <nil> <nil> true [0xc4215b2078 0xc4215b2090 0xc4215b20a8] [0xc4215b2078 0xc4215b2090 0xc4215b20a8] [0xc4215b2088 0xc4215b20a0] [0x8fd520 0x8fd520] 0xc420f7c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:55:59.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:55:59.442: INFO: rc: 1
Mar  9 15:55:59.442: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154ef30 exit status 1 <nil> <nil> true [0xc4215b20b0 0xc4215b20c8 0xc4215b20e0] [0xc4215b20b0 0xc4215b20c8 0xc4215b20e0] [0xc4215b20c0 0xc4215b20d8] [0x8fd520 0x8fd520] 0xc420f7c420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:56:09.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:56:09.505: INFO: rc: 1
Mar  9 15:56:09.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c4420 exit status 1 <nil> <nil> true [0xc42224e000 0xc42224e050 0xc42224e068] [0xc42224e000 0xc42224e050 0xc42224e068] [0xc42224e048 0xc42224e060] [0x8fd520 0x8fd520] 0xc4210300c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:56:19.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:56:19.565: INFO: rc: 1
Mar  9 15:56:19.565: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c47e0 exit status 1 <nil> <nil> true [0xc42224e088 0xc42224e0d8 0xc42224e110] [0xc42224e088 0xc42224e0d8 0xc42224e110] [0xc42224e0c0 0xc42224e108] [0x8fd520 0x8fd520] 0xc421030240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:56:29.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:56:29.626: INFO: rc: 1
Mar  9 15:56:29.626: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154f380 exit status 1 <nil> <nil> true [0xc4215b20e8 0xc4215b2100 0xc4215b2118] [0xc4215b20e8 0xc4215b2100 0xc4215b2118] [0xc4215b20f8 0xc4215b2110] [0x8fd520 0x8fd520] 0xc420f7c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:56:39.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:56:39.687: INFO: rc: 1
Mar  9 15:56:39.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154f740 exit status 1 <nil> <nil> true [0xc4215b2120 0xc4215b2138 0xc4215b2150] [0xc4215b2120 0xc4215b2138 0xc4215b2150] [0xc4215b2130 0xc4215b2148] [0x8fd520 0x8fd520] 0xc420f7c6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:56:49.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:56:49.748: INFO: rc: 1
Mar  9 15:56:49.748: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154fb30 exit status 1 <nil> <nil> true [0xc4215b2158 0xc4215b2170 0xc4215b2188] [0xc4215b2158 0xc4215b2170 0xc4215b2188] [0xc4215b2168 0xc4215b2180] [0x8fd520 0x8fd520] 0xc420f7c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:56:59.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:56:59.816: INFO: rc: 1
Mar  9 15:56:59.816: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c4c00 exit status 1 <nil> <nil> true [0xc42224e118 0xc42224e150 0xc42224e188] [0xc42224e118 0xc42224e150 0xc42224e188] [0xc42224e148 0xc42224e170] [0x8fd520 0x8fd520] 0xc4210303c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:57:09.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:57:09.879: INFO: rc: 1
Mar  9 15:57:09.880: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c4fc0 exit status 1 <nil> <nil> true [0xc42224e190 0xc42224e1a8 0xc42224e1c0] [0xc42224e190 0xc42224e1a8 0xc42224e1c0] [0xc42224e1a0 0xc42224e1b8] [0x8fd520 0x8fd520] 0xc4210304e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:57:19.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:57:19.947: INFO: rc: 1
Mar  9 15:57:19.947: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c5380 exit status 1 <nil> <nil> true [0xc42224e1c8 0xc42224e210 0xc42224e248] [0xc42224e1c8 0xc42224e210 0xc42224e248] [0xc42224e1f8 0xc42224e240] [0x8fd520 0x8fd520] 0xc421030600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:57:29.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:57:30.016: INFO: rc: 1
Mar  9 15:57:30.016: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c5710 exit status 1 <nil> <nil> true [0xc42224e270 0xc42224e298 0xc42224e318] [0xc42224e270 0xc42224e298 0xc42224e318] [0xc42224e290 0xc42224e310] [0x8fd520 0x8fd520] 0xc421030720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:57:40.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:57:40.084: INFO: rc: 1
Mar  9 15:57:40.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154e390 exit status 1 <nil> <nil> true [0xc42224e000 0xc42224e050 0xc42224e068] [0xc42224e000 0xc42224e050 0xc42224e068] [0xc42224e048 0xc42224e060] [0x8fd520 0x8fd520] 0xc4210300c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:57:50.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:57:50.144: INFO: rc: 1
Mar  9 15:57:50.144: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154e7b0 exit status 1 <nil> <nil> true [0xc42224e088 0xc42224e0d8 0xc42224e110] [0xc42224e088 0xc42224e0d8 0xc42224e110] [0xc42224e0c0 0xc42224e108] [0x8fd520 0x8fd520] 0xc421030240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:58:00.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:58:00.205: INFO: rc: 1
Mar  9 15:58:00.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c4450 exit status 1 <nil> <nil> true [0xc4215b2000 0xc4215b2018 0xc4215b2030] [0xc4215b2000 0xc4215b2018 0xc4215b2030] [0xc4215b2010 0xc4215b2028] [0x8fd520 0x8fd520] 0xc420f7c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:58:10.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:58:10.266: INFO: rc: 1
Mar  9 15:58:10.266: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c4840 exit status 1 <nil> <nil> true [0xc4215b2038 0xc4215b2050 0xc4215b2068] [0xc4215b2038 0xc4215b2050 0xc4215b2068] [0xc4215b2048 0xc4215b2060] [0x8fd520 0x8fd520] 0xc420f7c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:58:20.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:58:20.328: INFO: rc: 1
Mar  9 15:58:20.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154ec30 exit status 1 <nil> <nil> true [0xc42224e118 0xc42224e150 0xc42224e188] [0xc42224e118 0xc42224e150 0xc42224e188] [0xc42224e148 0xc42224e170] [0x8fd520 0x8fd520] 0xc4210303c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:58:30.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:58:30.390: INFO: rc: 1
Mar  9 15:58:30.390: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154f020 exit status 1 <nil> <nil> true [0xc42224e190 0xc42224e1a8 0xc42224e1c0] [0xc42224e190 0xc42224e1a8 0xc42224e1c0] [0xc42224e1a0 0xc42224e1b8] [0x8fd520 0x8fd520] 0xc4210304e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:58:40.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:58:40.453: INFO: rc: 1
Mar  9 15:58:40.453: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4213c4c90 exit status 1 <nil> <nil> true [0xc4215b2070 0xc4215b2088 0xc4215b20a0] [0xc4215b2070 0xc4215b2088 0xc4215b20a0] [0xc4215b2080 0xc4215b2098] [0x8fd520 0x8fd520] 0xc420f7c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:58:50.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:58:50.526: INFO: rc: 1
Mar  9 15:58:50.526: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154f440 exit status 1 <nil> <nil> true [0xc42224e1c8 0xc42224e210 0xc42224e248] [0xc42224e1c8 0xc42224e210 0xc42224e248] [0xc42224e1f8 0xc42224e240] [0x8fd520 0x8fd520] 0xc421030600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:59:00.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:59:00.587: INFO: rc: 1
Mar  9 15:59:00.587: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154f830 exit status 1 <nil> <nil> true [0xc42224e320 0xc42224e338 0xc42224e350] [0xc42224e320 0xc42224e338 0xc42224e350] [0xc42224e330 0xc42224e348] [0x8fd520 0x8fd520] 0xc421030840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:59:10.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:59:10.648: INFO: rc: 1
Mar  9 15:59:10.648: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154fc80 exit status 1 <nil> <nil> true [0xc42224e368 0xc42224e390 0xc42224e3a8] [0xc42224e368 0xc42224e390 0xc42224e3a8] [0xc42224e388 0xc42224e3a0] [0x8fd520 0x8fd520] 0xc421030960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:59:20.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:59:20.713: INFO: rc: 1
Mar  9 15:59:20.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42230e090 exit status 1 <nil> <nil> true [0xc42224e3b0 0xc42224e3c8 0xc42224e400] [0xc42224e3b0 0xc42224e3c8 0xc42224e400] [0xc42224e3c0 0xc42224e3e0] [0x8fd520 0x8fd520] 0xc421030a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:59:30.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:59:30.787: INFO: rc: 1
Mar  9 15:59:30.787: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42230e480 exit status 1 <nil> <nil> true [0xc42224e430 0xc42224e478 0xc42224e490] [0xc42224e430 0xc42224e478 0xc42224e490] [0xc42224e460 0xc42224e488] [0x8fd520 0x8fd520] 0xc421030ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:59:40.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:59:40.852: INFO: rc: 1
Mar  9 15:59:40.852: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154e330 exit status 1 <nil> <nil> true [0xc42224e000 0xc42224e050 0xc4215b2010] [0xc42224e000 0xc42224e050 0xc4215b2010] [0xc42224e048 0xc4215b2008] [0x8fd520 0x8fd520] 0xc420f7c000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 15:59:50.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 15:59:50.915: INFO: rc: 1
Mar  9 15:59:50.915: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42154e720 exit status 1 <nil> <nil> true [0xc4215b2018 0xc4215b2030 0xc4215b2048] [0xc4215b2018 0xc4215b2030 0xc4215b2048] [0xc4215b2028 0xc4215b2040] [0x8fd520 0x8fd520] 0xc420f7c120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar  9 16:00:00.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-jxc22 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:00:00.975: INFO: rc: 1
Mar  9 16:00:00.975: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Mar  9 16:00:00.975: INFO: Scaling statefulset ss to 0
Mar  9 16:00:00.980: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  9 16:00:00.981: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jxc22
Mar  9 16:00:00.982: INFO: Scaling statefulset ss to 0
Mar  9 16:00:00.993: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:00:00.994: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:00:01.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jxc22" for this suite.
Mar  9 16:00:07.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:00:07.035: INFO: namespace: e2e-tests-statefulset-jxc22, resource: bindings, ignored listing per whitelist
Mar  9 16:00:07.050: INFO: namespace e2e-tests-statefulset-jxc22 deletion completed in 6.048441761s

• [SLOW TEST:369.251 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:00:07.050: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:00:07.067433      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:00:07.090: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar  9 16:00:12.092: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  9 16:00:12.092: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  9 16:00:14.093: INFO: Creating deployment "test-rollover-deployment"
Mar  9 16:00:14.099: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  9 16:00:16.103: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  9 16:00:16.107: INFO: Ensure that both replica sets have 1 created replica
Mar  9 16:00:16.110: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  9 16:00:16.114: INFO: Updating deployment test-rollover-deployment
Mar  9 16:00:16.114: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  9 16:00:18.119: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  9 16:00:18.122: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  9 16:00:18.124: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 16:00:18.124: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744016, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 16:00:20.127: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 16:00:20.127: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744018, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 16:00:22.127: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 16:00:22.127: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744018, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 16:00:24.127: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 16:00:24.127: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744018, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 16:00:26.129: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 16:00:26.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744018, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 16:00:28.128: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 16:00:28.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744018, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687744014, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 16:00:30.128: INFO: 
Mar  9 16:00:30.128: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  9 16:00:30.131: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-g4rvn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g4rvn/deployments/test-rollover-deployment,UID:6cdb6a79-4284-11e9-9882-02b03e914f30,ResourceVersion:3296,Generation:2,CreationTimestamp:2019-03-09 16:00:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-09 16:00:14 +0000 UTC 2019-03-09 16:00:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-09 16:00:28 +0000 UTC 2019-03-09 16:00:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  9 16:00:30.133: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-g4rvn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g4rvn/replicasets/test-rollover-deployment-5b76ff8c4,UID:6e0fc017-4284-11e9-9882-02b03e914f30,ResourceVersion:3287,Generation:2,CreationTimestamp:2019-03-09 16:00:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6cdb6a79-4284-11e9-9882-02b03e914f30 0xc421da14e7 0xc421da14e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  9 16:00:30.133: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  9 16:00:30.133: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-g4rvn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g4rvn/replicasets/test-rollover-controller,UID:68ae0d03-4284-11e9-9882-02b03e914f30,ResourceVersion:3295,Generation:2,CreationTimestamp:2019-03-09 16:00:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6cdb6a79-4284-11e9-9882-02b03e914f30 0xc421da1437 0xc421da1438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  9 16:00:30.133: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-g4rvn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g4rvn/replicasets/test-rollover-deployment-6975f4fb87,UID:6cdde31d-4284-11e9-9882-02b03e914f30,ResourceVersion:3251,Generation:2,CreationTimestamp:2019-03-09 16:00:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6cdb6a79-4284-11e9-9882-02b03e914f30 0xc421da1627 0xc421da1628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  9 16:00:30.134: INFO: Pod "test-rollover-deployment-5b76ff8c4-2gczw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-2gczw,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-g4rvn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g4rvn/pods/test-rollover-deployment-5b76ff8c4-2gczw,UID:6e1205fd-4284-11e9-9882-02b03e914f30,ResourceVersion:3265,Generation:0,CreationTimestamp:2019-03-09 16:00:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 6e0fc017-4284-11e9-9882-02b03e914f30 0xc423160540 0xc423160541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jl4fx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jl4fx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jl4fx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4231605a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4231605c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:00:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:00:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:00:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:00:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.14,StartTime:2019-03-09 16:00:16 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-09 16:00:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://16f4ba65e50b7942f4579f0b7df319f296dff096d88afbbecb3841d179e16134}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:00:30.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-g4rvn" for this suite.
Mar  9 16:00:36.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:00:36.214: INFO: namespace: e2e-tests-deployment-g4rvn, resource: bindings, ignored listing per whitelist
Mar  9 16:00:36.217: INFO: namespace e2e-tests-deployment-g4rvn deletion completed in 6.081159458s

• [SLOW TEST:29.167 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:00:36.217: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:00:36.247808      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 16:00:36.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-zjs5n'
Mar  9 16:00:36.452: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  9 16:00:36.452: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar  9 16:00:38.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-zjs5n'
Mar  9 16:00:38.548: INFO: stderr: ""
Mar  9 16:00:38.548: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:00:38.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zjs5n" for this suite.
Mar  9 16:01:00.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:01:00.571: INFO: namespace: e2e-tests-kubectl-zjs5n, resource: bindings, ignored listing per whitelist
Mar  9 16:01:00.598: INFO: namespace e2e-tests-kubectl-zjs5n deletion completed in 22.048182603s

• [SLOW TEST:24.381 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:01:00.598: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:01:00.616224      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0309 16:01:10.827413      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 16:01:10.827: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:01:10.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-88kjp" for this suite.
Mar  9 16:01:16.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:01:16.860: INFO: namespace: e2e-tests-gc-88kjp, resource: bindings, ignored listing per whitelist
Mar  9 16:01:16.877: INFO: namespace e2e-tests-gc-88kjp deletion completed in 6.04901516s

• [SLOW TEST:16.279 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:01:16.877: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:01:16.895464      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-924d4a95-4284-11e9-923b-2eb43f2b540f
STEP: Creating secret with name s-test-opt-upd-924d4ac7-4284-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-924d4a95-4284-11e9-923b-2eb43f2b540f
STEP: Updating secret s-test-opt-upd-924d4ac7-4284-11e9-923b-2eb43f2b540f
STEP: Creating secret with name s-test-opt-create-924d4ad8-4284-11e9-923b-2eb43f2b540f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:01:20.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lcw2c" for this suite.
Mar  9 16:01:43.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:01:43.041: INFO: namespace: e2e-tests-projected-lcw2c, resource: bindings, ignored listing per whitelist
Mar  9 16:01:43.051: INFO: namespace e2e-tests-projected-lcw2c deletion completed in 22.049814418s

• [SLOW TEST:26.173 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:01:43.051: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:01:43.075677      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:01:43.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-hjwgk" to be "success or failure"
Mar  9 16:01:43.102: INFO: Pod "downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.349506ms
Mar  9 16:01:45.104: INFO: Pod "downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005208418s
STEP: Saw pod success
Mar  9 16:01:45.104: INFO: Pod "downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:01:45.105: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:01:45.115: INFO: Waiting for pod downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:01:45.117: INFO: Pod downwardapi-volume-a1e7c091-4284-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:01:45.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hjwgk" for this suite.
Mar  9 16:01:51.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:01:51.160: INFO: namespace: e2e-tests-projected-hjwgk, resource: bindings, ignored listing per whitelist
Mar  9 16:01:51.167: INFO: namespace e2e-tests-projected-hjwgk deletion completed in 6.049074534s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:01:51.167: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:01:51.184832      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:01:51.205: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-jlmqd" to be "success or failure"
Mar  9 16:01:51.208: INFO: Pod "downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.181494ms
Mar  9 16:01:53.209: INFO: Pod "downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00351499s
STEP: Saw pod success
Mar  9 16:01:53.209: INFO: Pod "downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:01:53.210: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:01:53.223: INFO: Waiting for pod downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:01:53.225: INFO: Pod downwardapi-volume-a6bceb5c-4284-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:01:53.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jlmqd" for this suite.
Mar  9 16:01:59.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:01:59.250: INFO: namespace: e2e-tests-downward-api-jlmqd, resource: bindings, ignored listing per whitelist
Mar  9 16:01:59.278: INFO: namespace e2e-tests-downward-api-jlmqd deletion completed in 6.049466396s

• [SLOW TEST:8.111 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:01:59.278: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:01:59.296093      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-cbdx
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 16:01:59.322: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cbdx" in namespace "e2e-tests-subpath-qjlng" to be "success or failure"
Mar  9 16:01:59.323: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Pending", Reason="", readiness=false. Elapsed: 1.820486ms
Mar  9 16:02:01.325: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00366309s
Mar  9 16:02:03.470: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.148357249s
Mar  9 16:02:05.472: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 6.150143406s
Mar  9 16:02:07.474: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 8.151998553s
Mar  9 16:02:09.475: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 10.15376041s
Mar  9 16:02:11.477: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 12.155447292s
Mar  9 16:02:13.481: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 14.159101616s
Mar  9 16:02:15.483: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 16.16103063s
Mar  9 16:02:17.484: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 18.162619156s
Mar  9 16:02:19.486: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 20.16421939s
Mar  9 16:02:21.487: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Running", Reason="", readiness=false. Elapsed: 22.165815486s
Mar  9 16:02:23.489: INFO: Pod "pod-subpath-test-configmap-cbdx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.167479481s
STEP: Saw pod success
Mar  9 16:02:23.489: INFO: Pod "pod-subpath-test-configmap-cbdx" satisfied condition "success or failure"
Mar  9 16:02:23.490: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-subpath-test-configmap-cbdx container test-container-subpath-configmap-cbdx: <nil>
STEP: delete the pod
Mar  9 16:02:23.500: INFO: Waiting for pod pod-subpath-test-configmap-cbdx to disappear
Mar  9 16:02:23.502: INFO: Pod pod-subpath-test-configmap-cbdx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cbdx
Mar  9 16:02:23.502: INFO: Deleting pod "pod-subpath-test-configmap-cbdx" in namespace "e2e-tests-subpath-qjlng"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:02:23.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qjlng" for this suite.
Mar  9 16:02:29.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:02:29.538: INFO: namespace: e2e-tests-subpath-qjlng, resource: bindings, ignored listing per whitelist
Mar  9 16:02:29.557: INFO: namespace e2e-tests-subpath-qjlng deletion completed in 6.053192703s

• [SLOW TEST:30.280 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:02:29.557: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:02:29.574740      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-bczpg
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-bczpg
STEP: Deleting pre-stop pod
Mar  9 16:02:40.616: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:02:40.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-bczpg" for this suite.
Mar  9 16:03:18.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:03:18.680: INFO: namespace: e2e-tests-prestop-bczpg, resource: bindings, ignored listing per whitelist
Mar  9 16:03:18.681: INFO: namespace e2e-tests-prestop-bczpg deletion completed in 38.060203909s

• [SLOW TEST:49.124 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:03:18.682: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:03:18.699228      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-dae6d04f-4284-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:03:18.723: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-7hpnd" to be "success or failure"
Mar  9 16:03:18.729: INFO: Pod "pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.053594ms
Mar  9 16:03:20.730: INFO: Pod "pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006740107s
STEP: Saw pod success
Mar  9 16:03:20.730: INFO: Pod "pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:03:20.732: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:03:20.741: INFO: Waiting for pod pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:03:20.742: INFO: Pod pod-projected-configmaps-dae70726-4284-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:03:20.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7hpnd" for this suite.
Mar  9 16:03:26.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:03:26.763: INFO: namespace: e2e-tests-projected-7hpnd, resource: bindings, ignored listing per whitelist
Mar  9 16:03:26.791: INFO: namespace e2e-tests-projected-7hpnd deletion completed in 6.047000446s

• [SLOW TEST:8.109 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:03:26.791: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:03:26.808463      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  9 16:03:26.828: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 16:03:26.831: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 16:03:26.832: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-70-73.us-west-2.compute.internal before test
Mar  9 16:03:26.836: INFO: weave-net-ft8zc from kube-system started at 2019-03-09 15:44:30 +0000 UTC (2 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container weave ready: true, restart count 1
Mar  9 16:03:26.836: INFO: 	Container weave-npc ready: true, restart count 0
Mar  9 16:03:26.836: INFO: autoscaler-aws-cluster-autoscaler-d9dcf4d85-69zpr from kube-system started at 2019-03-09 15:45:48 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container aws-cluster-autoscaler ready: true, restart count 0
Mar  9 16:03:26.836: INFO: ith-instance-termination-handler-mdlnc from pipeline-system started at 2019-03-09 15:45:53 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container instance-termination-handler ready: true, restart count 0
Mar  9 16:03:26.836: INFO: sonobuoy-systemd-logs-daemon-set-5a60dbf0cc4b44aa-9dhqt from heptio-sonobuoy started at 2019-03-09 15:53:02 +0000 UTC (2 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  9 16:03:26.836: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 16:03:26.836: INFO: pvc-operator-7c7766d9c6-xhzz8 from pipeline-system started at 2019-03-09 15:45:51 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container pvc-operator ready: true, restart count 0
Mar  9 16:03:26.836: INFO: hpa-operator-hpa-operator-5587f4b46c-tz255 from pipeline-system started at 2019-03-09 15:45:50 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container hpa-operator ready: true, restart count 0
Mar  9 16:03:26.836: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-09 15:52:59 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 16:03:26.836: INFO: tiller-deploy-865b88d89-pvn7z from kube-system started at 2019-03-09 15:44:30 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container tiller ready: true, restart count 0
Mar  9 16:03:26.836: INFO: kube-proxy-nxxjq from kube-system started at 2019-03-09 15:44:30 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 16:03:26.836: INFO: dns-external-dns-56d66c8bc-ct9md from pipeline-system started at 2019-03-09 15:45:42 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container external-dns ready: true, restart count 0
Mar  9 16:03:26.836: INFO: dashboard-kubernetes-dashboard-6469dff698-q4vtx from pipeline-system started at 2019-03-09 15:45:46 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  9 16:03:26.836: INFO: hpa-operator-metrics-server-d98ff747d-mkt2v from pipeline-system started at 2019-03-09 15:45:50 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container metrics-server ready: true, restart count 0
Mar  9 16:03:26.836: INFO: npls-nodepool-labels-operator-64d58d86f-cq2sp from pipeline-system started at 2019-03-09 15:45:33 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container nodepool-labels-operator ready: true, restart count 0
Mar  9 16:03:26.836: INFO: ingress-traefik-6db6c64c49-lfg8d from pipeline-system started at 2019-03-09 15:45:44 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container ingress-traefik ready: true, restart count 0
Mar  9 16:03:26.836: INFO: hpa-operator-kube-metrics-adapter-bf9dd978d-5jksc from pipeline-system started at 2019-03-09 15:45:49 +0000 UTC (1 container statuses recorded)
Mar  9 16:03:26.836: INFO: 	Container kube-metrics-adapter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod sonobuoy-systemd-logs-daemon-set-5a60dbf0cc4b44aa-9dhqt requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod autoscaler-aws-cluster-autoscaler-d9dcf4d85-69zpr requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod kube-proxy-nxxjq requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod tiller-deploy-865b88d89-pvn7z requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod weave-net-ft8zc requesting resource cpu=20m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod dashboard-kubernetes-dashboard-6469dff698-q4vtx requesting resource cpu=100m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod dns-external-dns-56d66c8bc-ct9md requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod hpa-operator-hpa-operator-5587f4b46c-tz255 requesting resource cpu=100m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod hpa-operator-kube-metrics-adapter-bf9dd978d-5jksc requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod hpa-operator-metrics-server-d98ff747d-mkt2v requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod ingress-traefik-6db6c64c49-lfg8d requesting resource cpu=100m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod ith-instance-termination-handler-mdlnc requesting resource cpu=120m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod npls-nodepool-labels-operator-64d58d86f-cq2sp requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
Mar  9 16:03:26.848: INFO: Pod pvc-operator-7c7766d9c6-xhzz8 requesting resource cpu=0m on Node ip-192-168-70-73.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dfbf627f-4284-11e9-923b-2eb43f2b540f.158a55d7ca6aa9a5], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-5hh98/filler-pod-dfbf627f-4284-11e9-923b-2eb43f2b540f to ip-192-168-70-73.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dfbf627f-4284-11e9-923b-2eb43f2b540f.158a55d7e61e3880], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dfbf627f-4284-11e9-923b-2eb43f2b540f.158a55d7e79ef6f2], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-dfbf627f-4284-11e9-923b-2eb43f2b540f.158a55d7ec12f977], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158a55d840a2f106], Reason = [FailedScheduling], Message = [0/2 nodes are available: 1 Insufficient cpu, 1 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-192-168-70-73.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:03:29.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5hh98" for this suite.
Mar  9 16:03:35.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:03:35.916: INFO: namespace: e2e-tests-sched-pred-5hh98, resource: bindings, ignored listing per whitelist
Mar  9 16:03:35.929: INFO: namespace e2e-tests-sched-pred-5hh98 deletion completed in 6.053553181s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.138 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:03:35.929: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:03:35.946726      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:03:35.966: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  9 16:03:35.971: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  9 16:03:40.973: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  9 16:03:40.973: INFO: Creating deployment "test-rolling-update-deployment"
Mar  9 16:03:40.975: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  9 16:03:40.981: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  9 16:03:42.984: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  9 16:03:42.985: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  9 16:03:42.989: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-v2cs6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2cs6/deployments/test-rolling-update-deployment,UID:e82aa44f-4284-11e9-9882-02b03e914f30,ResourceVersion:4250,Generation:1,CreationTimestamp:2019-03-09 16:03:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-09 16:03:40 +0000 UTC 2019-03-09 16:03:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-09 16:03:42 +0000 UTC 2019-03-09 16:03:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  9 16:03:42.990: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-v2cs6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2cs6/replicasets/test-rolling-update-deployment-65b7695dcf,UID:e82c4cbb-4284-11e9-9882-02b03e914f30,ResourceVersion:4241,Generation:1,CreationTimestamp:2019-03-09 16:03:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e82aa44f-4284-11e9-9882-02b03e914f30 0xc42139c307 0xc42139c308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  9 16:03:42.990: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  9 16:03:42.991: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-v2cs6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2cs6/replicasets/test-rolling-update-controller,UID:e52ebf5e-4284-11e9-9882-02b03e914f30,ResourceVersion:4249,Generation:2,CreationTimestamp:2019-03-09 16:03:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e82aa44f-4284-11e9-9882-02b03e914f30 0xc42139c257 0xc42139c258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  9 16:03:42.992: INFO: Pod "test-rolling-update-deployment-65b7695dcf-qgpmn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-qgpmn,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-v2cs6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v2cs6/pods/test-rolling-update-deployment-65b7695dcf-qgpmn,UID:e82cc47f-4284-11e9-9882-02b03e914f30,ResourceVersion:4240,Generation:0,CreationTimestamp:2019-03-09 16:03:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf e82c4cbb-4284-11e9-9882-02b03e914f30 0xc420dd7127 0xc420dd7128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wsqnb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsqnb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wsqnb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420dd7190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420dd71b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:03:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:03:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:03:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:03:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.14,StartTime:2019-03-09 16:03:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-09 16:03:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://3c09c9d9e7bc4c6abaa635e0171b873f2377f65b6c448e7d460a2a21b316d7f7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:03:42.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-v2cs6" for this suite.
Mar  9 16:03:48.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:03:49.029: INFO: namespace: e2e-tests-deployment-v2cs6, resource: bindings, ignored listing per whitelist
Mar  9 16:03:49.042: INFO: namespace e2e-tests-deployment-v2cs6 deletion completed in 6.048695315s

• [SLOW TEST:13.113 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:03:49.042: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:03:49.059836      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  9 16:03:49.085: INFO: Waiting up to 5m0s for pod "pod-ecffb260-4284-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-ncw9s" to be "success or failure"
Mar  9 16:03:49.088: INFO: Pod "pod-ecffb260-4284-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.549757ms
Mar  9 16:03:51.090: INFO: Pod "pod-ecffb260-4284-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005172012s
STEP: Saw pod success
Mar  9 16:03:51.090: INFO: Pod "pod-ecffb260-4284-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:03:51.091: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-ecffb260-4284-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:03:51.099: INFO: Waiting for pod pod-ecffb260-4284-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:03:51.101: INFO: Pod pod-ecffb260-4284-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:03:51.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ncw9s" for this suite.
Mar  9 16:03:57.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:03:57.139: INFO: namespace: e2e-tests-emptydir-ncw9s, resource: bindings, ignored listing per whitelist
Mar  9 16:03:57.151: INFO: namespace e2e-tests-emptydir-ncw9s deletion completed in 6.048199709s

• [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:03:57.151: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:03:57.176800      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:04:03.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-tkjdc" for this suite.
Mar  9 16:04:09.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:04:09.278: INFO: namespace: e2e-tests-namespaces-tkjdc, resource: bindings, ignored listing per whitelist
Mar  9 16:04:09.294: INFO: namespace e2e-tests-namespaces-tkjdc deletion completed in 6.054195484s
STEP: Destroying namespace "e2e-tests-nsdeletetest-z29ln" for this suite.
Mar  9 16:04:09.295: INFO: Namespace e2e-tests-nsdeletetest-z29ln was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-grhhw" for this suite.
Mar  9 16:04:15.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:04:15.309: INFO: namespace: e2e-tests-nsdeletetest-grhhw, resource: bindings, ignored listing per whitelist
Mar  9 16:04:15.343: INFO: namespace e2e-tests-nsdeletetest-grhhw deletion completed in 6.047830283s

• [SLOW TEST:18.193 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:04:15.343: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:04:15.361169      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-ktnbz
Mar  9 16:04:19.389: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-ktnbz
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 16:04:19.390: INFO: Initial restart count of pod liveness-http is 0
Mar  9 16:04:37.627: INFO: Restart count of pod e2e-tests-container-probe-ktnbz/liveness-http is now 1 (18.237092407s elapsed)
Mar  9 16:04:57.649: INFO: Restart count of pod e2e-tests-container-probe-ktnbz/liveness-http is now 2 (38.258193622s elapsed)
Mar  9 16:05:17.692: INFO: Restart count of pod e2e-tests-container-probe-ktnbz/liveness-http is now 3 (58.301956805s elapsed)
Mar  9 16:05:37.711: INFO: Restart count of pod e2e-tests-container-probe-ktnbz/liveness-http is now 4 (1m18.320403867s elapsed)
Mar  9 16:06:38.351: INFO: Restart count of pod e2e-tests-container-probe-ktnbz/liveness-http is now 5 (2m18.960687434s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:06:38.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ktnbz" for this suite.
Mar  9 16:06:44.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:06:44.891: INFO: namespace: e2e-tests-container-probe-ktnbz, resource: bindings, ignored listing per whitelist
Mar  9 16:06:44.915: INFO: namespace e2e-tests-container-probe-ktnbz deletion completed in 6.554697134s

• [SLOW TEST:149.572 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:06:44.915: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:06:44.932458      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  9 16:06:44.955: INFO: Waiting up to 5m0s for pod "pod-55d36756-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-qvwsl" to be "success or failure"
Mar  9 16:06:44.958: INFO: Pod "pod-55d36756-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.316955ms
Mar  9 16:06:46.959: INFO: Pod "pod-55d36756-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004720889s
STEP: Saw pod success
Mar  9 16:06:46.959: INFO: Pod "pod-55d36756-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:06:46.960: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-55d36756-4285-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:06:46.971: INFO: Waiting for pod pod-55d36756-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:06:46.972: INFO: Pod pod-55d36756-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:06:46.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qvwsl" for this suite.
Mar  9 16:06:52.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:06:52.992: INFO: namespace: e2e-tests-emptydir-qvwsl, resource: bindings, ignored listing per whitelist
Mar  9 16:06:53.021: INFO: namespace e2e-tests-emptydir-qvwsl deletion completed in 6.047870214s

• [SLOW TEST:8.106 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:06:53.021: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:06:53.039149      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  9 16:06:55.577: INFO: Successfully updated pod "labelsupdate5aa84194-4285-11e9-923b-2eb43f2b540f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:06:59.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q6wmm" for this suite.
Mar  9 16:07:21.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:07:21.619: INFO: namespace: e2e-tests-downward-api-q6wmm, resource: bindings, ignored listing per whitelist
Mar  9 16:07:21.638: INFO: namespace e2e-tests-downward-api-q6wmm deletion completed in 22.048842922s

• [SLOW TEST:28.617 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:07:21.638: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:07:21.655794      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar  9 16:07:21.675: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  9 16:07:21.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:21.852: INFO: stderr: ""
Mar  9 16:07:21.852: INFO: stdout: "service/redis-slave created\n"
Mar  9 16:07:21.853: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  9 16:07:21.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:22.028: INFO: stderr: ""
Mar  9 16:07:22.028: INFO: stdout: "service/redis-master created\n"
Mar  9 16:07:22.028: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  9 16:07:22.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:22.302: INFO: stderr: ""
Mar  9 16:07:22.302: INFO: stdout: "service/frontend created\n"
Mar  9 16:07:22.302: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  9 16:07:22.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:22.477: INFO: stderr: ""
Mar  9 16:07:22.477: INFO: stdout: "deployment.extensions/frontend created\n"
Mar  9 16:07:22.477: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  9 16:07:22.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:22.686: INFO: stderr: ""
Mar  9 16:07:22.686: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar  9 16:07:22.686: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  9 16:07:22.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:22.924: INFO: stderr: ""
Mar  9 16:07:22.924: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar  9 16:07:22.924: INFO: Waiting for all frontend pods to be Running.
Mar  9 16:07:32.974: INFO: Waiting for frontend to serve content.
Mar  9 16:07:38.014: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar  9 16:07:43.021: INFO: Trying to add a new entry to the guestbook.
Mar  9 16:07:43.027: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  9 16:07:43.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:43.122: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:07:43.122: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 16:07:43.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:43.219: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:07:43.219: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 16:07:43.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:43.314: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:07:43.314: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 16:07:43.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:43.412: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:07:43.412: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 16:07:43.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:43.534: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:07:43.534: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 16:07:43.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hk2gb'
Mar  9 16:07:43.612: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:07:43.612: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:07:43.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hk2gb" for this suite.
Mar  9 16:08:21.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:08:21.662: INFO: namespace: e2e-tests-kubectl-hk2gb, resource: bindings, ignored listing per whitelist
Mar  9 16:08:21.666: INFO: namespace e2e-tests-kubectl-hk2gb deletion completed in 38.049904404s

• [SLOW TEST:60.028 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:08:21.666: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:08:21.684942      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w5nl
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 16:08:21.724: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w5nl" in namespace "e2e-tests-subpath-zbvgh" to be "success or failure"
Mar  9 16:08:21.726: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Pending", Reason="", readiness=false. Elapsed: 1.388674ms
Mar  9 16:08:23.728: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003102491s
Mar  9 16:08:25.729: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 4.004569942s
Mar  9 16:08:27.731: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 6.00638149s
Mar  9 16:08:29.733: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 8.008184855s
Mar  9 16:08:31.735: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 10.010026154s
Mar  9 16:08:33.746: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 12.021114667s
Mar  9 16:08:35.747: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 14.022861294s
Mar  9 16:08:37.749: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 16.024520141s
Mar  9 16:08:39.751: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 18.026292727s
Mar  9 16:08:41.752: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 20.027802713s
Mar  9 16:08:43.754: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Running", Reason="", readiness=false. Elapsed: 22.029469212s
Mar  9 16:08:45.756: INFO: Pod "pod-subpath-test-configmap-w5nl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.031026036s
STEP: Saw pod success
Mar  9 16:08:45.756: INFO: Pod "pod-subpath-test-configmap-w5nl" satisfied condition "success or failure"
Mar  9 16:08:45.757: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-subpath-test-configmap-w5nl container test-container-subpath-configmap-w5nl: <nil>
STEP: delete the pod
Mar  9 16:08:45.767: INFO: Waiting for pod pod-subpath-test-configmap-w5nl to disappear
Mar  9 16:08:46.256: INFO: Pod pod-subpath-test-configmap-w5nl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w5nl
Mar  9 16:08:46.256: INFO: Deleting pod "pod-subpath-test-configmap-w5nl" in namespace "e2e-tests-subpath-zbvgh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:08:46.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zbvgh" for this suite.
Mar  9 16:08:52.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:08:52.285: INFO: namespace: e2e-tests-subpath-zbvgh, resource: bindings, ignored listing per whitelist
Mar  9 16:08:52.311: INFO: namespace e2e-tests-subpath-zbvgh deletion completed in 6.051323616s

• [SLOW TEST:30.645 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:08:52.311: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:08:52.328472      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a1c28bfb-4285-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:08:52.353: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-stm28" to be "success or failure"
Mar  9 16:08:52.357: INFO: Pod "pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320549ms
Mar  9 16:08:54.358: INFO: Pod "pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005774849s
STEP: Saw pod success
Mar  9 16:08:54.358: INFO: Pod "pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:08:54.360: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:08:54.368: INFO: Waiting for pod pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:08:54.369: INFO: Pod pod-projected-secrets-a1c2c937-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:08:54.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-stm28" for this suite.
Mar  9 16:09:00.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:09:00.407: INFO: namespace: e2e-tests-projected-stm28, resource: bindings, ignored listing per whitelist
Mar  9 16:09:00.418: INFO: namespace e2e-tests-projected-stm28 deletion completed in 6.047195235s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:09:00.418: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:09:00.435835      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-a69768c3-4285-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:09:00.459: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-ldvkt" to be "success or failure"
Mar  9 16:09:00.464: INFO: Pod "pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.673823ms
Mar  9 16:09:02.466: INFO: Pod "pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007487818s
STEP: Saw pod success
Mar  9 16:09:02.466: INFO: Pod "pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:09:02.468: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:09:02.477: INFO: Waiting for pod pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:09:02.478: INFO: Pod pod-projected-secrets-a697a8dd-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:09:02.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ldvkt" for this suite.
Mar  9 16:09:08.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:09:08.503: INFO: namespace: e2e-tests-projected-ldvkt, resource: bindings, ignored listing per whitelist
Mar  9 16:09:08.526: INFO: namespace e2e-tests-projected-ldvkt deletion completed in 6.046650682s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:09:08.526: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:09:08.543515      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:09:08.573: INFO: (0) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.957348ms)
Mar  9 16:09:08.575: INFO: (1) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.59619ms)
Mar  9 16:09:08.576: INFO: (2) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.542948ms)
Mar  9 16:09:08.578: INFO: (3) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.478261ms)
Mar  9 16:09:08.579: INFO: (4) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.481654ms)
Mar  9 16:09:08.581: INFO: (5) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.455699ms)
Mar  9 16:09:08.582: INFO: (6) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.403866ms)
Mar  9 16:09:08.584: INFO: (7) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.472566ms)
Mar  9 16:09:08.585: INFO: (8) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.474818ms)
Mar  9 16:09:08.587: INFO: (9) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.473531ms)
Mar  9 16:09:08.588: INFO: (10) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.54594ms)
Mar  9 16:09:08.590: INFO: (11) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.534726ms)
Mar  9 16:09:08.591: INFO: (12) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.504861ms)
Mar  9 16:09:08.593: INFO: (13) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.442767ms)
Mar  9 16:09:08.594: INFO: (14) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.515328ms)
Mar  9 16:09:08.596: INFO: (15) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.455922ms)
Mar  9 16:09:08.597: INFO: (16) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.509842ms)
Mar  9 16:09:08.599: INFO: (17) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.549458ms)
Mar  9 16:09:08.601: INFO: (18) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.501538ms)
Mar  9 16:09:08.602: INFO: (19) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.582961ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:09:08.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xhzdh" for this suite.
Mar  9 16:09:14.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:09:14.626: INFO: namespace: e2e-tests-proxy-xhzdh, resource: bindings, ignored listing per whitelist
Mar  9 16:09:14.653: INFO: namespace e2e-tests-proxy-xhzdh deletion completed in 6.049488953s

• [SLOW TEST:6.127 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:09:14.653: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:09:14.671656      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-l549w/configmap-test-af37521c-4285-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:09:14.937: INFO: Waiting up to 5m0s for pod "pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-l549w" to be "success or failure"
Mar  9 16:09:14.938: INFO: Pod "pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.312889ms
Mar  9 16:09:16.940: INFO: Pod "pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002937976s
STEP: Saw pod success
Mar  9 16:09:16.940: INFO: Pod "pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:09:16.941: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f container env-test: <nil>
STEP: delete the pod
Mar  9 16:09:16.950: INFO: Waiting for pod pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:09:16.952: INFO: Pod pod-configmaps-af379ec9-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:09:16.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-l549w" for this suite.
Mar  9 16:09:22.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:09:22.970: INFO: namespace: e2e-tests-configmap-l549w, resource: bindings, ignored listing per whitelist
Mar  9 16:09:23.002: INFO: namespace e2e-tests-configmap-l549w deletion completed in 6.049217269s

• [SLOW TEST:8.349 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:09:23.002: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:09:23.019583      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-cz2s
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 16:09:23.044: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cz2s" in namespace "e2e-tests-subpath-ddhtc" to be "success or failure"
Mar  9 16:09:23.049: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Pending", Reason="", readiness=false. Elapsed: 5.850287ms
Mar  9 16:09:25.051: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00767473s
Mar  9 16:09:27.053: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 4.009508877s
Mar  9 16:09:29.055: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 6.011275492s
Mar  9 16:09:31.056: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 8.012858736s
Mar  9 16:09:33.058: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 10.0145988s
Mar  9 16:09:35.060: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 12.016453225s
Mar  9 16:09:37.062: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 14.018180304s
Mar  9 16:09:39.063: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 16.019787699s
Mar  9 16:09:41.065: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 18.021579642s
Mar  9 16:09:43.067: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 20.023408939s
Mar  9 16:09:45.069: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Running", Reason="", readiness=false. Elapsed: 22.02505634s
Mar  9 16:09:47.070: INFO: Pod "pod-subpath-test-downwardapi-cz2s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.026776188s
STEP: Saw pod success
Mar  9 16:09:47.070: INFO: Pod "pod-subpath-test-downwardapi-cz2s" satisfied condition "success or failure"
Mar  9 16:09:47.072: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-subpath-test-downwardapi-cz2s container test-container-subpath-downwardapi-cz2s: <nil>
STEP: delete the pod
Mar  9 16:09:47.082: INFO: Waiting for pod pod-subpath-test-downwardapi-cz2s to disappear
Mar  9 16:09:47.084: INFO: Pod pod-subpath-test-downwardapi-cz2s no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cz2s
Mar  9 16:09:47.084: INFO: Deleting pod "pod-subpath-test-downwardapi-cz2s" in namespace "e2e-tests-subpath-ddhtc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:09:47.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ddhtc" for this suite.
Mar  9 16:09:53.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:09:53.112: INFO: namespace: e2e-tests-subpath-ddhtc, resource: bindings, ignored listing per whitelist
Mar  9 16:09:53.136: INFO: namespace e2e-tests-subpath-ddhtc deletion completed in 6.050430444s

• [SLOW TEST:30.134 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:09:53.137: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:09:53.154667      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  9 16:09:53.179: INFO: Waiting up to 5m0s for pod "pod-c6042a85-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-6hpjl" to be "success or failure"
Mar  9 16:09:53.184: INFO: Pod "pod-c6042a85-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.227295ms
Mar  9 16:09:55.185: INFO: Pod "pod-c6042a85-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00590872s
STEP: Saw pod success
Mar  9 16:09:55.185: INFO: Pod "pod-c6042a85-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:09:55.187: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-c6042a85-4285-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:09:55.196: INFO: Waiting for pod pod-c6042a85-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:09:55.198: INFO: Pod pod-c6042a85-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:09:55.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6hpjl" for this suite.
Mar  9 16:10:01.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:10:01.215: INFO: namespace: e2e-tests-emptydir-6hpjl, resource: bindings, ignored listing per whitelist
Mar  9 16:10:01.246: INFO: namespace e2e-tests-emptydir-6hpjl deletion completed in 6.046300593s

• [SLOW TEST:8.110 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:10:01.247: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:10:01.264408      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  9 16:10:01.286: INFO: Waiting up to 5m0s for pod "pod-cad92b8d-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-4jsxw" to be "success or failure"
Mar  9 16:10:01.291: INFO: Pod "pod-cad92b8d-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.153742ms
Mar  9 16:10:03.293: INFO: Pod "pod-cad92b8d-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006628486s
STEP: Saw pod success
Mar  9 16:10:03.293: INFO: Pod "pod-cad92b8d-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:10:03.294: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-cad92b8d-4285-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:10:03.302: INFO: Waiting for pod pod-cad92b8d-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:10:03.303: INFO: Pod pod-cad92b8d-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:10:03.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4jsxw" for this suite.
Mar  9 16:10:09.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:10:09.412: INFO: namespace: e2e-tests-emptydir-4jsxw, resource: bindings, ignored listing per whitelist
Mar  9 16:10:09.442: INFO: namespace e2e-tests-emptydir-4jsxw deletion completed in 6.137002427s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:10:09.442: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:10:09.462205      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  9 16:10:09.485: INFO: Waiting up to 5m0s for pod "pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-sclqc" to be "success or failure"
Mar  9 16:10:09.486: INFO: Pod "pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.520003ms
Mar  9 16:10:11.488: INFO: Pod "pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00294747s
STEP: Saw pod success
Mar  9 16:10:11.488: INFO: Pod "pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:10:11.489: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:10:11.501: INFO: Waiting for pod pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:10:11.502: INFO: Pod pod-cfbc4b3f-4285-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:10:11.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sclqc" for this suite.
Mar  9 16:10:17.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:10:17.532: INFO: namespace: e2e-tests-emptydir-sclqc, resource: bindings, ignored listing per whitelist
Mar  9 16:10:17.552: INFO: namespace e2e-tests-emptydir-sclqc deletion completed in 6.048572649s

• [SLOW TEST:8.110 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:10:17.552: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:10:17.573353      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  9 16:10:17.598: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:10:17.601: INFO: Number of nodes with available pods: 0
Mar  9 16:10:17.601: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:10:18.612: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:10:18.616: INFO: Number of nodes with available pods: 0
Mar  9 16:10:18.616: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:10:19.603: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:10:19.605: INFO: Number of nodes with available pods: 0
Mar  9 16:10:19.605: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:10:20.603: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:10:20.605: INFO: Number of nodes with available pods: 1
Mar  9 16:10:20.605: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  9 16:10:20.614: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:10:20.616: INFO: Number of nodes with available pods: 1
Mar  9 16:10:20.616: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-99jmh, will wait for the garbage collector to delete the pods
Mar  9 16:10:21.677: INFO: Deleting {extensions DaemonSet} daemon-set took: 4.757123ms
Mar  9 16:10:21.777: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.131564ms
Mar  9 16:11:00.079: INFO: Number of nodes with available pods: 0
Mar  9 16:11:00.079: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 16:11:00.081: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-99jmh/daemonsets","resourceVersion":"5765"},"items":null}

Mar  9 16:11:00.083: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-99jmh/pods","resourceVersion":"5765"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:11:00.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-99jmh" for this suite.
Mar  9 16:11:06.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:11:06.131: INFO: namespace: e2e-tests-daemonsets-99jmh, resource: bindings, ignored listing per whitelist
Mar  9 16:11:06.139: INFO: namespace e2e-tests-daemonsets-99jmh deletion completed in 6.052268454s

• [SLOW TEST:48.587 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:11:06.139: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:11:06.156793      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:12:06.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8zn6z" for this suite.
Mar  9 16:12:28.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:12:28.216: INFO: namespace: e2e-tests-container-probe-8zn6z, resource: bindings, ignored listing per whitelist
Mar  9 16:12:28.237: INFO: namespace e2e-tests-container-probe-8zn6z deletion completed in 22.055940038s

• [SLOW TEST:82.098 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:12:28.237: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:12:28.254984      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  9 16:12:28.278: INFO: Waiting up to 5m0s for pod "downward-api-227653d6-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-4hwqx" to be "success or failure"
Mar  9 16:12:28.280: INFO: Pod "downward-api-227653d6-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.579105ms
Mar  9 16:12:30.282: INFO: Pod "downward-api-227653d6-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004859552s
STEP: Saw pod success
Mar  9 16:12:30.282: INFO: Pod "downward-api-227653d6-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:12:30.284: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downward-api-227653d6-4286-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 16:12:30.294: INFO: Waiting for pod downward-api-227653d6-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:12:30.296: INFO: Pod downward-api-227653d6-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:12:30.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4hwqx" for this suite.
Mar  9 16:12:36.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:12:36.343: INFO: namespace: e2e-tests-downward-api-4hwqx, resource: bindings, ignored listing per whitelist
Mar  9 16:12:36.345: INFO: namespace e2e-tests-downward-api-4hwqx deletion completed in 6.047114294s

• [SLOW TEST:8.107 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:12:36.345: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:12:36.362588      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  9 16:12:42.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 16:12:42.403: INFO: Pod pod-with-poststart-http-hook still exists
Mar  9 16:12:44.403: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 16:12:44.405: INFO: Pod pod-with-poststart-http-hook still exists
Mar  9 16:12:46.403: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 16:12:46.405: INFO: Pod pod-with-poststart-http-hook still exists
Mar  9 16:12:48.403: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 16:12:48.404: INFO: Pod pod-with-poststart-http-hook still exists
Mar  9 16:12:50.403: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 16:12:50.405: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:12:50.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-b7fzn" for this suite.
Mar  9 16:13:12.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:13:12.436: INFO: namespace: e2e-tests-container-lifecycle-hook-b7fzn, resource: bindings, ignored listing per whitelist
Mar  9 16:13:12.457: INFO: namespace e2e-tests-container-lifecycle-hook-b7fzn deletion completed in 22.0511768s

• [SLOW TEST:36.112 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:13:12.457: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:13:12.480050      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  9 16:13:15.016: INFO: Successfully updated pod "pod-update-activedeadlineseconds-3cd28f2b-4286-11e9-923b-2eb43f2b540f"
Mar  9 16:13:15.016: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-3cd28f2b-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-pods-2dvmh" to be "terminated due to deadline exceeded"
Mar  9 16:13:15.017: INFO: Pod "pod-update-activedeadlineseconds-3cd28f2b-4286-11e9-923b-2eb43f2b540f": Phase="Running", Reason="", readiness=true. Elapsed: 1.058063ms
Mar  9 16:13:17.019: INFO: Pod "pod-update-activedeadlineseconds-3cd28f2b-4286-11e9-923b-2eb43f2b540f": Phase="Running", Reason="", readiness=true. Elapsed: 2.002681491s
Mar  9 16:13:19.020: INFO: Pod "pod-update-activedeadlineseconds-3cd28f2b-4286-11e9-923b-2eb43f2b540f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.004078238s
Mar  9 16:13:19.020: INFO: Pod "pod-update-activedeadlineseconds-3cd28f2b-4286-11e9-923b-2eb43f2b540f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:13:19.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2dvmh" for this suite.
Mar  9 16:13:25.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:13:25.056: INFO: namespace: e2e-tests-pods-2dvmh, resource: bindings, ignored listing per whitelist
Mar  9 16:13:25.070: INFO: namespace e2e-tests-pods-2dvmh deletion completed in 6.048947872s

• [SLOW TEST:12.613 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:13:25.070: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:13:25.088023      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:13:25.433: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  9 16:13:25.437: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:25.439: INFO: Number of nodes with available pods: 0
Mar  9 16:13:25.439: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:13:26.441: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:26.442: INFO: Number of nodes with available pods: 0
Mar  9 16:13:26.442: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:13:27.440: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:27.442: INFO: Number of nodes with available pods: 1
Mar  9 16:13:27.442: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  9 16:13:27.457: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:27.459: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:28.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:28.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:29.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:29.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:30.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:30.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:31.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:31.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:32.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:32.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:33.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:33.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:34.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:34.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:35.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:35.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:36.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:36.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:37.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:37.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:38.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:38.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:39.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:39.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:40.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:40.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:41.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:41.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:42.462: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:42.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:43.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:43.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:44.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:44.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:45.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:45.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:46.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:46.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:47.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:47.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:48.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:48.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:49.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:49.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:50.466: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:50.470: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:51.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:51.466: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:52.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:52.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:53.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:53.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:54.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:54.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:55.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:55.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:56.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:56.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:57.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:57.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:58.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:58.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:13:59.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:13:59.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:14:00.461: INFO: Wrong image for pod: daemon-set-7887q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  9 16:14:00.461: INFO: Pod daemon-set-7887q is not available
Mar  9 16:14:00.462: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:14:01.461: INFO: Pod daemon-set-5z59n is not available
Mar  9 16:14:01.463: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  9 16:14:01.464: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:14:01.465: INFO: Number of nodes with available pods: 0
Mar  9 16:14:01.465: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:14:02.467: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 16:14:02.468: INFO: Number of nodes with available pods: 1
Mar  9 16:14:02.468: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9vkrr, will wait for the garbage collector to delete the pods
Mar  9 16:14:02.528: INFO: Deleting {extensions DaemonSet} daemon-set took: 2.702202ms
Mar  9 16:14:02.628: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.114033ms
Mar  9 16:14:09.829: INFO: Number of nodes with available pods: 0
Mar  9 16:14:09.829: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 16:14:09.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9vkrr/daemonsets","resourceVersion":"6325"},"items":null}

Mar  9 16:14:09.831: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9vkrr/pods","resourceVersion":"6325"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:14:09.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9vkrr" for this suite.
Mar  9 16:14:15.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:14:15.865: INFO: namespace: e2e-tests-daemonsets-9vkrr, resource: bindings, ignored listing per whitelist
Mar  9 16:14:15.885: INFO: namespace e2e-tests-daemonsets-9vkrr deletion completed in 6.049465568s

• [SLOW TEST:50.814 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:14:15.885: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:14:15.904037      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  9 16:14:15.927: INFO: Waiting up to 5m0s for pod "pod-62a06123-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-qgvvm" to be "success or failure"
Mar  9 16:14:15.930: INFO: Pod "pod-62a06123-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.544313ms
Mar  9 16:14:17.932: INFO: Pod "pod-62a06123-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00429531s
STEP: Saw pod success
Mar  9 16:14:17.932: INFO: Pod "pod-62a06123-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:14:17.933: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-62a06123-4286-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:14:17.942: INFO: Waiting for pod pod-62a06123-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:14:17.944: INFO: Pod pod-62a06123-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:14:17.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qgvvm" for this suite.
Mar  9 16:14:23.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:14:23.987: INFO: namespace: e2e-tests-emptydir-qgvvm, resource: bindings, ignored listing per whitelist
Mar  9 16:14:23.995: INFO: namespace e2e-tests-emptydir-qgvvm deletion completed in 6.049957583s

• [SLOW TEST:8.110 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:14:23.995: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:14:24.012783      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-6775426c-4286-11e9-923b-2eb43f2b540f
STEP: Creating secret with name secret-projected-all-test-volume-6775425e-4286-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  9 16:14:24.036: INFO: Waiting up to 5m0s for pod "projected-volume-67754234-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-zv59l" to be "success or failure"
Mar  9 16:14:24.037: INFO: Pod "projected-volume-67754234-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.941506ms
Mar  9 16:14:26.039: INFO: Pod "projected-volume-67754234-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003628536s
STEP: Saw pod success
Mar  9 16:14:26.039: INFO: Pod "projected-volume-67754234-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:14:26.040: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod projected-volume-67754234-4286-11e9-923b-2eb43f2b540f container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  9 16:14:26.049: INFO: Waiting for pod projected-volume-67754234-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:14:26.051: INFO: Pod projected-volume-67754234-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:14:26.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zv59l" for this suite.
Mar  9 16:14:32.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:14:32.071: INFO: namespace: e2e-tests-projected-zv59l, resource: bindings, ignored listing per whitelist
Mar  9 16:14:32.117: INFO: namespace e2e-tests-projected-zv59l deletion completed in 6.064191743s

• [SLOW TEST:8.121 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:14:32.117: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:14:32.144719      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-scx5x;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-scx5x;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-scx5x.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-scx5x.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-scx5x.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 127.158.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.158.127_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 127.158.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.158.127_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-scx5x;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-scx5x;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-scx5x.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-scx5x.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-scx5x.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-scx5x.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-scx5x.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-scx5x.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 127.158.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.158.127_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 127.158.10.10.in-addr.arpa. PTR)" && echo OK > /results/10.10.158.127_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 16:14:50.258: INFO: DNS probes using e2e-tests-dns-scx5x/dns-test-6c51f773-4286-11e9-923b-2eb43f2b540f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:14:50.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-scx5x" for this suite.
Mar  9 16:14:56.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:14:56.340: INFO: namespace: e2e-tests-dns-scx5x, resource: bindings, ignored listing per whitelist
Mar  9 16:14:56.359: INFO: namespace e2e-tests-dns-scx5x deletion completed in 6.047775647s

• [SLOW TEST:24.242 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:14:56.359: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:14:56.376196      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  9 16:14:56.398: INFO: Waiting up to 5m0s for pod "pod-7abfc910-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-ls9zf" to be "success or failure"
Mar  9 16:14:56.401: INFO: Pod "pod-7abfc910-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.408383ms
Mar  9 16:14:58.403: INFO: Pod "pod-7abfc910-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004001753s
STEP: Saw pod success
Mar  9 16:14:58.403: INFO: Pod "pod-7abfc910-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:14:58.404: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-7abfc910-4286-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:14:58.412: INFO: Waiting for pod pod-7abfc910-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:14:58.413: INFO: Pod pod-7abfc910-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:14:58.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ls9zf" for this suite.
Mar  9 16:15:04.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:15:04.451: INFO: namespace: e2e-tests-emptydir-ls9zf, resource: bindings, ignored listing per whitelist
Mar  9 16:15:04.471: INFO: namespace e2e-tests-emptydir-ls9zf deletion completed in 6.055868922s

• [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:15:04.471: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:15:04.488921      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 16:15:04.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-j25hq'
Mar  9 16:15:04.689: INFO: stderr: ""
Mar  9 16:15:04.689: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar  9 16:15:04.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-j25hq'
Mar  9 16:15:09.830: INFO: stderr: ""
Mar  9 16:15:09.830: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:15:09.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j25hq" for this suite.
Mar  9 16:15:15.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:15:15.861: INFO: namespace: e2e-tests-kubectl-j25hq, resource: bindings, ignored listing per whitelist
Mar  9 16:15:15.881: INFO: namespace e2e-tests-kubectl-j25hq deletion completed in 6.04983822s

• [SLOW TEST:11.410 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:15:15.881: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:15:15.901978      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8663607d-4286-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:15:15.928: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-79lfh" to be "success or failure"
Mar  9 16:15:15.933: INFO: Pod "pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.090918ms
Mar  9 16:15:17.934: INFO: Pod "pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006454861s
STEP: Saw pod success
Mar  9 16:15:17.934: INFO: Pod "pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:15:17.935: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:15:17.944: INFO: Waiting for pod pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:15:17.946: INFO: Pod pod-projected-configmaps-8663979d-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:15:17.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-79lfh" for this suite.
Mar  9 16:15:23.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:15:23.967: INFO: namespace: e2e-tests-projected-79lfh, resource: bindings, ignored listing per whitelist
Mar  9 16:15:23.994: INFO: namespace e2e-tests-projected-79lfh deletion completed in 6.047170009s

• [SLOW TEST:8.113 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:15:23.994: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:15:24.011998      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9zmsv
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9zmsv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9zmsv
Mar  9 16:15:24.043: INFO: Found 0 stateful pods, waiting for 1
Mar  9 16:15:34.045: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  9 16:15:34.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 16:15:34.195: INFO: stderr: ""
Mar  9 16:15:34.195: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 16:15:34.195: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 16:15:34.197: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  9 16:15:44.199: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 16:15:44.199: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:15:44.214: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999973s
Mar  9 16:15:45.216: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989645372s
Mar  9 16:15:46.218: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987737805s
Mar  9 16:15:47.220: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985873993s
Mar  9 16:15:48.222: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983961335s
Mar  9 16:15:49.223: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982135202s
Mar  9 16:15:50.225: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.980256496s
Mar  9 16:15:51.227: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97838122s
Mar  9 16:15:52.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976547188s
Mar  9 16:15:53.231: INFO: Verifying statefulset ss doesn't scale past 1 for another 974.658597ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9zmsv
Mar  9 16:15:54.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:15:54.392: INFO: stderr: ""
Mar  9 16:15:54.392: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 16:15:54.392: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 16:15:54.394: INFO: Found 1 stateful pods, waiting for 3
Mar  9 16:16:04.396: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:16:04.396: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:16:04.396: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  9 16:16:04.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 16:16:04.544: INFO: stderr: ""
Mar  9 16:16:04.544: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 16:16:04.544: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 16:16:04.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 16:16:04.689: INFO: stderr: ""
Mar  9 16:16:04.689: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 16:16:04.689: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 16:16:04.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 16:16:04.832: INFO: stderr: ""
Mar  9 16:16:04.832: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 16:16:04.832: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 16:16:04.832: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:16:04.834: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar  9 16:16:14.837: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 16:16:14.837: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 16:16:14.837: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 16:16:14.843: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999679s
Mar  9 16:16:15.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996421199s
Mar  9 16:16:16.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994322365s
Mar  9 16:16:17.850: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992257696s
Mar  9 16:16:18.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.990255344s
Mar  9 16:16:19.854: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.988179261s
Mar  9 16:16:20.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.98601655s
Mar  9 16:16:21.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983808448s
Mar  9 16:16:22.918: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967706288s
Mar  9 16:16:23.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 922.297597ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9zmsv
Mar  9 16:16:25.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:16:25.174: INFO: stderr: ""
Mar  9 16:16:25.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 16:16:25.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 16:16:25.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:16:25.320: INFO: stderr: ""
Mar  9 16:16:25.320: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 16:16:25.320: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 16:16:25.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-9zmsv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:16:25.463: INFO: stderr: ""
Mar  9 16:16:25.463: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 16:16:25.463: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 16:16:25.463: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  9 16:16:35.470: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9zmsv
Mar  9 16:16:35.471: INFO: Scaling statefulset ss to 0
Mar  9 16:16:35.475: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:16:35.476: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:16:35.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9zmsv" for this suite.
Mar  9 16:16:41.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:16:41.520: INFO: namespace: e2e-tests-statefulset-9zmsv, resource: bindings, ignored listing per whitelist
Mar  9 16:16:41.535: INFO: namespace e2e-tests-statefulset-9zmsv deletion completed in 6.051154272s

• [SLOW TEST:77.541 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:16:41.536: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:16:41.553609      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:16:41.577: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-hkv7b" to be "success or failure"
Mar  9 16:16:41.581: INFO: Pod "downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.399785ms
Mar  9 16:16:43.583: INFO: Pod "downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006191661s
STEP: Saw pod success
Mar  9 16:16:43.583: INFO: Pod "downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:16:43.584: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:16:43.594: INFO: Waiting for pod downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:16:43.595: INFO: Pod downwardapi-volume-b9709e13-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:16:43.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hkv7b" for this suite.
Mar  9 16:16:49.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:16:49.637: INFO: namespace: e2e-tests-projected-hkv7b, resource: bindings, ignored listing per whitelist
Mar  9 16:16:49.654: INFO: namespace e2e-tests-projected-hkv7b deletion completed in 6.05831237s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:16:49.655: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:16:49.673683      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-be478ff5-4286-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:16:49.697: INFO: Waiting up to 5m0s for pod "pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-w9hk7" to be "success or failure"
Mar  9 16:16:49.701: INFO: Pod "pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.730057ms
Mar  9 16:16:51.703: INFO: Pod "pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005568466s
STEP: Saw pod success
Mar  9 16:16:51.703: INFO: Pod "pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:16:51.704: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:16:51.713: INFO: Waiting for pod pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:16:51.715: INFO: Pod pod-secrets-be47d480-4286-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:16:51.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w9hk7" for this suite.
Mar  9 16:16:57.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:16:57.772: INFO: namespace: e2e-tests-secrets-w9hk7, resource: bindings, ignored listing per whitelist
Mar  9 16:16:57.774: INFO: namespace e2e-tests-secrets-w9hk7 deletion completed in 6.057590358s

• [SLOW TEST:8.120 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:16:57.774: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:16:57.792492      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar  9 16:16:57.811: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-182708018 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:16:57.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8cj25" for this suite.
Mar  9 16:17:03.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:17:03.902: INFO: namespace: e2e-tests-kubectl-8cj25, resource: bindings, ignored listing per whitelist
Mar  9 16:17:03.938: INFO: namespace e2e-tests-kubectl-8cj25 deletion completed in 6.062444939s

• [SLOW TEST:6.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:17:03.938: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:17:03.955977      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-j4v6
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 16:17:03.981: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-j4v6" in namespace "e2e-tests-subpath-n4rwb" to be "success or failure"
Mar  9 16:17:03.985: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.627588ms
Mar  9 16:17:05.986: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 2.004977749s
Mar  9 16:17:07.988: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 4.006589286s
Mar  9 16:17:09.989: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 6.008135598s
Mar  9 16:17:11.991: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 8.00987163s
Mar  9 16:17:13.993: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 10.011555019s
Mar  9 16:17:15.994: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 12.013178019s
Mar  9 16:17:17.996: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 14.014667769s
Mar  9 16:17:19.998: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 16.016515507s
Mar  9 16:17:21.999: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 18.018267085s
Mar  9 16:17:24.001: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Running", Reason="", readiness=false. Elapsed: 20.019801003s
Mar  9 16:17:26.002: INFO: Pod "pod-subpath-test-secret-j4v6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.021132716s
STEP: Saw pod success
Mar  9 16:17:26.002: INFO: Pod "pod-subpath-test-secret-j4v6" satisfied condition "success or failure"
Mar  9 16:17:26.003: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-subpath-test-secret-j4v6 container test-container-subpath-secret-j4v6: <nil>
STEP: delete the pod
Mar  9 16:17:26.015: INFO: Waiting for pod pod-subpath-test-secret-j4v6 to disappear
Mar  9 16:17:26.018: INFO: Pod pod-subpath-test-secret-j4v6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-j4v6
Mar  9 16:17:26.018: INFO: Deleting pod "pod-subpath-test-secret-j4v6" in namespace "e2e-tests-subpath-n4rwb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:17:26.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-n4rwb" for this suite.
Mar  9 16:17:32.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:17:32.056: INFO: namespace: e2e-tests-subpath-n4rwb, resource: bindings, ignored listing per whitelist
Mar  9 16:17:32.070: INFO: namespace e2e-tests-subpath-n4rwb deletion completed in 6.050233748s

• [SLOW TEST:28.132 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:17:32.070: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:17:32.087631      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 16:17:32.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-2mqk6'
Mar  9 16:17:32.191: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  9 16:17:32.191: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar  9 16:17:32.199: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xnt54]
Mar  9 16:17:32.199: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xnt54" in namespace "e2e-tests-kubectl-2mqk6" to be "running and ready"
Mar  9 16:17:32.203: INFO: Pod "e2e-test-nginx-rc-xnt54": Phase="Pending", Reason="", readiness=false. Elapsed: 3.552754ms
Mar  9 16:17:34.205: INFO: Pod "e2e-test-nginx-rc-xnt54": Phase="Running", Reason="", readiness=true. Elapsed: 2.005305359s
Mar  9 16:17:34.205: INFO: Pod "e2e-test-nginx-rc-xnt54" satisfied condition "running and ready"
Mar  9 16:17:34.205: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xnt54]
Mar  9 16:17:34.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2mqk6'
Mar  9 16:17:34.286: INFO: stderr: ""
Mar  9 16:17:34.286: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar  9 16:17:34.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2mqk6'
Mar  9 16:17:34.365: INFO: stderr: ""
Mar  9 16:17:34.365: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:17:34.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2mqk6" for this suite.
Mar  9 16:17:56.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:17:56.418: INFO: namespace: e2e-tests-kubectl-2mqk6, resource: bindings, ignored listing per whitelist
Mar  9 16:17:56.426: INFO: namespace e2e-tests-kubectl-2mqk6 deletion completed in 22.059518498s

• [SLOW TEST:24.356 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:17:56.426: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:17:56.445909      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  9 16:17:56.474: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-rtpgf,SelfLink:/api/v1/namespaces/e2e-tests-watch-rtpgf/configmaps/e2e-watch-test-resource-version,UID:e6146dc1-4286-11e9-9882-02b03e914f30,ResourceVersion:7284,Generation:0,CreationTimestamp:2019-03-09 16:17:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 16:17:56.474: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-rtpgf,SelfLink:/api/v1/namespaces/e2e-tests-watch-rtpgf/configmaps/e2e-watch-test-resource-version,UID:e6146dc1-4286-11e9-9882-02b03e914f30,ResourceVersion:7285,Generation:0,CreationTimestamp:2019-03-09 16:17:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:17:56.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-rtpgf" for this suite.
Mar  9 16:18:02.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:18:02.505: INFO: namespace: e2e-tests-watch-rtpgf, resource: bindings, ignored listing per whitelist
Mar  9 16:18:02.525: INFO: namespace e2e-tests-watch-rtpgf deletion completed in 6.049534401s

• [SLOW TEST:6.099 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:18:02.525: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:18:02.542870      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar  9 16:18:04.584: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-e9b75247-4286-11e9-923b-2eb43f2b540f", GenerateName:"", Namespace:"e2e-tests-pods-9k2z6", SelfLink:"/api/v1/namespaces/e2e-tests-pods-9k2z6/pods/pod-submit-remove-e9b75247-4286-11e9-923b-2eb43f2b540f", UID:"e9b8138d-4286-11e9-9882-02b03e914f30", ResourceVersion:"7318", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687745082, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"566719625"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vcgjk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4222b6e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vcgjk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4213144c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-192-168-70-73.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42174a360), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421314500)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421314520)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421314528), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687745082, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687745084, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687745084, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687745082, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.70.73", PodIP:"10.20.192.13", StartTime:(*v1.Time)(0xc421dbc020), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421dbc040), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"containerd://882f01c694afc07c6cde2b3a37cc068b8aada7b7cb361c84923fa103595489b9"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  9 16:18:09.593: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:18:09.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9k2z6" for this suite.
Mar  9 16:18:15.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:18:15.637: INFO: namespace: e2e-tests-pods-9k2z6, resource: bindings, ignored listing per whitelist
Mar  9 16:18:15.644: INFO: namespace e2e-tests-pods-9k2z6 deletion completed in 6.048376172s

• [SLOW TEST:13.119 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:18:15.644: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:18:15.672094      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:18:15.693: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  9 16:18:15.697: INFO: Number of nodes with available pods: 0
Mar  9 16:18:15.697: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  9 16:18:15.710: INFO: Number of nodes with available pods: 0
Mar  9 16:18:15.710: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:16.712: INFO: Number of nodes with available pods: 0
Mar  9 16:18:16.712: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:17.712: INFO: Number of nodes with available pods: 1
Mar  9 16:18:17.712: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  9 16:18:17.724: INFO: Number of nodes with available pods: 0
Mar  9 16:18:17.724: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  9 16:18:17.729: INFO: Number of nodes with available pods: 0
Mar  9 16:18:17.729: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:18.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:18.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:19.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:19.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:20.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:20.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:21.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:21.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:22.733: INFO: Number of nodes with available pods: 0
Mar  9 16:18:22.733: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:23.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:23.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:24.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:24.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:25.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:25.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:26.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:26.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:27.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:27.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:28.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:28.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:29.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:29.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:30.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:30.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:31.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:31.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:32.736: INFO: Number of nodes with available pods: 0
Mar  9 16:18:32.736: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:33.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:33.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:34.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:34.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:35.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:35.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:36.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:36.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:37.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:37.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:38.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:38.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:39.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:39.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:40.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:40.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:41.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:41.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:42.737: INFO: Number of nodes with available pods: 0
Mar  9 16:18:42.737: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:43.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:43.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:44.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:44.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:45.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:45.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:46.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:46.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:47.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:47.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:48.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:48.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:49.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:49.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:50.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:50.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:51.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:51.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:52.734: INFO: Number of nodes with available pods: 0
Mar  9 16:18:52.734: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:53.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:53.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:54.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:54.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:55.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:55.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:56.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:56.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:57.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:57.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:58.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:58.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:18:59.731: INFO: Number of nodes with available pods: 0
Mar  9 16:18:59.731: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:19:00.732: INFO: Number of nodes with available pods: 0
Mar  9 16:19:00.732: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 16:19:01.731: INFO: Number of nodes with available pods: 1
Mar  9 16:19:01.731: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-gw9wq, will wait for the garbage collector to delete the pods
Mar  9 16:19:01.788: INFO: Deleting {extensions DaemonSet} daemon-set took: 3.289827ms
Mar  9 16:19:01.888: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.126436ms
Mar  9 16:19:39.890: INFO: Number of nodes with available pods: 0
Mar  9 16:19:39.890: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 16:19:39.891: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gw9wq/daemonsets","resourceVersion":"7564"},"items":null}

Mar  9 16:19:39.892: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gw9wq/pods","resourceVersion":"7564"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:19:39.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gw9wq" for this suite.
Mar  9 16:19:45.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:19:45.915: INFO: namespace: e2e-tests-daemonsets-gw9wq, resource: bindings, ignored listing per whitelist
Mar  9 16:19:45.950: INFO: namespace e2e-tests-daemonsets-gw9wq deletion completed in 6.04816415s

• [SLOW TEST:90.306 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:19:45.950: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:19:45.967265      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar  9 16:19:45.988: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-v75s5" to be "success or failure"
Mar  9 16:19:45.994: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.18801ms
Mar  9 16:19:47.995: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006780557s
STEP: Saw pod success
Mar  9 16:19:47.995: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  9 16:19:47.996: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  9 16:19:48.006: INFO: Waiting for pod pod-host-path-test to disappear
Mar  9 16:19:48.008: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:19:48.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-v75s5" for this suite.
Mar  9 16:19:54.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:19:54.044: INFO: namespace: e2e-tests-hostpath-v75s5, resource: bindings, ignored listing per whitelist
Mar  9 16:19:54.062: INFO: namespace e2e-tests-hostpath-v75s5 deletion completed in 6.053015725s

• [SLOW TEST:8.112 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:19:54.062: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:19:54.080063      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-72f4d in namespace e2e-tests-proxy-4lm5t
I0309 16:19:54.105505      15 runners.go:180] Created replication controller with name: proxy-service-72f4d, namespace: e2e-tests-proxy-4lm5t, replica count: 1
I0309 16:19:55.155789      15 runners.go:180] proxy-service-72f4d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 16:19:56.155919      15 runners.go:180] proxy-service-72f4d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 16:19:57.156058      15 runners.go:180] proxy-service-72f4d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0309 16:19:58.156197      15 runners.go:180] proxy-service-72f4d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0309 16:19:59.156334      15 runners.go:180] proxy-service-72f4d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0309 16:20:00.156472      15 runners.go:180] proxy-service-72f4d Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 16:20:00.158: INFO: setup took 6.061090855s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  9 16:20:00.195: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 37.523175ms)
Mar  9 16:20:00.195: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 37.332425ms)
Mar  9 16:20:00.196: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 37.666244ms)
Mar  9 16:20:00.196: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 37.721882ms)
Mar  9 16:20:00.200: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 41.989779ms)
Mar  9 16:20:00.200: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 41.685001ms)
Mar  9 16:20:00.204: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 46.410935ms)
Mar  9 16:20:00.204: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 46.517493ms)
Mar  9 16:20:00.204: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 46.861964ms)
Mar  9 16:20:00.205: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 47.118143ms)
Mar  9 16:20:00.206: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 47.893518ms)
Mar  9 16:20:00.206: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 47.774637ms)
Mar  9 16:20:00.206: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 47.907086ms)
Mar  9 16:20:00.206: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 47.928634ms)
Mar  9 16:20:00.206: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 48.295501ms)
Mar  9 16:20:00.208: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 50.538363ms)
Mar  9 16:20:00.213: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 4.500354ms)
Mar  9 16:20:00.213: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 4.60104ms)
Mar  9 16:20:00.213: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 4.484062ms)
Mar  9 16:20:00.213: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 4.472453ms)
Mar  9 16:20:00.213: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 4.168754ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 9.582866ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 9.373131ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 9.491153ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 9.474276ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 9.647898ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.56708ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 9.468804ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.629339ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.614882ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.569056ms)
Mar  9 16:20:00.218: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.469463ms)
Mar  9 16:20:00.224: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 5.989855ms)
Mar  9 16:20:00.224: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 5.711652ms)
Mar  9 16:20:00.224: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 6.126924ms)
Mar  9 16:20:00.225: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.326569ms)
Mar  9 16:20:00.225: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.378593ms)
Mar  9 16:20:00.225: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.516898ms)
Mar  9 16:20:00.225: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.110359ms)
Mar  9 16:20:00.225: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.149709ms)
Mar  9 16:20:00.226: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 7.433742ms)
Mar  9 16:20:00.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.32906ms)
Mar  9 16:20:00.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 8.808854ms)
Mar  9 16:20:00.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 8.958418ms)
Mar  9 16:20:00.227: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 8.79411ms)
Mar  9 16:20:00.228: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.259715ms)
Mar  9 16:20:00.228: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 9.243187ms)
Mar  9 16:20:00.228: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.530064ms)
Mar  9 16:20:00.234: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 5.957685ms)
Mar  9 16:20:00.234: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 6.041686ms)
Mar  9 16:20:00.234: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 6.096887ms)
Mar  9 16:20:00.235: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.229012ms)
Mar  9 16:20:00.235: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.247208ms)
Mar  9 16:20:00.235: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.944867ms)
Mar  9 16:20:00.235: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 7.383976ms)
Mar  9 16:20:00.235: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.944601ms)
Mar  9 16:20:00.236: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 8.079282ms)
Mar  9 16:20:00.236: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 7.838349ms)
Mar  9 16:20:00.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.675986ms)
Mar  9 16:20:00.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 8.687771ms)
Mar  9 16:20:00.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 8.990185ms)
Mar  9 16:20:00.237: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 8.75789ms)
Mar  9 16:20:00.239: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 10.024478ms)
Mar  9 16:20:00.239: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 10.172164ms)
Mar  9 16:20:00.243: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 4.200888ms)
Mar  9 16:20:00.243: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 4.656702ms)
Mar  9 16:20:00.245: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 5.95857ms)
Mar  9 16:20:00.245: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.47868ms)
Mar  9 16:20:00.245: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.219742ms)
Mar  9 16:20:00.245: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.572786ms)
Mar  9 16:20:00.246: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.850139ms)
Mar  9 16:20:00.248: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 9.102788ms)
Mar  9 16:20:00.248: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 8.606288ms)
Mar  9 16:20:00.248: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.462108ms)
Mar  9 16:20:00.248: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.258839ms)
Mar  9 16:20:00.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.463022ms)
Mar  9 16:20:00.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.30865ms)
Mar  9 16:20:00.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 9.57538ms)
Mar  9 16:20:00.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 9.657797ms)
Mar  9 16:20:00.249: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.784274ms)
Mar  9 16:20:00.257: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 7.282465ms)
Mar  9 16:20:00.257: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 7.137133ms)
Mar  9 16:20:00.257: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 7.248468ms)
Mar  9 16:20:00.257: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 7.301705ms)
Mar  9 16:20:00.257: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.34876ms)
Mar  9 16:20:00.258: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.303508ms)
Mar  9 16:20:00.258: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 8.389489ms)
Mar  9 16:20:00.258: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.7811ms)
Mar  9 16:20:00.258: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 8.743063ms)
Mar  9 16:20:00.259: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.019529ms)
Mar  9 16:20:00.259: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 9.146384ms)
Mar  9 16:20:00.259: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.685737ms)
Mar  9 16:20:00.260: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 9.8589ms)
Mar  9 16:20:00.260: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 10.347134ms)
Mar  9 16:20:00.260: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 10.579637ms)
Mar  9 16:20:00.261: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.849206ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.827663ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 10.159872ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 10.215129ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.091473ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 10.182486ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 10.152941ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 10.192169ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 10.303006ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 10.069979ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 10.107488ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 10.169994ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 10.21025ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.55431ms)
Mar  9 16:20:00.271: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 10.658759ms)
Mar  9 16:20:00.272: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 10.583599ms)
Mar  9 16:20:00.272: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 10.695005ms)
Mar  9 16:20:00.278: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.39218ms)
Mar  9 16:20:00.278: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.522156ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 9.200917ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 9.078005ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 8.907219ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 9.070446ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.16879ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 8.479972ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.162588ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.446351ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.077592ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.243427ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 8.567645ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.019176ms)
Mar  9 16:20:00.281: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.645889ms)
Mar  9 16:20:00.282: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 10.174347ms)
Mar  9 16:20:00.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.346046ms)
Mar  9 16:20:00.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 6.386804ms)
Mar  9 16:20:00.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.217135ms)
Mar  9 16:20:00.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.123436ms)
Mar  9 16:20:00.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 6.165621ms)
Mar  9 16:20:00.288: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.215605ms)
Mar  9 16:20:00.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 8.302726ms)
Mar  9 16:20:00.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 8.623296ms)
Mar  9 16:20:00.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.60774ms)
Mar  9 16:20:00.291: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 8.474136ms)
Mar  9 16:20:00.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.980741ms)
Mar  9 16:20:00.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.811288ms)
Mar  9 16:20:00.292: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 10.379569ms)
Mar  9 16:20:00.293: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 10.255534ms)
Mar  9 16:20:00.293: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 10.356594ms)
Mar  9 16:20:00.293: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 10.808228ms)
Mar  9 16:20:00.299: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.409396ms)
Mar  9 16:20:00.299: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.104997ms)
Mar  9 16:20:00.299: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 5.97304ms)
Mar  9 16:20:00.299: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.120253ms)
Mar  9 16:20:00.302: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.114408ms)
Mar  9 16:20:00.302: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.251168ms)
Mar  9 16:20:00.302: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 9.20892ms)
Mar  9 16:20:00.302: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.939758ms)
Mar  9 16:20:00.302: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 8.757916ms)
Mar  9 16:20:00.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 9.377703ms)
Mar  9 16:20:00.303: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.282154ms)
Mar  9 16:20:00.304: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 10.265417ms)
Mar  9 16:20:00.304: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 10.655629ms)
Mar  9 16:20:00.305: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.997456ms)
Mar  9 16:20:00.305: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 12.518801ms)
Mar  9 16:20:00.306: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 12.472585ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.470599ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.56555ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.175581ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.791024ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 7.170764ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 7.236484ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 7.038508ms)
Mar  9 16:20:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.550739ms)
Mar  9 16:20:00.314: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 7.351061ms)
Mar  9 16:20:00.314: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 7.285645ms)
Mar  9 16:20:00.315: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 8.910516ms)
Mar  9 16:20:00.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.442514ms)
Mar  9 16:20:00.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.568366ms)
Mar  9 16:20:00.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.507989ms)
Mar  9 16:20:00.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.580569ms)
Mar  9 16:20:00.316: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 9.705801ms)
Mar  9 16:20:00.322: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 5.792146ms)
Mar  9 16:20:00.322: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 5.620954ms)
Mar  9 16:20:00.323: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 6.806404ms)
Mar  9 16:20:00.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 6.669849ms)
Mar  9 16:20:00.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.870766ms)
Mar  9 16:20:00.324: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.110499ms)
Mar  9 16:20:00.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 7.968234ms)
Mar  9 16:20:00.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 7.951452ms)
Mar  9 16:20:00.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 8.388298ms)
Mar  9 16:20:00.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.403804ms)
Mar  9 16:20:00.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 8.519747ms)
Mar  9 16:20:00.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 8.30828ms)
Mar  9 16:20:00.327: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 10.506031ms)
Mar  9 16:20:00.327: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 10.135879ms)
Mar  9 16:20:00.327: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 10.52985ms)
Mar  9 16:20:00.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 10.582358ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 7.040419ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.8104ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 7.135497ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 4.910424ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.890033ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 5.026163ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.814795ms)
Mar  9 16:20:00.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 6.689846ms)
Mar  9 16:20:00.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 7.67151ms)
Mar  9 16:20:00.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.654173ms)
Mar  9 16:20:00.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.821223ms)
Mar  9 16:20:00.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.551092ms)
Mar  9 16:20:00.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 10.082914ms)
Mar  9 16:20:00.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 10.055205ms)
Mar  9 16:20:00.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.704559ms)
Mar  9 16:20:00.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 10.037904ms)
Mar  9 16:20:00.344: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.105602ms)
Mar  9 16:20:00.345: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.391534ms)
Mar  9 16:20:00.345: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.394909ms)
Mar  9 16:20:00.345: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 6.698592ms)
Mar  9 16:20:00.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 9.274845ms)
Mar  9 16:20:00.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 9.249325ms)
Mar  9 16:20:00.347: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.082917ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.871301ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 9.02578ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 8.936062ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.479221ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 8.997897ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.610714ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 9.102107ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.764096ms)
Mar  9 16:20:00.348: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.624857ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 6.861839ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.822251ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.968853ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 6.955461ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 7.044902ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.910563ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 7.07296ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 6.894819ms)
Mar  9 16:20:00.355: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 6.982285ms)
Mar  9 16:20:00.357: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.432247ms)
Mar  9 16:20:00.359: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 10.342666ms)
Mar  9 16:20:00.359: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 10.392852ms)
Mar  9 16:20:00.359: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.34393ms)
Mar  9 16:20:00.359: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 10.466956ms)
Mar  9 16:20:00.359: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 10.309042ms)
Mar  9 16:20:00.359: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 10.460999ms)
Mar  9 16:20:00.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 4.124994ms)
Mar  9 16:20:00.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 4.254705ms)
Mar  9 16:20:00.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 4.266937ms)
Mar  9 16:20:00.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 4.208747ms)
Mar  9 16:20:00.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 4.254848ms)
Mar  9 16:20:00.367: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 8.278028ms)
Mar  9 16:20:00.367: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 8.323596ms)
Mar  9 16:20:00.367: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 8.243631ms)
Mar  9 16:20:00.367: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 8.278866ms)
Mar  9 16:20:00.367: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 8.241201ms)
Mar  9 16:20:00.367: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 8.342786ms)
Mar  9 16:20:00.370: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 10.848931ms)
Mar  9 16:20:00.370: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.948948ms)
Mar  9 16:20:00.370: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 10.915288ms)
Mar  9 16:20:00.370: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 11.004286ms)
Mar  9 16:20:00.370: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 10.968434ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 7.406067ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 9.984604ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 9.964739ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.943772ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 10.087242ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 9.946335ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 10.200683ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 7.386424ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 7.694738ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 7.517899ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.685159ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 10.026726ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 7.678065ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 7.907144ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.559045ms)
Mar  9 16:20:00.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 7.87268ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.471401ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.676929ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.501689ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 7.063016ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 6.8368ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 6.817514ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 6.899805ms)
Mar  9 16:20:00.387: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 7.041567ms)
Mar  9 16:20:00.388: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 6.840018ms)
Mar  9 16:20:00.388: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.673354ms)
Mar  9 16:20:00.388: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 6.789925ms)
Mar  9 16:20:00.389: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.912178ms)
Mar  9 16:20:00.390: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 8.993464ms)
Mar  9 16:20:00.390: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 8.916587ms)
Mar  9 16:20:00.390: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 9.220496ms)
Mar  9 16:20:00.390: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 9.183445ms)
Mar  9 16:20:00.395: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 4.517813ms)
Mar  9 16:20:00.395: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 4.528033ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 7.846048ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 7.794881ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 7.769114ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 7.881211ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 7.674672ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 7.885392ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 7.857024ms)
Mar  9 16:20:00.398: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 8.275674ms)
Mar  9 16:20:00.399: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 9.086383ms)
Mar  9 16:20:00.400: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.316461ms)
Mar  9 16:20:00.400: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 9.727165ms)
Mar  9 16:20:00.401: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 10.277074ms)
Mar  9 16:20:00.401: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 10.268864ms)
Mar  9 16:20:00.401: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 10.246605ms)
Mar  9 16:20:00.406: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf/proxy/rewriteme"... (200; 5.563969ms)
Mar  9 16:20:00.407: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:1080/proxy/rewri... (200; 5.602654ms)
Mar  9 16:20:00.407: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:1080/proxy/... (200; 5.527285ms)
Mar  9 16:20:00.407: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 6.074835ms)
Mar  9 16:20:00.407: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:162/proxy/: bar (200; 4.96522ms)
Mar  9 16:20:00.408: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname2/proxy/: tls qux (200; 6.664728ms)
Mar  9 16:20:00.408: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:460/proxy/: tls baz (200; 6.97263ms)
Mar  9 16:20:00.408: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:443/proxy/... (200; 6.806034ms)
Mar  9 16:20:00.408: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/https:proxy-service-72f4d-4cjqf:462/proxy/: tls qux (200; 5.393151ms)
Mar  9 16:20:00.408: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.151578ms)
Mar  9 16:20:00.410: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/pods/http:proxy-service-72f4d-4cjqf:160/proxy/: foo (200; 7.005221ms)
Mar  9 16:20:00.410: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/https:proxy-service-72f4d:tlsportname1/proxy/: tls baz (200; 9.358368ms)
Mar  9 16:20:00.410: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname2/proxy/: bar (200; 9.127811ms)
Mar  9 16:20:00.410: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/http:proxy-service-72f4d:portname1/proxy/: foo (200; 9.191544ms)
Mar  9 16:20:00.411: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname2/proxy/: bar (200; 8.721465ms)
Mar  9 16:20:00.411: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-4lm5t/services/proxy-service-72f4d:portname1/proxy/: foo (200; 8.669394ms)
STEP: deleting { ReplicationController} proxy-service-72f4d in namespace e2e-tests-proxy-4lm5t, will wait for the garbage collector to delete the pods
Mar  9 16:20:00.465: INFO: Deleting { ReplicationController} proxy-service-72f4d took: 2.924366ms
Mar  9 16:20:00.565: INFO: Terminating { ReplicationController} proxy-service-72f4d pods took: 100.089518ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:20:02.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4lm5t" for this suite.
Mar  9 16:20:08.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:20:08.305: INFO: namespace: e2e-tests-proxy-4lm5t, resource: bindings, ignored listing per whitelist
Mar  9 16:20:08.319: INFO: namespace e2e-tests-proxy-4lm5t deletion completed in 6.050932389s

• [SLOW TEST:14.257 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:20:08.319: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:20:08.343592      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-34b250d4-4287-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:20:08.367: INFO: Waiting up to 5m0s for pod "pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-bvk8x" to be "success or failure"
Mar  9 16:20:08.370: INFO: Pod "pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.93774ms
Mar  9 16:20:10.371: INFO: Pod "pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004694138s
STEP: Saw pod success
Mar  9 16:20:10.371: INFO: Pod "pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:20:10.373: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f container secret-env-test: <nil>
STEP: delete the pod
Mar  9 16:20:10.381: INFO: Waiting for pod pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:20:10.382: INFO: Pod pod-secrets-34b28c6c-4287-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:20:10.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bvk8x" for this suite.
Mar  9 16:20:16.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:20:16.401: INFO: namespace: e2e-tests-secrets-bvk8x, resource: bindings, ignored listing per whitelist
Mar  9 16:20:16.435: INFO: namespace e2e-tests-secrets-bvk8x deletion completed in 6.050813875s

• [SLOW TEST:8.117 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:20:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:20:16.452813      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-39874c7e-4287-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:20:16.475: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-5lzll" to be "success or failure"
Mar  9 16:20:16.478: INFO: Pod "pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.009062ms
Mar  9 16:20:18.480: INFO: Pod "pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004632054s
STEP: Saw pod success
Mar  9 16:20:18.480: INFO: Pod "pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:20:18.481: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:20:18.491: INFO: Waiting for pod pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:20:18.492: INFO: Pod pod-projected-secrets-39878ed4-4287-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:20:18.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5lzll" for this suite.
Mar  9 16:20:24.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:20:24.516: INFO: namespace: e2e-tests-projected-5lzll, resource: bindings, ignored listing per whitelist
Mar  9 16:20:24.541: INFO: namespace e2e-tests-projected-5lzll deletion completed in 6.04764888s

• [SLOW TEST:8.105 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:20:24.541: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:20:24.564903      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zrw6t
Mar  9 16:20:26.610: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zrw6t
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 16:20:26.611: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:24:26.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zrw6t" for this suite.
Mar  9 16:24:32.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:24:32.897: INFO: namespace: e2e-tests-container-probe-zrw6t, resource: bindings, ignored listing per whitelist
Mar  9 16:24:32.897: INFO: namespace e2e-tests-container-probe-zrw6t deletion completed in 6.051034779s

• [SLOW TEST:248.356 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:24:32.898: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:24:32.914855      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-szmc7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 16:24:32.938: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 16:24:56.982: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.20.192.13:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-szmc7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:24:56.982: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:24:57.081: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:24:57.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-szmc7" for this suite.
Mar  9 16:25:19.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:25:19.104: INFO: namespace: e2e-tests-pod-network-test-szmc7, resource: bindings, ignored listing per whitelist
Mar  9 16:25:19.134: INFO: namespace e2e-tests-pod-network-test-szmc7 deletion completed in 22.050431194s

• [SLOW TEST:46.236 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:25:19.134: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:25:19.151613      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  9 16:25:19.175: INFO: Waiting up to 5m0s for pod "pod-edf3ec31-4287-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-x8tfj" to be "success or failure"
Mar  9 16:25:19.178: INFO: Pod "pod-edf3ec31-4287-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.245368ms
Mar  9 16:25:21.180: INFO: Pod "pod-edf3ec31-4287-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004954555s
STEP: Saw pod success
Mar  9 16:25:21.180: INFO: Pod "pod-edf3ec31-4287-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:25:21.181: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-edf3ec31-4287-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:25:21.190: INFO: Waiting for pod pod-edf3ec31-4287-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:25:21.192: INFO: Pod pod-edf3ec31-4287-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:25:21.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x8tfj" for this suite.
Mar  9 16:25:27.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:25:27.224: INFO: namespace: e2e-tests-emptydir-x8tfj, resource: bindings, ignored listing per whitelist
Mar  9 16:25:27.242: INFO: namespace e2e-tests-emptydir-x8tfj deletion completed in 6.048580372s

• [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:25:27.243: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:25:27.260196      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  9 16:25:27.283: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-ftjt4,SelfLink:/api/v1/namespaces/e2e-tests-watch-ftjt4/configmaps/e2e-watch-test-watch-closed,UID:f2c9343c-4287-11e9-9882-02b03e914f30,ResourceVersion:8481,Generation:0,CreationTimestamp:2019-03-09 16:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 16:25:27.283: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-ftjt4,SelfLink:/api/v1/namespaces/e2e-tests-watch-ftjt4/configmaps/e2e-watch-test-watch-closed,UID:f2c9343c-4287-11e9-9882-02b03e914f30,ResourceVersion:8482,Generation:0,CreationTimestamp:2019-03-09 16:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  9 16:25:27.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-ftjt4,SelfLink:/api/v1/namespaces/e2e-tests-watch-ftjt4/configmaps/e2e-watch-test-watch-closed,UID:f2c9343c-4287-11e9-9882-02b03e914f30,ResourceVersion:8483,Generation:0,CreationTimestamp:2019-03-09 16:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 16:25:27.289: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-ftjt4,SelfLink:/api/v1/namespaces/e2e-tests-watch-ftjt4/configmaps/e2e-watch-test-watch-closed,UID:f2c9343c-4287-11e9-9882-02b03e914f30,ResourceVersion:8484,Generation:0,CreationTimestamp:2019-03-09 16:25:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:25:27.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ftjt4" for this suite.
Mar  9 16:25:33.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:25:33.304: INFO: namespace: e2e-tests-watch-ftjt4, resource: bindings, ignored listing per whitelist
Mar  9 16:25:33.338: INFO: namespace e2e-tests-watch-ftjt4 deletion completed in 6.048050209s

• [SLOW TEST:6.096 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:25:33.339: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:25:33.356314      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-txzjq
Mar  9 16:25:35.383: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-txzjq
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 16:25:35.385: INFO: Initial restart count of pod liveness-exec is 0
Mar  9 16:26:23.997: INFO: Restart count of pod e2e-tests-container-probe-txzjq/liveness-exec is now 1 (48.612242665s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:26:24.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-txzjq" for this suite.
Mar  9 16:26:30.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:26:30.071: INFO: namespace: e2e-tests-container-probe-txzjq, resource: bindings, ignored listing per whitelist
Mar  9 16:26:30.094: INFO: namespace e2e-tests-container-probe-txzjq deletion completed in 6.056770456s

• [SLOW TEST:56.755 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:26:30.094: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:26:30.111183      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:26:30.135: INFO: Waiting up to 5m0s for pod "downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-72m6b" to be "success or failure"
Mar  9 16:26:30.139: INFO: Pod "downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799301ms
Mar  9 16:26:32.140: INFO: Pod "downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005249402s
STEP: Saw pod success
Mar  9 16:26:32.140: INFO: Pod "downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:26:32.141: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:26:32.151: INFO: Waiting for pod downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:26:32.153: INFO: Pod downwardapi-volume-183f62e3-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:26:32.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-72m6b" for this suite.
Mar  9 16:26:38.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:26:38.182: INFO: namespace: e2e-tests-projected-72m6b, resource: bindings, ignored listing per whitelist
Mar  9 16:26:38.201: INFO: namespace e2e-tests-projected-72m6b deletion completed in 6.046119419s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:26:38.201: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:26:38.218162      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:26:38.246: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-8vblx" to be "success or failure"
Mar  9 16:26:38.323: INFO: Pod "downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 76.790832ms
Mar  9 16:26:40.325: INFO: Pod "downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f": Phase="Running", Reason="", readiness=true. Elapsed: 2.07854629s
Mar  9 16:26:42.327: INFO: Pod "downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.080335521s
STEP: Saw pod success
Mar  9 16:26:42.327: INFO: Pod "downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:26:42.328: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:26:42.337: INFO: Waiting for pod downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:26:42.339: INFO: Pod downwardapi-volume-1d141967-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:26:42.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8vblx" for this suite.
Mar  9 16:26:48.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:26:48.358: INFO: namespace: e2e-tests-downward-api-8vblx, resource: bindings, ignored listing per whitelist
Mar  9 16:26:48.387: INFO: namespace e2e-tests-downward-api-8vblx deletion completed in 6.046785782s

• [SLOW TEST:10.186 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:26:48.387: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:26:48.404485      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-z2r7p
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar  9 16:26:48.432: INFO: Found 0 stateful pods, waiting for 3
Mar  9 16:26:58.434: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:26:58.434: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:26:58.434: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:26:58.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-z2r7p ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 16:26:58.588: INFO: stderr: ""
Mar  9 16:26:58.589: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 16:26:58.589: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  9 16:27:08.611: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  9 16:27:18.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-z2r7p ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:27:18.772: INFO: stderr: ""
Mar  9 16:27:18.772: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 16:27:18.772: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 16:27:28.781: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2r7p/ss2 to complete update
Mar  9 16:27:28.781: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  9 16:27:28.781: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  9 16:27:28.781: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  9 16:27:38.785: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2r7p/ss2 to complete update
Mar  9 16:27:38.785: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  9 16:27:38.785: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  9 16:27:48.784: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2r7p/ss2 to complete update
Mar  9 16:27:48.784: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar  9 16:27:58.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-z2r7p ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  9 16:27:58.936: INFO: stderr: ""
Mar  9 16:27:58.936: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  9 16:27:58.936: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  9 16:28:08.956: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  9 16:28:18.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 exec --namespace=e2e-tests-statefulset-z2r7p ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  9 16:28:19.129: INFO: stderr: ""
Mar  9 16:28:19.129: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  9 16:28:19.129: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  9 16:28:29.137: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2r7p/ss2 to complete update
Mar  9 16:28:29.137: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  9 16:28:29.137: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  9 16:28:29.137: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  9 16:28:39.140: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2r7p/ss2 to complete update
Mar  9 16:28:39.140: INFO: Waiting for Pod e2e-tests-statefulset-z2r7p/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  9 16:28:49.140: INFO: Deleting all statefulset in ns e2e-tests-statefulset-z2r7p
Mar  9 16:28:49.141: INFO: Scaling statefulset ss2 to 0
Mar  9 16:29:29.149: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:29:29.151: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:29:29.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-z2r7p" for this suite.
Mar  9 16:29:35.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:29:35.193: INFO: namespace: e2e-tests-statefulset-z2r7p, resource: bindings, ignored listing per whitelist
Mar  9 16:29:35.213: INFO: namespace e2e-tests-statefulset-z2r7p deletion completed in 6.052803415s

• [SLOW TEST:166.826 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:29:35.213: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:29:35.231751      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-8696e13e-4288-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:29:37.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fspdz" for this suite.
Mar  9 16:29:59.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:29:59.310: INFO: namespace: e2e-tests-configmap-fspdz, resource: bindings, ignored listing per whitelist
Mar  9 16:29:59.317: INFO: namespace e2e-tests-configmap-fspdz deletion completed in 22.048900491s

• [SLOW TEST:24.104 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:29:59.317: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:29:59.334413      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  9 16:29:59.357: INFO: Waiting up to 5m0s for pod "downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-7jwm9" to be "success or failure"
Mar  9 16:29:59.361: INFO: Pod "downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.730204ms
Mar  9 16:30:01.363: INFO: Pod "downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005580124s
STEP: Saw pod success
Mar  9 16:30:01.363: INFO: Pod "downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:30:01.364: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 16:30:01.374: INFO: Waiting for pod downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:30:01.375: INFO: Pod downward-api-94f46f43-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:30:01.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7jwm9" for this suite.
Mar  9 16:30:07.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:30:07.396: INFO: namespace: e2e-tests-downward-api-7jwm9, resource: bindings, ignored listing per whitelist
Mar  9 16:30:07.424: INFO: namespace e2e-tests-downward-api-7jwm9 deletion completed in 6.046934916s

• [SLOW TEST:8.107 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:30:07.424: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:30:07.441351      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:30:07.465: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-9dt7x" to be "success or failure"
Mar  9 16:30:07.468: INFO: Pod "downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.815723ms
Mar  9 16:30:09.470: INFO: Pod "downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004392426s
STEP: Saw pod success
Mar  9 16:30:09.470: INFO: Pod "downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:30:09.471: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:30:09.481: INFO: Waiting for pod downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:30:09.482: INFO: Pod downwardapi-volume-99c9a297-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:30:09.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9dt7x" for this suite.
Mar  9 16:30:15.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:30:15.500: INFO: namespace: e2e-tests-projected-9dt7x, resource: bindings, ignored listing per whitelist
Mar  9 16:30:15.532: INFO: namespace e2e-tests-projected-9dt7x deletion completed in 6.049215939s

• [SLOW TEST:8.109 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:30:15.533: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:30:15.550260      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9ea0adb5-4288-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:30:15.588: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-n576w" to be "success or failure"
Mar  9 16:30:15.589: INFO: Pod "pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.598594ms
Mar  9 16:30:17.594: INFO: Pod "pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006460177s
STEP: Saw pod success
Mar  9 16:30:17.594: INFO: Pod "pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:30:17.595: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:30:17.603: INFO: Waiting for pod pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:30:17.604: INFO: Pod pod-projected-configmaps-9ea0e920-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:30:17.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n576w" for this suite.
Mar  9 16:30:23.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:30:23.659: INFO: namespace: e2e-tests-projected-n576w, resource: bindings, ignored listing per whitelist
Mar  9 16:30:23.664: INFO: namespace e2e-tests-projected-n576w deletion completed in 6.053198749s

• [SLOW TEST:8.131 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:30:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:30:23.681707      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  9 16:30:23.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:24.041: INFO: stderr: ""
Mar  9 16:30:24.041: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 16:30:24.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:24.140: INFO: stderr: ""
Mar  9 16:30:24.140: INFO: stdout: "update-demo-nautilus-6wx2r update-demo-nautilus-fk6pq "
Mar  9 16:30:24.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6wx2r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:24.214: INFO: stderr: ""
Mar  9 16:30:24.214: INFO: stdout: ""
Mar  9 16:30:24.214: INFO: update-demo-nautilus-6wx2r is created but not running
Mar  9 16:30:29.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.294: INFO: stderr: ""
Mar  9 16:30:29.294: INFO: stdout: "update-demo-nautilus-6wx2r update-demo-nautilus-fk6pq "
Mar  9 16:30:29.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6wx2r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.369: INFO: stderr: ""
Mar  9 16:30:29.369: INFO: stdout: "true"
Mar  9 16:30:29.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6wx2r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.446: INFO: stderr: ""
Mar  9 16:30:29.446: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 16:30:29.446: INFO: validating pod update-demo-nautilus-6wx2r
Mar  9 16:30:29.452: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 16:30:29.452: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 16:30:29.452: INFO: update-demo-nautilus-6wx2r is verified up and running
Mar  9 16:30:29.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-fk6pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.527: INFO: stderr: ""
Mar  9 16:30:29.527: INFO: stdout: "true"
Mar  9 16:30:29.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-fk6pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.603: INFO: stderr: ""
Mar  9 16:30:29.603: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 16:30:29.603: INFO: validating pod update-demo-nautilus-fk6pq
Mar  9 16:30:29.606: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 16:30:29.606: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 16:30:29.606: INFO: update-demo-nautilus-fk6pq is verified up and running
STEP: using delete to clean up resources
Mar  9 16:30:29.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.681: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 16:30:29.681: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  9 16:30:29.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-xj88x'
Mar  9 16:30:29.803: INFO: stderr: "No resources found.\n"
Mar  9 16:30:29.803: INFO: stdout: ""
Mar  9 16:30:29.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -l name=update-demo --namespace=e2e-tests-kubectl-xj88x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 16:30:29.884: INFO: stderr: ""
Mar  9 16:30:29.884: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:30:29.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xj88x" for this suite.
Mar  9 16:30:51.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:30:51.927: INFO: namespace: e2e-tests-kubectl-xj88x, resource: bindings, ignored listing per whitelist
Mar  9 16:30:51.937: INFO: namespace e2e-tests-kubectl-xj88x deletion completed in 22.050928252s

• [SLOW TEST:28.273 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:30:51.937: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:30:51.955039      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b451bcf1-4288-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:30:51.980: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-2bwjp" to be "success or failure"
Mar  9 16:30:51.984: INFO: Pod "pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.456261ms
Mar  9 16:30:53.986: INFO: Pod "pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005230536s
STEP: Saw pod success
Mar  9 16:30:53.986: INFO: Pod "pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:30:53.987: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:30:53.997: INFO: Waiting for pod pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:30:53.999: INFO: Pod pod-projected-configmaps-b451f88d-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:30:53.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2bwjp" for this suite.
Mar  9 16:31:00.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:31:00.020: INFO: namespace: e2e-tests-projected-2bwjp, resource: bindings, ignored listing per whitelist
Mar  9 16:31:00.048: INFO: namespace e2e-tests-projected-2bwjp deletion completed in 6.047246894s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:31:00.048: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:31:00.065665      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:31:00.088: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-5zvkf" to be "success or failure"
Mar  9 16:31:00.092: INFO: Pod "downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.674598ms
Mar  9 16:31:02.094: INFO: Pod "downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005569768s
STEP: Saw pod success
Mar  9 16:31:02.094: INFO: Pod "downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:31:02.095: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:31:02.105: INFO: Waiting for pod downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:31:02.107: INFO: Pod downwardapi-volume-b927122a-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:31:02.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5zvkf" for this suite.
Mar  9 16:31:08.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:31:08.150: INFO: namespace: e2e-tests-downward-api-5zvkf, resource: bindings, ignored listing per whitelist
Mar  9 16:31:08.157: INFO: namespace e2e-tests-downward-api-5zvkf deletion completed in 6.048726541s

• [SLOW TEST:8.109 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:31:08.157: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:31:08.174707      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:31:08.198: INFO: (0) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.05112ms)
Mar  9 16:31:08.199: INFO: (1) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.568922ms)
Mar  9 16:31:08.201: INFO: (2) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.608533ms)
Mar  9 16:31:08.203: INFO: (3) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.519122ms)
Mar  9 16:31:08.204: INFO: (4) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.569819ms)
Mar  9 16:31:08.206: INFO: (5) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.509552ms)
Mar  9 16:31:08.207: INFO: (6) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.50021ms)
Mar  9 16:31:08.209: INFO: (7) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.480898ms)
Mar  9 16:31:08.210: INFO: (8) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.526212ms)
Mar  9 16:31:08.212: INFO: (9) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.879716ms)
Mar  9 16:31:08.214: INFO: (10) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.57614ms)
Mar  9 16:31:08.216: INFO: (11) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.865102ms)
Mar  9 16:31:08.217: INFO: (12) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.587748ms)
Mar  9 16:31:08.219: INFO: (13) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.88213ms)
Mar  9 16:31:08.222: INFO: (14) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.778219ms)
Mar  9 16:31:08.224: INFO: (15) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.68048ms)
Mar  9 16:31:08.225: INFO: (16) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.675768ms)
Mar  9 16:31:08.227: INFO: (17) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.617959ms)
Mar  9 16:31:08.228: INFO: (18) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.544967ms)
Mar  9 16:31:08.234: INFO: (19) /api/v1/nodes/ip-192-168-70-73.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.279911ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:31:08.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g4jmh" for this suite.
Mar  9 16:31:14.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:31:14.275: INFO: namespace: e2e-tests-proxy-g4jmh, resource: bindings, ignored listing per whitelist
Mar  9 16:31:14.281: INFO: namespace e2e-tests-proxy-g4jmh deletion completed in 6.045988263s

• [SLOW TEST:6.124 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:31:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:31:14.299619      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  9 16:31:18.336: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.336: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.435: INFO: Exec stderr: ""
Mar  9 16:31:18.435: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.435: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.546: INFO: Exec stderr: ""
Mar  9 16:31:18.546: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.546: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.631: INFO: Exec stderr: ""
Mar  9 16:31:18.631: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.631: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.715: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  9 16:31:18.715: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.715: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.793: INFO: Exec stderr: ""
Mar  9 16:31:18.793: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.793: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.875: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  9 16:31:18.875: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.875: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:18.954: INFO: Exec stderr: ""
Mar  9 16:31:18.954: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:18.954: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:19.047: INFO: Exec stderr: ""
Mar  9 16:31:19.047: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:19.047: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:19.136: INFO: Exec stderr: ""
Mar  9 16:31:19.136: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4z2bj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:31:19.136: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:31:19.212: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:31:19.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-4z2bj" for this suite.
Mar  9 16:31:57.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:31:57.233: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-4z2bj, resource: bindings, ignored listing per whitelist
Mar  9 16:31:57.262: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-4z2bj deletion completed in 38.048032399s

• [SLOW TEST:42.981 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:31:57.262: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:31:57.280273      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  9 16:31:59.816: INFO: Successfully updated pod "pod-update-db415780-4288-11e9-923b-2eb43f2b540f"
STEP: verifying the updated pod is in kubernetes
Mar  9 16:31:59.818: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:31:59.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5h9s8" for this suite.
Mar  9 16:32:21.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:32:21.844: INFO: namespace: e2e-tests-pods-5h9s8, resource: bindings, ignored listing per whitelist
Mar  9 16:32:21.873: INFO: namespace e2e-tests-pods-5h9s8 deletion completed in 22.052088338s

• [SLOW TEST:24.611 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:32:21.873: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:32:21.890592      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e9ecb9da-4288-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:32:21.914: INFO: Waiting up to 5m0s for pod "pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-fthzp" to be "success or failure"
Mar  9 16:32:21.918: INFO: Pod "pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.734833ms
Mar  9 16:32:23.919: INFO: Pod "pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005161325s
STEP: Saw pod success
Mar  9 16:32:23.919: INFO: Pod "pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:32:23.920: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:32:23.929: INFO: Waiting for pod pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:32:23.931: INFO: Pod pod-configmaps-e9ecf11f-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:32:23.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fthzp" for this suite.
Mar  9 16:32:29.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:32:29.952: INFO: namespace: e2e-tests-configmap-fthzp, resource: bindings, ignored listing per whitelist
Mar  9 16:32:29.981: INFO: namespace e2e-tests-configmap-fthzp deletion completed in 6.049112722s

• [SLOW TEST:8.108 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:32:29.981: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:32:29.999033      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-m7kbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m7kbw to expose endpoints map[]
Mar  9 16:32:30.022: INFO: Get endpoints failed (2.214334ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar  9 16:32:31.024: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m7kbw exposes endpoints map[] (1.003864305s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-m7kbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m7kbw to expose endpoints map[pod1:[100]]
Mar  9 16:32:33.038: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m7kbw exposes endpoints map[pod1:[100]] (2.009883961s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-m7kbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m7kbw to expose endpoints map[pod1:[100] pod2:[101]]
Mar  9 16:32:35.055: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m7kbw exposes endpoints map[pod2:[101] pod1:[100]] (2.013512359s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-m7kbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m7kbw to expose endpoints map[pod2:[101]]
Mar  9 16:32:35.065: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m7kbw exposes endpoints map[pod2:[101]] (5.446937ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-m7kbw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m7kbw to expose endpoints map[]
Mar  9 16:32:35.073: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m7kbw exposes endpoints map[] (2.189384ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:32:35.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-m7kbw" for this suite.
Mar  9 16:32:41.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:32:41.133: INFO: namespace: e2e-tests-services-m7kbw, resource: bindings, ignored listing per whitelist
Mar  9 16:32:41.155: INFO: namespace e2e-tests-services-m7kbw deletion completed in 6.065212005s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:11.173 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:32:41.155: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:32:41.172920      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f56af158-4288-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:32:41.197: INFO: Waiting up to 5m0s for pod "pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-j6x64" to be "success or failure"
Mar  9 16:32:41.200: INFO: Pod "pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.903125ms
Mar  9 16:32:43.202: INFO: Pod "pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00462429s
STEP: Saw pod success
Mar  9 16:32:43.202: INFO: Pod "pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:32:43.203: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:32:43.212: INFO: Waiting for pod pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:32:43.213: INFO: Pod pod-secrets-f56b312d-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:32:43.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j6x64" for this suite.
Mar  9 16:32:49.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:32:49.241: INFO: namespace: e2e-tests-secrets-j6x64, resource: bindings, ignored listing per whitelist
Mar  9 16:32:49.264: INFO: namespace e2e-tests-secrets-j6x64 deletion completed in 6.048102079s

• [SLOW TEST:8.109 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:32:49.264: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:32:49.281096      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fa3fe7b2-4288-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:32:49.304: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-w7wm7" to be "success or failure"
Mar  9 16:32:49.308: INFO: Pod "pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.087246ms
Mar  9 16:32:51.309: INFO: Pod "pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004592128s
STEP: Saw pod success
Mar  9 16:32:51.309: INFO: Pod "pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:32:51.310: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:32:51.320: INFO: Waiting for pod pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:32:51.321: INFO: Pod pod-projected-configmaps-fa402769-4288-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:32:51.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w7wm7" for this suite.
Mar  9 16:32:57.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:32:57.370: INFO: namespace: e2e-tests-projected-w7wm7, resource: bindings, ignored listing per whitelist
Mar  9 16:32:57.371: INFO: namespace e2e-tests-projected-w7wm7 deletion completed in 6.048419093s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:32:57.371: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:32:57.389007      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar  9 16:32:57.916: INFO: created pod pod-service-account-defaultsa
Mar  9 16:32:57.916: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  9 16:32:57.923: INFO: created pod pod-service-account-mountsa
Mar  9 16:32:57.923: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  9 16:32:57.930: INFO: created pod pod-service-account-nomountsa
Mar  9 16:32:57.930: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  9 16:32:57.936: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  9 16:32:57.936: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  9 16:32:57.944: INFO: created pod pod-service-account-mountsa-mountspec
Mar  9 16:32:57.944: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  9 16:32:57.949: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  9 16:32:57.949: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  9 16:32:57.954: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  9 16:32:57.954: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  9 16:32:57.958: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  9 16:32:57.958: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  9 16:32:57.964: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  9 16:32:57.964: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:32:57.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cfxkf" for this suite.
Mar  9 16:33:19.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:33:20.026: INFO: namespace: e2e-tests-svcaccounts-cfxkf, resource: bindings, ignored listing per whitelist
Mar  9 16:33:20.026: INFO: namespace e2e-tests-svcaccounts-cfxkf deletion completed in 22.057354011s

• [SLOW TEST:22.655 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:33:20.026: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:33:20.043969      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  9 16:33:22.584: INFO: Successfully updated pod "labelsupdate0c965583-4289-11e9-923b-2eb43f2b540f"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:33:26.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-245rm" for this suite.
Mar  9 16:33:48.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:33:48.637: INFO: namespace: e2e-tests-projected-245rm, resource: bindings, ignored listing per whitelist
Mar  9 16:33:48.658: INFO: namespace e2e-tests-projected-245rm deletion completed in 22.063327735s

• [SLOW TEST:28.632 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:33:48.658: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:33:48.675025      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:33:48.694: INFO: Creating deployment "test-recreate-deployment"
Mar  9 16:33:48.696: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  9 16:33:48.701: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar  9 16:33:50.704: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  9 16:33:50.705: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  9 16:33:50.708: INFO: Updating deployment test-recreate-deployment
Mar  9 16:33:50.708: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  9 16:33:50.760: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-qx2zr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qx2zr/deployments/test-recreate-deployment,UID:1da6ffc1-4289-11e9-9882-02b03e914f30,ResourceVersion:10469,Generation:2,CreationTimestamp:2019-03-09 16:33:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-09 16:33:50 +0000 UTC 2019-03-09 16:33:50 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-09 16:33:50 +0000 UTC 2019-03-09 16:33:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar  9 16:33:50.762: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-qx2zr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qx2zr/replicasets/test-recreate-deployment-7cf749666b,UID:1ede223e-4289-11e9-9882-02b03e914f30,ResourceVersion:10467,Generation:1,CreationTimestamp:2019-03-09 16:33:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1da6ffc1-4289-11e9-9882-02b03e914f30 0xc4213f96d7 0xc4213f96d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  9 16:33:50.762: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  9 16:33:50.762: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-qx2zr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qx2zr/replicasets/test-recreate-deployment-79f694ff59,UID:1da7ed06-4289-11e9-9882-02b03e914f30,ResourceVersion:10457,Generation:2,CreationTimestamp:2019-03-09 16:33:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1da6ffc1-4289-11e9-9882-02b03e914f30 0xc4213f9617 0xc4213f9618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  9 16:33:50.763: INFO: Pod "test-recreate-deployment-7cf749666b-x24z7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-x24z7,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-qx2zr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qx2zr/pods/test-recreate-deployment-7cf749666b-x24z7,UID:1ede8707-4289-11e9-9882-02b03e914f30,ResourceVersion:10468,Generation:0,CreationTimestamp:2019-03-09 16:33:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 1ede223e-4289-11e9-9882-02b03e914f30 0xc4217003d7 0xc4217003d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v5dfn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v5dfn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-v5dfn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421700440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421700460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:33:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:33:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:33:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:33:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:,StartTime:2019-03-09 16:33:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:33:50.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qx2zr" for this suite.
Mar  9 16:33:56.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:33:56.789: INFO: namespace: e2e-tests-deployment-qx2zr, resource: bindings, ignored listing per whitelist
Mar  9 16:33:56.816: INFO: namespace e2e-tests-deployment-qx2zr deletion completed in 6.050849905s

• [SLOW TEST:8.158 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:33:56.816: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:33:56.833153      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:33:56.858: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-t4qt4" to be "success or failure"
Mar  9 16:33:56.865: INFO: Pod "downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.704659ms
Mar  9 16:33:58.867: INFO: Pod "downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009379554s
STEP: Saw pod success
Mar  9 16:33:58.867: INFO: Pod "downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:33:58.868: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:33:58.878: INFO: Waiting for pod downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:33:58.879: INFO: Pod downwardapi-volume-22838900-4289-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:33:58.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t4qt4" for this suite.
Mar  9 16:34:04.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:34:04.943: INFO: namespace: e2e-tests-downward-api-t4qt4, resource: bindings, ignored listing per whitelist
Mar  9 16:34:04.943: INFO: namespace e2e-tests-downward-api-t4qt4 deletion completed in 6.062394262s

• [SLOW TEST:8.127 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:34:04.943: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:34:04.961345      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  9 16:34:04.984: INFO: Waiting up to 5m0s for pod "downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-scfwb" to be "success or failure"
Mar  9 16:34:04.987: INFO: Pod "downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031743ms
Mar  9 16:34:06.989: INFO: Pod "downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004893801s
STEP: Saw pod success
Mar  9 16:34:06.989: INFO: Pod "downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:34:06.991: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 16:34:07.000: INFO: Waiting for pod downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:34:07.002: INFO: Pod downward-api-275c00c8-4289-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:34:07.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-scfwb" for this suite.
Mar  9 16:34:13.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:34:13.018: INFO: namespace: e2e-tests-downward-api-scfwb, resource: bindings, ignored listing per whitelist
Mar  9 16:34:13.049: INFO: namespace e2e-tests-downward-api-scfwb deletion completed in 6.045820831s

• [SLOW TEST:8.105 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:34:13.049: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:34:13.066046      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  9 16:36:55.110: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:36:55.111: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:36:57.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:36:57.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:36:59.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:36:59.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:01.112: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:01.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:03.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:03.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:05.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:05.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:07.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:07.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:09.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:09.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:11.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:11.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:13.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:13.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:15.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:15.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:17.112: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:17.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:19.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:19.113: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 16:37:21.111: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 16:37:21.113: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:37:21.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-nlkkh" for this suite.
Mar  9 16:37:43.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:37:43.134: INFO: namespace: e2e-tests-container-lifecycle-hook-nlkkh, resource: bindings, ignored listing per whitelist
Mar  9 16:37:43.166: INFO: namespace e2e-tests-container-lifecycle-hook-nlkkh deletion completed in 22.051033601s

• [SLOW TEST:210.117 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:37:43.166: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:37:43.183663      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:37:43.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-4f98q" to be "success or failure"
Mar  9 16:37:43.212: INFO: Pod "downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.362156ms
Mar  9 16:37:45.213: INFO: Pod "downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00596331s
STEP: Saw pod success
Mar  9 16:37:45.213: INFO: Pod "downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:37:45.215: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:37:45.225: INFO: Waiting for pod downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:37:45.226: INFO: Pod downwardapi-volume-a96e21b5-4289-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:37:45.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4f98q" for this suite.
Mar  9 16:37:51.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:37:51.260: INFO: namespace: e2e-tests-downward-api-4f98q, resource: bindings, ignored listing per whitelist
Mar  9 16:37:51.277: INFO: namespace e2e-tests-downward-api-4f98q deletion completed in 6.048507396s

• [SLOW TEST:8.111 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:37:51.278: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:37:51.295300      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  9 16:37:51.313: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 16:37:51.316: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 16:37:51.317: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-70-73.us-west-2.compute.internal before test
Mar  9 16:37:51.321: INFO: pvc-operator-7c7766d9c6-xhzz8 from pipeline-system started at 2019-03-09 15:45:51 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container pvc-operator ready: true, restart count 0
Mar  9 16:37:51.321: INFO: hpa-operator-metrics-server-d98ff747d-mkt2v from pipeline-system started at 2019-03-09 15:45:50 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container metrics-server ready: true, restart count 0
Mar  9 16:37:51.321: INFO: hpa-operator-hpa-operator-5587f4b46c-tz255 from pipeline-system started at 2019-03-09 15:45:50 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container hpa-operator ready: true, restart count 0
Mar  9 16:37:51.321: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-09 15:52:59 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 16:37:51.321: INFO: tiller-deploy-865b88d89-pvn7z from kube-system started at 2019-03-09 15:44:30 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container tiller ready: true, restart count 0
Mar  9 16:37:51.321: INFO: kube-proxy-nxxjq from kube-system started at 2019-03-09 15:44:30 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 16:37:51.321: INFO: dns-external-dns-56d66c8bc-ct9md from pipeline-system started at 2019-03-09 15:45:42 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container external-dns ready: true, restart count 0
Mar  9 16:37:51.321: INFO: dashboard-kubernetes-dashboard-6469dff698-q4vtx from pipeline-system started at 2019-03-09 15:45:46 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  9 16:37:51.321: INFO: npls-nodepool-labels-operator-64d58d86f-cq2sp from pipeline-system started at 2019-03-09 15:45:33 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container nodepool-labels-operator ready: true, restart count 0
Mar  9 16:37:51.321: INFO: ingress-traefik-6db6c64c49-lfg8d from pipeline-system started at 2019-03-09 15:45:44 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container ingress-traefik ready: true, restart count 0
Mar  9 16:37:51.321: INFO: hpa-operator-kube-metrics-adapter-bf9dd978d-5jksc from pipeline-system started at 2019-03-09 15:45:49 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container kube-metrics-adapter ready: true, restart count 0
Mar  9 16:37:51.321: INFO: weave-net-ft8zc from kube-system started at 2019-03-09 15:44:30 +0000 UTC (2 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container weave ready: true, restart count 1
Mar  9 16:37:51.321: INFO: 	Container weave-npc ready: true, restart count 0
Mar  9 16:37:51.321: INFO: autoscaler-aws-cluster-autoscaler-d9dcf4d85-69zpr from kube-system started at 2019-03-09 15:45:48 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container aws-cluster-autoscaler ready: true, restart count 0
Mar  9 16:37:51.321: INFO: ith-instance-termination-handler-mdlnc from pipeline-system started at 2019-03-09 15:45:53 +0000 UTC (1 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container instance-termination-handler ready: true, restart count 0
Mar  9 16:37:51.321: INFO: sonobuoy-systemd-logs-daemon-set-5a60dbf0cc4b44aa-9dhqt from heptio-sonobuoy started at 2019-03-09 15:53:02 +0000 UTC (2 container statuses recorded)
Mar  9 16:37:51.321: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  9 16:37:51.321: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-af7881d4-4289-11e9-923b-2eb43f2b540f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-af7881d4-4289-11e9-923b-2eb43f2b540f off the node ip-192-168-70-73.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-af7881d4-4289-11e9-923b-2eb43f2b540f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:37:55.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-n5lzl" for this suite.
Mar  9 16:38:03.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:38:03.406: INFO: namespace: e2e-tests-sched-pred-n5lzl, resource: bindings, ignored listing per whitelist
Mar  9 16:38:03.412: INFO: namespace e2e-tests-sched-pred-n5lzl deletion completed in 8.04880468s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.134 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:38:03.412: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:38:03.430025      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0309 16:38:13.463642      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 16:38:13.463: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:38:13.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fgvmr" for this suite.
Mar  9 16:38:19.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:38:19.493: INFO: namespace: e2e-tests-gc-fgvmr, resource: bindings, ignored listing per whitelist
Mar  9 16:38:19.513: INFO: namespace e2e-tests-gc-fgvmr deletion completed in 6.048197187s

• [SLOW TEST:16.101 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:38:19.513: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:38:19.530912      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  9 16:38:22.068: INFO: Successfully updated pod "annotationupdatebf184214-4289-11e9-923b-2eb43f2b540f"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:38:26.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wjdzz" for this suite.
Mar  9 16:38:48.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:38:48.108: INFO: namespace: e2e-tests-projected-wjdzz, resource: bindings, ignored listing per whitelist
Mar  9 16:38:48.126: INFO: namespace e2e-tests-projected-wjdzz deletion completed in 22.046772776s

• [SLOW TEST:28.613 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:38:48.126: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:38:48.143668      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar  9 16:38:48.166: INFO: Waiting up to 5m0s for pod "client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-containers-wx2c7" to be "success or failure"
Mar  9 16:38:48.169: INFO: Pod "client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.00654ms
Mar  9 16:38:50.171: INFO: Pod "client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004739369s
Mar  9 16:38:52.172: INFO: Pod "client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006510613s
STEP: Saw pod success
Mar  9 16:38:52.172: INFO: Pod "client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:38:52.174: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:38:52.183: INFO: Waiting for pod client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:38:52.184: INFO: Pod client-containers-d02629f0-4289-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:38:52.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wx2c7" for this suite.
Mar  9 16:38:58.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:38:58.205: INFO: namespace: e2e-tests-containers-wx2c7, resource: bindings, ignored listing per whitelist
Mar  9 16:38:58.237: INFO: namespace e2e-tests-containers-wx2c7 deletion completed in 6.051354939s

• [SLOW TEST:10.111 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:38:58.237: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:38:58.255399      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:38:58.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-7fn6v" to be "success or failure"
Mar  9 16:38:58.283: INFO: Pod "downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.173874ms
Mar  9 16:39:00.285: INFO: Pod "downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006922279s
STEP: Saw pod success
Mar  9 16:39:00.285: INFO: Pod "downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:39:00.286: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:39:00.296: INFO: Waiting for pod downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:39:00.297: INFO: Pod downwardapi-volume-d62d2ba3-4289-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:39:00.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7fn6v" for this suite.
Mar  9 16:39:06.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:39:06.333: INFO: namespace: e2e-tests-downward-api-7fn6v, resource: bindings, ignored listing per whitelist
Mar  9 16:39:06.346: INFO: namespace e2e-tests-downward-api-7fn6v deletion completed in 6.048143911s

• [SLOW TEST:8.109 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:39:06.347: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:39:06.363870      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0309 16:39:07.407919      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 16:39:07.407: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:39:07.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zq48g" for this suite.
Mar  9 16:39:13.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:39:13.447: INFO: namespace: e2e-tests-gc-zq48g, resource: bindings, ignored listing per whitelist
Mar  9 16:39:13.462: INFO: namespace e2e-tests-gc-zq48g deletion completed in 6.053015144s

• [SLOW TEST:7.115 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:39:13.462: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:39:13.479873      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  9 16:39:16.017: INFO: Successfully updated pod "annotationupdatedf402b95-4289-11e9-923b-2eb43f2b540f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:39:20.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xhbtm" for this suite.
Mar  9 16:39:42.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:39:42.053: INFO: namespace: e2e-tests-downward-api-xhbtm, resource: bindings, ignored listing per whitelist
Mar  9 16:39:42.080: INFO: namespace e2e-tests-downward-api-xhbtm deletion completed in 22.051857991s

• [SLOW TEST:28.618 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:39:42.080: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:39:42.109450      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  9 16:39:42.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-qx4fv'
Mar  9 16:39:42.332: INFO: stderr: ""
Mar  9 16:39:42.332: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  9 16:39:43.334: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:39:43.334: INFO: Found 0 / 1
Mar  9 16:39:44.334: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:39:44.334: INFO: Found 1 / 1
Mar  9 16:39:44.334: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  9 16:39:44.336: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:39:44.336: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  9 16:39:44.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 patch pod redis-master-h5fms --namespace=e2e-tests-kubectl-qx4fv -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  9 16:39:44.417: INFO: stderr: ""
Mar  9 16:39:44.417: INFO: stdout: "pod/redis-master-h5fms patched\n"
STEP: checking annotations
Mar  9 16:39:44.418: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:39:44.418: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:39:44.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qx4fv" for this suite.
Mar  9 16:40:06.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:40:06.476: INFO: namespace: e2e-tests-kubectl-qx4fv, resource: bindings, ignored listing per whitelist
Mar  9 16:40:06.479: INFO: namespace e2e-tests-kubectl-qx4fv deletion completed in 22.05972003s

• [SLOW TEST:24.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:40:06.479: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:40:06.506458      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-fedc3ac9-4289-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-fedc3ac9-4289-11e9-923b-2eb43f2b540f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:40:10.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r9ddv" for this suite.
Mar  9 16:40:32.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:40:32.616: INFO: namespace: e2e-tests-configmap-r9ddv, resource: bindings, ignored listing per whitelist
Mar  9 16:40:32.620: INFO: namespace e2e-tests-configmap-r9ddv deletion completed in 22.047468269s

• [SLOW TEST:26.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:40:32.620: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:40:32.637232      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0e6e9bbd-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:40:32.662: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-l4f8x" to be "success or failure"
Mar  9 16:40:32.664: INFO: Pod "pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.734794ms
Mar  9 16:40:34.666: INFO: Pod "pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004459772s
STEP: Saw pod success
Mar  9 16:40:34.666: INFO: Pod "pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:40:34.667: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:40:34.676: INFO: Waiting for pod pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:40:34.678: INFO: Pod pod-projected-configmaps-0e6ed614-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:40:34.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l4f8x" for this suite.
Mar  9 16:40:40.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:40:40.717: INFO: namespace: e2e-tests-projected-l4f8x, resource: bindings, ignored listing per whitelist
Mar  9 16:40:40.727: INFO: namespace e2e-tests-projected-l4f8x deletion completed in 6.047479274s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:40:40.727: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:40:40.744745      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar  9 16:40:40.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:41.009: INFO: stderr: ""
Mar  9 16:40:41.009: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 16:40:41.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:41.107: INFO: stderr: ""
Mar  9 16:40:41.107: INFO: stdout: "update-demo-nautilus-gn8jg update-demo-nautilus-krlkx "
Mar  9 16:40:41.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-gn8jg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:41.182: INFO: stderr: ""
Mar  9 16:40:41.182: INFO: stdout: ""
Mar  9 16:40:41.182: INFO: update-demo-nautilus-gn8jg is created but not running
Mar  9 16:40:46.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:46.265: INFO: stderr: ""
Mar  9 16:40:46.265: INFO: stdout: "update-demo-nautilus-gn8jg update-demo-nautilus-krlkx "
Mar  9 16:40:46.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-gn8jg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:46.341: INFO: stderr: ""
Mar  9 16:40:46.341: INFO: stdout: "true"
Mar  9 16:40:46.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-gn8jg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:46.415: INFO: stderr: ""
Mar  9 16:40:46.415: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 16:40:46.415: INFO: validating pod update-demo-nautilus-gn8jg
Mar  9 16:40:46.418: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 16:40:46.418: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 16:40:46.418: INFO: update-demo-nautilus-gn8jg is verified up and running
Mar  9 16:40:46.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-krlkx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:46.492: INFO: stderr: ""
Mar  9 16:40:46.492: INFO: stdout: "true"
Mar  9 16:40:46.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-krlkx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:40:46.568: INFO: stderr: ""
Mar  9 16:40:46.568: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 16:40:46.568: INFO: validating pod update-demo-nautilus-krlkx
Mar  9 16:40:46.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 16:40:46.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 16:40:46.571: INFO: update-demo-nautilus-krlkx is verified up and running
STEP: rolling-update to new replication controller
Mar  9 16:40:46.572: INFO: scanned /root for discovery docs: <nil>
Mar  9 16:40:46.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:41:06.925: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  9 16:41:06.925: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 16:41:06.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:41:07.009: INFO: stderr: ""
Mar  9 16:41:07.009: INFO: stdout: "update-demo-kitten-2mp9d update-demo-kitten-gxp29 "
Mar  9 16:41:07.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-kitten-2mp9d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:41:07.087: INFO: stderr: ""
Mar  9 16:41:07.087: INFO: stdout: "true"
Mar  9 16:41:07.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-kitten-2mp9d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:41:07.163: INFO: stderr: ""
Mar  9 16:41:07.163: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  9 16:41:07.163: INFO: validating pod update-demo-kitten-2mp9d
Mar  9 16:41:07.166: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  9 16:41:07.166: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  9 16:41:07.166: INFO: update-demo-kitten-2mp9d is verified up and running
Mar  9 16:41:07.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-kitten-gxp29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:41:07.241: INFO: stderr: ""
Mar  9 16:41:07.241: INFO: stdout: "true"
Mar  9 16:41:07.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-kitten-gxp29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sn99w'
Mar  9 16:41:07.314: INFO: stderr: ""
Mar  9 16:41:07.314: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  9 16:41:07.314: INFO: validating pod update-demo-kitten-gxp29
Mar  9 16:41:07.317: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  9 16:41:07.317: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  9 16:41:07.317: INFO: update-demo-kitten-gxp29 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:41:07.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sn99w" for this suite.
Mar  9 16:41:29.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:41:29.367: INFO: namespace: e2e-tests-kubectl-sn99w, resource: bindings, ignored listing per whitelist
Mar  9 16:41:29.369: INFO: namespace e2e-tests-kubectl-sn99w deletion completed in 22.050325736s

• [SLOW TEST:48.642 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:41:29.369: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:41:29.387300      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  9 16:41:29.411: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:41:33.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-nzbgw" for this suite.
Mar  9 16:41:39.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:41:39.072: INFO: namespace: e2e-tests-init-container-nzbgw, resource: bindings, ignored listing per whitelist
Mar  9 16:41:39.096: INFO: namespace e2e-tests-init-container-nzbgw deletion completed in 6.050588744s

• [SLOW TEST:9.727 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:41:39.097: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:41:39.114407      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:41:39.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-7v8zg" to be "success or failure"
Mar  9 16:41:39.141: INFO: Pod "downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.958141ms
Mar  9 16:41:41.143: INFO: Pod "downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005471341s
STEP: Saw pod success
Mar  9 16:41:41.143: INFO: Pod "downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:41:41.144: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:41:41.155: INFO: Waiting for pod downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:41:41.157: INFO: Pod downwardapi-volume-360e68ad-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:41:41.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7v8zg" for this suite.
Mar  9 16:41:47.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:41:47.205: INFO: namespace: e2e-tests-downward-api-7v8zg, resource: bindings, ignored listing per whitelist
Mar  9 16:41:47.210: INFO: namespace e2e-tests-downward-api-7v8zg deletion completed in 6.051290411s

• [SLOW TEST:8.113 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:41:47.210: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:41:47.227231      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3ae4195e-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:41:47.251: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-dbflt" to be "success or failure"
Mar  9 16:41:47.256: INFO: Pod "pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.637049ms
Mar  9 16:41:49.257: INFO: Pod "pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00622003s
STEP: Saw pod success
Mar  9 16:41:49.257: INFO: Pod "pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:41:49.258: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:41:49.268: INFO: Waiting for pod pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:41:49.269: INFO: Pod pod-projected-secrets-3ae45c2f-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:41:49.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dbflt" for this suite.
Mar  9 16:41:55.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:41:55.291: INFO: namespace: e2e-tests-projected-dbflt, resource: bindings, ignored listing per whitelist
Mar  9 16:41:55.320: INFO: namespace e2e-tests-projected-dbflt deletion completed in 6.048934477s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:41:55.320: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:41:55.337479      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ht7kb
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 16:41:55.354: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 16:42:15.384: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.20.192.15 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ht7kb PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:42:15.384: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:42:16.455: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:42:16.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ht7kb" for this suite.
Mar  9 16:42:38.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:42:38.474: INFO: namespace: e2e-tests-pod-network-test-ht7kb, resource: bindings, ignored listing per whitelist
Mar  9 16:42:38.506: INFO: namespace e2e-tests-pod-network-test-ht7kb deletion completed in 22.049348268s

• [SLOW TEST:43.186 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:42:38.506: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:42:38.523526      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5977481b-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:42:38.547: INFO: Waiting up to 5m0s for pod "pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-8hvtd" to be "success or failure"
Mar  9 16:42:38.551: INFO: Pod "pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.146398ms
Mar  9 16:42:40.553: INFO: Pod "pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005858992s
STEP: Saw pod success
Mar  9 16:42:40.553: INFO: Pod "pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:42:40.554: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:42:40.565: INFO: Waiting for pod pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:42:40.566: INFO: Pod pod-secrets-597781b2-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:42:40.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8hvtd" for this suite.
Mar  9 16:42:46.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:42:46.582: INFO: namespace: e2e-tests-secrets-8hvtd, resource: bindings, ignored listing per whitelist
Mar  9 16:42:46.620: INFO: namespace e2e-tests-secrets-8hvtd deletion completed in 6.052276592s

• [SLOW TEST:8.114 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:42:46.620: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:42:46.637680      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:42:46.654: INFO: Creating ReplicaSet my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f
Mar  9 16:42:46.658: INFO: Pod name my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f: Found 0 pods out of 1
Mar  9 16:42:51.660: INFO: Pod name my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f: Found 1 pods out of 1
Mar  9 16:42:51.660: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f" is running
Mar  9 16:42:51.661: INFO: Pod "my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f-fbg4d" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:42:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:42:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:42:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:42:46 +0000 UTC Reason: Message:}])
Mar  9 16:42:51.661: INFO: Trying to dial the pod
Mar  9 16:42:56.667: INFO: Controller my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f: Got expected result from replica 1 [my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f-fbg4d]: "my-hostname-basic-5e4d3440-428a-11e9-923b-2eb43f2b540f-fbg4d", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:42:56.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9tdhl" for this suite.
Mar  9 16:43:02.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:43:02.681: INFO: namespace: e2e-tests-replicaset-9tdhl, resource: bindings, ignored listing per whitelist
Mar  9 16:43:02.719: INFO: namespace e2e-tests-replicaset-9tdhl deletion completed in 6.050652089s

• [SLOW TEST:16.099 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:43:02.719: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:43:02.747743      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-67ea08f3-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:43:02.789: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-gct7b" to be "success or failure"
Mar  9 16:43:02.793: INFO: Pod "pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.409258ms
Mar  9 16:43:04.795: INFO: Pod "pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006132981s
STEP: Saw pod success
Mar  9 16:43:04.795: INFO: Pod "pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:43:04.796: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:43:04.806: INFO: Waiting for pod pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:43:04.807: INFO: Pod pod-projected-secrets-67ea5d94-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:43:04.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gct7b" for this suite.
Mar  9 16:43:10.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:43:10.826: INFO: namespace: e2e-tests-projected-gct7b, resource: bindings, ignored listing per whitelist
Mar  9 16:43:10.858: INFO: namespace e2e-tests-projected-gct7b deletion completed in 6.049240165s

• [SLOW TEST:8.139 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:43:10.858: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:43:10.888425      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  9 16:43:10.913: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dnhpw,SelfLink:/api/v1/namespaces/e2e-tests-watch-dnhpw/configmaps/e2e-watch-test-label-changed,UID:6cc1cee2-428a-11e9-9882-02b03e914f30,ResourceVersion:12388,Generation:0,CreationTimestamp:2019-03-09 16:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 16:43:10.913: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dnhpw,SelfLink:/api/v1/namespaces/e2e-tests-watch-dnhpw/configmaps/e2e-watch-test-label-changed,UID:6cc1cee2-428a-11e9-9882-02b03e914f30,ResourceVersion:12389,Generation:0,CreationTimestamp:2019-03-09 16:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  9 16:43:10.913: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dnhpw,SelfLink:/api/v1/namespaces/e2e-tests-watch-dnhpw/configmaps/e2e-watch-test-label-changed,UID:6cc1cee2-428a-11e9-9882-02b03e914f30,ResourceVersion:12390,Generation:0,CreationTimestamp:2019-03-09 16:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  9 16:43:20.923: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dnhpw,SelfLink:/api/v1/namespaces/e2e-tests-watch-dnhpw/configmaps/e2e-watch-test-label-changed,UID:6cc1cee2-428a-11e9-9882-02b03e914f30,ResourceVersion:12411,Generation:0,CreationTimestamp:2019-03-09 16:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 16:43:20.923: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dnhpw,SelfLink:/api/v1/namespaces/e2e-tests-watch-dnhpw/configmaps/e2e-watch-test-label-changed,UID:6cc1cee2-428a-11e9-9882-02b03e914f30,ResourceVersion:12412,Generation:0,CreationTimestamp:2019-03-09 16:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  9 16:43:20.923: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dnhpw,SelfLink:/api/v1/namespaces/e2e-tests-watch-dnhpw/configmaps/e2e-watch-test-label-changed,UID:6cc1cee2-428a-11e9-9882-02b03e914f30,ResourceVersion:12413,Generation:0,CreationTimestamp:2019-03-09 16:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:43:20.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dnhpw" for this suite.
Mar  9 16:43:26.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:43:26.949: INFO: namespace: e2e-tests-watch-dnhpw, resource: bindings, ignored listing per whitelist
Mar  9 16:43:26.975: INFO: namespace e2e-tests-watch-dnhpw deletion completed in 6.0500559s

• [SLOW TEST:16.117 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:43:26.975: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:43:26.992975      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-765b5c71-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:43:27.018: INFO: Waiting up to 5m0s for pod "pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-2dn5r" to be "success or failure"
Mar  9 16:43:27.021: INFO: Pod "pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.312893ms
Mar  9 16:43:29.023: INFO: Pod "pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004870069s
STEP: Saw pod success
Mar  9 16:43:29.023: INFO: Pod "pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:43:29.024: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:43:29.033: INFO: Waiting for pod pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:43:29.035: INFO: Pod pod-configmaps-765b9602-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:43:29.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2dn5r" for this suite.
Mar  9 16:43:35.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:43:35.060: INFO: namespace: e2e-tests-configmap-2dn5r, resource: bindings, ignored listing per whitelist
Mar  9 16:43:35.085: INFO: namespace e2e-tests-configmap-2dn5r deletion completed in 6.048558941s

• [SLOW TEST:8.110 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:43:35.085: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:43:35.103073      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:43:53.129: INFO: Container started at 2019-03-09 16:43:35 +0000 UTC, pod became ready at 2019-03-09 16:43:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:43:53.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7xsfh" for this suite.
Mar  9 16:44:15.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:44:15.171: INFO: namespace: e2e-tests-container-probe-7xsfh, resource: bindings, ignored listing per whitelist
Mar  9 16:44:15.181: INFO: namespace e2e-tests-container-probe-7xsfh deletion completed in 22.050321481s

• [SLOW TEST:40.096 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:44:15.181: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:44:15.198402      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f
Mar  9 16:44:15.222: INFO: Pod name my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f: Found 0 pods out of 1
Mar  9 16:44:20.224: INFO: Pod name my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f: Found 1 pods out of 1
Mar  9 16:44:20.224: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f" are running
Mar  9 16:44:20.225: INFO: Pod "my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f-jwgwp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:44:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:44:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:44:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-09 16:44:15 +0000 UTC Reason: Message:}])
Mar  9 16:44:20.225: INFO: Trying to dial the pod
Mar  9 16:44:25.231: INFO: Controller my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f: Got expected result from replica 1 [my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f-jwgwp]: "my-hostname-basic-9316e783-428a-11e9-923b-2eb43f2b540f-jwgwp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:44:25.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-4drmr" for this suite.
Mar  9 16:44:31.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:44:31.270: INFO: namespace: e2e-tests-replication-controller-4drmr, resource: bindings, ignored listing per whitelist
Mar  9 16:44:31.280: INFO: namespace e2e-tests-replication-controller-4drmr deletion completed in 6.048185531s

• [SLOW TEST:16.100 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:44:31.280: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:44:31.298551      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:44:33.342: INFO: Waiting up to 5m0s for pod "client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-pods-5lgd5" to be "success or failure"
Mar  9 16:44:33.346: INFO: Pod "client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.573369ms
Mar  9 16:44:35.348: INFO: Pod "client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006038054s
STEP: Saw pod success
Mar  9 16:44:35.348: INFO: Pod "client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:44:35.349: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f container env3cont: <nil>
STEP: delete the pod
Mar  9 16:44:35.359: INFO: Waiting for pod client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:44:35.360: INFO: Pod client-envvars-9de35db7-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:44:35.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5lgd5" for this suite.
Mar  9 16:45:13.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:45:13.402: INFO: namespace: e2e-tests-pods-5lgd5, resource: bindings, ignored listing per whitelist
Mar  9 16:45:13.411: INFO: namespace e2e-tests-pods-5lgd5 deletion completed in 38.049463783s

• [SLOW TEST:42.130 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:45:13.411: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:45:13.428941      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar  9 16:45:15.477: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:45:39.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5zbxs" for this suite.
Mar  9 16:45:45.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:45:45.543: INFO: namespace: e2e-tests-namespaces-5zbxs, resource: bindings, ignored listing per whitelist
Mar  9 16:45:45.551: INFO: namespace e2e-tests-namespaces-5zbxs deletion completed in 6.04957494s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hctpz" for this suite.
Mar  9 16:45:45.552: INFO: Namespace e2e-tests-nsdeletetest-hctpz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-t8lsf" for this suite.
Mar  9 16:45:51.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:45:51.572: INFO: namespace: e2e-tests-nsdeletetest-t8lsf, resource: bindings, ignored listing per whitelist
Mar  9 16:45:51.602: INFO: namespace e2e-tests-nsdeletetest-t8lsf deletion completed in 6.049785508s

• [SLOW TEST:38.191 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:45:51.602: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:45:51.619956      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  9 16:45:51.638: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:45:54.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-c4t57" for this suite.
Mar  9 16:46:16.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:46:16.573: INFO: namespace: e2e-tests-init-container-c4t57, resource: bindings, ignored listing per whitelist
Mar  9 16:46:16.573: INFO: namespace e2e-tests-init-container-c4t57 deletion completed in 22.048506635s

• [SLOW TEST:24.971 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:46:16.573: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:46:16.590372      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:46:16.609: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:46:17.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-82g5f" for this suite.
Mar  9 16:46:23.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:46:23.665: INFO: namespace: e2e-tests-custom-resource-definition-82g5f, resource: bindings, ignored listing per whitelist
Mar  9 16:46:23.700: INFO: namespace e2e-tests-custom-resource-definition-82g5f deletion completed in 6.064434626s

• [SLOW TEST:7.127 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:46:23.700: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:46:23.721817      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-dfb2f749-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:46:23.756: INFO: Waiting up to 5m0s for pod "pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-bhbxq" to be "success or failure"
Mar  9 16:46:23.765: INFO: Pod "pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.716167ms
Mar  9 16:46:25.766: INFO: Pod "pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010430826s
STEP: Saw pod success
Mar  9 16:46:25.766: INFO: Pod "pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:46:25.768: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:46:25.777: INFO: Waiting for pod pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:46:25.779: INFO: Pod pod-configmaps-dfb35376-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:46:25.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bhbxq" for this suite.
Mar  9 16:46:31.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:46:31.823: INFO: namespace: e2e-tests-configmap-bhbxq, resource: bindings, ignored listing per whitelist
Mar  9 16:46:31.828: INFO: namespace e2e-tests-configmap-bhbxq deletion completed in 6.048218757s

• [SLOW TEST:8.128 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:46:31.828: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:46:31.846486      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:46:31.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-xf9pn" for this suite.
Mar  9 16:46:37.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:46:37.922: INFO: namespace: e2e-tests-services-xf9pn, resource: bindings, ignored listing per whitelist
Mar  9 16:46:37.928: INFO: namespace e2e-tests-services-xf9pn deletion completed in 6.059427625s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.100 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:46:37.928: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:46:37.946180      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  9 16:46:37.967: INFO: Waiting up to 5m0s for pod "pod-e82c20c2-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-fcvk7" to be "success or failure"
Mar  9 16:46:37.969: INFO: Pod "pod-e82c20c2-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.825483ms
Mar  9 16:46:39.970: INFO: Pod "pod-e82c20c2-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003417138s
STEP: Saw pod success
Mar  9 16:46:39.970: INFO: Pod "pod-e82c20c2-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:46:39.971: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-e82c20c2-428a-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:46:39.980: INFO: Waiting for pod pod-e82c20c2-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:46:39.981: INFO: Pod pod-e82c20c2-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:46:39.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fcvk7" for this suite.
Mar  9 16:46:45.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:46:46.025: INFO: namespace: e2e-tests-emptydir-fcvk7, resource: bindings, ignored listing per whitelist
Mar  9 16:46:46.030: INFO: namespace e2e-tests-emptydir-fcvk7 deletion completed in 6.047491277s

• [SLOW TEST:8.102 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:46:46.030: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:46:46.048074      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-zxfsz/secret-test-ed00b55d-428a-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:46:46.072: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-zxfsz" to be "success or failure"
Mar  9 16:46:46.076: INFO: Pod "pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.313452ms
Mar  9 16:46:48.078: INFO: Pod "pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005426728s
STEP: Saw pod success
Mar  9 16:46:48.078: INFO: Pod "pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:46:48.079: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f container env-test: <nil>
STEP: delete the pod
Mar  9 16:46:48.088: INFO: Waiting for pod pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:46:48.089: INFO: Pod pod-configmaps-ed00f642-428a-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:46:48.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zxfsz" for this suite.
Mar  9 16:46:54.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:46:54.109: INFO: namespace: e2e-tests-secrets-zxfsz, resource: bindings, ignored listing per whitelist
Mar  9 16:46:54.139: INFO: namespace e2e-tests-secrets-zxfsz deletion completed in 6.048259992s

• [SLOW TEST:8.109 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:46:54.139: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:46:54.157293      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tllvm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 16:46:54.175: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 16:47:12.204: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.192.14:8080/dial?request=hostName&protocol=http&host=10.20.192.13&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-tllvm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 16:47:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 16:47:12.293: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:47:12.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tllvm" for this suite.
Mar  9 16:47:34.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:47:34.903: INFO: namespace: e2e-tests-pod-network-test-tllvm, resource: bindings, ignored listing per whitelist
Mar  9 16:47:34.913: INFO: namespace e2e-tests-pod-network-test-tllvm deletion completed in 22.253662711s

• [SLOW TEST:40.774 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:47:34.913: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:47:34.930302      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  9 16:47:34.953: INFO: Waiting up to 5m0s for pod "pod-0a238970-428b-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-l5q7c" to be "success or failure"
Mar  9 16:47:34.957: INFO: Pod "pod-0a238970-428b-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.616874ms
Mar  9 16:47:36.959: INFO: Pod "pod-0a238970-428b-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005225752s
STEP: Saw pod success
Mar  9 16:47:36.959: INFO: Pod "pod-0a238970-428b-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:47:36.960: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-0a238970-428b-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:47:36.971: INFO: Waiting for pod pod-0a238970-428b-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:47:36.973: INFO: Pod pod-0a238970-428b-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:47:36.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l5q7c" for this suite.
Mar  9 16:47:42.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:47:43.007: INFO: namespace: e2e-tests-emptydir-l5q7c, resource: bindings, ignored listing per whitelist
Mar  9 16:47:43.022: INFO: namespace e2e-tests-emptydir-l5q7c deletion completed in 6.048037935s

• [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:47:43.022: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:47:43.040003      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:47:43.065: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-vvhqs" to be "success or failure"
Mar  9 16:47:43.069: INFO: Pod "downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.842314ms
Mar  9 16:47:45.072: INFO: Pod "downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006158949s
STEP: Saw pod success
Mar  9 16:47:45.072: INFO: Pod "downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:47:45.073: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:47:45.083: INFO: Waiting for pod downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:47:45.085: INFO: Pod downwardapi-volume-0ef8f5d1-428b-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:47:45.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vvhqs" for this suite.
Mar  9 16:47:51.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:47:51.137: INFO: namespace: e2e-tests-projected-vvhqs, resource: bindings, ignored listing per whitelist
Mar  9 16:47:51.137: INFO: namespace e2e-tests-projected-vvhqs deletion completed in 6.051236584s

• [SLOW TEST:8.115 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:47:51.137: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:47:51.155100      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  9 16:47:51.175: INFO: namespace e2e-tests-kubectl-lgx22
Mar  9 16:47:51.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-lgx22'
Mar  9 16:47:51.352: INFO: stderr: ""
Mar  9 16:47:51.352: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  9 16:47:52.354: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:47:52.354: INFO: Found 0 / 1
Mar  9 16:47:53.354: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:47:53.354: INFO: Found 1 / 1
Mar  9 16:47:53.354: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  9 16:47:53.355: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:47:53.355: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  9 16:47:53.355: INFO: wait on redis-master startup in e2e-tests-kubectl-lgx22 
Mar  9 16:47:53.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 logs redis-master-bxt9s redis-master --namespace=e2e-tests-kubectl-lgx22'
Mar  9 16:47:53.433: INFO: stderr: ""
Mar  9 16:47:53.433: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Mar 16:47:51.919 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Mar 16:47:51.919 # Server started, Redis version 3.2.12\n1:M 09 Mar 16:47:51.919 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Mar 16:47:51.919 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar  9 16:47:53.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-lgx22'
Mar  9 16:47:53.532: INFO: stderr: ""
Mar  9 16:47:53.532: INFO: stdout: "service/rm2 exposed\n"
Mar  9 16:47:53.535: INFO: Service rm2 in namespace e2e-tests-kubectl-lgx22 found.
STEP: exposing service
Mar  9 16:47:55.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-lgx22'
Mar  9 16:47:55.629: INFO: stderr: ""
Mar  9 16:47:55.629: INFO: stdout: "service/rm3 exposed\n"
Mar  9 16:47:55.631: INFO: Service rm3 in namespace e2e-tests-kubectl-lgx22 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:47:57.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lgx22" for this suite.
Mar  9 16:48:19.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:48:19.678: INFO: namespace: e2e-tests-kubectl-lgx22, resource: bindings, ignored listing per whitelist
Mar  9 16:48:19.707: INFO: namespace e2e-tests-kubectl-lgx22 deletion completed in 22.072557699s

• [SLOW TEST:28.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:48:19.707: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:48:19.724292      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar  9 16:48:19.744: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-182708018 proxy --unix-socket=/tmp/kubectl-proxy-unix738303209/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:48:19.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xjbkx" for this suite.
Mar  9 16:48:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:48:25.836: INFO: namespace: e2e-tests-kubectl-xjbkx, resource: bindings, ignored listing per whitelist
Mar  9 16:48:25.860: INFO: namespace e2e-tests-kubectl-xjbkx deletion completed in 6.047764027s

• [SLOW TEST:6.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:48:25.860: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:48:25.877909      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar  9 16:48:26.402: INFO: Waiting up to 5m0s for pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm" in namespace "e2e-tests-svcaccounts-9gbnw" to be "success or failure"
Mar  9 16:48:26.407: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402068ms
Mar  9 16:48:28.409: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006234585s
STEP: Saw pod success
Mar  9 16:48:28.409: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm" satisfied condition "success or failure"
Mar  9 16:48:28.410: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm container token-test: <nil>
STEP: delete the pod
Mar  9 16:48:28.419: INFO: Waiting for pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm to disappear
Mar  9 16:48:28.421: INFO: Pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-hcgdm no longer exists
STEP: Creating a pod to test consume service account root CA
Mar  9 16:48:28.423: INFO: Waiting up to 5m0s for pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll" in namespace "e2e-tests-svcaccounts-9gbnw" to be "success or failure"
Mar  9 16:48:28.425: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll": Phase="Pending", Reason="", readiness=false. Elapsed: 2.196408ms
Mar  9 16:48:30.427: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004085954s
STEP: Saw pod success
Mar  9 16:48:30.427: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll" satisfied condition "success or failure"
Mar  9 16:48:30.429: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll container root-ca-test: <nil>
STEP: delete the pod
Mar  9 16:48:30.439: INFO: Waiting for pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll to disappear
Mar  9 16:48:30.441: INFO: Pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-k4jll no longer exists
STEP: Creating a pod to test consume service account namespace
Mar  9 16:48:30.443: INFO: Waiting up to 5m0s for pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl" in namespace "e2e-tests-svcaccounts-9gbnw" to be "success or failure"
Mar  9 16:48:30.445: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl": Phase="Pending", Reason="", readiness=false. Elapsed: 1.655961ms
Mar  9 16:48:32.447: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003301888s
STEP: Saw pod success
Mar  9 16:48:32.447: INFO: Pod "pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl" satisfied condition "success or failure"
Mar  9 16:48:32.448: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl container namespace-test: <nil>
STEP: delete the pod
Mar  9 16:48:32.457: INFO: Waiting for pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl to disappear
Mar  9 16:48:32.458: INFO: Pod pod-service-account-28ce0d7d-428b-11e9-923b-2eb43f2b540f-2lzbl no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:48:32.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9gbnw" for this suite.
Mar  9 16:48:38.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:48:38.504: INFO: namespace: e2e-tests-svcaccounts-9gbnw, resource: bindings, ignored listing per whitelist
Mar  9 16:48:38.509: INFO: namespace e2e-tests-svcaccounts-9gbnw deletion completed in 6.049245758s

• [SLOW TEST:12.649 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:48:38.509: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:48:38.526803      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:48:38.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 version'
Mar  9 16:48:38.611: INFO: stderr: ""
Mar  9 16:48:38.611: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.2\", GitCommit:\"17c77c7898218073f14c8d573582e8d2313dc740\", GitTreeState:\"clean\", BuildDate:\"2018-10-24T06:43:59Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:48:38.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fpfj9" for this suite.
Mar  9 16:48:44.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:48:44.636: INFO: namespace: e2e-tests-kubectl-fpfj9, resource: bindings, ignored listing per whitelist
Mar  9 16:48:44.662: INFO: namespace e2e-tests-kubectl-fpfj9 deletion completed in 6.048938566s

• [SLOW TEST:6.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:48:44.662: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:48:44.679896      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 16:48:44.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c77pp'
Mar  9 16:48:44.783: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  9 16:48:44.783: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar  9 16:48:46.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-c77pp'
Mar  9 16:48:46.875: INFO: stderr: ""
Mar  9 16:48:46.875: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:48:46.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c77pp" for this suite.
Mar  9 16:48:52.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:48:52.903: INFO: namespace: e2e-tests-kubectl-c77pp, resource: bindings, ignored listing per whitelist
Mar  9 16:48:52.928: INFO: namespace e2e-tests-kubectl-c77pp deletion completed in 6.051263453s

• [SLOW TEST:8.266 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:48:52.928: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:48:52.946147      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  9 16:48:52.969: INFO: Waiting up to 5m0s for pod "downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-k4pqg" to be "success or failure"
Mar  9 16:48:52.972: INFO: Pod "downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450774ms
Mar  9 16:48:54.974: INFO: Pod "downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005286133s
STEP: Saw pod success
Mar  9 16:48:54.974: INFO: Pod "downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:48:54.976: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 16:48:54.985: INFO: Waiting for pod downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:48:54.988: INFO: Pod downward-api-38a3b719-428b-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:48:54.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k4pqg" for this suite.
Mar  9 16:49:00.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:49:01.010: INFO: namespace: e2e-tests-downward-api-k4pqg, resource: bindings, ignored listing per whitelist
Mar  9 16:49:01.041: INFO: namespace e2e-tests-downward-api-k4pqg deletion completed in 6.051228829s

• [SLOW TEST:8.112 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:49:01.041: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:49:01.058822      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 16:49:01.080: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-dlxlx" to be "success or failure"
Mar  9 16:49:01.084: INFO: Pod "downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.650476ms
Mar  9 16:49:03.086: INFO: Pod "downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006074475s
STEP: Saw pod success
Mar  9 16:49:03.086: INFO: Pod "downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:49:03.087: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 16:49:03.095: INFO: Waiting for pod downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:49:03.098: INFO: Pod downwardapi-volume-3d795952-428b-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:49:03.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dlxlx" for this suite.
Mar  9 16:49:09.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:49:09.136: INFO: namespace: e2e-tests-projected-dlxlx, resource: bindings, ignored listing per whitelist
Mar  9 16:49:09.160: INFO: namespace e2e-tests-projected-dlxlx deletion completed in 6.060674095s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:49:09.160: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:49:09.186016      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  9 16:49:09.209: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 16:49:09.212: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 16:49:09.213: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-70-73.us-west-2.compute.internal before test
Mar  9 16:49:09.217: INFO: hpa-operator-metrics-server-d98ff747d-mkt2v from pipeline-system started at 2019-03-09 15:45:50 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container metrics-server ready: true, restart count 0
Mar  9 16:49:09.217: INFO: hpa-operator-hpa-operator-5587f4b46c-tz255 from pipeline-system started at 2019-03-09 15:45:50 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container hpa-operator ready: true, restart count 0
Mar  9 16:49:09.217: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-09 15:52:59 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 16:49:09.217: INFO: tiller-deploy-865b88d89-pvn7z from kube-system started at 2019-03-09 15:44:30 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container tiller ready: true, restart count 0
Mar  9 16:49:09.217: INFO: kube-proxy-nxxjq from kube-system started at 2019-03-09 15:44:30 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 16:49:09.217: INFO: dns-external-dns-56d66c8bc-ct9md from pipeline-system started at 2019-03-09 15:45:42 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container external-dns ready: true, restart count 0
Mar  9 16:49:09.217: INFO: dashboard-kubernetes-dashboard-6469dff698-q4vtx from pipeline-system started at 2019-03-09 15:45:46 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  9 16:49:09.217: INFO: npls-nodepool-labels-operator-64d58d86f-cq2sp from pipeline-system started at 2019-03-09 15:45:33 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container nodepool-labels-operator ready: true, restart count 0
Mar  9 16:49:09.217: INFO: ingress-traefik-6db6c64c49-lfg8d from pipeline-system started at 2019-03-09 15:45:44 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container ingress-traefik ready: true, restart count 0
Mar  9 16:49:09.217: INFO: hpa-operator-kube-metrics-adapter-bf9dd978d-5jksc from pipeline-system started at 2019-03-09 15:45:49 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container kube-metrics-adapter ready: true, restart count 0
Mar  9 16:49:09.217: INFO: weave-net-ft8zc from kube-system started at 2019-03-09 15:44:30 +0000 UTC (2 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container weave ready: true, restart count 1
Mar  9 16:49:09.217: INFO: 	Container weave-npc ready: true, restart count 0
Mar  9 16:49:09.217: INFO: autoscaler-aws-cluster-autoscaler-d9dcf4d85-69zpr from kube-system started at 2019-03-09 15:45:48 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container aws-cluster-autoscaler ready: true, restart count 0
Mar  9 16:49:09.217: INFO: ith-instance-termination-handler-mdlnc from pipeline-system started at 2019-03-09 15:45:53 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container instance-termination-handler ready: true, restart count 0
Mar  9 16:49:09.217: INFO: sonobuoy-systemd-logs-daemon-set-5a60dbf0cc4b44aa-9dhqt from heptio-sonobuoy started at 2019-03-09 15:53:02 +0000 UTC (2 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  9 16:49:09.217: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 16:49:09.217: INFO: pvc-operator-7c7766d9c6-xhzz8 from pipeline-system started at 2019-03-09 15:45:51 +0000 UTC (1 container statuses recorded)
Mar  9 16:49:09.217: INFO: 	Container pvc-operator ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158a58564aa8bde0], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:49:10.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-t6h95" for this suite.
Mar  9 16:49:16.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:49:16.314: INFO: namespace: e2e-tests-sched-pred-t6h95, resource: bindings, ignored listing per whitelist
Mar  9 16:49:16.319: INFO: namespace e2e-tests-sched-pred-t6h95 deletion completed in 6.090427928s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.160 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:49:16.320: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:49:16.339422      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-gj4dn.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-gj4dn.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gj4dn.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-gj4dn.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-gj4dn.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gj4dn.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 16:49:28.400: INFO: DNS probes using e2e-tests-dns-gj4dn/dns-test-4695293e-428b-11e9-923b-2eb43f2b540f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:49:28.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gj4dn" for this suite.
Mar  9 16:49:34.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:49:34.460: INFO: namespace: e2e-tests-dns-gj4dn, resource: bindings, ignored listing per whitelist
Mar  9 16:49:34.462: INFO: namespace e2e-tests-dns-gj4dn deletion completed in 6.050466206s

• [SLOW TEST:18.142 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:49:34.462: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:49:34.479824      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-51656130-428b-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:49:34.505: INFO: Waiting up to 5m0s for pod "pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-b65nw" to be "success or failure"
Mar  9 16:49:34.509: INFO: Pod "pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338934ms
Mar  9 16:49:36.511: INFO: Pod "pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005192871s
STEP: Saw pod success
Mar  9 16:49:36.511: INFO: Pod "pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:49:36.512: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:49:36.524: INFO: Waiting for pod pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:49:36.525: INFO: Pod pod-configmaps-51659e05-428b-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:49:36.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b65nw" for this suite.
Mar  9 16:49:42.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:49:42.545: INFO: namespace: e2e-tests-configmap-b65nw, resource: bindings, ignored listing per whitelist
Mar  9 16:49:42.573: INFO: namespace e2e-tests-configmap-b65nw deletion completed in 6.047255579s

• [SLOW TEST:8.111 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:49:42.573: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:49:42.591728      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-563b4006-428b-11e9-923b-2eb43f2b540f
STEP: Creating secret with name s-test-opt-upd-563b403a-428b-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-563b4006-428b-11e9-923b-2eb43f2b540f
STEP: Updating secret s-test-opt-upd-563b403a-428b-11e9-923b-2eb43f2b540f
STEP: Creating secret with name s-test-opt-create-563b404a-428b-11e9-923b-2eb43f2b540f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:49:48.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5tr64" for this suite.
Mar  9 16:50:10.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:50:10.696: INFO: namespace: e2e-tests-secrets-5tr64, resource: bindings, ignored listing per whitelist
Mar  9 16:50:10.713: INFO: namespace e2e-tests-secrets-5tr64 deletion completed in 22.055140454s

• [SLOW TEST:28.139 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:50:10.713: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:50:10.730926      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-d8hbt
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-d8hbt
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-d8hbt
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-d8hbt
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-d8hbt
Mar  9 16:50:14.776: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d8hbt, name: ss-0, uid: 6929feeb-428b-11e9-9882-02b03e914f30, status phase: Pending. Waiting for statefulset controller to delete.
Mar  9 16:50:14.968: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d8hbt, name: ss-0, uid: 6929feeb-428b-11e9-9882-02b03e914f30, status phase: Failed. Waiting for statefulset controller to delete.
Mar  9 16:50:14.972: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-d8hbt, name: ss-0, uid: 6929feeb-428b-11e9-9882-02b03e914f30, status phase: Failed. Waiting for statefulset controller to delete.
Mar  9 16:50:14.973: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-d8hbt
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-d8hbt
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-d8hbt and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  9 16:50:18.988: INFO: Deleting all statefulset in ns e2e-tests-statefulset-d8hbt
Mar  9 16:50:18.990: INFO: Scaling statefulset ss to 0
Mar  9 16:50:39.000: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:50:39.001: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:50:39.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-d8hbt" for this suite.
Mar  9 16:50:45.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:50:45.025: INFO: namespace: e2e-tests-statefulset-d8hbt, resource: bindings, ignored listing per whitelist
Mar  9 16:50:45.058: INFO: namespace e2e-tests-statefulset-d8hbt deletion completed in 6.048073073s

• [SLOW TEST:34.345 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:50:45.058: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:50:45.076301      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  9 16:50:47.107: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-7b79944d-428b-11e9-923b-2eb43f2b540f,GenerateName:,Namespace:e2e-tests-events-xj987,SelfLink:/api/v1/namespaces/e2e-tests-events-xj987/pods/send-events-7b79944d-428b-11e9-923b-2eb43f2b540f,UID:7b79cad5-428b-11e9-9882-02b03e914f30,ResourceVersion:14233,Generation:0,CreationTimestamp:2019-03-09 16:50:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 96357817,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-b8j7q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b8j7q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-b8j7q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc423004ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc423004cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:50:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:50:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:50:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 16:50:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.13,StartTime:2019-03-09 16:50:45 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-09 16:50:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://79111d87a8ba016e6c2c742923534942b4d9e92d4cce2f07b74c6db6f59d7457}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar  9 16:50:49.109: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  9 16:50:51.111: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:50:51.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xj987" for this suite.
Mar  9 16:51:31.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:51:31.147: INFO: namespace: e2e-tests-events-xj987, resource: bindings, ignored listing per whitelist
Mar  9 16:51:31.169: INFO: namespace e2e-tests-events-xj987 deletion completed in 40.052725112s

• [SLOW TEST:46.112 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:51:31.170: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:51:31.187413      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-sjh82
Mar  9 16:51:33.218: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-sjh82
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 16:51:33.220: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:55:33.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sjh82" for this suite.
Mar  9 16:55:39.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:55:39.852: INFO: namespace: e2e-tests-container-probe-sjh82, resource: bindings, ignored listing per whitelist
Mar  9 16:55:39.877: INFO: namespace e2e-tests-container-probe-sjh82 deletion completed in 6.429330991s

• [SLOW TEST:248.707 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:55:39.877: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:55:39.894484      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar  9 16:55:39.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 cluster-info'
Mar  9 16:55:40.068: INFO: stderr: ""
Mar  9 16:55:40.068: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:55:40.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fpwdw" for this suite.
Mar  9 16:55:46.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:55:46.096: INFO: namespace: e2e-tests-kubectl-fpwdw, resource: bindings, ignored listing per whitelist
Mar  9 16:55:46.118: INFO: namespace e2e-tests-kubectl-fpwdw deletion completed in 6.047756447s

• [SLOW TEST:6.241 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:55:46.118: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:55:46.135369      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2eeb4fba-428c-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 16:55:46.159: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-r758r" to be "success or failure"
Mar  9 16:55:46.162: INFO: Pod "pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.748734ms
Mar  9 16:55:48.164: INFO: Pod "pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004535762s
STEP: Saw pod success
Mar  9 16:55:48.164: INFO: Pod "pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:55:48.165: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 16:55:48.176: INFO: Waiting for pod pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:55:48.179: INFO: Pod pod-projected-configmaps-2eeb873a-428c-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:55:48.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r758r" for this suite.
Mar  9 16:55:54.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:55:54.203: INFO: namespace: e2e-tests-projected-r758r, resource: bindings, ignored listing per whitelist
Mar  9 16:55:54.229: INFO: namespace e2e-tests-projected-r758r deletion completed in 6.049161495s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:55:54.229: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:55:54.246626      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-33c12954-428c-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:55:54.271: INFO: Waiting up to 5m0s for pod "pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-rr72m" to be "success or failure"
Mar  9 16:55:54.275: INFO: Pod "pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.812486ms
Mar  9 16:55:56.277: INFO: Pod "pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005589747s
STEP: Saw pod success
Mar  9 16:55:56.277: INFO: Pod "pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:55:56.278: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:55:56.287: INFO: Waiting for pod pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:55:56.289: INFO: Pod pod-secrets-33c163f1-428c-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:55:56.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rr72m" for this suite.
Mar  9 16:56:02.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:56:02.310: INFO: namespace: e2e-tests-secrets-rr72m, resource: bindings, ignored listing per whitelist
Mar  9 16:56:02.340: INFO: namespace e2e-tests-secrets-rr72m deletion completed in 6.049973698s

• [SLOW TEST:8.111 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:56:02.340: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:56:02.358156      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:56:02.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-n78rz" for this suite.
Mar  9 16:56:24.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:56:24.412: INFO: namespace: e2e-tests-pods-n78rz, resource: bindings, ignored listing per whitelist
Mar  9 16:56:24.456: INFO: namespace e2e-tests-pods-n78rz deletion completed in 22.069632918s

• [SLOW TEST:22.116 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:56:24.456: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:56:24.478904      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar  9 16:56:24.522: INFO: Waiting up to 5m0s for pod "var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-var-expansion-ztxdp" to be "success or failure"
Mar  9 16:56:24.527: INFO: Pod "var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.273734ms
Mar  9 16:56:26.528: INFO: Pod "var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005949406s
STEP: Saw pod success
Mar  9 16:56:26.528: INFO: Pod "var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:56:26.530: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 16:56:26.539: INFO: Waiting for pod var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:56:26.541: INFO: Pod var-expansion-45c91f55-428c-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:56:26.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ztxdp" for this suite.
Mar  9 16:56:32.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:56:32.581: INFO: namespace: e2e-tests-var-expansion-ztxdp, resource: bindings, ignored listing per whitelist
Mar  9 16:56:32.603: INFO: namespace e2e-tests-var-expansion-ztxdp deletion completed in 6.060864604s

• [SLOW TEST:8.147 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:56:32.603: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:56:32.621466      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6b8z4
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar  9 16:56:32.650: INFO: Found 0 stateful pods, waiting for 3
Mar  9 16:56:42.652: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:56:42.652: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:56:42.652: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  9 16:56:42.670: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  9 16:56:52.701: INFO: Updating stateful set ss2
Mar  9 16:56:52.720: INFO: Waiting for Pod e2e-tests-statefulset-6b8z4/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar  9 16:57:02.784: INFO: Found 2 stateful pods, waiting for 3
Mar  9 16:57:12.789: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:57:12.789: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 16:57:12.789: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  9 16:57:12.807: INFO: Updating stateful set ss2
Mar  9 16:57:12.814: INFO: Waiting for Pod e2e-tests-statefulset-6b8z4/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  9 16:57:22.831: INFO: Updating stateful set ss2
Mar  9 16:57:22.837: INFO: Waiting for StatefulSet e2e-tests-statefulset-6b8z4/ss2 to complete update
Mar  9 16:57:22.837: INFO: Waiting for Pod e2e-tests-statefulset-6b8z4/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  9 16:57:32.840: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6b8z4
Mar  9 16:57:32.841: INFO: Scaling statefulset ss2 to 0
Mar  9 16:57:42.850: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 16:57:42.851: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:57:42.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6b8z4" for this suite.
Mar  9 16:57:48.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:57:48.893: INFO: namespace: e2e-tests-statefulset-6b8z4, resource: bindings, ignored listing per whitelist
Mar  9 16:57:48.912: INFO: namespace e2e-tests-statefulset-6b8z4 deletion completed in 6.049869416s

• [SLOW TEST:76.309 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:57:48.912: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:57:48.929395      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  9 16:57:52.972: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:57:52.973: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:57:54.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:57:54.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:57:56.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:57:56.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:57:58.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:57:58.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:00.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:00.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:02.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:02.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:04.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:04.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:06.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:06.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:08.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:08.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:10.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:10.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:12.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:12.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:14.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:14.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:16.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:16.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:18.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:18.975: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 16:58:20.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 16:58:20.975: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:58:20.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-b7mfw" for this suite.
Mar  9 16:58:42.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:58:43.011: INFO: namespace: e2e-tests-container-lifecycle-hook-b7mfw, resource: bindings, ignored listing per whitelist
Mar  9 16:58:43.028: INFO: namespace e2e-tests-container-lifecycle-hook-b7mfw deletion completed in 22.049156042s

• [SLOW TEST:54.117 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:58:43.028: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:58:43.046207      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-985e1dc1-428c-11e9-923b-2eb43f2b540f
STEP: Creating configMap with name cm-test-opt-upd-985e1dea-428c-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-985e1dc1-428c-11e9-923b-2eb43f2b540f
STEP: Updating configmap cm-test-opt-upd-985e1dea-428c-11e9-923b-2eb43f2b540f
STEP: Creating configMap with name cm-test-opt-create-985e1df8-428c-11e9-923b-2eb43f2b540f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:58:49.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6ptpp" for this suite.
Mar  9 16:59:11.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:59:11.131: INFO: namespace: e2e-tests-configmap-6ptpp, resource: bindings, ignored listing per whitelist
Mar  9 16:59:11.160: INFO: namespace e2e-tests-configmap-6ptpp deletion completed in 22.047545888s

• [SLOW TEST:28.132 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:59:11.161: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:59:11.178457      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a9227308-428c-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 16:59:11.201: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-k74lw" to be "success or failure"
Mar  9 16:59:11.204: INFO: Pod "pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.170254ms
Mar  9 16:59:13.207: INFO: Pod "pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006305986s
STEP: Saw pod success
Mar  9 16:59:13.207: INFO: Pod "pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:59:13.211: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 16:59:13.228: INFO: Waiting for pod pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:59:13.230: INFO: Pod pod-projected-secrets-a922abca-428c-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:59:13.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k74lw" for this suite.
Mar  9 16:59:19.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:59:19.258: INFO: namespace: e2e-tests-projected-k74lw, resource: bindings, ignored listing per whitelist
Mar  9 16:59:19.293: INFO: namespace e2e-tests-projected-k74lw deletion completed in 6.060956249s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:59:19.293: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:59:19.310520      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  9 16:59:19.341: INFO: Waiting up to 5m0s for pod "pod-adfc8c12-428c-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-45glx" to be "success or failure"
Mar  9 16:59:19.344: INFO: Pod "pod-adfc8c12-428c-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.979302ms
Mar  9 16:59:21.346: INFO: Pod "pod-adfc8c12-428c-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004660727s
STEP: Saw pod success
Mar  9 16:59:21.346: INFO: Pod "pod-adfc8c12-428c-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 16:59:21.347: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-adfc8c12-428c-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 16:59:21.356: INFO: Waiting for pod pod-adfc8c12-428c-11e9-923b-2eb43f2b540f to disappear
Mar  9 16:59:21.358: INFO: Pod pod-adfc8c12-428c-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:59:21.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-45glx" for this suite.
Mar  9 16:59:27.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:59:27.391: INFO: namespace: e2e-tests-emptydir-45glx, resource: bindings, ignored listing per whitelist
Mar  9 16:59:27.409: INFO: namespace e2e-tests-emptydir-45glx deletion completed in 6.049508869s

• [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:59:27.409: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:59:27.426783      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 16:59:27.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-scjzm'
Mar  9 16:59:27.558: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  9 16:59:27.558: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar  9 16:59:27.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-scjzm'
Mar  9 16:59:27.657: INFO: stderr: ""
Mar  9 16:59:27.657: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:59:27.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-scjzm" for this suite.
Mar  9 16:59:33.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:59:33.712: INFO: namespace: e2e-tests-kubectl-scjzm, resource: bindings, ignored listing per whitelist
Mar  9 16:59:33.714: INFO: namespace e2e-tests-kubectl-scjzm deletion completed in 6.055878462s

• [SLOW TEST:6.305 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:59:33.714: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:59:33.732583      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar  9 16:59:33.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 api-versions'
Mar  9 16:59:33.815: INFO: stderr: ""
Mar  9 16:59:33.815: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbanzaicloud.com/v1alpha1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncustom.metrics.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nlabels.banzaicloud.io/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:59:33.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ln54t" for this suite.
Mar  9 16:59:39.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 16:59:39.836: INFO: namespace: e2e-tests-kubectl-ln54t, resource: bindings, ignored listing per whitelist
Mar  9 16:59:39.864: INFO: namespace e2e-tests-kubectl-ln54t deletion completed in 6.047908095s

• [SLOW TEST:6.150 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 16:59:39.865: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 16:59:39.882155      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 16:59:39.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 version --client'
Mar  9 16:59:39.963: INFO: stderr: ""
Mar  9 16:59:39.963: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar  9 16:59:39.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-zhc8m'
Mar  9 16:59:40.141: INFO: stderr: ""
Mar  9 16:59:40.141: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  9 16:59:40.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-zhc8m'
Mar  9 16:59:40.305: INFO: stderr: ""
Mar  9 16:59:40.305: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  9 16:59:41.307: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:59:41.307: INFO: Found 1 / 1
Mar  9 16:59:41.307: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  9 16:59:41.308: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 16:59:41.308: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  9 16:59:41.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 describe pod redis-master-6zl9j --namespace=e2e-tests-kubectl-zhc8m'
Mar  9 16:59:41.394: INFO: stderr: ""
Mar  9 16:59:41.394: INFO: stdout: "Name:               redis-master-6zl9j\nNamespace:          e2e-tests-kubectl-zhc8m\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-192-168-70-73.us-west-2.compute.internal/192.168.70.73\nStart Time:         Sat, 09 Mar 2019 16:59:40 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.20.192.14\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://d59056b881dca8c283a7b277862a2586db5a6e93891c0178951379f2eb83dfde\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 09 Mar 2019 16:59:40 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pplj5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pplj5:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pplj5\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                  Message\n  ----    ------     ----  ----                                                  -------\n  Normal  Scheduled  1s    default-scheduler                                     Successfully assigned e2e-tests-kubectl-zhc8m/redis-master-6zl9j to ip-192-168-70-73.us-west-2.compute.internal\n  Normal  Pulled     1s    kubelet, ip-192-168-70-73.us-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-192-168-70-73.us-west-2.compute.internal  Created container\n  Normal  Started    1s    kubelet, ip-192-168-70-73.us-west-2.compute.internal  Started container\n"
Mar  9 16:59:41.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 describe rc redis-master --namespace=e2e-tests-kubectl-zhc8m'
Mar  9 16:59:41.513: INFO: stderr: ""
Mar  9 16:59:41.513: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-zhc8m\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-6zl9j\n"
Mar  9 16:59:41.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 describe service redis-master --namespace=e2e-tests-kubectl-zhc8m'
Mar  9 16:59:41.592: INFO: stderr: ""
Mar  9 16:59:41.592: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-zhc8m\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.10.196.217\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.20.192.14:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  9 16:59:41.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 describe node ip-192-168-65-29.us-west-2.compute.internal'
Mar  9 16:59:41.685: INFO: stderr: ""
Mar  9 16:59:41.685: INFO: stdout: "Name:               ip-192-168-65-29.us-west-2.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=c5.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=us-west-2a\n                    kubernetes.io/hostname=ip-192-168-65-29.us-west-2.compute.internal\n                    node-role.kubernetes.io/master=\n                    node.banzaicloud.io/ondemand=true\n                    nodepool.banzaicloud.io/name=master\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    nodepool.banzaicloud.io/managed-labels: [\"node.banzaicloud.io/ondemand\",\"nodepool.banzaicloud.io/name\"]\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 09 Mar 2019 15:41:21 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 09 Mar 2019 15:41:47 +0000   Sat, 09 Mar 2019 15:41:47 +0000   WeaveIsUp                    Weave pod has set this\n  OutOfDisk            False   Sat, 09 Mar 2019 16:59:36 +0000   Sat, 09 Mar 2019 15:41:21 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Sat, 09 Mar 2019 16:59:36 +0000   Sat, 09 Mar 2019 15:41:21 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 09 Mar 2019 16:59:36 +0000   Sat, 09 Mar 2019 15:41:21 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 09 Mar 2019 16:59:36 +0000   Sat, 09 Mar 2019 15:41:21 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 09 Mar 2019 16:59:36 +0000   Sat, 09 Mar 2019 15:41:51 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   192.168.65.29\n  ExternalIP:   52.33.67.153\n  InternalDNS:  ip-192-168-65-29.us-west-2.compute.internal\n  Hostname:     ip-192-168-65-29.us-west-2.compute.internal\n  ExternalDNS:  ec2-52-33-67-153.us-west-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           52417516Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3635296Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           48307982666\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      3532896Ki\n pods:                        110\nSystem Info:\n Machine ID:                 b30d0f2110ac3807b210c19ede3ce88f\n System UUID:                EC23828C-F38C-AB3C-EE7E-72CA911FFA19\n Boot ID:                    06dcd1ae-e3d4-4c88-99a2-1d8dc69f463b\n Kernel Version:             3.10.0-862.3.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.4\n Kubelet Version:            v1.12.2\n Kube-Proxy Version:         v1.12.2\nPodCIDR:                     10.20.0.0/24\nProviderID:                  aws:///us-west-2a/i-01432ab256efd6a78\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                                   ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-24c513aab9fa40db                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-5a60dbf0cc4b44aa-jd287                0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-576cbf47c7-4w9k4                                               100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)\n  kube-system                coredns-576cbf47c7-qm7z9                                               100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)\n  kube-system                etcd-ip-192-168-65-29.us-west-2.compute.internal                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-ip-192-168-65-29.us-west-2.compute.internal             250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-ip-192-168-65-29.us-west-2.compute.internal    200m (10%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-s5r5z                                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-ip-192-168-65-29.us-west-2.compute.internal             100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                weave-net-dbkt9                                                        20m (1%)      0 (0%)      0 (0%)           0 (0%)\n  pipeline-system            ith-instance-termination-handler-xhnf6                                 120m (6%)     0 (0%)      256Mi (7%)       0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests     Limits\n  --------                    --------     ------\n  cpu                         890m (44%)   0 (0%)\n  memory                      396Mi (11%)  340Mi (9%)\n  attachable-volumes-aws-ebs  0            0\nEvents:                       <none>\n"
Mar  9 16:59:41.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 describe namespace e2e-tests-kubectl-zhc8m'
Mar  9 16:59:41.765: INFO: stderr: ""
Mar  9 16:59:41.765: INFO: stdout: "Name:         e2e-tests-kubectl-zhc8m\nLabels:       e2e-framework=kubectl\n              e2e-run=767ef7fc-4283-11e9-923b-2eb43f2b540f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 16:59:41.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zhc8m" for this suite.
Mar  9 17:00:03.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:00:03.814: INFO: namespace: e2e-tests-kubectl-zhc8m, resource: bindings, ignored listing per whitelist
Mar  9 17:00:03.818: INFO: namespace e2e-tests-kubectl-zhc8m deletion completed in 22.051388001s

• [SLOW TEST:23.953 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:00:03.818: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:00:03.836054      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  9 17:00:03.860: INFO: Waiting up to 5m0s for pod "downward-api-c8859893-428c-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-g5njg" to be "success or failure"
Mar  9 17:00:03.864: INFO: Pod "downward-api-c8859893-428c-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.672172ms
Mar  9 17:00:05.865: INFO: Pod "downward-api-c8859893-428c-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005281616s
STEP: Saw pod success
Mar  9 17:00:05.865: INFO: Pod "downward-api-c8859893-428c-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:00:05.867: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downward-api-c8859893-428c-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 17:00:05.878: INFO: Waiting for pod downward-api-c8859893-428c-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:00:05.879: INFO: Pod downward-api-c8859893-428c-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:00:05.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g5njg" for this suite.
Mar  9 17:00:11.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:00:11.918: INFO: namespace: e2e-tests-downward-api-g5njg, resource: bindings, ignored listing per whitelist
Mar  9 17:00:11.929: INFO: namespace e2e-tests-downward-api-g5njg deletion completed in 6.04928889s

• [SLOW TEST:8.111 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:00:11.930: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:00:11.947683      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-msr8
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 17:00:11.974: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-msr8" in namespace "e2e-tests-subpath-6fj2k" to be "success or failure"
Mar  9 17:00:11.976: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.885938ms
Mar  9 17:00:13.978: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004666829s
Mar  9 17:00:15.980: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 4.006329717s
Mar  9 17:00:17.982: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 6.008058303s
Mar  9 17:00:19.983: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 8.009789285s
Mar  9 17:00:21.985: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 10.011643703s
Mar  9 17:00:23.987: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 12.013337963s
Mar  9 17:00:25.989: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 14.015008241s
Mar  9 17:00:27.990: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 16.016783083s
Mar  9 17:00:29.992: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 18.018301558s
Mar  9 17:00:31.994: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 20.020046654s
Mar  9 17:00:33.995: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Running", Reason="", readiness=false. Elapsed: 22.02174371s
Mar  9 17:00:35.997: INFO: Pod "pod-subpath-test-projected-msr8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023512314s
STEP: Saw pod success
Mar  9 17:00:35.997: INFO: Pod "pod-subpath-test-projected-msr8" satisfied condition "success or failure"
Mar  9 17:00:35.998: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-subpath-test-projected-msr8 container test-container-subpath-projected-msr8: <nil>
STEP: delete the pod
Mar  9 17:00:36.010: INFO: Waiting for pod pod-subpath-test-projected-msr8 to disappear
Mar  9 17:00:36.011: INFO: Pod pod-subpath-test-projected-msr8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-msr8
Mar  9 17:00:36.011: INFO: Deleting pod "pod-subpath-test-projected-msr8" in namespace "e2e-tests-subpath-6fj2k"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:00:36.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6fj2k" for this suite.
Mar  9 17:00:42.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:00:42.039: INFO: namespace: e2e-tests-subpath-6fj2k, resource: bindings, ignored listing per whitelist
Mar  9 17:00:42.079: INFO: namespace e2e-tests-subpath-6fj2k deletion completed in 6.065323848s

• [SLOW TEST:30.149 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:00:42.079: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:00:42.096094      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  9 17:00:42.115: INFO: PodSpec: initContainers in spec.initContainers
Mar  9 17:01:29.333: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-df5378fc-428c-11e9-923b-2eb43f2b540f", GenerateName:"", Namespace:"e2e-tests-init-container-8wmvl", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-8wmvl/pods/pod-init-df5378fc-428c-11e9-923b-2eb43f2b540f", UID:"df53b303-428c-11e9-9882-02b03e914f30", ResourceVersion:"16187", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687747642, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"115515043"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-96k8j", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc423170040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-96k8j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-96k8j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-96k8j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4217b1bb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-192-168-70-73.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420f9fd40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4217b1c30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4217b1c50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4217b1c58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687747642, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687747642, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687747642, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687747642, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.70.73", PodIP:"10.20.192.13", StartTime:(*v1.Time)(0xc420dbc700), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421c25030)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421c250a0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://737aaed9c2b9989915cca4a16925f3525a099f9ea787196559dbd8824dff5598"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420dbc740), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420dbc720), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:01:29.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8wmvl" for this suite.
Mar  9 17:01:45.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:01:45.386: INFO: namespace: e2e-tests-init-container-8wmvl, resource: bindings, ignored listing per whitelist
Mar  9 17:01:45.390: INFO: namespace e2e-tests-init-container-8wmvl deletion completed in 16.046803646s

• [SLOW TEST:63.311 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:01:45.390: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:01:45.407241      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-050fd8d7-428d-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 17:01:45.431: INFO: Waiting up to 5m0s for pod "pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-zhqjq" to be "success or failure"
Mar  9 17:01:45.435: INFO: Pod "pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.369908ms
Mar  9 17:01:47.436: INFO: Pod "pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004672594s
STEP: Saw pod success
Mar  9 17:01:47.436: INFO: Pod "pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:01:47.437: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 17:01:47.449: INFO: Waiting for pod pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:01:47.452: INFO: Pod pod-secrets-051018b6-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:01:47.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zhqjq" for this suite.
Mar  9 17:01:53.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:01:53.499: INFO: namespace: e2e-tests-secrets-zhqjq, resource: bindings, ignored listing per whitelist
Mar  9 17:01:53.501: INFO: namespace e2e-tests-secrets-zhqjq deletion completed in 6.046969531s

• [SLOW TEST:8.111 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:01:53.501: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:01:53.518810      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-09e5b576-428d-11e9-923b-2eb43f2b540f
STEP: Creating configMap with name cm-test-opt-upd-09e5b5c9-428d-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-09e5b576-428d-11e9-923b-2eb43f2b540f
STEP: Updating configmap cm-test-opt-upd-09e5b5c9-428d-11e9-923b-2eb43f2b540f
STEP: Creating configMap with name cm-test-opt-create-09e5b5d9-428d-11e9-923b-2eb43f2b540f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:03:13.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5zm86" for this suite.
Mar  9 17:03:35.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:03:35.728: INFO: namespace: e2e-tests-projected-5zm86, resource: bindings, ignored listing per whitelist
Mar  9 17:03:35.759: INFO: namespace e2e-tests-projected-5zm86 deletion completed in 22.048492707s

• [SLOW TEST:102.258 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:03:35.759: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:03:35.777479      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar  9 17:03:35.802: INFO: Waiting up to 5m0s for pod "client-containers-46d96028-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-containers-qmc4d" to be "success or failure"
Mar  9 17:03:35.805: INFO: Pod "client-containers-46d96028-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.029261ms
Mar  9 17:03:37.806: INFO: Pod "client-containers-46d96028-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004765607s
STEP: Saw pod success
Mar  9 17:03:37.807: INFO: Pod "client-containers-46d96028-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:03:37.808: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod client-containers-46d96028-428d-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 17:03:37.818: INFO: Waiting for pod client-containers-46d96028-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:03:37.819: INFO: Pod client-containers-46d96028-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:03:37.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qmc4d" for this suite.
Mar  9 17:03:43.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:03:43.866: INFO: namespace: e2e-tests-containers-qmc4d, resource: bindings, ignored listing per whitelist
Mar  9 17:03:43.880: INFO: namespace e2e-tests-containers-qmc4d deletion completed in 6.059405023s

• [SLOW TEST:8.120 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:03:43.880: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:03:43.897062      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4bafd1b8-428d-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 17:03:43.919: INFO: Waiting up to 5m0s for pod "pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-2mcnz" to be "success or failure"
Mar  9 17:03:43.923: INFO: Pod "pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.762257ms
Mar  9 17:03:45.924: INFO: Pod "pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005041957s
STEP: Saw pod success
Mar  9 17:03:45.925: INFO: Pod "pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:03:45.926: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 17:03:45.934: INFO: Waiting for pod pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:03:45.935: INFO: Pod pod-secrets-4bb00ebb-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:03:45.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2mcnz" for this suite.
Mar  9 17:03:51.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:03:51.976: INFO: namespace: e2e-tests-secrets-2mcnz, resource: bindings, ignored listing per whitelist
Mar  9 17:03:51.986: INFO: namespace e2e-tests-secrets-2mcnz deletion completed in 6.049450333s

• [SLOW TEST:8.107 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:03:51.987: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:03:52.004620      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 17:03:52.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-gf2m2'
Mar  9 17:03:52.103: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  9 17:03:52.103: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar  9 17:03:52.110: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  9 17:03:52.116: INFO: scanned /root for discovery docs: <nil>
Mar  9 17:03:52.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-gf2m2'
Mar  9 17:04:06.454: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  9 17:04:06.454: INFO: stdout: "Created e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0\nScaling up e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar  9 17:04:06.454: INFO: stdout: "Created e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0\nScaling up e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar  9 17:04:06.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gf2m2'
Mar  9 17:04:06.541: INFO: stderr: ""
Mar  9 17:04:06.541: INFO: stdout: "e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0-f7scw "
Mar  9 17:04:06.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0-f7scw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gf2m2'
Mar  9 17:04:06.617: INFO: stderr: ""
Mar  9 17:04:06.617: INFO: stdout: "true"
Mar  9 17:04:06.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0-f7scw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gf2m2'
Mar  9 17:04:06.694: INFO: stderr: ""
Mar  9 17:04:06.694: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar  9 17:04:06.694: INFO: e2e-test-nginx-rc-7000edc085970702799960e6f709dbd0-f7scw is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar  9 17:04:06.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gf2m2'
Mar  9 17:04:06.773: INFO: stderr: ""
Mar  9 17:04:06.773: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:04:06.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gf2m2" for this suite.
Mar  9 17:04:28.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:04:28.816: INFO: namespace: e2e-tests-kubectl-gf2m2, resource: bindings, ignored listing per whitelist
Mar  9 17:04:28.829: INFO: namespace e2e-tests-kubectl-gf2m2 deletion completed in 22.053627457s

• [SLOW TEST:36.842 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:04:28.829: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:04:28.846589      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  9 17:04:28.868: INFO: Waiting up to 5m0s for pod "pod-667aade8-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-vs7k5" to be "success or failure"
Mar  9 17:04:28.872: INFO: Pod "pod-667aade8-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044964ms
Mar  9 17:04:30.874: INFO: Pod "pod-667aade8-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005736696s
STEP: Saw pod success
Mar  9 17:04:30.874: INFO: Pod "pod-667aade8-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:04:30.875: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-667aade8-428d-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 17:04:30.885: INFO: Waiting for pod pod-667aade8-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:04:30.886: INFO: Pod pod-667aade8-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:04:30.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vs7k5" for this suite.
Mar  9 17:04:36.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:04:36.930: INFO: namespace: e2e-tests-emptydir-vs7k5, resource: bindings, ignored listing per whitelist
Mar  9 17:04:36.936: INFO: namespace e2e-tests-emptydir-vs7k5 deletion completed in 6.049133953s

• [SLOW TEST:8.107 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:04:36.936: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:04:36.954594      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 17:04:36.976: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-ktdcj" to be "success or failure"
Mar  9 17:04:36.980: INFO: Pod "downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.95962ms
Mar  9 17:04:39.273: INFO: Pod "downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.296926618s
STEP: Saw pod success
Mar  9 17:04:39.273: INFO: Pod "downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:04:39.275: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 17:04:39.285: INFO: Waiting for pod downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:04:39.286: INFO: Pod downwardapi-volume-6b4fdbd3-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:04:39.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ktdcj" for this suite.
Mar  9 17:04:45.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:04:45.317: INFO: namespace: e2e-tests-projected-ktdcj, resource: bindings, ignored listing per whitelist
Mar  9 17:04:45.350: INFO: namespace e2e-tests-projected-ktdcj deletion completed in 6.062600241s

• [SLOW TEST:8.414 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:04:45.351: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:04:45.367748      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar  9 17:04:45.392: INFO: Waiting up to 5m0s for pod "client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-containers-8bjlx" to be "success or failure"
Mar  9 17:04:45.395: INFO: Pod "client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.313195ms
Mar  9 17:04:47.397: INFO: Pod "client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004914224s
STEP: Saw pod success
Mar  9 17:04:47.397: INFO: Pod "client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:04:47.398: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 17:04:47.407: INFO: Waiting for pod client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:04:47.408: INFO: Pod client-containers-7053dca6-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:04:47.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8bjlx" for this suite.
Mar  9 17:04:53.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:04:53.466: INFO: namespace: e2e-tests-containers-8bjlx, resource: bindings, ignored listing per whitelist
Mar  9 17:04:53.469: INFO: namespace e2e-tests-containers-8bjlx deletion completed in 6.059254861s

• [SLOW TEST:8.119 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:04:53.469: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:04:53.487783      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar  9 17:04:55.515: INFO: Pod pod-hostip-752aa7bd-428d-11e9-923b-2eb43f2b540f has hostIP: 192.168.70.73
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:04:55.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j9bph" for this suite.
Mar  9 17:05:17.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:05:17.557: INFO: namespace: e2e-tests-pods-j9bph, resource: bindings, ignored listing per whitelist
Mar  9 17:05:17.566: INFO: namespace e2e-tests-pods-j9bph deletion completed in 22.049609911s

• [SLOW TEST:24.097 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:05:17.566: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:05:17.584280      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 17:05:17.609: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  9 17:05:22.610: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  9 17:05:22.610: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  9 17:05:22.621: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-62ncj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-62ncj/deployments/test-cleanup-deployment,UID:8683f100-428d-11e9-9882-02b03e914f30,ResourceVersion:16972,Generation:1,CreationTimestamp:2019-03-09 17:05:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar  9 17:05:22.622: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:05:22.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-62ncj" for this suite.
Mar  9 17:05:28.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:05:28.652: INFO: namespace: e2e-tests-deployment-62ncj, resource: bindings, ignored listing per whitelist
Mar  9 17:05:28.684: INFO: namespace e2e-tests-deployment-62ncj deletion completed in 6.055983888s

• [SLOW TEST:11.118 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:05:28.684: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:05:28.701902      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  9 17:05:28.725: INFO: Waiting up to 5m0s for pod "pod-8a281ab3-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-49kcx" to be "success or failure"
Mar  9 17:05:28.726: INFO: Pod "pod-8a281ab3-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.462271ms
Mar  9 17:05:30.728: INFO: Pod "pod-8a281ab3-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003145904s
STEP: Saw pod success
Mar  9 17:05:30.728: INFO: Pod "pod-8a281ab3-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:05:30.729: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-8a281ab3-428d-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 17:05:30.738: INFO: Waiting for pod pod-8a281ab3-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:05:30.740: INFO: Pod pod-8a281ab3-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:05:30.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-49kcx" for this suite.
Mar  9 17:05:36.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:05:36.755: INFO: namespace: e2e-tests-emptydir-49kcx, resource: bindings, ignored listing per whitelist
Mar  9 17:05:36.788: INFO: namespace e2e-tests-emptydir-49kcx deletion completed in 6.046945747s

• [SLOW TEST:8.104 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:05:36.788: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:05:36.806271      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  9 17:05:36.832: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:36.835: INFO: Number of nodes with available pods: 0
Mar  9 17:05:36.835: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:37.837: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:37.839: INFO: Number of nodes with available pods: 0
Mar  9 17:05:37.839: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:39.367: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:39.369: INFO: Number of nodes with available pods: 1
Mar  9 17:05:39.369: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  9 17:05:39.377: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:39.378: INFO: Number of nodes with available pods: 0
Mar  9 17:05:39.378: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:40.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:40.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:40.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:41.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:41.382: INFO: Number of nodes with available pods: 0
Mar  9 17:05:41.382: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:42.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:42.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:42.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:43.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:43.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:43.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:44.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:44.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:44.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:45.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:45.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:45.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:46.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:46.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:46.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:47.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:47.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:47.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:48.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:48.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:48.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:49.379: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:49.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:49.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:50.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:50.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:50.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:51.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:51.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:51.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:52.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:52.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:52.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:53.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:53.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:53.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:54.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:54.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:54.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:55.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:55.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:55.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:56.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:56.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:56.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:57.379: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:57.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:57.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:58.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:58.381: INFO: Number of nodes with available pods: 0
Mar  9 17:05:58.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:05:59.381: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:05:59.382: INFO: Number of nodes with available pods: 0
Mar  9 17:05:59.382: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:00.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:00.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:00.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:01.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:01.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:01.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:02.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:02.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:02.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:03.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:03.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:03.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:04.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:04.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:04.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:05.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:05.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:05.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:06.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:06.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:06.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:07.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:07.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:07.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:08.667: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:08.669: INFO: Number of nodes with available pods: 0
Mar  9 17:06:08.669: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:09.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:09.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:09.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:10.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:10.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:10.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:11.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:11.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:11.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:12.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:12.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:12.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:13.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:13.381: INFO: Number of nodes with available pods: 0
Mar  9 17:06:13.381: INFO: Node ip-192-168-70-73.us-west-2.compute.internal is running more than one daemon pod
Mar  9 17:06:14.380: INFO: DaemonSet pods can't tolerate node ip-192-168-65-29.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 17:06:14.381: INFO: Number of nodes with available pods: 1
Mar  9 17:06:14.381: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-5xdw5, will wait for the garbage collector to delete the pods
Mar  9 17:06:14.436: INFO: Deleting {extensions DaemonSet} daemon-set took: 2.745808ms
Mar  9 17:06:14.536: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.150349ms
Mar  9 17:06:49.838: INFO: Number of nodes with available pods: 0
Mar  9 17:06:49.838: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 17:06:49.839: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5xdw5/daemonsets","resourceVersion":"17221"},"items":null}

Mar  9 17:06:49.840: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5xdw5/pods","resourceVersion":"17221"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:06:49.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5xdw5" for this suite.
Mar  9 17:06:55.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:06:55.862: INFO: namespace: e2e-tests-daemonsets-5xdw5, resource: bindings, ignored listing per whitelist
Mar  9 17:06:55.890: INFO: namespace e2e-tests-daemonsets-5xdw5 deletion completed in 6.046472398s

• [SLOW TEST:79.102 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:06:55.891: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:06:55.912372      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kqjjb
Mar  9 17:06:57.943: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kqjjb
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 17:06:57.945: INFO: Initial restart count of pod liveness-http is 0
Mar  9 17:07:21.965: INFO: Restart count of pod e2e-tests-container-probe-kqjjb/liveness-http is now 1 (24.020289114s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:07:21.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kqjjb" for this suite.
Mar  9 17:07:27.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:07:28.013: INFO: namespace: e2e-tests-container-probe-kqjjb, resource: bindings, ignored listing per whitelist
Mar  9 17:07:28.027: INFO: namespace e2e-tests-container-probe-kqjjb deletion completed in 6.052082213s

• [SLOW TEST:32.136 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:07:28.027: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:07:28.044327      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-gkn42
I0309 17:07:28.066419      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-gkn42, replica count: 1
I0309 17:07:29.116692      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 17:07:29.222: INFO: Created: latency-svc-2xbp2
Mar  9 17:07:29.227: INFO: Got endpoints: latency-svc-2xbp2 [10.3136ms]
Mar  9 17:07:29.234: INFO: Created: latency-svc-9bk5d
Mar  9 17:07:29.238: INFO: Got endpoints: latency-svc-9bk5d [11.41093ms]
Mar  9 17:07:29.242: INFO: Created: latency-svc-p4btz
Mar  9 17:07:29.246: INFO: Got endpoints: latency-svc-p4btz [19.149872ms]
Mar  9 17:07:29.255: INFO: Created: latency-svc-bsww8
Mar  9 17:07:29.255: INFO: Created: latency-svc-z6t8d
Mar  9 17:07:29.255: INFO: Got endpoints: latency-svc-z6t8d [27.541573ms]
Mar  9 17:07:29.258: INFO: Got endpoints: latency-svc-bsww8 [31.240066ms]
Mar  9 17:07:29.259: INFO: Created: latency-svc-nbxbt
Mar  9 17:07:29.262: INFO: Got endpoints: latency-svc-nbxbt [34.184913ms]
Mar  9 17:07:29.263: INFO: Created: latency-svc-qft9p
Mar  9 17:07:29.266: INFO: Created: latency-svc-sbn7p
Mar  9 17:07:29.266: INFO: Got endpoints: latency-svc-qft9p [37.491571ms]
Mar  9 17:07:29.272: INFO: Got endpoints: latency-svc-sbn7p [43.201636ms]
Mar  9 17:07:29.272: INFO: Created: latency-svc-gg5r4
Mar  9 17:07:29.274: INFO: Got endpoints: latency-svc-gg5r4 [45.587431ms]
Mar  9 17:07:29.280: INFO: Created: latency-svc-57cvp
Mar  9 17:07:29.282: INFO: Got endpoints: latency-svc-57cvp [53.209638ms]
Mar  9 17:07:29.287: INFO: Created: latency-svc-bmzgc
Mar  9 17:07:29.291: INFO: Got endpoints: latency-svc-bmzgc [61.576101ms]
Mar  9 17:07:29.293: INFO: Created: latency-svc-4db6g
Mar  9 17:07:29.297: INFO: Got endpoints: latency-svc-4db6g [67.714364ms]
Mar  9 17:07:29.305: INFO: Created: latency-svc-r4p94
Mar  9 17:07:29.307: INFO: Got endpoints: latency-svc-r4p94 [78.448526ms]
Mar  9 17:07:29.318: INFO: Created: latency-svc-gzfkw
Mar  9 17:07:29.324: INFO: Got endpoints: latency-svc-gzfkw [94.764045ms]
Mar  9 17:07:29.325: INFO: Created: latency-svc-lth7q
Mar  9 17:07:29.329: INFO: Got endpoints: latency-svc-lth7q [99.740881ms]
Mar  9 17:07:29.330: INFO: Created: latency-svc-p26lh
Mar  9 17:07:29.333: INFO: Got endpoints: latency-svc-p26lh [103.712112ms]
Mar  9 17:07:29.345: INFO: Created: latency-svc-tzhxf
Mar  9 17:07:29.345: INFO: Got endpoints: latency-svc-tzhxf [106.840036ms]
Mar  9 17:07:29.349: INFO: Created: latency-svc-rjbft
Mar  9 17:07:29.353: INFO: Got endpoints: latency-svc-rjbft [107.188687ms]
Mar  9 17:07:29.356: INFO: Created: latency-svc-9n666
Mar  9 17:07:29.359: INFO: Got endpoints: latency-svc-9n666 [104.032418ms]
Mar  9 17:07:29.362: INFO: Created: latency-svc-t5mfn
Mar  9 17:07:29.364: INFO: Got endpoints: latency-svc-t5mfn [105.505299ms]
Mar  9 17:07:29.367: INFO: Created: latency-svc-njqvc
Mar  9 17:07:29.371: INFO: Got endpoints: latency-svc-njqvc [108.979938ms]
Mar  9 17:07:29.375: INFO: Created: latency-svc-vn7l2
Mar  9 17:07:29.376: INFO: Got endpoints: latency-svc-vn7l2 [110.352036ms]
Mar  9 17:07:29.382: INFO: Created: latency-svc-h64dg
Mar  9 17:07:29.384: INFO: Got endpoints: latency-svc-h64dg [112.374381ms]
Mar  9 17:07:29.389: INFO: Created: latency-svc-xmfld
Mar  9 17:07:29.391: INFO: Got endpoints: latency-svc-xmfld [116.92089ms]
Mar  9 17:07:29.397: INFO: Created: latency-svc-bl48n
Mar  9 17:07:29.399: INFO: Got endpoints: latency-svc-bl48n [116.987504ms]
Mar  9 17:07:29.401: INFO: Created: latency-svc-fkd49
Mar  9 17:07:29.407: INFO: Got endpoints: latency-svc-fkd49 [116.129488ms]
Mar  9 17:07:29.407: INFO: Created: latency-svc-t547z
Mar  9 17:07:29.409: INFO: Got endpoints: latency-svc-t547z [112.229161ms]
Mar  9 17:07:29.416: INFO: Created: latency-svc-mvw5m
Mar  9 17:07:29.419: INFO: Got endpoints: latency-svc-mvw5m [111.682137ms]
Mar  9 17:07:29.424: INFO: Created: latency-svc-xctbr
Mar  9 17:07:29.427: INFO: Got endpoints: latency-svc-xctbr [103.601621ms]
Mar  9 17:07:29.432: INFO: Created: latency-svc-85s8q
Mar  9 17:07:29.436: INFO: Created: latency-svc-nddkz
Mar  9 17:07:29.437: INFO: Got endpoints: latency-svc-85s8q [107.63195ms]
Mar  9 17:07:29.440: INFO: Got endpoints: latency-svc-nddkz [106.853653ms]
Mar  9 17:07:29.444: INFO: Created: latency-svc-xxsn8
Mar  9 17:07:29.453: INFO: Got endpoints: latency-svc-xxsn8 [107.625548ms]
Mar  9 17:07:29.458: INFO: Created: latency-svc-jrr6n
Mar  9 17:07:29.460: INFO: Got endpoints: latency-svc-jrr6n [106.307993ms]
Mar  9 17:07:29.463: INFO: Created: latency-svc-58vrn
Mar  9 17:07:29.466: INFO: Got endpoints: latency-svc-58vrn [107.073226ms]
Mar  9 17:07:29.466: INFO: Created: latency-svc-5wgpg
Mar  9 17:07:29.472: INFO: Created: latency-svc-t79k9
Mar  9 17:07:29.477: INFO: Got endpoints: latency-svc-5wgpg [113.263674ms]
Mar  9 17:07:29.479: INFO: Created: latency-svc-qtgp8
Mar  9 17:07:29.483: INFO: Created: latency-svc-nhbq2
Mar  9 17:07:29.488: INFO: Created: latency-svc-ntm69
Mar  9 17:07:29.493: INFO: Created: latency-svc-p7xgc
Mar  9 17:07:29.500: INFO: Created: latency-svc-mbbvv
Mar  9 17:07:29.503: INFO: Created: latency-svc-gschx
Mar  9 17:07:29.508: INFO: Created: latency-svc-xcrmh
Mar  9 17:07:29.512: INFO: Created: latency-svc-tjrsc
Mar  9 17:07:29.518: INFO: Created: latency-svc-jwr57
Mar  9 17:07:29.523: INFO: Created: latency-svc-dzpqg
Mar  9 17:07:29.524: INFO: Got endpoints: latency-svc-t79k9 [152.366889ms]
Mar  9 17:07:29.527: INFO: Created: latency-svc-gwtlp
Mar  9 17:07:29.532: INFO: Created: latency-svc-n2njj
Mar  9 17:07:29.538: INFO: Created: latency-svc-94h7q
Mar  9 17:07:29.544: INFO: Created: latency-svc-xh2bb
Mar  9 17:07:29.547: INFO: Created: latency-svc-bt5l4
Mar  9 17:07:29.573: INFO: Got endpoints: latency-svc-qtgp8 [196.752526ms]
Mar  9 17:07:29.579: INFO: Created: latency-svc-wsrml
Mar  9 17:07:29.623: INFO: Got endpoints: latency-svc-nhbq2 [238.640089ms]
Mar  9 17:07:29.628: INFO: Created: latency-svc-stf5q
Mar  9 17:07:29.674: INFO: Got endpoints: latency-svc-ntm69 [282.495907ms]
Mar  9 17:07:29.681: INFO: Created: latency-svc-vqcgx
Mar  9 17:07:29.724: INFO: Got endpoints: latency-svc-p7xgc [325.070285ms]
Mar  9 17:07:29.730: INFO: Created: latency-svc-zc6n5
Mar  9 17:07:29.774: INFO: Got endpoints: latency-svc-mbbvv [366.491062ms]
Mar  9 17:07:29.781: INFO: Created: latency-svc-df44m
Mar  9 17:07:29.825: INFO: Got endpoints: latency-svc-gschx [416.141338ms]
Mar  9 17:07:29.830: INFO: Created: latency-svc-qg2l2
Mar  9 17:07:29.874: INFO: Got endpoints: latency-svc-xcrmh [454.813434ms]
Mar  9 17:07:29.880: INFO: Created: latency-svc-p2jcd
Mar  9 17:07:29.924: INFO: Got endpoints: latency-svc-tjrsc [496.092322ms]
Mar  9 17:07:29.930: INFO: Created: latency-svc-wmfq6
Mar  9 17:07:29.974: INFO: Got endpoints: latency-svc-jwr57 [536.836324ms]
Mar  9 17:07:29.980: INFO: Created: latency-svc-25842
Mar  9 17:07:30.023: INFO: Got endpoints: latency-svc-dzpqg [582.756913ms]
Mar  9 17:07:30.029: INFO: Created: latency-svc-m6v5n
Mar  9 17:07:30.074: INFO: Got endpoints: latency-svc-gwtlp [621.639599ms]
Mar  9 17:07:30.079: INFO: Created: latency-svc-vmpcb
Mar  9 17:07:30.125: INFO: Got endpoints: latency-svc-n2njj [665.095408ms]
Mar  9 17:07:30.131: INFO: Created: latency-svc-9474j
Mar  9 17:07:30.175: INFO: Got endpoints: latency-svc-94h7q [708.848191ms]
Mar  9 17:07:30.181: INFO: Created: latency-svc-gffhf
Mar  9 17:07:30.224: INFO: Got endpoints: latency-svc-xh2bb [746.779564ms]
Mar  9 17:07:30.230: INFO: Created: latency-svc-dxhpk
Mar  9 17:07:30.274: INFO: Got endpoints: latency-svc-bt5l4 [749.551539ms]
Mar  9 17:07:30.284: INFO: Created: latency-svc-tswrb
Mar  9 17:07:30.325: INFO: Got endpoints: latency-svc-wsrml [751.331146ms]
Mar  9 17:07:30.331: INFO: Created: latency-svc-l6gfp
Mar  9 17:07:30.375: INFO: Got endpoints: latency-svc-stf5q [752.358306ms]
Mar  9 17:07:30.381: INFO: Created: latency-svc-n4252
Mar  9 17:07:30.425: INFO: Got endpoints: latency-svc-vqcgx [751.340412ms]
Mar  9 17:07:30.431: INFO: Created: latency-svc-ft92s
Mar  9 17:07:30.473: INFO: Got endpoints: latency-svc-zc6n5 [749.148994ms]
Mar  9 17:07:30.479: INFO: Created: latency-svc-xplp5
Mar  9 17:07:30.525: INFO: Got endpoints: latency-svc-df44m [750.957724ms]
Mar  9 17:07:30.531: INFO: Created: latency-svc-mnsmh
Mar  9 17:07:30.575: INFO: Got endpoints: latency-svc-qg2l2 [749.890673ms]
Mar  9 17:07:30.581: INFO: Created: latency-svc-9jc62
Mar  9 17:07:30.623: INFO: Got endpoints: latency-svc-p2jcd [749.180268ms]
Mar  9 17:07:30.630: INFO: Created: latency-svc-tz745
Mar  9 17:07:30.675: INFO: Got endpoints: latency-svc-wmfq6 [751.881903ms]
Mar  9 17:07:30.683: INFO: Created: latency-svc-x7xjn
Mar  9 17:07:30.724: INFO: Got endpoints: latency-svc-25842 [750.444747ms]
Mar  9 17:07:30.732: INFO: Created: latency-svc-vhc42
Mar  9 17:07:30.775: INFO: Got endpoints: latency-svc-m6v5n [752.73895ms]
Mar  9 17:07:30.781: INFO: Created: latency-svc-fcr7n
Mar  9 17:07:30.823: INFO: Got endpoints: latency-svc-vmpcb [748.955509ms]
Mar  9 17:07:30.831: INFO: Created: latency-svc-xdpc6
Mar  9 17:07:30.874: INFO: Got endpoints: latency-svc-9474j [749.347289ms]
Mar  9 17:07:30.880: INFO: Created: latency-svc-69xmf
Mar  9 17:07:30.923: INFO: Got endpoints: latency-svc-gffhf [748.673069ms]
Mar  9 17:07:30.929: INFO: Created: latency-svc-ffnkx
Mar  9 17:07:30.973: INFO: Got endpoints: latency-svc-dxhpk [749.257432ms]
Mar  9 17:07:30.979: INFO: Created: latency-svc-9q8bn
Mar  9 17:07:31.026: INFO: Got endpoints: latency-svc-tswrb [751.728005ms]
Mar  9 17:07:31.033: INFO: Created: latency-svc-ws285
Mar  9 17:07:31.074: INFO: Got endpoints: latency-svc-l6gfp [749.534647ms]
Mar  9 17:07:31.081: INFO: Created: latency-svc-p9n8n
Mar  9 17:07:31.124: INFO: Got endpoints: latency-svc-n4252 [748.497708ms]
Mar  9 17:07:31.128: INFO: Created: latency-svc-84qdx
Mar  9 17:07:31.175: INFO: Got endpoints: latency-svc-ft92s [749.581699ms]
Mar  9 17:07:31.180: INFO: Created: latency-svc-g7hvq
Mar  9 17:07:31.224: INFO: Got endpoints: latency-svc-xplp5 [751.142178ms]
Mar  9 17:07:31.231: INFO: Created: latency-svc-22xkd
Mar  9 17:07:31.273: INFO: Got endpoints: latency-svc-mnsmh [748.602734ms]
Mar  9 17:07:31.279: INFO: Created: latency-svc-mxt5x
Mar  9 17:07:31.324: INFO: Got endpoints: latency-svc-9jc62 [749.279195ms]
Mar  9 17:07:31.331: INFO: Created: latency-svc-wh449
Mar  9 17:07:31.375: INFO: Got endpoints: latency-svc-tz745 [751.638561ms]
Mar  9 17:07:31.382: INFO: Created: latency-svc-f4sff
Mar  9 17:07:31.424: INFO: Got endpoints: latency-svc-x7xjn [748.268634ms]
Mar  9 17:07:31.429: INFO: Created: latency-svc-5r6vt
Mar  9 17:07:31.474: INFO: Got endpoints: latency-svc-vhc42 [749.817229ms]
Mar  9 17:07:31.484: INFO: Created: latency-svc-sg9r2
Mar  9 17:07:31.524: INFO: Got endpoints: latency-svc-fcr7n [748.298086ms]
Mar  9 17:07:31.531: INFO: Created: latency-svc-gmkw5
Mar  9 17:07:31.573: INFO: Got endpoints: latency-svc-xdpc6 [750.037537ms]
Mar  9 17:07:31.577: INFO: Created: latency-svc-4rn7x
Mar  9 17:07:31.625: INFO: Got endpoints: latency-svc-69xmf [750.341405ms]
Mar  9 17:07:31.631: INFO: Created: latency-svc-z9fhj
Mar  9 17:07:31.674: INFO: Got endpoints: latency-svc-ffnkx [750.1445ms]
Mar  9 17:07:31.679: INFO: Created: latency-svc-4mzvm
Mar  9 17:07:31.724: INFO: Got endpoints: latency-svc-9q8bn [750.551225ms]
Mar  9 17:07:31.731: INFO: Created: latency-svc-vnlbh
Mar  9 17:07:31.773: INFO: Got endpoints: latency-svc-ws285 [746.987556ms]
Mar  9 17:07:31.780: INFO: Created: latency-svc-rbxtn
Mar  9 17:07:31.824: INFO: Got endpoints: latency-svc-p9n8n [749.807448ms]
Mar  9 17:07:31.830: INFO: Created: latency-svc-hnjgw
Mar  9 17:07:31.873: INFO: Got endpoints: latency-svc-84qdx [749.27826ms]
Mar  9 17:07:31.880: INFO: Created: latency-svc-ptsnf
Mar  9 17:07:31.925: INFO: Got endpoints: latency-svc-g7hvq [750.909888ms]
Mar  9 17:07:31.932: INFO: Created: latency-svc-d88v8
Mar  9 17:07:31.973: INFO: Got endpoints: latency-svc-22xkd [748.654267ms]
Mar  9 17:07:31.979: INFO: Created: latency-svc-zxtlq
Mar  9 17:07:32.024: INFO: Got endpoints: latency-svc-mxt5x [750.649814ms]
Mar  9 17:07:32.030: INFO: Created: latency-svc-gs8j2
Mar  9 17:07:32.074: INFO: Got endpoints: latency-svc-wh449 [749.411759ms]
Mar  9 17:07:32.081: INFO: Created: latency-svc-66hk9
Mar  9 17:07:32.123: INFO: Got endpoints: latency-svc-f4sff [748.338933ms]
Mar  9 17:07:32.130: INFO: Created: latency-svc-nnvvd
Mar  9 17:07:32.173: INFO: Got endpoints: latency-svc-5r6vt [749.10144ms]
Mar  9 17:07:32.179: INFO: Created: latency-svc-d2d85
Mar  9 17:07:32.225: INFO: Got endpoints: latency-svc-sg9r2 [750.484456ms]
Mar  9 17:07:32.231: INFO: Created: latency-svc-28xzv
Mar  9 17:07:32.273: INFO: Got endpoints: latency-svc-gmkw5 [749.377757ms]
Mar  9 17:07:32.278: INFO: Created: latency-svc-zf92c
Mar  9 17:07:32.324: INFO: Got endpoints: latency-svc-4rn7x [750.506382ms]
Mar  9 17:07:32.329: INFO: Created: latency-svc-qnkk9
Mar  9 17:07:32.373: INFO: Got endpoints: latency-svc-z9fhj [748.473789ms]
Mar  9 17:07:32.379: INFO: Created: latency-svc-fj8xz
Mar  9 17:07:32.424: INFO: Got endpoints: latency-svc-4mzvm [750.501488ms]
Mar  9 17:07:32.428: INFO: Created: latency-svc-mxvqj
Mar  9 17:07:32.473: INFO: Got endpoints: latency-svc-vnlbh [748.965834ms]
Mar  9 17:07:32.479: INFO: Created: latency-svc-4d7g6
Mar  9 17:07:32.524: INFO: Got endpoints: latency-svc-rbxtn [751.058031ms]
Mar  9 17:07:32.529: INFO: Created: latency-svc-7tjmv
Mar  9 17:07:32.573: INFO: Got endpoints: latency-svc-hnjgw [749.400208ms]
Mar  9 17:07:32.580: INFO: Created: latency-svc-vghjg
Mar  9 17:07:32.624: INFO: Got endpoints: latency-svc-ptsnf [751.323835ms]
Mar  9 17:07:32.631: INFO: Created: latency-svc-ckdjs
Mar  9 17:07:32.673: INFO: Got endpoints: latency-svc-d88v8 [747.334664ms]
Mar  9 17:07:32.679: INFO: Created: latency-svc-7qklg
Mar  9 17:07:32.724: INFO: Got endpoints: latency-svc-zxtlq [751.041411ms]
Mar  9 17:07:32.734: INFO: Created: latency-svc-mhnkj
Mar  9 17:07:32.773: INFO: Got endpoints: latency-svc-gs8j2 [749.398331ms]
Mar  9 17:07:32.780: INFO: Created: latency-svc-qlzwc
Mar  9 17:07:32.831: INFO: Got endpoints: latency-svc-66hk9 [757.492556ms]
Mar  9 17:07:32.846: INFO: Created: latency-svc-hhgs9
Mar  9 17:07:32.876: INFO: Got endpoints: latency-svc-nnvvd [752.462558ms]
Mar  9 17:07:32.881: INFO: Created: latency-svc-qnzpl
Mar  9 17:07:32.923: INFO: Got endpoints: latency-svc-d2d85 [749.830645ms]
Mar  9 17:07:32.928: INFO: Created: latency-svc-kmqcx
Mar  9 17:07:32.974: INFO: Got endpoints: latency-svc-28xzv [749.859771ms]
Mar  9 17:07:32.982: INFO: Created: latency-svc-9fz28
Mar  9 17:07:33.024: INFO: Got endpoints: latency-svc-zf92c [750.587263ms]
Mar  9 17:07:33.029: INFO: Created: latency-svc-2rnh8
Mar  9 17:07:33.074: INFO: Got endpoints: latency-svc-qnkk9 [750.517129ms]
Mar  9 17:07:33.082: INFO: Created: latency-svc-p8p75
Mar  9 17:07:33.123: INFO: Got endpoints: latency-svc-fj8xz [749.708553ms]
Mar  9 17:07:33.130: INFO: Created: latency-svc-gjdw8
Mar  9 17:07:33.175: INFO: Got endpoints: latency-svc-mxvqj [750.649707ms]
Mar  9 17:07:33.182: INFO: Created: latency-svc-kkrp9
Mar  9 17:07:33.224: INFO: Got endpoints: latency-svc-4d7g6 [750.758713ms]
Mar  9 17:07:33.229: INFO: Created: latency-svc-kwvrr
Mar  9 17:07:33.274: INFO: Got endpoints: latency-svc-7tjmv [750.321709ms]
Mar  9 17:07:33.280: INFO: Created: latency-svc-tqnwm
Mar  9 17:07:33.323: INFO: Got endpoints: latency-svc-vghjg [749.247936ms]
Mar  9 17:07:33.328: INFO: Created: latency-svc-fw8r4
Mar  9 17:07:33.374: INFO: Got endpoints: latency-svc-ckdjs [749.616178ms]
Mar  9 17:07:33.379: INFO: Created: latency-svc-cr4tl
Mar  9 17:07:33.423: INFO: Got endpoints: latency-svc-7qklg [749.776001ms]
Mar  9 17:07:33.429: INFO: Created: latency-svc-chkxt
Mar  9 17:07:33.474: INFO: Got endpoints: latency-svc-mhnkj [749.420349ms]
Mar  9 17:07:33.481: INFO: Created: latency-svc-l8mtd
Mar  9 17:07:33.523: INFO: Got endpoints: latency-svc-qlzwc [750.016505ms]
Mar  9 17:07:33.529: INFO: Created: latency-svc-drw2g
Mar  9 17:07:33.574: INFO: Got endpoints: latency-svc-hhgs9 [742.611096ms]
Mar  9 17:07:33.584: INFO: Created: latency-svc-8cvn9
Mar  9 17:07:33.625: INFO: Got endpoints: latency-svc-qnzpl [749.012416ms]
Mar  9 17:07:33.631: INFO: Created: latency-svc-vdvh6
Mar  9 17:07:33.676: INFO: Got endpoints: latency-svc-kmqcx [753.657895ms]
Mar  9 17:07:33.686: INFO: Created: latency-svc-dtjg5
Mar  9 17:07:33.724: INFO: Got endpoints: latency-svc-9fz28 [749.74926ms]
Mar  9 17:07:33.733: INFO: Created: latency-svc-4vln9
Mar  9 17:07:33.777: INFO: Got endpoints: latency-svc-2rnh8 [752.749884ms]
Mar  9 17:07:33.782: INFO: Created: latency-svc-k9jbk
Mar  9 17:07:33.824: INFO: Got endpoints: latency-svc-p8p75 [749.133169ms]
Mar  9 17:07:33.829: INFO: Created: latency-svc-fzxf5
Mar  9 17:07:33.874: INFO: Got endpoints: latency-svc-gjdw8 [750.902583ms]
Mar  9 17:07:33.880: INFO: Created: latency-svc-v99l5
Mar  9 17:07:33.924: INFO: Got endpoints: latency-svc-kkrp9 [749.296958ms]
Mar  9 17:07:33.930: INFO: Created: latency-svc-55rv7
Mar  9 17:07:33.973: INFO: Got endpoints: latency-svc-kwvrr [749.339202ms]
Mar  9 17:07:33.980: INFO: Created: latency-svc-kr69d
Mar  9 17:07:34.029: INFO: Got endpoints: latency-svc-tqnwm [754.759609ms]
Mar  9 17:07:34.034: INFO: Created: latency-svc-gw4nw
Mar  9 17:07:34.074: INFO: Got endpoints: latency-svc-fw8r4 [750.922365ms]
Mar  9 17:07:34.078: INFO: Created: latency-svc-rpbfx
Mar  9 17:07:34.124: INFO: Got endpoints: latency-svc-cr4tl [750.25503ms]
Mar  9 17:07:34.132: INFO: Created: latency-svc-x52vj
Mar  9 17:07:34.184: INFO: Got endpoints: latency-svc-chkxt [761.793728ms]
Mar  9 17:07:34.191: INFO: Created: latency-svc-tctkm
Mar  9 17:07:34.224: INFO: Got endpoints: latency-svc-l8mtd [750.222072ms]
Mar  9 17:07:34.229: INFO: Created: latency-svc-d46rw
Mar  9 17:07:34.274: INFO: Got endpoints: latency-svc-drw2g [750.290037ms]
Mar  9 17:07:34.280: INFO: Created: latency-svc-7vn99
Mar  9 17:07:34.323: INFO: Got endpoints: latency-svc-8cvn9 [749.438286ms]
Mar  9 17:07:34.329: INFO: Created: latency-svc-f5lmj
Mar  9 17:07:34.374: INFO: Got endpoints: latency-svc-vdvh6 [749.014995ms]
Mar  9 17:07:34.380: INFO: Created: latency-svc-4ftkc
Mar  9 17:07:34.423: INFO: Got endpoints: latency-svc-dtjg5 [746.970955ms]
Mar  9 17:07:34.428: INFO: Created: latency-svc-qlrw5
Mar  9 17:07:34.474: INFO: Got endpoints: latency-svc-4vln9 [748.998941ms]
Mar  9 17:07:34.480: INFO: Created: latency-svc-46gsk
Mar  9 17:07:34.527: INFO: Got endpoints: latency-svc-k9jbk [750.440583ms]
Mar  9 17:07:34.534: INFO: Created: latency-svc-fhqpp
Mar  9 17:07:34.575: INFO: Got endpoints: latency-svc-fzxf5 [750.951896ms]
Mar  9 17:07:34.580: INFO: Created: latency-svc-rcfsn
Mar  9 17:07:34.624: INFO: Got endpoints: latency-svc-v99l5 [750.62197ms]
Mar  9 17:07:34.631: INFO: Created: latency-svc-wzxxt
Mar  9 17:07:34.673: INFO: Got endpoints: latency-svc-55rv7 [748.537802ms]
Mar  9 17:07:34.678: INFO: Created: latency-svc-qsznm
Mar  9 17:07:34.724: INFO: Got endpoints: latency-svc-kr69d [750.665615ms]
Mar  9 17:07:34.734: INFO: Created: latency-svc-jprjc
Mar  9 17:07:34.774: INFO: Got endpoints: latency-svc-gw4nw [744.821466ms]
Mar  9 17:07:34.783: INFO: Created: latency-svc-xrrfr
Mar  9 17:07:34.823: INFO: Got endpoints: latency-svc-rpbfx [749.566451ms]
Mar  9 17:07:34.829: INFO: Created: latency-svc-hfcrm
Mar  9 17:07:34.874: INFO: Got endpoints: latency-svc-x52vj [749.342458ms]
Mar  9 17:07:34.880: INFO: Created: latency-svc-ld7th
Mar  9 17:07:34.924: INFO: Got endpoints: latency-svc-tctkm [739.281717ms]
Mar  9 17:07:34.929: INFO: Created: latency-svc-7bdfd
Mar  9 17:07:34.973: INFO: Got endpoints: latency-svc-d46rw [749.371931ms]
Mar  9 17:07:34.979: INFO: Created: latency-svc-kkb5d
Mar  9 17:07:35.031: INFO: Got endpoints: latency-svc-7vn99 [757.57977ms]
Mar  9 17:07:35.038: INFO: Created: latency-svc-r24kd
Mar  9 17:07:35.074: INFO: Got endpoints: latency-svc-f5lmj [750.813543ms]
Mar  9 17:07:35.080: INFO: Created: latency-svc-557l6
Mar  9 17:07:35.124: INFO: Got endpoints: latency-svc-4ftkc [749.943975ms]
Mar  9 17:07:35.131: INFO: Created: latency-svc-qhnzq
Mar  9 17:07:35.173: INFO: Got endpoints: latency-svc-qlrw5 [749.987598ms]
Mar  9 17:07:35.178: INFO: Created: latency-svc-k6q9h
Mar  9 17:07:35.224: INFO: Got endpoints: latency-svc-46gsk [750.017077ms]
Mar  9 17:07:35.232: INFO: Created: latency-svc-dxsmk
Mar  9 17:07:35.273: INFO: Got endpoints: latency-svc-fhqpp [745.669273ms]
Mar  9 17:07:35.279: INFO: Created: latency-svc-xm9ff
Mar  9 17:07:35.324: INFO: Got endpoints: latency-svc-rcfsn [749.094092ms]
Mar  9 17:07:35.332: INFO: Created: latency-svc-t2f8g
Mar  9 17:07:35.380: INFO: Got endpoints: latency-svc-wzxxt [756.061159ms]
Mar  9 17:07:35.387: INFO: Created: latency-svc-tr9vw
Mar  9 17:07:35.424: INFO: Got endpoints: latency-svc-qsznm [751.665891ms]
Mar  9 17:07:35.430: INFO: Created: latency-svc-gv7l2
Mar  9 17:07:35.474: INFO: Got endpoints: latency-svc-jprjc [750.443583ms]
Mar  9 17:07:35.480: INFO: Created: latency-svc-dz5ft
Mar  9 17:07:35.526: INFO: Got endpoints: latency-svc-xrrfr [752.387231ms]
Mar  9 17:07:35.533: INFO: Created: latency-svc-8l5hr
Mar  9 17:07:35.573: INFO: Got endpoints: latency-svc-hfcrm [749.876127ms]
Mar  9 17:07:35.578: INFO: Created: latency-svc-sdfd2
Mar  9 17:07:35.624: INFO: Got endpoints: latency-svc-ld7th [749.892519ms]
Mar  9 17:07:35.630: INFO: Created: latency-svc-7k96w
Mar  9 17:07:35.674: INFO: Got endpoints: latency-svc-7bdfd [750.233835ms]
Mar  9 17:07:35.680: INFO: Created: latency-svc-x7jmb
Mar  9 17:07:35.722: INFO: Got endpoints: latency-svc-kkb5d [748.915306ms]
Mar  9 17:07:35.728: INFO: Created: latency-svc-w2q7m
Mar  9 17:07:35.774: INFO: Got endpoints: latency-svc-r24kd [742.168766ms]
Mar  9 17:07:35.779: INFO: Created: latency-svc-4hjxq
Mar  9 17:07:35.824: INFO: Got endpoints: latency-svc-557l6 [749.577053ms]
Mar  9 17:07:35.830: INFO: Created: latency-svc-nxgsh
Mar  9 17:07:35.872: INFO: Got endpoints: latency-svc-qhnzq [748.725496ms]
Mar  9 17:07:35.877: INFO: Created: latency-svc-fd2zc
Mar  9 17:07:35.923: INFO: Got endpoints: latency-svc-k6q9h [749.790408ms]
Mar  9 17:07:35.930: INFO: Created: latency-svc-5fl59
Mar  9 17:07:35.974: INFO: Got endpoints: latency-svc-dxsmk [750.22812ms]
Mar  9 17:07:35.980: INFO: Created: latency-svc-nnprk
Mar  9 17:07:36.023: INFO: Got endpoints: latency-svc-xm9ff [750.463018ms]
Mar  9 17:07:36.030: INFO: Created: latency-svc-mzk2q
Mar  9 17:07:36.073: INFO: Got endpoints: latency-svc-t2f8g [749.746814ms]
Mar  9 17:07:36.080: INFO: Created: latency-svc-d6zcm
Mar  9 17:07:36.125: INFO: Got endpoints: latency-svc-tr9vw [744.912657ms]
Mar  9 17:07:36.131: INFO: Created: latency-svc-kps8n
Mar  9 17:07:36.173: INFO: Got endpoints: latency-svc-gv7l2 [749.045884ms]
Mar  9 17:07:36.182: INFO: Created: latency-svc-9tqff
Mar  9 17:07:36.225: INFO: Got endpoints: latency-svc-dz5ft [750.273188ms]
Mar  9 17:07:36.230: INFO: Created: latency-svc-f8sgf
Mar  9 17:07:36.275: INFO: Got endpoints: latency-svc-8l5hr [748.464948ms]
Mar  9 17:07:36.281: INFO: Created: latency-svc-4hwvs
Mar  9 17:07:36.324: INFO: Got endpoints: latency-svc-sdfd2 [750.979837ms]
Mar  9 17:07:36.330: INFO: Created: latency-svc-b82d4
Mar  9 17:07:36.375: INFO: Got endpoints: latency-svc-7k96w [750.557256ms]
Mar  9 17:07:36.381: INFO: Created: latency-svc-cw7pq
Mar  9 17:07:36.424: INFO: Got endpoints: latency-svc-x7jmb [749.989044ms]
Mar  9 17:07:36.429: INFO: Created: latency-svc-wb4bz
Mar  9 17:07:36.476: INFO: Got endpoints: latency-svc-w2q7m [753.682428ms]
Mar  9 17:07:36.515: INFO: Created: latency-svc-8wngd
Mar  9 17:07:36.524: INFO: Got endpoints: latency-svc-4hjxq [749.887791ms]
Mar  9 17:07:36.530: INFO: Created: latency-svc-6rqtm
Mar  9 17:07:36.575: INFO: Got endpoints: latency-svc-nxgsh [750.537838ms]
Mar  9 17:07:36.582: INFO: Created: latency-svc-mvp86
Mar  9 17:07:36.624: INFO: Got endpoints: latency-svc-fd2zc [751.90785ms]
Mar  9 17:07:36.630: INFO: Created: latency-svc-pmxdm
Mar  9 17:07:36.674: INFO: Got endpoints: latency-svc-5fl59 [750.787913ms]
Mar  9 17:07:36.682: INFO: Created: latency-svc-7g4w6
Mar  9 17:07:36.726: INFO: Got endpoints: latency-svc-nnprk [751.997898ms]
Mar  9 17:07:36.733: INFO: Created: latency-svc-nvvg6
Mar  9 17:07:36.774: INFO: Got endpoints: latency-svc-mzk2q [750.997149ms]
Mar  9 17:07:36.782: INFO: Created: latency-svc-xpf8b
Mar  9 17:07:36.825: INFO: Got endpoints: latency-svc-d6zcm [751.17763ms]
Mar  9 17:07:36.832: INFO: Created: latency-svc-x4bpb
Mar  9 17:07:36.874: INFO: Got endpoints: latency-svc-kps8n [748.77771ms]
Mar  9 17:07:36.882: INFO: Created: latency-svc-9j4pg
Mar  9 17:07:36.924: INFO: Got endpoints: latency-svc-9tqff [751.036273ms]
Mar  9 17:07:36.933: INFO: Created: latency-svc-62q9v
Mar  9 17:07:36.975: INFO: Got endpoints: latency-svc-f8sgf [750.334656ms]
Mar  9 17:07:36.983: INFO: Created: latency-svc-jbhkx
Mar  9 17:07:37.024: INFO: Got endpoints: latency-svc-4hwvs [749.821845ms]
Mar  9 17:07:37.033: INFO: Created: latency-svc-6glvq
Mar  9 17:07:37.074: INFO: Got endpoints: latency-svc-b82d4 [750.063521ms]
Mar  9 17:07:37.126: INFO: Got endpoints: latency-svc-cw7pq [750.862058ms]
Mar  9 17:07:37.174: INFO: Got endpoints: latency-svc-wb4bz [750.277503ms]
Mar  9 17:07:37.224: INFO: Got endpoints: latency-svc-8wngd [747.87615ms]
Mar  9 17:07:37.273: INFO: Got endpoints: latency-svc-6rqtm [749.200701ms]
Mar  9 17:07:37.323: INFO: Got endpoints: latency-svc-mvp86 [748.662614ms]
Mar  9 17:07:37.373: INFO: Got endpoints: latency-svc-pmxdm [748.638021ms]
Mar  9 17:07:37.423: INFO: Got endpoints: latency-svc-7g4w6 [748.921022ms]
Mar  9 17:07:37.473: INFO: Got endpoints: latency-svc-nvvg6 [747.314401ms]
Mar  9 17:07:37.523: INFO: Got endpoints: latency-svc-xpf8b [748.678977ms]
Mar  9 17:07:37.573: INFO: Got endpoints: latency-svc-x4bpb [748.672819ms]
Mar  9 17:07:37.624: INFO: Got endpoints: latency-svc-9j4pg [750.136064ms]
Mar  9 17:07:37.673: INFO: Got endpoints: latency-svc-62q9v [748.377385ms]
Mar  9 17:07:37.728: INFO: Got endpoints: latency-svc-jbhkx [752.523514ms]
Mar  9 17:07:37.774: INFO: Got endpoints: latency-svc-6glvq [749.550124ms]
Mar  9 17:07:37.774: INFO: Latencies: [11.41093ms 19.149872ms 27.541573ms 31.240066ms 34.184913ms 37.491571ms 43.201636ms 45.587431ms 53.209638ms 61.576101ms 67.714364ms 78.448526ms 94.764045ms 99.740881ms 103.601621ms 103.712112ms 104.032418ms 105.505299ms 106.307993ms 106.840036ms 106.853653ms 107.073226ms 107.188687ms 107.625548ms 107.63195ms 108.979938ms 110.352036ms 111.682137ms 112.229161ms 112.374381ms 113.263674ms 116.129488ms 116.92089ms 116.987504ms 152.366889ms 196.752526ms 238.640089ms 282.495907ms 325.070285ms 366.491062ms 416.141338ms 454.813434ms 496.092322ms 536.836324ms 582.756913ms 621.639599ms 665.095408ms 708.848191ms 739.281717ms 742.168766ms 742.611096ms 744.821466ms 744.912657ms 745.669273ms 746.779564ms 746.970955ms 746.987556ms 747.314401ms 747.334664ms 747.87615ms 748.268634ms 748.298086ms 748.338933ms 748.377385ms 748.464948ms 748.473789ms 748.497708ms 748.537802ms 748.602734ms 748.638021ms 748.654267ms 748.662614ms 748.672819ms 748.673069ms 748.678977ms 748.725496ms 748.77771ms 748.915306ms 748.921022ms 748.955509ms 748.965834ms 748.998941ms 749.012416ms 749.014995ms 749.045884ms 749.094092ms 749.10144ms 749.133169ms 749.148994ms 749.180268ms 749.200701ms 749.247936ms 749.257432ms 749.27826ms 749.279195ms 749.296958ms 749.339202ms 749.342458ms 749.347289ms 749.371931ms 749.377757ms 749.398331ms 749.400208ms 749.411759ms 749.420349ms 749.438286ms 749.534647ms 749.550124ms 749.551539ms 749.566451ms 749.577053ms 749.581699ms 749.616178ms 749.708553ms 749.746814ms 749.74926ms 749.776001ms 749.790408ms 749.807448ms 749.817229ms 749.821845ms 749.830645ms 749.859771ms 749.876127ms 749.887791ms 749.890673ms 749.892519ms 749.943975ms 749.987598ms 749.989044ms 750.016505ms 750.017077ms 750.037537ms 750.063521ms 750.136064ms 750.1445ms 750.222072ms 750.22812ms 750.233835ms 750.25503ms 750.273188ms 750.277503ms 750.290037ms 750.321709ms 750.334656ms 750.341405ms 750.440583ms 750.443583ms 750.444747ms 750.463018ms 750.484456ms 750.501488ms 750.506382ms 750.517129ms 750.537838ms 750.551225ms 750.557256ms 750.587263ms 750.62197ms 750.649707ms 750.649814ms 750.665615ms 750.758713ms 750.787913ms 750.813543ms 750.862058ms 750.902583ms 750.909888ms 750.922365ms 750.951896ms 750.957724ms 750.979837ms 750.997149ms 751.036273ms 751.041411ms 751.058031ms 751.142178ms 751.17763ms 751.323835ms 751.331146ms 751.340412ms 751.638561ms 751.665891ms 751.728005ms 751.881903ms 751.90785ms 751.997898ms 752.358306ms 752.387231ms 752.462558ms 752.523514ms 752.73895ms 752.749884ms 753.657895ms 753.682428ms 754.759609ms 756.061159ms 757.492556ms 757.57977ms 761.793728ms]
Mar  9 17:07:37.774: INFO: 50 %ile: 749.377757ms
Mar  9 17:07:37.774: INFO: 90 %ile: 751.340412ms
Mar  9 17:07:37.774: INFO: 99 %ile: 757.57977ms
Mar  9 17:07:37.774: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:07:37.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-gkn42" for this suite.
Mar  9 17:07:51.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:07:51.796: INFO: namespace: e2e-tests-svc-latency-gkn42, resource: bindings, ignored listing per whitelist
Mar  9 17:07:51.826: INFO: namespace e2e-tests-svc-latency-gkn42 deletion completed in 14.048892342s

• [SLOW TEST:23.800 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:07:51.827: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:07:51.845279      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar  9 17:07:51.870: INFO: Waiting up to 5m0s for pod "var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-var-expansion-qd4mm" to be "success or failure"
Mar  9 17:07:51.874: INFO: Pod "var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.39253ms
Mar  9 17:07:53.876: INFO: Pod "var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005502108s
STEP: Saw pod success
Mar  9 17:07:53.876: INFO: Pod "var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:07:53.877: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 17:07:53.891: INFO: Waiting for pod var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:07:53.893: INFO: Pod var-expansion-df7a2073-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:07:53.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qd4mm" for this suite.
Mar  9 17:07:59.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:07:59.948: INFO: namespace: e2e-tests-var-expansion-qd4mm, resource: bindings, ignored listing per whitelist
Mar  9 17:07:59.955: INFO: namespace e2e-tests-var-expansion-qd4mm deletion completed in 6.06021409s

• [SLOW TEST:8.128 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:07:59.955: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:07:59.973044      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e4522d1a-428d-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume secrets
Mar  9 17:08:00.013: INFO: Waiting up to 5m0s for pod "pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-secrets-7q48b" to be "success or failure"
Mar  9 17:08:00.016: INFO: Pod "pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.65586ms
Mar  9 17:08:02.017: INFO: Pod "pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004412554s
STEP: Saw pod success
Mar  9 17:08:02.018: INFO: Pod "pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:08:02.019: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 17:08:02.028: INFO: Waiting for pod pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:08:02.029: INFO: Pod pod-secrets-e454e840-428d-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:08:02.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7q48b" for this suite.
Mar  9 17:08:08.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:08:08.056: INFO: namespace: e2e-tests-secrets-7q48b, resource: bindings, ignored listing per whitelist
Mar  9 17:08:08.083: INFO: namespace e2e-tests-secrets-7q48b deletion completed in 6.052874786s
STEP: Destroying namespace "e2e-tests-secret-namespace-xbc8f" for this suite.
Mar  9 17:08:14.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:08:14.112: INFO: namespace: e2e-tests-secret-namespace-xbc8f, resource: bindings, ignored listing per whitelist
Mar  9 17:08:14.132: INFO: namespace e2e-tests-secret-namespace-xbc8f deletion completed in 6.048534209s

• [SLOW TEST:14.177 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:08:14.132: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:08:14.163239      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0309 17:08:54.196684      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 17:08:54.196: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:08:54.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w4djm" for this suite.
Mar  9 17:09:00.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:09:00.247: INFO: namespace: e2e-tests-gc-w4djm, resource: bindings, ignored listing per whitelist
Mar  9 17:09:00.252: INFO: namespace e2e-tests-gc-w4djm deletion completed in 6.053930932s

• [SLOW TEST:46.120 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:09:00.252: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:09:00.269588      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar  9 17:09:00.295: INFO: Waiting up to 5m0s for pod "var-expansion-08433396-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-var-expansion-gg7zc" to be "success or failure"
Mar  9 17:09:00.298: INFO: Pod "var-expansion-08433396-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.776578ms
Mar  9 17:09:02.300: INFO: Pod "var-expansion-08433396-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00449968s
Mar  9 17:09:04.301: INFO: Pod "var-expansion-08433396-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006084497s
STEP: Saw pod success
Mar  9 17:09:04.302: INFO: Pod "var-expansion-08433396-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:09:04.303: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod var-expansion-08433396-428e-11e9-923b-2eb43f2b540f container dapi-container: <nil>
STEP: delete the pod
Mar  9 17:09:04.313: INFO: Waiting for pod var-expansion-08433396-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:09:04.314: INFO: Pod var-expansion-08433396-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:09:04.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gg7zc" for this suite.
Mar  9 17:09:10.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:09:10.348: INFO: namespace: e2e-tests-var-expansion-gg7zc, resource: bindings, ignored listing per whitelist
Mar  9 17:09:10.363: INFO: namespace e2e-tests-var-expansion-gg7zc deletion completed in 6.048407449s

• [SLOW TEST:10.112 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:09:10.364: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:09:10.381075      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 17:09:10.405: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-projected-rfk8j" to be "success or failure"
Mar  9 17:09:10.408: INFO: Pod "downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.451682ms
Mar  9 17:09:12.410: INFO: Pod "downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004228967s
STEP: Saw pod success
Mar  9 17:09:12.410: INFO: Pod "downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:09:12.411: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 17:09:12.422: INFO: Waiting for pod downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:09:12.423: INFO: Pod downwardapi-volume-0e499893-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:09:12.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rfk8j" for this suite.
Mar  9 17:09:18.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:09:18.455: INFO: namespace: e2e-tests-projected-rfk8j, resource: bindings, ignored listing per whitelist
Mar  9 17:09:18.471: INFO: namespace e2e-tests-projected-rfk8j deletion completed in 6.046454758s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:09:18.471: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:09:18.489094      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar  9 17:09:18.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-nvsfj'
Mar  9 17:09:18.828: INFO: stderr: ""
Mar  9 17:09:18.828: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar  9 17:09:19.830: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 17:09:19.830: INFO: Found 0 / 1
Mar  9 17:09:20.830: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 17:09:20.830: INFO: Found 1 / 1
Mar  9 17:09:20.830: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  9 17:09:20.831: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 17:09:20.831: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar  9 17:09:20.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 logs redis-master-bwr54 redis-master --namespace=e2e-tests-kubectl-nvsfj'
Mar  9 17:09:20.911: INFO: stderr: ""
Mar  9 17:09:20.911: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Mar 17:09:19.441 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Mar 17:09:19.441 # Server started, Redis version 3.2.12\n1:M 09 Mar 17:09:19.442 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Mar 17:09:19.442 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar  9 17:09:20.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 log redis-master-bwr54 redis-master --namespace=e2e-tests-kubectl-nvsfj --tail=1'
Mar  9 17:09:20.989: INFO: stderr: ""
Mar  9 17:09:20.989: INFO: stdout: "1:M 09 Mar 17:09:19.442 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar  9 17:09:20.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 log redis-master-bwr54 redis-master --namespace=e2e-tests-kubectl-nvsfj --limit-bytes=1'
Mar  9 17:09:21.071: INFO: stderr: ""
Mar  9 17:09:21.071: INFO: stdout: " "
STEP: exposing timestamps
Mar  9 17:09:21.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 log redis-master-bwr54 redis-master --namespace=e2e-tests-kubectl-nvsfj --tail=1 --timestamps'
Mar  9 17:09:21.149: INFO: stderr: ""
Mar  9 17:09:21.149: INFO: stdout: "2019-03-09T17:09:19.44284677Z 1:M 09 Mar 17:09:19.442 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar  9 17:09:23.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 log redis-master-bwr54 redis-master --namespace=e2e-tests-kubectl-nvsfj --since=1s'
Mar  9 17:09:24.056: INFO: stderr: ""
Mar  9 17:09:24.056: INFO: stdout: ""
Mar  9 17:09:24.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 log redis-master-bwr54 redis-master --namespace=e2e-tests-kubectl-nvsfj --since=24h'
Mar  9 17:09:24.135: INFO: stderr: ""
Mar  9 17:09:24.135: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Mar 17:09:19.441 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Mar 17:09:19.441 # Server started, Redis version 3.2.12\n1:M 09 Mar 17:09:19.442 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Mar 17:09:19.442 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar  9 17:09:24.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nvsfj'
Mar  9 17:09:24.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 17:09:24.210: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar  9 17:09:24.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-nvsfj'
Mar  9 17:09:24.298: INFO: stderr: "No resources found.\n"
Mar  9 17:09:24.298: INFO: stdout: ""
Mar  9 17:09:24.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -l name=nginx --namespace=e2e-tests-kubectl-nvsfj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 17:09:24.374: INFO: stderr: ""
Mar  9 17:09:24.374: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:09:24.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nvsfj" for this suite.
Mar  9 17:09:30.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:09:30.402: INFO: namespace: e2e-tests-kubectl-nvsfj, resource: bindings, ignored listing per whitelist
Mar  9 17:09:30.424: INFO: namespace e2e-tests-kubectl-nvsfj deletion completed in 6.048061497s

• [SLOW TEST:11.953 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:09:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:09:30.441287      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1a3ea1d5-428e-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 17:09:30.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-frdc8" to be "success or failure"
Mar  9 17:09:30.470: INFO: Pod "pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.437237ms
Mar  9 17:09:32.472: INFO: Pod "pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005206792s
STEP: Saw pod success
Mar  9 17:09:32.472: INFO: Pod "pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:09:32.473: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 17:09:32.481: INFO: Waiting for pod pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:09:32.483: INFO: Pod pod-configmaps-1a3edb3b-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:09:32.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-frdc8" for this suite.
Mar  9 17:09:38.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:09:38.519: INFO: namespace: e2e-tests-configmap-frdc8, resource: bindings, ignored listing per whitelist
Mar  9 17:09:38.540: INFO: namespace e2e-tests-configmap-frdc8 deletion completed in 6.055394066s

• [SLOW TEST:8.116 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:09:38.540: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:09:38.558415      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 17:09:38.594: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-kmrrs" to be "success or failure"
Mar  9 17:09:38.598: INFO: Pod "downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047757ms
Mar  9 17:09:40.599: INFO: Pod "downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005759862s
STEP: Saw pod success
Mar  9 17:09:40.599: INFO: Pod "downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:09:40.601: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 17:09:40.611: INFO: Waiting for pod downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:09:40.612: INFO: Pod downwardapi-volume-1f16f242-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:09:40.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kmrrs" for this suite.
Mar  9 17:09:46.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:09:46.634: INFO: namespace: e2e-tests-downward-api-kmrrs, resource: bindings, ignored listing per whitelist
Mar  9 17:09:46.661: INFO: namespace e2e-tests-downward-api-kmrrs deletion completed in 6.047948471s

• [SLOW TEST:8.122 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:09:46.662: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:09:46.678798      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 17:09:46.697: INFO: Creating deployment "nginx-deployment"
Mar  9 17:09:46.700: INFO: Waiting for observed generation 1
Mar  9 17:09:48.703: INFO: Waiting for all required pods to come up
Mar  9 17:09:48.705: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  9 17:09:54.713: INFO: Waiting for deployment "nginx-deployment" to complete
Mar  9 17:09:54.715: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar  9 17:09:54.719: INFO: Updating deployment nginx-deployment
Mar  9 17:09:54.719: INFO: Waiting for observed generation 2
Mar  9 17:09:56.724: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  9 17:09:56.726: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  9 17:09:56.727: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  9 17:09:56.730: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  9 17:09:56.730: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  9 17:09:56.731: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  9 17:09:56.733: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar  9 17:09:56.733: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar  9 17:09:56.736: INFO: Updating deployment nginx-deployment
Mar  9 17:09:56.736: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar  9 17:09:56.742: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  9 17:09:56.744: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  9 17:09:56.757: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-bfplx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bfplx/deployments/nginx-deployment,UID:23ec2d2c-428e-11e9-9882-02b03e914f30,ResourceVersion:19441,Generation:3,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-03-09 17:09:54 +0000 UTC 2019-03-09 17:09:46 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-03-09 17:09:56 +0000 UTC 2019-03-09 17:09:56 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar  9 17:09:56.773: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-bfplx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bfplx/replicasets/nginx-deployment-7dc8f79789,UID:28b43dbf-428e-11e9-9882-02b03e914f30,ResourceVersion:19439,Generation:3,CreationTimestamp:2019-03-09 17:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 23ec2d2c-428e-11e9-9882-02b03e914f30 0xc422eebba7 0xc422eebba8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  9 17:09:56.773: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar  9 17:09:56.773: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-bfplx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bfplx/replicasets/nginx-deployment-7f9675fb8b,UID:23ed0097-428e-11e9-9882-02b03e914f30,ResourceVersion:19438,Generation:3,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 23ec2d2c-428e-11e9-9882-02b03e914f30 0xc422eebc67 0xc422eebc68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar  9 17:09:56.813: INFO: Pod "nginx-deployment-7dc8f79789-7cs4h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7cs4h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-7cs4h,UID:29ebc07d-428e-11e9-9882-02b03e914f30,ResourceVersion:19448,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc422876517 0xc422876518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228765a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.816: INFO: Pod "nginx-deployment-7dc8f79789-brd9n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-brd9n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-brd9n,UID:28bdd43e-428e-11e9-9882-02b03e914f30,ResourceVersion:19429,Generation:0,CreationTimestamp:2019-03-09 17:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc4228765f7 0xc4228765f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:,StartTime:2019-03-09 17:09:54 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.819: INFO: Pod "nginx-deployment-7dc8f79789-cp4cb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cp4cb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-cp4cb,UID:28b5e73d-428e-11e9-9882-02b03e914f30,ResourceVersion:19417,Generation:0,CreationTimestamp:2019-03-09 17:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc422876740 0xc422876741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228767b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228767d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:,StartTime:2019-03-09 17:09:54 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.823: INFO: Pod "nginx-deployment-7dc8f79789-fqk26" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fqk26,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-fqk26,UID:28b5cd15-428e-11e9-9882-02b03e914f30,ResourceVersion:19400,Generation:0,CreationTimestamp:2019-03-09 17:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc422876890 0xc422876891}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:,StartTime:2019-03-09 17:09:54 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.831: INFO: Pod "nginx-deployment-7dc8f79789-jdjxn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jdjxn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-jdjxn,UID:28b4ad48-428e-11e9-9882-02b03e914f30,ResourceVersion:19395,Generation:0,CreationTimestamp:2019-03-09 17:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc4228769e0 0xc4228769e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:,StartTime:2019-03-09 17:09:54 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.832: INFO: Pod "nginx-deployment-7dc8f79789-nhnsj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nhnsj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-nhnsj,UID:29edd059-428e-11e9-9882-02b03e914f30,ResourceVersion:19452,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc422876b30 0xc422876b31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.832: INFO: Pod "nginx-deployment-7dc8f79789-rk8w6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rk8w6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-rk8w6,UID:28bd1d69-428e-11e9-9882-02b03e914f30,ResourceVersion:19425,Generation:0,CreationTimestamp:2019-03-09 17:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc422876c17 0xc422876c18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:54 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:,StartTime:2019-03-09 17:09:54 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.832: INFO: Pod "nginx-deployment-7dc8f79789-sr6bn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sr6bn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7dc8f79789-sr6bn,UID:29ed90a3-428e-11e9-9882-02b03e914f30,ResourceVersion:19456,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 28b43dbf-428e-11e9-9882-02b03e914f30 0xc422876d60 0xc422876d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.836: INFO: Pod "nginx-deployment-7f9675fb8b-7nb8t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7nb8t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-7nb8t,UID:23f087b8-428e-11e9-9882-02b03e914f30,ResourceVersion:19331,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422876e47 0xc422876e48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422876eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422876ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.14,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://db2b446fc0260ad41435454cb3639acd639d4c466a43a4026ccb574abb4fb016}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.837: INFO: Pod "nginx-deployment-7f9675fb8b-86t87" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-86t87,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-86t87,UID:23f25bb5-428e-11e9-9882-02b03e914f30,ResourceVersion:19341,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422876f97 0xc422876f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422877000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.17,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://e2994d919851fcd620deda427f6ebadd2ac7e7035c3032322f3d91c14d6a62dd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.846: INFO: Pod "nginx-deployment-7f9675fb8b-cdjzg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cdjzg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-cdjzg,UID:23ef51cc-428e-11e9-9882-02b03e914f30,ResourceVersion:19354,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc4228770e7 0xc4228770e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422877150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.18,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:50 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://fa129660607449396539575ca33b648a8ff87ae4cd02945a03147c404bcb82d7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.847: INFO: Pod "nginx-deployment-7f9675fb8b-chxl7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-chxl7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-chxl7,UID:29eb7cdd-428e-11e9-9882-02b03e914f30,ResourceVersion:19450,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877237 0xc422877238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228772a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228772c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:56 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.850: INFO: Pod "nginx-deployment-7f9675fb8b-drwz9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-drwz9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-drwz9,UID:23f23fd9-428e-11e9-9882-02b03e914f30,ResourceVersion:19336,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877330 0xc422877331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422877390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228773b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.15,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://158149804f689b1affe0a3ac5ddd6dea289f2bc325b1d5426dc46517072a8c82}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.850: INFO: Pod "nginx-deployment-7f9675fb8b-fbr84" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fbr84,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-fbr84,UID:29eb9a4d-428e-11e9-9882-02b03e914f30,ResourceVersion:19453,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877477 0xc422877478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228774e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:56 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.851: INFO: Pod "nginx-deployment-7f9675fb8b-fh686" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fh686,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-fh686,UID:29edb34f-428e-11e9-9882-02b03e914f30,ResourceVersion:19455,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877570 0xc422877571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228775d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228775f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.854: INFO: Pod "nginx-deployment-7f9675fb8b-fqhrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fqhrv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-fqhrv,UID:29ea7a4a-428e-11e9-9882-02b03e914f30,ResourceVersion:19445,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877647 0xc422877648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228776b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228776d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:56 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.854: INFO: Pod "nginx-deployment-7f9675fb8b-lt6nk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lt6nk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-lt6nk,UID:23f066a6-428e-11e9-9882-02b03e914f30,ResourceVersion:19348,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877740 0xc422877741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228777a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228777c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.20,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:50 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://c3eeda85536d3db31f97206f39c3a000436db182b48612f07488b9ef8ecd1364}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.854: INFO: Pod "nginx-deployment-7f9675fb8b-p8ftp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p8ftp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-p8ftp,UID:29ed836e-428e-11e9-9882-02b03e914f30,ResourceVersion:19454,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877887 0xc422877888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228778f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.855: INFO: Pod "nginx-deployment-7f9675fb8b-s64st" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-s64st,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-s64st,UID:23ee884a-428e-11e9-9882-02b03e914f30,ResourceVersion:19364,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877967 0xc422877968}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228779d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228779f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.19,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:50 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://b7d96e25b7925b66f3906b230cd5e948de28f8cd831ff9a80252f549dc8cbe02}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.856: INFO: Pod "nginx-deployment-7f9675fb8b-txg8h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-txg8h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-txg8h,UID:29ed9b93-428e-11e9-9882-02b03e914f30,ResourceVersion:19457,Generation:0,CreationTimestamp:2019-03-09 17:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877ab7 0xc422877ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422877b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.856: INFO: Pod "nginx-deployment-7f9675fb8b-vl6w9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vl6w9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-vl6w9,UID:23f07315-428e-11e9-9882-02b03e914f30,ResourceVersion:19327,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877b97 0xc422877b98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422877c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.13,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://8304618ef7b780156cbbda227dac7fea8e9249781b639bad42052bb9bae2b30b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  9 17:09:56.858: INFO: Pod "nginx-deployment-7f9675fb8b-wvcwb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wvcwb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-bfplx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bfplx/pods/nginx-deployment-7f9675fb8b-wvcwb,UID:23f2785c-428e-11e9-9882-02b03e914f30,ResourceVersion:19324,Generation:0,CreationTimestamp:2019-03-09 17:09:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 23ed0097-428e-11e9-9882-02b03e914f30 0xc422877ce7 0xc422877ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qw66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qw66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5qw66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-70-73.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422877d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422877d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-09 17:09:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.70.73,PodIP:10.20.192.16,StartTime:2019-03-09 17:09:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-09 17:09:49 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d containerd://df5210e4e8029804c6edc42a71aafe5d536dd8bd5947ef1758135d1eed467991}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:09:56.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bfplx" for this suite.
Mar  9 17:10:02.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:10:02.926: INFO: namespace: e2e-tests-deployment-bfplx, resource: bindings, ignored listing per whitelist
Mar  9 17:10:02.942: INFO: namespace e2e-tests-deployment-bfplx deletion completed in 6.070041537s

• [SLOW TEST:16.280 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:10:02.942: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:10:02.960490      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  9 17:10:02.981: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:10:10.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-94s7n" for this suite.
Mar  9 17:10:16.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:10:16.351: INFO: namespace: e2e-tests-init-container-94s7n, resource: bindings, ignored listing per whitelist
Mar  9 17:10:16.379: INFO: namespace e2e-tests-init-container-94s7n deletion completed in 6.050104906s

• [SLOW TEST:13.438 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:10:16.379: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:10:16.396928      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-g9dxd/configmap-test-35a2c21b-428e-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 17:10:16.421: INFO: Waiting up to 5m0s for pod "pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-g9dxd" to be "success or failure"
Mar  9 17:10:16.425: INFO: Pod "pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106387ms
Mar  9 17:10:18.426: INFO: Pod "pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005432288s
STEP: Saw pod success
Mar  9 17:10:18.426: INFO: Pod "pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:10:18.427: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f container env-test: <nil>
STEP: delete the pod
Mar  9 17:10:18.436: INFO: Waiting for pod pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:10:18.437: INFO: Pod pod-configmaps-35a2ffa2-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:10:18.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g9dxd" for this suite.
Mar  9 17:10:24.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:10:24.479: INFO: namespace: e2e-tests-configmap-g9dxd, resource: bindings, ignored listing per whitelist
Mar  9 17:10:24.488: INFO: namespace e2e-tests-configmap-g9dxd deletion completed in 6.049154601s

• [SLOW TEST:8.108 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:10:24.488: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:10:24.506175      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar  9 17:10:24.528: INFO: Waiting up to 5m0s for pod "client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-containers-z4mbz" to be "success or failure"
Mar  9 17:10:24.530: INFO: Pod "client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.56677ms
Mar  9 17:10:26.533: INFO: Pod "client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005041118s
STEP: Saw pod success
Mar  9 17:10:26.533: INFO: Pod "client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:10:26.535: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 17:10:26.549: INFO: Waiting for pod client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:10:26.550: INFO: Pod client-containers-3a77f996-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:10:26.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-z4mbz" for this suite.
Mar  9 17:10:32.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:10:32.595: INFO: namespace: e2e-tests-containers-z4mbz, resource: bindings, ignored listing per whitelist
Mar  9 17:10:32.599: INFO: namespace e2e-tests-containers-z4mbz deletion completed in 6.048237824s

• [SLOW TEST:8.111 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:10:32.600: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:10:32.617837      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-3f4e08e2-428e-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 17:10:32.645: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-k4844" to be "success or failure"
Mar  9 17:10:32.648: INFO: Pod "pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.358334ms
Mar  9 17:10:34.650: INFO: Pod "pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005008666s
STEP: Saw pod success
Mar  9 17:10:34.650: INFO: Pod "pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:10:34.651: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 17:10:34.661: INFO: Waiting for pod pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:10:34.662: INFO: Pod pod-configmaps-3f4e425b-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:10:34.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k4844" for this suite.
Mar  9 17:10:40.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:10:40.701: INFO: namespace: e2e-tests-configmap-k4844, resource: bindings, ignored listing per whitelist
Mar  9 17:10:40.715: INFO: namespace e2e-tests-configmap-k4844 deletion completed in 6.050892785s

• [SLOW TEST:8.115 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:10:40.715: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:10:40.732141      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  9 17:10:40.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:40.900: INFO: stderr: ""
Mar  9 17:10:40.900: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 17:10:40.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:41.002: INFO: stderr: ""
Mar  9 17:10:41.002: INFO: stdout: "update-demo-nautilus-6mnjn update-demo-nautilus-rrp5s "
Mar  9 17:10:41.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:41.077: INFO: stderr: ""
Mar  9 17:10:41.077: INFO: stdout: ""
Mar  9 17:10:41.077: INFO: update-demo-nautilus-6mnjn is created but not running
Mar  9 17:10:46.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.160: INFO: stderr: ""
Mar  9 17:10:46.160: INFO: stdout: "update-demo-nautilus-6mnjn update-demo-nautilus-rrp5s "
Mar  9 17:10:46.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.233: INFO: stderr: ""
Mar  9 17:10:46.233: INFO: stdout: "true"
Mar  9 17:10:46.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.308: INFO: stderr: ""
Mar  9 17:10:46.308: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 17:10:46.308: INFO: validating pod update-demo-nautilus-6mnjn
Mar  9 17:10:46.311: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 17:10:46.311: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 17:10:46.311: INFO: update-demo-nautilus-6mnjn is verified up and running
Mar  9 17:10:46.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-rrp5s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.406: INFO: stderr: ""
Mar  9 17:10:46.406: INFO: stdout: "true"
Mar  9 17:10:46.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-rrp5s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.479: INFO: stderr: ""
Mar  9 17:10:46.479: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 17:10:46.479: INFO: validating pod update-demo-nautilus-rrp5s
Mar  9 17:10:46.482: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 17:10:46.482: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 17:10:46.482: INFO: update-demo-nautilus-rrp5s is verified up and running
STEP: scaling down the replication controller
Mar  9 17:10:46.483: INFO: scanned /root for discovery docs: <nil>
Mar  9 17:10:46.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.599: INFO: stderr: ""
Mar  9 17:10:46.599: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 17:10:46.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:46.681: INFO: stderr: ""
Mar  9 17:10:46.681: INFO: stdout: "update-demo-nautilus-6mnjn update-demo-nautilus-rrp5s "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  9 17:10:51.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:51.760: INFO: stderr: ""
Mar  9 17:10:51.760: INFO: stdout: "update-demo-nautilus-6mnjn update-demo-nautilus-rrp5s "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  9 17:10:56.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:10:56.842: INFO: stderr: ""
Mar  9 17:10:56.842: INFO: stdout: "update-demo-nautilus-6mnjn update-demo-nautilus-rrp5s "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  9 17:11:01.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:01.920: INFO: stderr: ""
Mar  9 17:11:01.920: INFO: stdout: "update-demo-nautilus-6mnjn "
Mar  9 17:11:01.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:01.998: INFO: stderr: ""
Mar  9 17:11:01.998: INFO: stdout: "true"
Mar  9 17:11:01.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:02.079: INFO: stderr: ""
Mar  9 17:11:02.079: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 17:11:02.079: INFO: validating pod update-demo-nautilus-6mnjn
Mar  9 17:11:02.081: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 17:11:02.081: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 17:11:02.081: INFO: update-demo-nautilus-6mnjn is verified up and running
STEP: scaling up the replication controller
Mar  9 17:11:02.082: INFO: scanned /root for discovery docs: <nil>
Mar  9 17:11:02.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.207: INFO: stderr: ""
Mar  9 17:11:03.207: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 17:11:03.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.284: INFO: stderr: ""
Mar  9 17:11:03.284: INFO: stdout: "update-demo-nautilus-6mnjn update-demo-nautilus-lrkg2 "
Mar  9 17:11:03.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.358: INFO: stderr: ""
Mar  9 17:11:03.358: INFO: stdout: "true"
Mar  9 17:11:03.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-6mnjn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.433: INFO: stderr: ""
Mar  9 17:11:03.433: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 17:11:03.433: INFO: validating pod update-demo-nautilus-6mnjn
Mar  9 17:11:03.435: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 17:11:03.435: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 17:11:03.435: INFO: update-demo-nautilus-6mnjn is verified up and running
Mar  9 17:11:03.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-lrkg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.519: INFO: stderr: ""
Mar  9 17:11:03.519: INFO: stdout: "true"
Mar  9 17:11:03.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods update-demo-nautilus-lrkg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.595: INFO: stderr: ""
Mar  9 17:11:03.595: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  9 17:11:03.595: INFO: validating pod update-demo-nautilus-lrkg2
Mar  9 17:11:03.598: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 17:11:03.598: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 17:11:03.598: INFO: update-demo-nautilus-lrkg2 is verified up and running
STEP: using delete to clean up resources
Mar  9 17:11:03.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.672: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 17:11:03.672: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  9 17:11:03.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-6k7kl'
Mar  9 17:11:03.769: INFO: stderr: "No resources found.\n"
Mar  9 17:11:03.769: INFO: stdout: ""
Mar  9 17:11:03.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -l name=update-demo --namespace=e2e-tests-kubectl-6k7kl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 17:11:03.857: INFO: stderr: ""
Mar  9 17:11:03.857: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:11:03.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6k7kl" for this suite.
Mar  9 17:11:25.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:11:25.908: INFO: namespace: e2e-tests-kubectl-6k7kl, resource: bindings, ignored listing per whitelist
Mar  9 17:11:25.913: INFO: namespace e2e-tests-kubectl-6k7kl deletion completed in 22.054052402s

• [SLOW TEST:45.199 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:11:25.913: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:11:25.930427      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar  9 17:11:25.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 create -f - --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:26.130: INFO: stderr: ""
Mar  9 17:11:26.130: INFO: stdout: "pod/pause created\n"
Mar  9 17:11:26.130: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  9 17:11:26.130: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-czwtk" to be "running and ready"
Mar  9 17:11:26.132: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192916ms
Mar  9 17:11:28.134: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.003523886s
Mar  9 17:11:28.134: INFO: Pod "pause" satisfied condition "running and ready"
Mar  9 17:11:28.134: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  9 17:11:28.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:28.215: INFO: stderr: ""
Mar  9 17:11:28.215: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  9 17:11:28.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pod pause -L testing-label --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:28.294: INFO: stderr: ""
Mar  9 17:11:28.294: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  9 17:11:28.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 label pods pause testing-label- --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:28.376: INFO: stderr: ""
Mar  9 17:11:28.376: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  9 17:11:28.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pod pause -L testing-label --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:28.451: INFO: stderr: ""
Mar  9 17:11:28.451: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar  9 17:11:28.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:28.525: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 17:11:28.525: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  9 17:11:28.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-czwtk'
Mar  9 17:11:28.613: INFO: stderr: "No resources found.\n"
Mar  9 17:11:28.613: INFO: stdout: ""
Mar  9 17:11:28.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pods -l name=pause --namespace=e2e-tests-kubectl-czwtk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 17:11:28.692: INFO: stderr: ""
Mar  9 17:11:28.692: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:11:28.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-czwtk" for this suite.
Mar  9 17:11:34.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:11:34.722: INFO: namespace: e2e-tests-kubectl-czwtk, resource: bindings, ignored listing per whitelist
Mar  9 17:11:34.742: INFO: namespace e2e-tests-kubectl-czwtk deletion completed in 6.047699767s

• [SLOW TEST:8.829 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:11:34.742: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:11:34.773058      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  9 17:11:34.794: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20072,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 17:11:34.794: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20072,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  9 17:11:44.798: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20092,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  9 17:11:44.798: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20092,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  9 17:11:54.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20112,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 17:11:54.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20112,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  9 17:12:04.804: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20132,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 17:12:04.805: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-a,UID:645a3485-428e-11e9-9882-02b03e914f30,ResourceVersion:20132,Generation:0,CreationTimestamp:2019-03-09 17:11:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  9 17:12:14.808: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-b,UID:7c339c24-428e-11e9-9882-02b03e914f30,ResourceVersion:20152,Generation:0,CreationTimestamp:2019-03-09 17:12:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 17:12:14.808: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-b,UID:7c339c24-428e-11e9-9882-02b03e914f30,ResourceVersion:20152,Generation:0,CreationTimestamp:2019-03-09 17:12:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  9 17:12:24.811: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-b,UID:7c339c24-428e-11e9-9882-02b03e914f30,ResourceVersion:20171,Generation:0,CreationTimestamp:2019-03-09 17:12:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 17:12:24.811: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-n7fkz,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7fkz/configmaps/e2e-watch-test-configmap-b,UID:7c339c24-428e-11e9-9882-02b03e914f30,ResourceVersion:20171,Generation:0,CreationTimestamp:2019-03-09 17:12:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:12:34.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-n7fkz" for this suite.
Mar  9 17:12:40.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:12:40.862: INFO: namespace: e2e-tests-watch-n7fkz, resource: bindings, ignored listing per whitelist
Mar  9 17:12:40.877: INFO: namespace e2e-tests-watch-n7fkz deletion completed in 6.064024696s

• [SLOW TEST:66.135 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:12:40.877: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:12:40.894852      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rjrw2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 17:12:40.914: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 17:12:54.945: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.192.14:8080/dial?request=hostName&protocol=udp&host=10.20.192.13&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-rjrw2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 17:12:54.945: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
Mar  9 17:12:55.033: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:12:55.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rjrw2" for this suite.
Mar  9 17:13:17.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:13:17.061: INFO: namespace: e2e-tests-pod-network-test-rjrw2, resource: bindings, ignored listing per whitelist
Mar  9 17:13:17.083: INFO: namespace e2e-tests-pod-network-test-rjrw2 deletion completed in 22.048306378s

• [SLOW TEST:36.205 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:13:17.083: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:13:17.100822      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  9 17:13:17.123: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-downward-api-t9zpf" to be "success or failure"
Mar  9 17:13:17.125: INFO: Pod "downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.484113ms
Mar  9 17:13:19.127: INFO: Pod "downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003162959s
STEP: Saw pod success
Mar  9 17:13:19.127: INFO: Pod "downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:13:19.130: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f container client-container: <nil>
STEP: delete the pod
Mar  9 17:13:19.145: INFO: Waiting for pod downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:13:19.147: INFO: Pod downwardapi-volume-a15806e2-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:13:19.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t9zpf" for this suite.
Mar  9 17:13:25.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:13:25.163: INFO: namespace: e2e-tests-downward-api-t9zpf, resource: bindings, ignored listing per whitelist
Mar  9 17:13:25.198: INFO: namespace e2e-tests-downward-api-t9zpf deletion completed in 6.049133878s

• [SLOW TEST:8.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:13:25.198: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:13:25.216163      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a62e3c31-428e-11e9-923b-2eb43f2b540f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a62e3c31-428e-11e9-923b-2eb43f2b540f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:13:29.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ldzvb" for this suite.
Mar  9 17:13:51.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:13:51.278: INFO: namespace: e2e-tests-projected-ldzvb, resource: bindings, ignored listing per whitelist
Mar  9 17:13:51.308: INFO: namespace e2e-tests-projected-ldzvb deletion completed in 22.049721388s

• [SLOW TEST:26.109 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:13:51.308: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:13:51.325507      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar  9 17:13:51.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 --namespace=e2e-tests-kubectl-2kqcz run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  9 17:13:52.425: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  9 17:13:52.425: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:13:54.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2kqcz" for this suite.
Mar  9 17:14:00.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:14:00.456: INFO: namespace: e2e-tests-kubectl-2kqcz, resource: bindings, ignored listing per whitelist
Mar  9 17:14:00.476: INFO: namespace e2e-tests-kubectl-2kqcz deletion completed in 6.047414326s

• [SLOW TEST:9.169 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:14:00.476: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:14:00.493994      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  9 17:14:00.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vdrxt'
Mar  9 17:14:00.606: INFO: stderr: ""
Mar  9 17:14:00.606: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar  9 17:14:05.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vdrxt -o json'
Mar  9 17:14:05.735: INFO: stderr: ""
Mar  9 17:14:05.735: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-09T17:14:00Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-vdrxt\",\n        \"resourceVersion\": \"20511\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-vdrxt/pods/e2e-test-nginx-pod\",\n        \"uid\": \"bb4187a7-428e-11e9-9882-02b03e914f30\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-jl4v4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-192-168-70-73.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-jl4v4\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-jl4v4\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-09T17:14:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-09T17:14:01Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-09T17:14:01Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-09T17:14:00Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://e548f0b4be29c1c2cfdc131052bd72bcedc5d6d371a51706305a43575a1829ec\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-09T17:14:01Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.70.73\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.20.192.13\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-09T17:14:00Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  9 17:14:05.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 replace -f - --namespace=e2e-tests-kubectl-vdrxt'
Mar  9 17:14:05.881: INFO: stderr: ""
Mar  9 17:14:05.881: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar  9 17:14:05.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-182708018 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vdrxt'
Mar  9 17:14:09.821: INFO: stderr: ""
Mar  9 17:14:09.821: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:14:09.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vdrxt" for this suite.
Mar  9 17:14:15.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:14:15.834: INFO: namespace: e2e-tests-kubectl-vdrxt, resource: bindings, ignored listing per whitelist
Mar  9 17:14:15.869: INFO: namespace e2e-tests-kubectl-vdrxt deletion completed in 6.047283816s

• [SLOW TEST:15.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:14:15.870: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:14:15.888124      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0309 17:14:21.924970      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 17:14:21.925: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:14:21.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-q6vjc" for this suite.
Mar  9 17:14:27.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:14:27.946: INFO: namespace: e2e-tests-gc-q6vjc, resource: bindings, ignored listing per whitelist
Mar  9 17:14:27.976: INFO: namespace e2e-tests-gc-q6vjc deletion completed in 6.049637359s

• [SLOW TEST:12.106 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:14:27.976: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:14:27.993525      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cb9990ae-428e-11e9-923b-2eb43f2b540f
STEP: Creating a pod to test consume configMaps
Mar  9 17:14:28.021: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-configmap-95g5p" to be "success or failure"
Mar  9 17:14:28.026: INFO: Pod "pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.817489ms
Mar  9 17:14:30.027: INFO: Pod "pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006250846s
STEP: Saw pod success
Mar  9 17:14:30.027: INFO: Pod "pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:14:30.029: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 17:14:30.039: INFO: Waiting for pod pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:14:30.041: INFO: Pod pod-configmaps-cb99c9be-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:14:30.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-95g5p" for this suite.
Mar  9 17:14:36.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:14:36.084: INFO: namespace: e2e-tests-configmap-95g5p, resource: bindings, ignored listing per whitelist
Mar  9 17:14:36.088: INFO: namespace e2e-tests-configmap-95g5p deletion completed in 6.04477558s

• [SLOW TEST:8.112 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:14:36.088: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:14:36.105482      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 17:14:36.125: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Mar  9 17:14:36.128: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hrfmq/daemonsets","resourceVersion":"20814"},"items":null}

Mar  9 17:14:36.129: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hrfmq/pods","resourceVersion":"20814"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:14:36.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hrfmq" for this suite.
Mar  9 17:14:42.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:14:42.170: INFO: namespace: e2e-tests-daemonsets-hrfmq, resource: bindings, ignored listing per whitelist
Mar  9 17:14:42.181: INFO: namespace e2e-tests-daemonsets-hrfmq deletion completed in 6.047028792s

S [SKIPPING] [6.093 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar  9 17:14:36.125: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:14:42.181: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:14:42.198436      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  9 17:14:46.237: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:46.238: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:14:48.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:48.239: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:14:50.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:50.239: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:14:52.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:52.240: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:14:54.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:54.240: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:14:56.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:56.240: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:14:58.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:14:58.240: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 17:15:00.238: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 17:15:00.240: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:15:00.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-v2gkt" for this suite.
Mar  9 17:15:22.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:15:22.291: INFO: namespace: e2e-tests-container-lifecycle-hook-v2gkt, resource: bindings, ignored listing per whitelist
Mar  9 17:15:22.305: INFO: namespace e2e-tests-container-lifecycle-hook-v2gkt deletion completed in 22.061279961s

• [SLOW TEST:40.124 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:15:22.305: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:15:22.323215      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  9 17:15:22.363: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ebfd0803-428e-11e9-9882-02b03e914f30", Controller:(*bool)(0xc4213f93be), BlockOwnerDeletion:(*bool)(0xc4213f93bf)}}
Mar  9 17:15:22.366: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ebfbb58e-428e-11e9-9882-02b03e914f30", Controller:(*bool)(0xc4208ac40e), BlockOwnerDeletion:(*bool)(0xc4208ac40f)}}
Mar  9 17:15:22.369: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ebfc3a19-428e-11e9-9882-02b03e914f30", Controller:(*bool)(0xc4213f958e), BlockOwnerDeletion:(*bool)(0xc4213f958f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:15:27.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b72pg" for this suite.
Mar  9 17:15:33.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:15:33.410: INFO: namespace: e2e-tests-gc-b72pg, resource: bindings, ignored listing per whitelist
Mar  9 17:15:33.424: INFO: namespace e2e-tests-gc-b72pg deletion completed in 6.049339138s

• [SLOW TEST:11.119 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:15:33.424: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:15:33.441532      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  9 17:15:33.467: INFO: Waiting up to 5m0s for pod "pod-f29c5eea-428e-11e9-923b-2eb43f2b540f" in namespace "e2e-tests-emptydir-m75md" to be "success or failure"
Mar  9 17:15:33.469: INFO: Pod "pod-f29c5eea-428e-11e9-923b-2eb43f2b540f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.411544ms
Mar  9 17:15:35.471: INFO: Pod "pod-f29c5eea-428e-11e9-923b-2eb43f2b540f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003885833s
STEP: Saw pod success
Mar  9 17:15:35.471: INFO: Pod "pod-f29c5eea-428e-11e9-923b-2eb43f2b540f" satisfied condition "success or failure"
Mar  9 17:15:35.472: INFO: Trying to get logs from node ip-192-168-70-73.us-west-2.compute.internal pod pod-f29c5eea-428e-11e9-923b-2eb43f2b540f container test-container: <nil>
STEP: delete the pod
Mar  9 17:15:35.481: INFO: Waiting for pod pod-f29c5eea-428e-11e9-923b-2eb43f2b540f to disappear
Mar  9 17:15:35.482: INFO: Pod pod-f29c5eea-428e-11e9-923b-2eb43f2b540f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:15:35.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m75md" for this suite.
Mar  9 17:15:41.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:15:41.533: INFO: namespace: e2e-tests-emptydir-m75md, resource: bindings, ignored listing per whitelist
Mar  9 17:15:41.534: INFO: namespace e2e-tests-emptydir-m75md deletion completed in 6.050209136s

• [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  9 17:15:41.534: INFO: >>> kubeConfig: /tmp/kubeconfig-182708018
E0309 17:15:41.551721      15 memcache.go:134] couldn't get resource list for custom.metrics.k8s.io/v1beta1: <nil>
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0309 17:16:12.085215      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 17:16:12.085: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  9 17:16:12.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mwzjd" for this suite.
Mar  9 17:16:18.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 17:16:18.113: INFO: namespace: e2e-tests-gc-mwzjd, resource: bindings, ignored listing per whitelist
Mar  9 17:16:18.135: INFO: namespace e2e-tests-gc-mwzjd deletion completed in 6.049092619s

• [SLOW TEST:36.602 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSMar  9 17:16:18.135: INFO: Running AfterSuite actions on all node
Mar  9 17:16:18.135: INFO: Running AfterSuite actions on node 1
Mar  9 17:16:18.135: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4976.735 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h22m57.465956023s
Test Suite Passed
