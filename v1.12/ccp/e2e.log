Feb 13 21:19:07.118: INFO: Overriding default scale value of zero to 1
Feb 13 21:19:07.118: INFO: Overriding default milliseconds value of zero to 5000
I0213 21:19:07.599194      16 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-495519211
I0213 21:19:07.600600      16 e2e.go:304] Starting e2e run "ff1076d2-2fd4-11e9-829f-22a36399a92d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550092746 - Will randomize all specs
Will run 188 of 1814 specs

Feb 13 21:19:07.791: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 21:19:07.793: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 13 21:19:07.804: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 13 21:19:07.824: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 13 21:19:07.824: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Feb 13 21:19:07.824: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 13 21:19:07.828: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 13 21:19:07.828: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 13 21:19:07.828: INFO: e2e test version: v1.12.1
Feb 13 21:19:07.829: INFO: kube-apiserver version: v1.12.3
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:19:07.829: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
Feb 13 21:19:07.878: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 13 21:19:07.886: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-q89mj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-q89mj
Feb 13 21:19:12.017: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-q89mj
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 21:19:12.018: INFO: Initial restart count of pod liveness-http is 0
Feb 13 21:19:26.031: INFO: Restart count of pod e2e-tests-container-probe-q89mj/liveness-http is now 1 (14.013284239s elapsed)
Feb 13 21:19:46.048: INFO: Restart count of pod e2e-tests-container-probe-q89mj/liveness-http is now 2 (34.030284188s elapsed)
Feb 13 21:20:06.065: INFO: Restart count of pod e2e-tests-container-probe-q89mj/liveness-http is now 3 (54.047267202s elapsed)
Feb 13 21:20:24.081: INFO: Restart count of pod e2e-tests-container-probe-q89mj/liveness-http is now 4 (1m12.063070186s elapsed)
Feb 13 21:21:28.145: INFO: Restart count of pod e2e-tests-container-probe-q89mj/liveness-http is now 5 (2m16.127236445s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:21:28.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q89mj" for this suite.
Feb 13 21:21:34.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:21:34.197: INFO: namespace: e2e-tests-container-probe-q89mj, resource: bindings, ignored listing per whitelist
Feb 13 21:21:34.205: INFO: namespace e2e-tests-container-probe-q89mj deletion completed in 6.046798959s

• [SLOW TEST:146.376 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:21:34.205: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d6wth
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:21:34.344: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-d6wth" to be "success or failure"
Feb 13 21:21:34.348: INFO: Pod "downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.412307ms
Feb 13 21:21:36.350: INFO: Pod "downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005135074s
Feb 13 21:21:38.352: INFO: Pod "downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00707788s
STEP: Saw pod success
Feb 13 21:21:38.352: INFO: Pod "downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:21:38.353: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:21:38.366: INFO: Waiting for pod downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d to disappear
Feb 13 21:21:38.367: INFO: Pod downwardapi-volume-56dd6598-2fd5-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:21:38.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d6wth" for this suite.
Feb 13 21:21:44.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:21:44.405: INFO: namespace: e2e-tests-projected-d6wth, resource: bindings, ignored listing per whitelist
Feb 13 21:21:44.418: INFO: namespace e2e-tests-projected-d6wth deletion completed in 6.049431603s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:21:44.419: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rgrmf
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 13 21:21:44.566: INFO: Waiting up to 5m0s for pod "pod-5cf48d53-2fd5-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-rgrmf" to be "success or failure"
Feb 13 21:21:44.570: INFO: Pod "pod-5cf48d53-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.245448ms
Feb 13 21:21:46.572: INFO: Pod "pod-5cf48d53-2fd5-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006234171s
STEP: Saw pod success
Feb 13 21:21:46.572: INFO: Pod "pod-5cf48d53-2fd5-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:21:46.574: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-5cf48d53-2fd5-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:21:46.584: INFO: Waiting for pod pod-5cf48d53-2fd5-11e9-829f-22a36399a92d to disappear
Feb 13 21:21:46.585: INFO: Pod pod-5cf48d53-2fd5-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:21:46.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rgrmf" for this suite.
Feb 13 21:21:52.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:21:52.628: INFO: namespace: e2e-tests-emptydir-rgrmf, resource: bindings, ignored listing per whitelist
Feb 13 21:21:52.628: INFO: namespace e2e-tests-emptydir-rgrmf deletion completed in 6.040475373s

• [SLOW TEST:8.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:21:52.628: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-cfxs8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 13 21:21:53.268: INFO: Waiting up to 5m0s for pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m" in namespace "e2e-tests-svcaccounts-cfxs8" to be "success or failure"
Feb 13 21:21:53.275: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m": Phase="Pending", Reason="", readiness=false. Elapsed: 6.841902ms
Feb 13 21:21:55.276: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008715555s
Feb 13 21:21:57.278: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010223768s
STEP: Saw pod success
Feb 13 21:21:57.278: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m" satisfied condition "success or failure"
Feb 13 21:21:57.279: INFO: Trying to get logs from node alex-300-cp3-vsp1-workerdf4199ef27 pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m container token-test: <nil>
STEP: delete the pod
Feb 13 21:21:57.295: INFO: Waiting for pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m to disappear
Feb 13 21:21:57.296: INFO: Pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-djx8m no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 13 21:21:57.298: INFO: Waiting up to 5m0s for pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n" in namespace "e2e-tests-svcaccounts-cfxs8" to be "success or failure"
Feb 13 21:21:57.307: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n": Phase="Pending", Reason="", readiness=false. Elapsed: 8.159418ms
Feb 13 21:21:59.309: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010180517s
Feb 13 21:22:01.311: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01221316s
STEP: Saw pod success
Feb 13 21:22:01.311: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n" satisfied condition "success or failure"
Feb 13 21:22:01.312: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n container root-ca-test: <nil>
STEP: delete the pod
Feb 13 21:22:01.323: INFO: Waiting for pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n to disappear
Feb 13 21:22:01.325: INFO: Pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-zjk9n no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 13 21:22:01.329: INFO: Waiting up to 5m0s for pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4" in namespace "e2e-tests-svcaccounts-cfxs8" to be "success or failure"
Feb 13 21:22:01.332: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.213099ms
Feb 13 21:22:03.334: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004954666s
Feb 13 21:22:05.336: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007021843s
STEP: Saw pod success
Feb 13 21:22:05.336: INFO: Pod "pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4" satisfied condition "success or failure"
Feb 13 21:22:05.337: INFO: Trying to get logs from node alex-300-cp3-vsp1-workerdf4199ef27 pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4 container namespace-test: <nil>
STEP: delete the pod
Feb 13 21:22:05.351: INFO: Waiting for pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4 to disappear
Feb 13 21:22:05.353: INFO: Pod pod-service-account-6224bc5f-2fd5-11e9-829f-22a36399a92d-c6jp4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:22:05.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cfxs8" for this suite.
Feb 13 21:22:11.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:22:11.377: INFO: namespace: e2e-tests-svcaccounts-cfxs8, resource: bindings, ignored listing per whitelist
Feb 13 21:22:11.406: INFO: namespace e2e-tests-svcaccounts-cfxs8 deletion completed in 6.050449266s

• [SLOW TEST:18.778 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:22:11.406: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pqjrg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 21:22:11.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-pqjrg'
Feb 13 21:22:11.852: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 21:22:11.852: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb 13 21:22:13.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pqjrg'
Feb 13 21:22:13.952: INFO: stderr: ""
Feb 13 21:22:13.952: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:22:13.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pqjrg" for this suite.
Feb 13 21:22:19.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:22:19.995: INFO: namespace: e2e-tests-kubectl-pqjrg, resource: bindings, ignored listing per whitelist
Feb 13 21:22:20.010: INFO: namespace e2e-tests-kubectl-pqjrg deletion completed in 6.055221077s

• [SLOW TEST:8.604 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:22:20.011: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-v7klh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 13 21:22:20.147: INFO: Waiting up to 5m0s for pod "var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d" in namespace "e2e-tests-var-expansion-v7klh" to be "success or failure"
Feb 13 21:22:20.150: INFO: Pod "var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.871485ms
Feb 13 21:22:22.152: INFO: Pod "var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004707036s
Feb 13 21:22:24.153: INFO: Pod "var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006223959s
STEP: Saw pod success
Feb 13 21:22:24.153: INFO: Pod "var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:22:24.155: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 21:22:24.168: INFO: Waiting for pod var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d to disappear
Feb 13 21:22:24.169: INFO: Pod var-expansion-722a664f-2fd5-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:22:24.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-v7klh" for this suite.
Feb 13 21:22:30.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:22:30.210: INFO: namespace: e2e-tests-var-expansion-v7klh, resource: bindings, ignored listing per whitelist
Feb 13 21:22:30.220: INFO: namespace e2e-tests-var-expansion-v7klh deletion completed in 6.048589539s

• [SLOW TEST:10.210 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:22:30.222: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-8dqt4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0213 21:22:31.384242      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 21:22:31.384: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:22:31.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8dqt4" for this suite.
Feb 13 21:22:37.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:22:37.400: INFO: namespace: e2e-tests-gc-8dqt4, resource: bindings, ignored listing per whitelist
Feb 13 21:22:37.429: INFO: namespace e2e-tests-gc-8dqt4 deletion completed in 6.042573903s

• [SLOW TEST:7.207 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:22:37.430: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rnhvm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 13 21:22:37.590: INFO: namespace e2e-tests-kubectl-rnhvm
Feb 13 21:22:37.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-rnhvm'
Feb 13 21:22:37.773: INFO: stderr: ""
Feb 13 21:22:37.773: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 21:22:38.775: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:22:38.775: INFO: Found 0 / 1
Feb 13 21:22:39.775: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:22:39.775: INFO: Found 0 / 1
Feb 13 21:22:40.775: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:22:40.775: INFO: Found 0 / 1
Feb 13 21:22:41.775: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:22:41.775: INFO: Found 1 / 1
Feb 13 21:22:41.775: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 21:22:41.777: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:22:41.777: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 21:22:41.777: INFO: wait on redis-master startup in e2e-tests-kubectl-rnhvm 
Feb 13 21:22:41.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 logs redis-master-c8drf redis-master --namespace=e2e-tests-kubectl-rnhvm'
Feb 13 21:22:41.854: INFO: stderr: ""
Feb 13 21:22:41.854: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 21:22:34.013 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 21:22:34.013 # Server started, Redis version 3.2.12\n1:M 13 Feb 21:22:34.013 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 21:22:34.013 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 13 21:22:41.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-rnhvm'
Feb 13 21:22:41.946: INFO: stderr: ""
Feb 13 21:22:41.946: INFO: stdout: "service/rm2 exposed\n"
Feb 13 21:22:41.951: INFO: Service rm2 in namespace e2e-tests-kubectl-rnhvm found.
STEP: exposing service
Feb 13 21:22:43.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-rnhvm'
Feb 13 21:22:44.044: INFO: stderr: ""
Feb 13 21:22:44.044: INFO: stdout: "service/rm3 exposed\n"
Feb 13 21:22:44.045: INFO: Service rm3 in namespace e2e-tests-kubectl-rnhvm found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:22:46.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rnhvm" for this suite.
Feb 13 21:23:08.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:23:08.075: INFO: namespace: e2e-tests-kubectl-rnhvm, resource: bindings, ignored listing per whitelist
Feb 13 21:23:08.092: INFO: namespace e2e-tests-kubectl-rnhvm deletion completed in 22.042375139s

• [SLOW TEST:30.662 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:23:08.093: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dk4pv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:23:08.233: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-dk4pv" to be "success or failure"
Feb 13 21:23:08.239: INFO: Pod "downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.15085ms
Feb 13 21:23:10.241: INFO: Pod "downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008126097s
STEP: Saw pod success
Feb 13 21:23:10.242: INFO: Pod "downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:23:10.243: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:23:10.254: INFO: Waiting for pod downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d to disappear
Feb 13 21:23:10.255: INFO: Pod downwardapi-volume-8ed38aae-2fd5-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:23:10.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dk4pv" for this suite.
Feb 13 21:23:16.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:23:16.289: INFO: namespace: e2e-tests-downward-api-dk4pv, resource: bindings, ignored listing per whitelist
Feb 13 21:23:16.308: INFO: namespace e2e-tests-downward-api-dk4pv deletion completed in 6.051142217s

• [SLOW TEST:8.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:23:16.309: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6hf8j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 13 21:23:16.453: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-495519211 proxy --unix-socket=/tmp/kubectl-proxy-unix443570766/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:23:16.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6hf8j" for this suite.
Feb 13 21:23:22.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:23:22.553: INFO: namespace: e2e-tests-kubectl-6hf8j, resource: bindings, ignored listing per whitelist
Feb 13 21:23:22.569: INFO: namespace e2e-tests-kubectl-6hf8j deletion completed in 6.052554768s

• [SLOW TEST:6.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:23:22.570: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-shf7t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 21:23:22.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-shf7t'
Feb 13 21:23:22.785: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 21:23:22.785: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb 13 21:23:22.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-shf7t'
Feb 13 21:23:22.881: INFO: stderr: ""
Feb 13 21:23:22.881: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:23:22.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-shf7t" for this suite.
Feb 13 21:23:44.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:23:44.918: INFO: namespace: e2e-tests-kubectl-shf7t, resource: bindings, ignored listing per whitelist
Feb 13 21:23:44.932: INFO: namespace e2e-tests-kubectl-shf7t deletion completed in 22.046302909s

• [SLOW TEST:22.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:23:44.932: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-f7z6q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 21:23:45.065: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:23:48.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-f7z6q" for this suite.
Feb 13 21:23:54.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:23:54.919: INFO: namespace: e2e-tests-init-container-f7z6q, resource: bindings, ignored listing per whitelist
Feb 13 21:23:54.924: INFO: namespace e2e-tests-init-container-f7z6q deletion completed in 6.044727073s

• [SLOW TEST:9.991 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:23:54.925: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q4xf9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:23:55.064: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-q4xf9" to be "success or failure"
Feb 13 21:23:55.069: INFO: Pod "downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.872735ms
Feb 13 21:23:57.070: INFO: Pod "downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006588474s
STEP: Saw pod success
Feb 13 21:23:57.071: INFO: Pod "downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:23:57.072: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:23:57.083: INFO: Waiting for pod downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d to disappear
Feb 13 21:23:57.084: INFO: Pod downwardapi-volume-aabd9924-2fd5-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:23:57.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q4xf9" for this suite.
Feb 13 21:24:03.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:24:03.112: INFO: namespace: e2e-tests-downward-api-q4xf9, resource: bindings, ignored listing per whitelist
Feb 13 21:24:03.142: INFO: namespace e2e-tests-downward-api-q4xf9 deletion completed in 6.056352209s

• [SLOW TEST:8.217 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:24:03.142: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-zh82s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:24:03.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-zh82s" for this suite.
Feb 13 21:24:09.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:24:09.321: INFO: namespace: e2e-tests-services-zh82s, resource: bindings, ignored listing per whitelist
Feb 13 21:24:09.334: INFO: namespace e2e-tests-services-zh82s deletion completed in 6.051143361s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.191 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:24:09.335: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-ck2b6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0213 21:24:49.489132      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 21:24:49.489: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:24:49.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ck2b6" for this suite.
Feb 13 21:24:55.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:24:55.527: INFO: namespace: e2e-tests-gc-ck2b6, resource: bindings, ignored listing per whitelist
Feb 13 21:24:55.535: INFO: namespace e2e-tests-gc-ck2b6 deletion completed in 6.044389861s

• [SLOW TEST:46.200 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:24:55.535: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v4hdk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 13 21:24:55.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:24:55.819: INFO: stderr: ""
Feb 13 21:24:55.819: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 21:24:55.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:24:55.908: INFO: stderr: ""
Feb 13 21:24:55.908: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-ss7xg "
Feb 13 21:24:55.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:24:55.964: INFO: stderr: ""
Feb 13 21:24:55.964: INFO: stdout: ""
Feb 13 21:24:55.964: INFO: update-demo-nautilus-pxv4w is created but not running
Feb 13 21:25:00.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:01.035: INFO: stderr: ""
Feb 13 21:25:01.035: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-ss7xg "
Feb 13 21:25:01.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:01.097: INFO: stderr: ""
Feb 13 21:25:01.097: INFO: stdout: "true"
Feb 13 21:25:01.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:01.152: INFO: stderr: ""
Feb 13 21:25:01.152: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 21:25:01.152: INFO: validating pod update-demo-nautilus-pxv4w
Feb 13 21:25:01.155: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 21:25:01.155: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 21:25:01.155: INFO: update-demo-nautilus-pxv4w is verified up and running
Feb 13 21:25:01.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-ss7xg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:01.229: INFO: stderr: ""
Feb 13 21:25:01.229: INFO: stdout: "true"
Feb 13 21:25:01.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-ss7xg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:01.296: INFO: stderr: ""
Feb 13 21:25:01.296: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 21:25:01.296: INFO: validating pod update-demo-nautilus-ss7xg
Feb 13 21:25:01.299: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 21:25:01.299: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 21:25:01.299: INFO: update-demo-nautilus-ss7xg is verified up and running
STEP: scaling down the replication controller
Feb 13 21:25:01.301: INFO: scanned /root for discovery docs: <nil>
Feb 13 21:25:01.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:02.387: INFO: stderr: ""
Feb 13 21:25:02.387: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 21:25:02.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:02.471: INFO: stderr: ""
Feb 13 21:25:02.471: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-ss7xg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 21:25:07.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:07.537: INFO: stderr: ""
Feb 13 21:25:07.537: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-ss7xg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 21:25:12.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:12.608: INFO: stderr: ""
Feb 13 21:25:12.608: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-ss7xg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 13 21:25:17.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:17.664: INFO: stderr: ""
Feb 13 21:25:17.664: INFO: stdout: "update-demo-nautilus-pxv4w "
Feb 13 21:25:17.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:17.718: INFO: stderr: ""
Feb 13 21:25:17.718: INFO: stdout: "true"
Feb 13 21:25:17.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:17.781: INFO: stderr: ""
Feb 13 21:25:17.781: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 21:25:17.781: INFO: validating pod update-demo-nautilus-pxv4w
Feb 13 21:25:17.783: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 21:25:17.783: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 21:25:17.783: INFO: update-demo-nautilus-pxv4w is verified up and running
STEP: scaling up the replication controller
Feb 13 21:25:17.784: INFO: scanned /root for discovery docs: <nil>
Feb 13 21:25:17.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:18.867: INFO: stderr: ""
Feb 13 21:25:18.867: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 21:25:18.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:18.939: INFO: stderr: ""
Feb 13 21:25:18.939: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-zxmgq "
Feb 13 21:25:18.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:18.994: INFO: stderr: ""
Feb 13 21:25:18.994: INFO: stdout: "true"
Feb 13 21:25:18.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:19.057: INFO: stderr: ""
Feb 13 21:25:19.057: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 21:25:19.057: INFO: validating pod update-demo-nautilus-pxv4w
Feb 13 21:25:19.059: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 21:25:19.059: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 21:25:19.059: INFO: update-demo-nautilus-pxv4w is verified up and running
Feb 13 21:25:19.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-zxmgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:19.130: INFO: stderr: ""
Feb 13 21:25:19.130: INFO: stdout: ""
Feb 13 21:25:19.130: INFO: update-demo-nautilus-zxmgq is created but not running
Feb 13 21:25:24.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.189: INFO: stderr: ""
Feb 13 21:25:24.189: INFO: stdout: "update-demo-nautilus-pxv4w update-demo-nautilus-zxmgq "
Feb 13 21:25:24.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.245: INFO: stderr: ""
Feb 13 21:25:24.245: INFO: stdout: "true"
Feb 13 21:25:24.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-pxv4w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.306: INFO: stderr: ""
Feb 13 21:25:24.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 21:25:24.306: INFO: validating pod update-demo-nautilus-pxv4w
Feb 13 21:25:24.308: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 21:25:24.308: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 21:25:24.308: INFO: update-demo-nautilus-pxv4w is verified up and running
Feb 13 21:25:24.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-zxmgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.374: INFO: stderr: ""
Feb 13 21:25:24.374: INFO: stdout: "true"
Feb 13 21:25:24.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-zxmgq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.443: INFO: stderr: ""
Feb 13 21:25:24.443: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 21:25:24.443: INFO: validating pod update-demo-nautilus-zxmgq
Feb 13 21:25:24.446: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 21:25:24.446: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 21:25:24.446: INFO: update-demo-nautilus-zxmgq is verified up and running
STEP: using delete to clean up resources
Feb 13 21:25:24.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.525: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:25:24.525: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 21:25:24.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-v4hdk'
Feb 13 21:25:24.600: INFO: stderr: "No resources found.\n"
Feb 13 21:25:24.600: INFO: stdout: ""
Feb 13 21:25:24.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -l name=update-demo --namespace=e2e-tests-kubectl-v4hdk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 21:25:24.661: INFO: stderr: ""
Feb 13 21:25:24.661: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:25:24.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v4hdk" for this suite.
Feb 13 21:25:46.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:25:46.707: INFO: namespace: e2e-tests-kubectl-v4hdk, resource: bindings, ignored listing per whitelist
Feb 13 21:25:46.711: INFO: namespace e2e-tests-kubectl-v4hdk deletion completed in 22.047416362s

• [SLOW TEST:51.176 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:25:46.712: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-gwk8s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gwk8s
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-gwk8s
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-gwk8s
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-gwk8s
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-gwk8s
Feb 13 21:25:50.877: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-gwk8s, name: ss-0, uid: ef6bcb98-2fd5-11e9-8578-0050569e397b, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 21:25:50.879: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-gwk8s, name: ss-0, uid: ef6bcb98-2fd5-11e9-8578-0050569e397b, status phase: Failed. Waiting for statefulset controller to delete.
Feb 13 21:25:50.883: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-gwk8s
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-gwk8s
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-gwk8s and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 21:25:54.902: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gwk8s
Feb 13 21:25:54.905: INFO: Scaling statefulset ss to 0
Feb 13 21:26:04.916: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:26:04.917: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:26:04.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gwk8s" for this suite.
Feb 13 21:26:10.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:26:10.989: INFO: namespace: e2e-tests-statefulset-gwk8s, resource: bindings, ignored listing per whitelist
Feb 13 21:26:11.001: INFO: namespace e2e-tests-statefulset-gwk8s deletion completed in 6.071270722s

• [SLOW TEST:24.289 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:26:11.001: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8r26k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:26:11.139: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 21:26:11.145: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:11.149: INFO: Number of nodes with available pods: 0
Feb 13 21:26:11.149: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 21:26:12.158: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:12.159: INFO: Number of nodes with available pods: 0
Feb 13 21:26:12.159: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 21:26:13.151: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:13.152: INFO: Number of nodes with available pods: 0
Feb 13 21:26:13.152: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 21:26:14.152: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:14.153: INFO: Number of nodes with available pods: 0
Feb 13 21:26:14.153: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 21:26:15.152: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:15.154: INFO: Number of nodes with available pods: 1
Feb 13 21:26:15.154: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:26:16.151: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:16.153: INFO: Number of nodes with available pods: 2
Feb 13 21:26:16.153: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 13 21:26:16.169: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:16.169: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:16.172: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:17.179: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:17.179: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:17.182: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:18.179: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:18.179: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:18.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:19.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:19.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:19.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:20.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:20.179: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:20.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:21.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:21.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:21.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:22.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:22.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:22.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:23.179: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:23.179: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:23.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:24.183: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:24.183: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:24.185: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:25.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:25.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:25.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:26.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:26.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:26.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:27.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:27.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:27.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:28.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:28.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:28.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:29.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:29.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:29.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:30.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:30.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:30.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:31.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:31.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:31.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:32.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:32.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:32.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:33.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:33.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:33.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:34.182: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:34.182: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:34.189: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:35.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:35.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:35.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:36.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:36.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:36.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:37.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:37.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:37.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:38.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:38.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:38.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:39.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:39.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:39.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:40.179: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:40.179: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:40.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:41.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:41.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:41.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:42.180: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:42.180: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:42.189: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:43.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:43.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:43.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:44.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:44.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:44.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:45.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:45.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:45.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:46.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:46.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:46.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:47.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:47.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:47.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:48.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:48.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:48.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:49.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:49.178: INFO: Wrong image for pod: daemon-set-ddl4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:49.178: INFO: Pod daemon-set-ddl4n is not available
Feb 13 21:26:49.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:50.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:50.178: INFO: Pod daemon-set-6tngz is not available
Feb 13 21:26:50.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:51.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:51.178: INFO: Pod daemon-set-6tngz is not available
Feb 13 21:26:51.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:52.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:52.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:53.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:53.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:54.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:54.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:55.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:55.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:56.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:56.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:57.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:57.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:58.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:58.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:26:59.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:26:59.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:00.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:00.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:01.179: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:01.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:02.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:02.179: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:03.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:03.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:04.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:04.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:05.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:05.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:06.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:06.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:07.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:07.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:08.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:08.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:09.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:09.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:10.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:10.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:11.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:11.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:12.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:12.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:13.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:13.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:14.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:14.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:15.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:15.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:16.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:16.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:17.179: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:17.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:18.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:18.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:19.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:19.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:20.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:20.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:21.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:21.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:22.178: INFO: Wrong image for pod: daemon-set-5cl4x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 13 21:27:22.178: INFO: Pod daemon-set-5cl4x is not available
Feb 13 21:27:22.181: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:23.178: INFO: Pod daemon-set-4m2x8 is not available
Feb 13 21:27:23.180: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 13 21:27:23.182: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:23.184: INFO: Number of nodes with available pods: 1
Feb 13 21:27:23.184: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:27:24.187: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:24.188: INFO: Number of nodes with available pods: 1
Feb 13 21:27:24.188: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:27:25.186: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:25.187: INFO: Number of nodes with available pods: 1
Feb 13 21:27:25.188: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:27:26.190: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:26.213: INFO: Number of nodes with available pods: 1
Feb 13 21:27:26.214: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:27:27.187: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:27.188: INFO: Number of nodes with available pods: 1
Feb 13 21:27:27.188: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:27:28.186: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:27:28.191: INFO: Number of nodes with available pods: 2
Feb 13 21:27:28.191: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8r26k, will wait for the garbage collector to delete the pods
Feb 13 21:27:28.252: INFO: Deleting {extensions DaemonSet} daemon-set took: 4.085039ms
Feb 13 21:27:28.352: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.303602ms
Feb 13 21:27:34.754: INFO: Number of nodes with available pods: 0
Feb 13 21:27:34.754: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 21:27:34.755: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8r26k/daemonsets","resourceVersion":"1262401"},"items":null}

Feb 13 21:27:34.756: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8r26k/pods","resourceVersion":"1262401"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:27:34.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8r26k" for this suite.
Feb 13 21:27:40.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:27:40.786: INFO: namespace: e2e-tests-daemonsets-8r26k, resource: bindings, ignored listing per whitelist
Feb 13 21:27:40.820: INFO: namespace e2e-tests-daemonsets-8r26k deletion completed in 6.056845735s

• [SLOW TEST:89.819 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:27:40.821: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mtxv6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:27:40.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-mtxv6" to be "success or failure"
Feb 13 21:27:40.963: INFO: Pod "downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.189966ms
Feb 13 21:27:42.965: INFO: Pod "downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006467504s
STEP: Saw pod success
Feb 13 21:27:42.965: INFO: Pod "downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:27:42.966: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:27:42.980: INFO: Waiting for pod downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d to disappear
Feb 13 21:27:42.981: INFO: Pod downwardapi-volume-316235d9-2fd6-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:27:42.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mtxv6" for this suite.
Feb 13 21:27:48.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:27:49.015: INFO: namespace: e2e-tests-projected-mtxv6, resource: bindings, ignored listing per whitelist
Feb 13 21:27:49.028: INFO: namespace e2e-tests-projected-mtxv6 deletion completed in 6.04588301s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:27:49.028: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6t8mg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 21:27:49.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6t8mg'
Feb 13 21:27:49.243: INFO: stderr: ""
Feb 13 21:27:49.243: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb 13 21:27:49.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6t8mg'
Feb 13 21:27:54.701: INFO: stderr: ""
Feb 13 21:27:54.701: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:27:54.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6t8mg" for this suite.
Feb 13 21:28:00.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:28:00.737: INFO: namespace: e2e-tests-kubectl-6t8mg, resource: bindings, ignored listing per whitelist
Feb 13 21:28:00.745: INFO: namespace e2e-tests-kubectl-6t8mg deletion completed in 6.041716043s

• [SLOW TEST:11.717 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:28:00.745: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-228qm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3d42e5b0-2fd6-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:28:00.888: INFO: Waiting up to 5m0s for pod "pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-228qm" to be "success or failure"
Feb 13 21:28:00.895: INFO: Pod "pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.4746ms
Feb 13 21:28:02.897: INFO: Pod "pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.008631957s
Feb 13 21:28:04.899: INFO: Pod "pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010129567s
STEP: Saw pod success
Feb 13 21:28:04.899: INFO: Pod "pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:28:04.900: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:28:04.910: INFO: Waiting for pod pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d to disappear
Feb 13 21:28:04.911: INFO: Pod pod-secrets-3d434d22-2fd6-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:28:04.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-228qm" for this suite.
Feb 13 21:28:10.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:28:10.952: INFO: namespace: e2e-tests-secrets-228qm, resource: bindings, ignored listing per whitelist
Feb 13 21:28:10.966: INFO: namespace e2e-tests-secrets-228qm deletion completed in 6.053341124s

• [SLOW TEST:10.221 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:28:10.967: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zhdph
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 13 21:28:11.107: INFO: Waiting up to 5m0s for pod "pod-435a9daa-2fd6-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-zhdph" to be "success or failure"
Feb 13 21:28:11.108: INFO: Pod "pod-435a9daa-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.203618ms
Feb 13 21:28:13.109: INFO: Pod "pod-435a9daa-2fd6-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002606352s
STEP: Saw pod success
Feb 13 21:28:13.109: INFO: Pod "pod-435a9daa-2fd6-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:28:13.111: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-435a9daa-2fd6-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:28:13.123: INFO: Waiting for pod pod-435a9daa-2fd6-11e9-829f-22a36399a92d to disappear
Feb 13 21:28:13.124: INFO: Pod pod-435a9daa-2fd6-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:28:13.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zhdph" for this suite.
Feb 13 21:28:19.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:28:19.161: INFO: namespace: e2e-tests-emptydir-zhdph, resource: bindings, ignored listing per whitelist
Feb 13 21:28:19.171: INFO: namespace e2e-tests-emptydir-zhdph deletion completed in 6.045642079s

• [SLOW TEST:8.204 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:28:19.171: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-g9cs7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-g9cs7
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-g9cs7
STEP: Deleting pre-stop pod
Feb 13 21:28:32.338: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:28:32.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-g9cs7" for this suite.
Feb 13 21:29:10.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:29:10.369: INFO: namespace: e2e-tests-prestop-g9cs7, resource: bindings, ignored listing per whitelist
Feb 13 21:29:10.389: INFO: namespace e2e-tests-prestop-g9cs7 deletion completed in 38.044463813s

• [SLOW TEST:51.217 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:29:10.389: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-h7k6t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 21:29:10.558: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:10.562: INFO: Number of nodes with available pods: 0
Feb 13 21:29:10.562: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 21:29:11.564: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:11.565: INFO: Number of nodes with available pods: 0
Feb 13 21:29:11.565: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 21:29:12.564: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:12.566: INFO: Number of nodes with available pods: 2
Feb 13 21:29:12.566: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 13 21:29:12.574: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:12.575: INFO: Number of nodes with available pods: 1
Feb 13 21:29:12.575: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:13.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:13.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:13.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:14.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:14.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:14.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:15.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:15.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:15.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:16.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:16.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:16.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:17.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:17.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:17.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:18.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:18.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:18.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:19.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:19.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:19.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:20.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:20.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:20.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:21.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:21.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:21.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:22.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:22.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:22.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:23.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:23.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:23.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:24.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:24.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:24.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:25.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:25.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:25.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:26.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:26.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:26.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:27.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:27.578: INFO: Number of nodes with available pods: 1
Feb 13 21:29:27.578: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:28.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:28.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:28.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:29.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:29.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:29.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:30.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:30.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:30.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:31.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:31.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:31.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:32.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:32.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:32.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:33.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:33.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:33.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:34.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:34.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:34.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:35.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:35.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:35.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:36.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:36.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:36.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:37.588: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:37.589: INFO: Number of nodes with available pods: 1
Feb 13 21:29:37.589: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:38.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:38.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:38.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:39.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:39.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:39.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:40.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:40.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:40.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:41.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:41.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:41.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:42.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:42.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:42.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:43.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:43.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:43.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:44.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:44.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:44.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:45.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:45.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:45.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:46.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:46.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:46.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:47.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:47.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:47.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:48.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:48.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:48.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:49.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:49.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:49.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:50.577: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:50.579: INFO: Number of nodes with available pods: 1
Feb 13 21:29:50.579: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:51.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:51.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:51.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:52.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:52.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:52.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:53.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:53.580: INFO: Number of nodes with available pods: 1
Feb 13 21:29:53.580: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:54.581: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:54.586: INFO: Number of nodes with available pods: 1
Feb 13 21:29:54.586: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:55.579: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:55.585: INFO: Number of nodes with available pods: 1
Feb 13 21:29:55.585: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 21:29:56.578: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 21:29:56.579: INFO: Number of nodes with available pods: 2
Feb 13 21:29:56.579: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-h7k6t, will wait for the garbage collector to delete the pods
Feb 13 21:29:56.636: INFO: Deleting {extensions DaemonSet} daemon-set took: 3.899126ms
Feb 13 21:29:56.736: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.128732ms
Feb 13 21:30:34.737: INFO: Number of nodes with available pods: 0
Feb 13 21:30:34.737: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 21:30:34.739: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h7k6t/daemonsets","resourceVersion":"1262975"},"items":null}

Feb 13 21:30:34.740: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h7k6t/pods","resourceVersion":"1262975"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:30:34.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h7k6t" for this suite.
Feb 13 21:30:40.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:30:40.803: INFO: namespace: e2e-tests-daemonsets-h7k6t, resource: bindings, ignored listing per whitelist
Feb 13 21:30:40.808: INFO: namespace e2e-tests-daemonsets-h7k6t deletion completed in 6.060211825s

• [SLOW TEST:90.419 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:30:40.809: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l4vqh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:30:40.949: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-l4vqh" to be "success or failure"
Feb 13 21:30:40.952: INFO: Pod "downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.004354ms
Feb 13 21:30:42.954: INFO: Pod "downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005258431s
STEP: Saw pod success
Feb 13 21:30:42.955: INFO: Pod "downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:30:42.963: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:30:43.044: INFO: Waiting for pod downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d to disappear
Feb 13 21:30:43.045: INFO: Pod downwardapi-volume-9caaabea-2fd6-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:30:43.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l4vqh" for this suite.
Feb 13 21:30:49.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:30:49.071: INFO: namespace: e2e-tests-projected-l4vqh, resource: bindings, ignored listing per whitelist
Feb 13 21:30:49.109: INFO: namespace e2e-tests-projected-l4vqh deletion completed in 6.060393924s

• [SLOW TEST:8.300 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:30:49.109: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-v5cjp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 13 21:30:49.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263057,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 21:30:49.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263057,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 13 21:30:59.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263077,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 13 21:30:59.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263077,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 13 21:31:09.305: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263095,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 21:31:09.305: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263095,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 13 21:31:19.310: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263114,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 21:31:19.310: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-a,UID:a1a4b1ad-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263114,Generation:0,CreationTimestamp:2019-02-13 21:30:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 13 21:31:29.316: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-b,UID:b97ed923-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263134,Generation:0,CreationTimestamp:2019-02-13 21:31:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 21:31:29.316: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-b,UID:b97ed923-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263134,Generation:0,CreationTimestamp:2019-02-13 21:31:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 13 21:31:39.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-b,UID:b97ed923-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263153,Generation:0,CreationTimestamp:2019-02-13 21:31:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 21:31:39.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v5cjp,SelfLink:/api/v1/namespaces/e2e-tests-watch-v5cjp/configmaps/e2e-watch-test-configmap-b,UID:b97ed923-2fd6-11e9-8578-0050569e397b,ResourceVersion:1263153,Generation:0,CreationTimestamp:2019-02-13 21:31:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:31:49.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-v5cjp" for this suite.
Feb 13 21:31:55.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:31:55.357: INFO: namespace: e2e-tests-watch-v5cjp, resource: bindings, ignored listing per whitelist
Feb 13 21:31:55.369: INFO: namespace e2e-tests-watch-v5cjp deletion completed in 6.045446978s

• [SLOW TEST:66.259 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:31:55.369: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-992nv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 13 21:31:55.508: INFO: Waiting up to 5m0s for pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-992nv" to be "success or failure"
Feb 13 21:31:55.512: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.659675ms
Feb 13 21:31:57.513: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005888461s
Feb 13 21:31:59.515: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007239327s
Feb 13 21:32:01.516: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0083862s
Feb 13 21:32:03.518: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009995484s
Feb 13 21:32:05.520: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.012511161s
STEP: Saw pod success
Feb 13 21:32:05.520: INFO: Pod "pod-c91b666a-2fd6-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:32:05.521: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-c91b666a-2fd6-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:32:05.532: INFO: Waiting for pod pod-c91b666a-2fd6-11e9-829f-22a36399a92d to disappear
Feb 13 21:32:05.534: INFO: Pod pod-c91b666a-2fd6-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:32:05.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-992nv" for this suite.
Feb 13 21:32:11.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:32:11.575: INFO: namespace: e2e-tests-emptydir-992nv, resource: bindings, ignored listing per whitelist
Feb 13 21:32:11.592: INFO: namespace e2e-tests-emptydir-992nv deletion completed in 6.055384671s

• [SLOW TEST:16.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:32:11.592: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2l4v9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2l4v9
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-2l4v9
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-2l4v9
Feb 13 21:32:11.744: INFO: Found 0 stateful pods, waiting for 1
Feb 13 21:32:21.747: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 13 21:32:21.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:32:21.883: INFO: stderr: ""
Feb 13 21:32:21.883: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:32:21.883: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:32:21.884: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 21:32:31.887: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:32:31.887: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:32:31.895: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999998s
Feb 13 21:32:32.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997132642s
Feb 13 21:32:33.899: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994982862s
Feb 13 21:32:34.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.993048887s
Feb 13 21:32:35.903: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.99091247s
Feb 13 21:32:36.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.988918224s
Feb 13 21:32:37.907: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.986851463s
Feb 13 21:32:38.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.984737884s
Feb 13 21:32:39.911: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.982643224s
Feb 13 21:32:40.914: INFO: Verifying statefulset ss doesn't scale past 1 for another 980.733339ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-2l4v9
Feb 13 21:32:41.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:32:42.047: INFO: stderr: ""
Feb 13 21:32:42.047: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:32:42.047: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:32:42.049: INFO: Found 1 stateful pods, waiting for 3
Feb 13 21:32:52.051: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:32:52.051: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:32:52.051: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 13 21:32:52.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:32:52.171: INFO: stderr: ""
Feb 13 21:32:52.171: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:32:52.171: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:32:52.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:32:52.291: INFO: stderr: ""
Feb 13 21:32:52.291: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:32:52.291: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:32:52.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:32:52.419: INFO: stderr: ""
Feb 13 21:32:52.419: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:32:52.419: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:32:52.419: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:32:52.420: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 13 21:33:02.423: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:33:02.423: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:33:02.423: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 21:33:02.430: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999736s
Feb 13 21:33:03.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996559341s
Feb 13 21:33:04.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994191147s
Feb 13 21:33:05.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992049774s
Feb 13 21:33:06.439: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98989942s
Feb 13 21:33:07.441: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987598517s
Feb 13 21:33:08.443: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985625674s
Feb 13 21:33:09.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983247359s
Feb 13 21:33:10.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.981242885s
Feb 13 21:33:11.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 979.225179ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-2l4v9
Feb 13 21:33:12.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:33:12.600: INFO: stderr: ""
Feb 13 21:33:12.600: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:33:12.600: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:33:12.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:33:12.745: INFO: stderr: ""
Feb 13 21:33:12.745: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:33:12.745: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:33:12.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-2l4v9 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:33:12.883: INFO: stderr: ""
Feb 13 21:33:12.883: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:33:12.883: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:33:12.883: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 21:33:42.890: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2l4v9
Feb 13 21:33:42.892: INFO: Scaling statefulset ss to 0
Feb 13 21:33:42.896: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:33:42.897: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:33:42.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2l4v9" for this suite.
Feb 13 21:33:48.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:33:48.933: INFO: namespace: e2e-tests-statefulset-2l4v9, resource: bindings, ignored listing per whitelist
Feb 13 21:33:48.952: INFO: namespace e2e-tests-statefulset-2l4v9 deletion completed in 6.046340421s

• [SLOW TEST:97.360 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:33:48.954: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-45hj7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-0ccf25b5-2fd7-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:33:49.096: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-45hj7" to be "success or failure"
Feb 13 21:33:49.103: INFO: Pod "pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.877794ms
Feb 13 21:33:51.104: INFO: Pod "pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00836904s
STEP: Saw pod success
Feb 13 21:33:51.104: INFO: Pod "pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:33:51.106: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:33:51.117: INFO: Waiting for pod pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:33:51.118: INFO: Pod pod-projected-secrets-0ccf96bd-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:33:51.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-45hj7" for this suite.
Feb 13 21:33:57.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:33:57.166: INFO: namespace: e2e-tests-projected-45hj7, resource: bindings, ignored listing per whitelist
Feb 13 21:33:57.167: INFO: namespace e2e-tests-projected-45hj7 deletion completed in 6.04673718s

• [SLOW TEST:8.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:33:57.168: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-hfp85
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hfp85
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 13 21:33:57.312: INFO: Found 0 stateful pods, waiting for 3
Feb 13 21:34:07.314: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:34:07.314: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:34:07.314: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 13 21:34:07.333: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 13 21:34:17.355: INFO: Updating stateful set ss2
Feb 13 21:34:17.360: INFO: Waiting for Pod e2e-tests-statefulset-hfp85/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 13 21:34:27.401: INFO: Found 1 stateful pods, waiting for 3
Feb 13 21:34:37.403: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:34:37.403: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:34:37.403: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 13 21:34:37.420: INFO: Updating stateful set ss2
Feb 13 21:34:37.433: INFO: Waiting for Pod e2e-tests-statefulset-hfp85/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 21:34:47.450: INFO: Updating stateful set ss2
Feb 13 21:34:47.455: INFO: Waiting for StatefulSet e2e-tests-statefulset-hfp85/ss2 to complete update
Feb 13 21:34:47.458: INFO: Waiting for Pod e2e-tests-statefulset-hfp85/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 21:34:57.461: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hfp85
Feb 13 21:34:57.463: INFO: Scaling statefulset ss2 to 0
Feb 13 21:35:07.471: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:35:07.472: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:35:07.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hfp85" for this suite.
Feb 13 21:35:13.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:35:13.499: INFO: namespace: e2e-tests-statefulset-hfp85, resource: bindings, ignored listing per whitelist
Feb 13 21:35:13.542: INFO: namespace e2e-tests-statefulset-hfp85 deletion completed in 6.059447697s

• [SLOW TEST:76.374 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:35:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-f4hqx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 13 21:35:13.683: INFO: Waiting up to 5m0s for pod "pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-f4hqx" to be "success or failure"
Feb 13 21:35:13.686: INFO: Pod "pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.045258ms
Feb 13 21:35:15.688: INFO: Pod "pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004729752s
STEP: Saw pod success
Feb 13 21:35:15.688: INFO: Pod "pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:35:15.689: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:35:15.703: INFO: Waiting for pod pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:35:15.705: INFO: Pod pod-3f3a97fe-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:35:15.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f4hqx" for this suite.
Feb 13 21:35:21.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:35:21.737: INFO: namespace: e2e-tests-emptydir-f4hqx, resource: bindings, ignored listing per whitelist
Feb 13 21:35:21.750: INFO: namespace e2e-tests-emptydir-f4hqx deletion completed in 6.043814606s

• [SLOW TEST:8.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:35:21.751: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mr7jq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 13 21:35:21.890: INFO: Waiting up to 5m0s for pod "pod-441ed2bc-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-mr7jq" to be "success or failure"
Feb 13 21:35:21.895: INFO: Pod "pod-441ed2bc-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507339ms
Feb 13 21:35:23.897: INFO: Pod "pod-441ed2bc-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007281448s
STEP: Saw pod success
Feb 13 21:35:23.897: INFO: Pod "pod-441ed2bc-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:35:23.898: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-441ed2bc-2fd7-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:35:23.912: INFO: Waiting for pod pod-441ed2bc-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:35:23.913: INFO: Pod pod-441ed2bc-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:35:23.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mr7jq" for this suite.
Feb 13 21:35:29.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:35:29.941: INFO: namespace: e2e-tests-emptydir-mr7jq, resource: bindings, ignored listing per whitelist
Feb 13 21:35:29.965: INFO: namespace e2e-tests-emptydir-mr7jq deletion completed in 6.050893767s

• [SLOW TEST:8.215 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:35:29.967: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v6687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:35:30.112: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-v6687" to be "success or failure"
Feb 13 21:35:30.118: INFO: Pod "downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.153351ms
Feb 13 21:35:32.120: INFO: Pod "downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.008100923s
Feb 13 21:35:34.122: INFO: Pod "downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01000065s
STEP: Saw pod success
Feb 13 21:35:34.122: INFO: Pod "downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:35:34.123: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:35:34.135: INFO: Waiting for pod downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:35:34.136: INFO: Pod downwardapi-volume-49055e89-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:35:34.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v6687" for this suite.
Feb 13 21:35:40.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:35:40.158: INFO: namespace: e2e-tests-downward-api-v6687, resource: bindings, ignored listing per whitelist
Feb 13 21:35:40.182: INFO: namespace e2e-tests-downward-api-v6687 deletion completed in 6.044867902s

• [SLOW TEST:10.216 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:35:40.183: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4v46f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 13 21:35:40.333: INFO: Waiting up to 5m0s for pod "pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-4v46f" to be "success or failure"
Feb 13 21:35:40.343: INFO: Pod "pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.178892ms
Feb 13 21:35:42.345: INFO: Pod "pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.012052341s
Feb 13 21:35:44.346: INFO: Pod "pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013641427s
STEP: Saw pod success
Feb 13 21:35:44.346: INFO: Pod "pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:35:44.348: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:35:44.362: INFO: Waiting for pod pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:35:44.363: INFO: Pod pod-4f1c74f5-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:35:44.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4v46f" for this suite.
Feb 13 21:35:50.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:35:50.413: INFO: namespace: e2e-tests-emptydir-4v46f, resource: bindings, ignored listing per whitelist
Feb 13 21:35:50.415: INFO: namespace e2e-tests-emptydir-4v46f deletion completed in 6.049268644s

• [SLOW TEST:10.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:35:50.416: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-wqgqj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:35:50.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wqgqj" for this suite.
Feb 13 21:36:12.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:12.645: INFO: namespace: e2e-tests-pods-wqgqj, resource: bindings, ignored listing per whitelist
Feb 13 21:36:12.658: INFO: namespace e2e-tests-pods-wqgqj deletion completed in 22.067903378s

• [SLOW TEST:22.242 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:36:12.658: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2hxhr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-62768a83-2fd7-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 21:36:12.800: INFO: Waiting up to 5m0s for pod "pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-2hxhr" to be "success or failure"
Feb 13 21:36:12.804: INFO: Pod "pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.374014ms
Feb 13 21:36:14.806: INFO: Pod "pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005844755s
STEP: Saw pod success
Feb 13 21:36:14.806: INFO: Pod "pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:36:14.807: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:36:14.819: INFO: Waiting for pod pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:36:14.821: INFO: Pod pod-configmaps-6276dc01-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:36:14.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2hxhr" for this suite.
Feb 13 21:36:20.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:20.856: INFO: namespace: e2e-tests-configmap-2hxhr, resource: bindings, ignored listing per whitelist
Feb 13 21:36:20.869: INFO: namespace e2e-tests-configmap-2hxhr deletion completed in 6.046958265s

• [SLOW TEST:8.211 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:36:20.870: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q6j5m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 21:36:21.008: INFO: Waiting up to 5m0s for pod "downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-q6j5m" to be "success or failure"
Feb 13 21:36:21.012: INFO: Pod "downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.877142ms
Feb 13 21:36:23.013: INFO: Pod "downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005422797s
STEP: Saw pod success
Feb 13 21:36:23.013: INFO: Pod "downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:36:23.015: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 21:36:23.026: INFO: Waiting for pod downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:36:23.028: INFO: Pod downward-api-675b7f81-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:36:23.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q6j5m" for this suite.
Feb 13 21:36:29.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:29.076: INFO: namespace: e2e-tests-downward-api-q6j5m, resource: bindings, ignored listing per whitelist
Feb 13 21:36:29.079: INFO: namespace e2e-tests-downward-api-q6j5m deletion completed in 6.048745989s

• [SLOW TEST:8.210 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:36:29.080: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-2gbct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 13 21:36:29.219: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-2gbct" to be "success or failure"
Feb 13 21:36:29.223: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.979086ms
Feb 13 21:36:31.225: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005644349s
STEP: Saw pod success
Feb 13 21:36:31.225: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 13 21:36:31.226: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 13 21:36:31.240: INFO: Waiting for pod pod-host-path-test to disappear
Feb 13 21:36:31.241: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:36:31.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-2gbct" for this suite.
Feb 13 21:36:37.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:37.279: INFO: namespace: e2e-tests-hostpath-2gbct, resource: bindings, ignored listing per whitelist
Feb 13 21:36:37.293: INFO: namespace e2e-tests-hostpath-2gbct deletion completed in 6.049915636s

• [SLOW TEST:8.213 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:36:37.294: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-n4b8z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 13 21:36:37.431: INFO: Waiting up to 5m0s for pod "pod-7125973a-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-n4b8z" to be "success or failure"
Feb 13 21:36:37.432: INFO: Pod "pod-7125973a-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.490331ms
Feb 13 21:36:39.434: INFO: Pod "pod-7125973a-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002960657s
STEP: Saw pod success
Feb 13 21:36:39.434: INFO: Pod "pod-7125973a-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:36:39.435: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-7125973a-2fd7-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:36:39.451: INFO: Waiting for pod pod-7125973a-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:36:39.452: INFO: Pod pod-7125973a-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:36:39.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n4b8z" for this suite.
Feb 13 21:36:45.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:36:45.477: INFO: namespace: e2e-tests-emptydir-n4b8z, resource: bindings, ignored listing per whitelist
Feb 13 21:36:45.500: INFO: namespace e2e-tests-emptydir-n4b8z deletion completed in 6.045657187s

• [SLOW TEST:8.206 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:36:45.501: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-sjbcs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-sjbcs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sjbcs to expose endpoints map[]
Feb 13 21:36:45.648: INFO: Get endpoints failed (1.261136ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 13 21:36:46.650: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sjbcs exposes endpoints map[] (1.003246491s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-sjbcs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sjbcs to expose endpoints map[pod1:[100]]
Feb 13 21:36:49.667: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sjbcs exposes endpoints map[pod1:[100]] (3.012636451s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-sjbcs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sjbcs to expose endpoints map[pod1:[100] pod2:[101]]
Feb 13 21:36:52.688: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sjbcs exposes endpoints map[pod1:[100] pod2:[101]] (3.016809576s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-sjbcs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sjbcs to expose endpoints map[pod2:[101]]
Feb 13 21:36:53.702: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sjbcs exposes endpoints map[pod2:[101]] (1.010012166s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-sjbcs
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sjbcs to expose endpoints map[]
Feb 13 21:36:53.713: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sjbcs exposes endpoints map[] (7.414261ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:36:53.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-sjbcs" for this suite.
Feb 13 21:37:15.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:37:15.787: INFO: namespace: e2e-tests-services-sjbcs, resource: bindings, ignored listing per whitelist
Feb 13 21:37:15.798: INFO: namespace e2e-tests-services-sjbcs deletion completed in 22.048330338s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.297 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:37:15.798: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g8lgq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 13 21:37:15.939: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-495519211 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:37:15.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g8lgq" for this suite.
Feb 13 21:37:22.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:37:22.043: INFO: namespace: e2e-tests-kubectl-g8lgq, resource: bindings, ignored listing per whitelist
Feb 13 21:37:22.046: INFO: namespace e2e-tests-kubectl-g8lgq deletion completed in 6.047650249s

• [SLOW TEST:6.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:37:22.047: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bl2q7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 13 21:37:30.263: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:30.264: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:32.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:32.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:34.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:34.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:36.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:36.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:38.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:38.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:40.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:40.267: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:42.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:42.267: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:44.265: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:44.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:46.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:46.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:48.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:48.266: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 13 21:37:50.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 13 21:37:50.266: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:37:50.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bl2q7" for this suite.
Feb 13 21:38:12.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:38:12.283: INFO: namespace: e2e-tests-container-lifecycle-hook-bl2q7, resource: bindings, ignored listing per whitelist
Feb 13 21:38:12.312: INFO: namespace e2e-tests-container-lifecycle-hook-bl2q7 deletion completed in 22.04350654s

• [SLOW TEST:50.265 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:38:12.313: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ldgr2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a9cbd62f-2fd7-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:38:12.485: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-ldgr2" to be "success or failure"
Feb 13 21:38:12.494: INFO: Pod "pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.836845ms
Feb 13 21:38:14.495: INFO: Pod "pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010294437s
STEP: Saw pod success
Feb 13 21:38:14.495: INFO: Pod "pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:38:14.497: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:38:14.511: INFO: Waiting for pod pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:38:14.512: INFO: Pod pod-projected-secrets-a9cc2aed-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:38:14.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ldgr2" for this suite.
Feb 13 21:38:20.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:38:20.541: INFO: namespace: e2e-tests-projected-ldgr2, resource: bindings, ignored listing per whitelist
Feb 13 21:38:20.571: INFO: namespace e2e-tests-projected-ldgr2 deletion completed in 6.056189308s

• [SLOW TEST:8.258 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:38:20.571: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-dmrmr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 21:38:20.703: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:38:24.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dmrmr" for this suite.
Feb 13 21:38:46.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:38:47.024: INFO: namespace: e2e-tests-init-container-dmrmr, resource: bindings, ignored listing per whitelist
Feb 13 21:38:47.025: INFO: namespace e2e-tests-init-container-dmrmr deletion completed in 22.04089904s

• [SLOW TEST:26.454 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:38:47.027: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-kxcvz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:38:47.169: INFO: (0) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.066741ms)
Feb 13 21:38:47.171: INFO: (1) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.853794ms)
Feb 13 21:38:47.173: INFO: (2) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.87051ms)
Feb 13 21:38:47.175: INFO: (3) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.848678ms)
Feb 13 21:38:47.176: INFO: (4) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.853189ms)
Feb 13 21:38:47.178: INFO: (5) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.800837ms)
Feb 13 21:38:47.180: INFO: (6) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.815902ms)
Feb 13 21:38:47.182: INFO: (7) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.67151ms)
Feb 13 21:38:47.184: INFO: (8) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.854911ms)
Feb 13 21:38:47.186: INFO: (9) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.843389ms)
Feb 13 21:38:47.188: INFO: (10) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.714759ms)
Feb 13 21:38:47.190: INFO: (11) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.953888ms)
Feb 13 21:38:47.191: INFO: (12) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.907525ms)
Feb 13 21:38:47.193: INFO: (13) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.85474ms)
Feb 13 21:38:47.195: INFO: (14) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.863799ms)
Feb 13 21:38:47.197: INFO: (15) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.104636ms)
Feb 13 21:38:47.199: INFO: (16) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.829884ms)
Feb 13 21:38:47.201: INFO: (17) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.918431ms)
Feb 13 21:38:47.204: INFO: (18) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.268316ms)
Feb 13 21:38:47.206: INFO: (19) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.804544ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:38:47.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-kxcvz" for this suite.
Feb 13 21:38:53.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:38:53.250: INFO: namespace: e2e-tests-proxy-kxcvz, resource: bindings, ignored listing per whitelist
Feb 13 21:38:53.256: INFO: namespace e2e-tests-proxy-kxcvz deletion completed in 6.047615424s

• [SLOW TEST:6.229 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:38:53.256: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5k8t5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-msw6d
STEP: Creating secret with name secret-test-c231d1e5-2fd7-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:38:53.529: INFO: Waiting up to 5m0s for pod "pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-5k8t5" to be "success or failure"
Feb 13 21:38:53.534: INFO: Pod "pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.337367ms
Feb 13 21:38:55.536: INFO: Pod "pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006974355s
STEP: Saw pod success
Feb 13 21:38:55.536: INFO: Pod "pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:38:55.537: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:38:55.553: INFO: Waiting for pod pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:38:55.554: INFO: Pod pod-secrets-c2445c5f-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:38:55.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5k8t5" for this suite.
Feb 13 21:39:01.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:39:01.580: INFO: namespace: e2e-tests-secrets-5k8t5, resource: bindings, ignored listing per whitelist
Feb 13 21:39:01.601: INFO: namespace e2e-tests-secrets-5k8t5 deletion completed in 6.044864954s
STEP: Destroying namespace "e2e-tests-secret-namespace-msw6d" for this suite.
Feb 13 21:39:07.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:39:07.645: INFO: namespace: e2e-tests-secret-namespace-msw6d, resource: bindings, ignored listing per whitelist
Feb 13 21:39:07.645: INFO: namespace e2e-tests-secret-namespace-msw6d deletion completed in 6.0436557s

• [SLOW TEST:14.389 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:39:07.646: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-dmhqb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 13 21:39:07.792: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-dmhqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-dmhqb/configmaps/e2e-watch-test-resource-version,UID:cac3df9b-2fd7-11e9-8578-0050569e397b,ResourceVersion:1264995,Generation:0,CreationTimestamp:2019-02-13 21:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 21:39:07.792: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-dmhqb,SelfLink:/api/v1/namespaces/e2e-tests-watch-dmhqb/configmaps/e2e-watch-test-resource-version,UID:cac3df9b-2fd7-11e9-8578-0050569e397b,ResourceVersion:1264996,Generation:0,CreationTimestamp:2019-02-13 21:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:39:07.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dmhqb" for this suite.
Feb 13 21:39:13.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:39:13.843: INFO: namespace: e2e-tests-watch-dmhqb, resource: bindings, ignored listing per whitelist
Feb 13 21:39:13.852: INFO: namespace e2e-tests-watch-dmhqb deletion completed in 6.054391936s

• [SLOW TEST:6.207 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:39:13.852: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z7g6p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ce78ce30-2fd7-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 21:39:14.009: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-z7g6p" to be "success or failure"
Feb 13 21:39:14.013: INFO: Pod "pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.489191ms
Feb 13 21:39:16.015: INFO: Pod "pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00606914s
STEP: Saw pod success
Feb 13 21:39:16.015: INFO: Pod "pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:39:16.016: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:39:16.028: INFO: Waiting for pod pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:39:16.029: INFO: Pod pod-configmaps-ce792a17-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:39:16.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z7g6p" for this suite.
Feb 13 21:39:22.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:39:22.056: INFO: namespace: e2e-tests-configmap-z7g6p, resource: bindings, ignored listing per whitelist
Feb 13 21:39:22.078: INFO: namespace e2e-tests-configmap-z7g6p deletion completed in 6.04680208s

• [SLOW TEST:8.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:39:22.079: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-pxqwk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-qkwwb
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 13 21:39:24.358: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-2flpd
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:39:48.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-pxqwk" for this suite.
Feb 13 21:39:54.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:39:54.497: INFO: namespace: e2e-tests-namespaces-pxqwk, resource: bindings, ignored listing per whitelist
Feb 13 21:39:54.534: INFO: namespace e2e-tests-namespaces-pxqwk deletion completed in 6.04759647s
STEP: Destroying namespace "e2e-tests-nsdeletetest-qkwwb" for this suite.
Feb 13 21:39:54.536: INFO: Namespace e2e-tests-nsdeletetest-qkwwb was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2flpd" for this suite.
Feb 13 21:40:00.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:40:00.580: INFO: namespace: e2e-tests-nsdeletetest-2flpd, resource: bindings, ignored listing per whitelist
Feb 13 21:40:00.587: INFO: namespace e2e-tests-nsdeletetest-2flpd deletion completed in 6.050947417s

• [SLOW TEST:38.508 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:40:00.587: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-p5wn2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 13 21:40:04.739: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-ea51d6cf-2fd7-11e9-829f-22a36399a92d", GenerateName:"", Namespace:"e2e-tests-pods-p5wn2", SelfLink:"/api/v1/namespaces/e2e-tests-pods-p5wn2/pods/pod-submit-remove-ea51d6cf-2fd7-11e9-829f-22a36399a92d", UID:"ea526630-2fd7-11e9-8578-0050569e397b", ResourceVersion:"1265213", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685690800, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"721688595"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.79/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dz9sb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421ba4480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dz9sb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421ba8388), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"alex-300-cp3-vsp1-worker71a62db265", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4224eb3e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421ba83c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421ba83e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421ba83e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685690793, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685690796, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685690796, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685690800, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.100.39", PodIP:"192.168.1.79", StartTime:(*v1.Time)(0xc4224a6aa0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4224a6ac0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://f4227d27f8be5f560678162bd277070399f12319165c0a2ed5c88d2a7a64da03"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 13 21:40:09.749: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:40:09.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p5wn2" for this suite.
Feb 13 21:40:15.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:40:15.787: INFO: namespace: e2e-tests-pods-p5wn2, resource: bindings, ignored listing per whitelist
Feb 13 21:40:15.805: INFO: namespace e2e-tests-pods-p5wn2 deletion completed in 6.05130799s

• [SLOW TEST:15.217 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:40:15.805: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-6mzmn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:40:15.942: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 13 21:40:15.950: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 13 21:40:20.952: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 13 21:40:20.952: INFO: Creating deployment "test-rolling-update-deployment"
Feb 13 21:40:20.956: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 13 21:40:20.960: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 13 21:40:22.964: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 13 21:40:22.965: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 21:40:22.969: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-6mzmn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6mzmn/deployments/test-rolling-update-deployment,UID:f660ef8e-2fd7-11e9-8578-0050569e397b,ResourceVersion:1265312,Generation:1,CreationTimestamp:2019-02-13 21:40:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-13 21:40:20 +0000 UTC 2019-02-13 21:40:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-13 21:40:22 +0000 UTC 2019-02-13 21:40:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 21:40:22.971: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-6mzmn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6mzmn/replicasets/test-rolling-update-deployment-65b7695dcf,UID:f662d823-2fd7-11e9-8578-0050569e397b,ResourceVersion:1265302,Generation:1,CreationTimestamp:2019-02-13 21:40:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f660ef8e-2fd7-11e9-8578-0050569e397b 0xc4217b7607 0xc4217b7608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 13 21:40:22.971: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 13 21:40:22.971: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-6mzmn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6mzmn/replicasets/test-rolling-update-controller,UID:f3647886-2fd7-11e9-8578-0050569e397b,ResourceVersion:1265311,Generation:2,CreationTimestamp:2019-02-13 21:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f660ef8e-2fd7-11e9-8578-0050569e397b 0xc4217b73fe 0xc4217b73ff}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 21:40:22.972: INFO: Pod "test-rolling-update-deployment-65b7695dcf-l6npl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-l6npl,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-6mzmn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6mzmn/pods/test-rolling-update-deployment-65b7695dcf-l6npl,UID:f6631b02-2fd7-11e9-8578-0050569e397b,ResourceVersion:1265301,Generation:0,CreationTimestamp:2019-02-13 21:40:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.81/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf f662d823-2fd7-11e9-8578-0050569e397b 0xc421484157 0xc421484158}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sdpnf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sdpnf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-sdpnf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214841c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214841e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:40:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:40:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:40:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:40:20 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.81,StartTime:2019-02-13 21:40:14 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-13 21:40:15 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4bc9d1ded760931f69cfb10664d04c4a741a993f3d936741df11ceca738e9a72}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:40:22.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6mzmn" for this suite.
Feb 13 21:40:28.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:40:28.986: INFO: namespace: e2e-tests-deployment-6mzmn, resource: bindings, ignored listing per whitelist
Feb 13 21:40:29.019: INFO: namespace e2e-tests-deployment-6mzmn deletion completed in 6.044535181s

• [SLOW TEST:13.214 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:40:29.019: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kshwm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fb43e354-2fd7-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 21:40:29.160: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-kshwm" to be "success or failure"
Feb 13 21:40:29.164: INFO: Pod "pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317925ms
Feb 13 21:40:31.166: INFO: Pod "pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005288203s
STEP: Saw pod success
Feb 13 21:40:31.166: INFO: Pod "pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:40:31.167: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:40:31.183: INFO: Waiting for pod pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d to disappear
Feb 13 21:40:31.184: INFO: Pod pod-projected-configmaps-fb443575-2fd7-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:40:31.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kshwm" for this suite.
Feb 13 21:40:37.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:40:37.200: INFO: namespace: e2e-tests-projected-kshwm, resource: bindings, ignored listing per whitelist
Feb 13 21:40:37.230: INFO: namespace e2e-tests-projected-kshwm deletion completed in 6.043873397s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:40:37.230: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lwtr4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-002aa02a-2fd8-11e9-829f-22a36399a92d
STEP: Creating configMap with name cm-test-opt-upd-002aa05d-2fd8-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-002aa02a-2fd8-11e9-829f-22a36399a92d
STEP: Updating configmap cm-test-opt-upd-002aa05d-2fd8-11e9-829f-22a36399a92d
STEP: Creating configMap with name cm-test-opt-create-002aa06b-2fd8-11e9-829f-22a36399a92d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:40:41.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lwtr4" for this suite.
Feb 13 21:41:03.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:41:03.460: INFO: namespace: e2e-tests-projected-lwtr4, resource: bindings, ignored listing per whitelist
Feb 13 21:41:03.479: INFO: namespace e2e-tests-projected-lwtr4 deletion completed in 22.046119076s

• [SLOW TEST:26.249 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:41:03.480: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-mz2gh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 13 21:41:03.617: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 21:41:03.621: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 21:41:03.622: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp3-vsp1-worker71a62db265 before test
Feb 13 21:41:03.627: INFO: calico-typha-785658b69-2ddnl from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 21:41:03.627: INFO: kubernetes-dashboard-65dc48675f-4cffw from ccp started at 2019-02-05 19:07:32 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 13 21:41:03.627: INFO: ccp-efk-elasticsearch-curator-1550019600-r5f2q from ccp started at 2019-02-13 00:59:58 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 21:41:03.627: INFO: kube-proxy-9zq7t from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 21:41:03.627: INFO: ccp-efk-elasticsearch-curator-1549933200-h87dw from ccp started at 2019-02-12 00:59:57 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 21:41:03.627: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 21:18:28 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 21:41:03.627: INFO: metallb-speaker-jg54f from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container speaker ready: true, restart count 0
Feb 13 21:41:03.627: INFO: ccp-monitor-prometheus-node-exporter-4nmw9 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 21:41:03.627: INFO: ccp-monitor-prometheus-kube-state-metrics-78dc9f46d4-wsrkg from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.627: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Feb 13 21:41:03.628: INFO: nginx-ingress-default-backend-765bbc8b9d-j86sx from ccp started at 2019-02-05 19:07:30 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb 13 21:41:03.628: INFO: calico-node-hk7rf from kube-system started at 2019-02-05 19:06:38 +0000 UTC (2 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 21:41:03.628: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 21:41:03.628: INFO: nginx-ingress-controller-zg2sn from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 21:41:03.628: INFO: sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-nzdld from heptio-sonobuoy started at 2019-02-13 21:18:37 +0000 UTC (2 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 21:41:03.628: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 21:41:03.628: INFO: ccp-monitor-prometheus-server-6bddddb9cc-d8k6p from ccp started at 2019-02-05 19:07:34 +0000 UTC (2 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container prometheus-server ready: true, restart count 0
Feb 13 21:41:03.628: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Feb 13 21:41:03.628: INFO: fluentd-es-v2.0.2-sbv67 from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 21:41:03.628: INFO: ccp-efk-elasticsearch-curator-1549846800-4rsp5 from ccp started at 2019-02-11 00:59:57 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.628: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 21:41:03.628: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp3-vsp1-workerdf4199ef27 before test
Feb 13 21:41:03.633: INFO: kube-proxy-25b5j from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 21:41:03.633: INFO: metallb-speaker-nl4pl from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container speaker ready: true, restart count 0
Feb 13 21:41:03.633: INFO: elasticsearch-logging-0 from ccp started at 2019-02-05 19:07:36 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Feb 13 21:41:03.633: INFO: fluentd-es-v2.0.2-dhjg4 from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 21:41:03.633: INFO: sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-zrxgv from heptio-sonobuoy started at 2019-02-13 21:18:37 +0000 UTC (2 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 21:41:03.633: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 21:41:03.633: INFO: calico-node-xdz82 from kube-system started at 2019-02-05 19:06:38 +0000 UTC (2 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 21:41:03.633: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 21:41:03.633: INFO: calico-typha-785658b69-48jm5 from kube-system started at 2019-02-05 19:06:48 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 21:41:03.633: INFO: metallb-controller-56fd5dc6c8-bf86h from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container controller ready: true, restart count 0
Feb 13 21:41:03.633: INFO: ccp-monitor-prometheus-pushgateway-5c4f64c9d8-lc5m5 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
Feb 13 21:41:03.633: INFO: ccp-efk-kibana-56784656d5-8sffs from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container kibana ready: true, restart count 0
Feb 13 21:41:03.633: INFO: cert-manager-897586cc6-rxv6p from ccp started at 2019-02-05 19:07:30 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container cert-manager ready: true, restart count 1
Feb 13 21:41:03.633: INFO: nginx-ingress-controller-6xl6l from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 21:41:03.633: INFO: ccp-monitor-prometheus-node-exporter-6vlbz from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 21:41:03.633: INFO: ccp-monitor-grafana-577f9c8c7c-wshx8 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container grafana ready: true, restart count 0
Feb 13 21:41:03.633: INFO: ccp-monitor-prometheus-alertmanager-5cbfbfcc66-jqz5z from ccp started at 2019-02-05 19:07:36 +0000 UTC (2 container statuses recorded)
Feb 13 21:41:03.633: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Feb 13 21:41:03.633: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-110514a3-2fd8-11e9-829f-22a36399a92d 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-110514a3-2fd8-11e9-829f-22a36399a92d off the node alex-300-cp3-vsp1-worker71a62db265
STEP: verifying the node doesn't have the label kubernetes.io/e2e-110514a3-2fd8-11e9-829f-22a36399a92d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:41:07.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mz2gh" for this suite.
Feb 13 21:41:17.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:41:17.696: INFO: namespace: e2e-tests-sched-pred-mz2gh, resource: bindings, ignored listing per whitelist
Feb 13 21:41:17.720: INFO: namespace e2e-tests-sched-pred-mz2gh deletion completed in 10.041282569s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:14.240 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:41:17.720: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6btgw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-6btgw/configmap-test-184c0386-2fd8-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 21:41:17.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-6btgw" to be "success or failure"
Feb 13 21:41:17.868: INFO: Pod "pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.85313ms
Feb 13 21:41:19.870: INFO: Pod "pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004960418s
STEP: Saw pod success
Feb 13 21:41:19.870: INFO: Pod "pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:41:19.871: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d container env-test: <nil>
STEP: delete the pod
Feb 13 21:41:19.884: INFO: Waiting for pod pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d to disappear
Feb 13 21:41:19.885: INFO: Pod pod-configmaps-184c5a52-2fd8-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:41:19.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6btgw" for this suite.
Feb 13 21:41:25.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:41:25.931: INFO: namespace: e2e-tests-configmap-6btgw, resource: bindings, ignored listing per whitelist
Feb 13 21:41:25.943: INFO: namespace e2e-tests-configmap-6btgw deletion completed in 6.054924373s

• [SLOW TEST:8.222 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:41:25.943: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rfrzc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 21:41:26.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-rfrzc'
Feb 13 21:41:26.397: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 21:41:26.397: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Feb 13 21:41:26.400: INFO: scanned /root for discovery docs: <nil>
Feb 13 21:41:26.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-rfrzc'
Feb 13 21:41:39.147: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 13 21:41:39.147: INFO: stdout: "Created e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2\nScaling up e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 13 21:41:39.147: INFO: stdout: "Created e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2\nScaling up e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 13 21:41:39.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rfrzc'
Feb 13 21:41:39.229: INFO: stderr: ""
Feb 13 21:41:39.229: INFO: stdout: "e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2-55sdz "
Feb 13 21:41:39.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2-55sdz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rfrzc'
Feb 13 21:41:39.285: INFO: stderr: ""
Feb 13 21:41:39.285: INFO: stdout: "true"
Feb 13 21:41:39.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2-55sdz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rfrzc'
Feb 13 21:41:39.347: INFO: stderr: ""
Feb 13 21:41:39.347: INFO: stdout: "nginx:1.14-alpine"
Feb 13 21:41:39.347: INFO: e2e-test-nginx-rc-8990693462a322ca7423e7de4e509ed2-55sdz is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb 13 21:41:39.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rfrzc'
Feb 13 21:41:39.409: INFO: stderr: ""
Feb 13 21:41:39.409: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:41:39.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rfrzc" for this suite.
Feb 13 21:41:45.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:41:45.452: INFO: namespace: e2e-tests-kubectl-rfrzc, resource: bindings, ignored listing per whitelist
Feb 13 21:41:45.457: INFO: namespace e2e-tests-kubectl-rfrzc deletion completed in 6.044165384s

• [SLOW TEST:19.514 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:41:45.457: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hhtnt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 13 21:41:49.625: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:41:49.626: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:41:51.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:41:51.630: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:41:53.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:41:53.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:41:55.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:41:55.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:41:57.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:41:57.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:41:59.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:41:59.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:42:01.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:42:01.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:42:03.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:42:03.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:42:05.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:42:05.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:42:07.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:42:07.628: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 13 21:42:09.626: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 13 21:42:09.628: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:42:09.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hhtnt" for this suite.
Feb 13 21:42:31.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:42:31.662: INFO: namespace: e2e-tests-container-lifecycle-hook-hhtnt, resource: bindings, ignored listing per whitelist
Feb 13 21:42:31.682: INFO: namespace e2e-tests-container-lifecycle-hook-hhtnt deletion completed in 22.047132134s

• [SLOW TEST:46.225 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:42:31.683: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vzkdx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 21:42:34.344: INFO: Successfully updated pod "annotationupdate44619e0e-2fd8-11e9-829f-22a36399a92d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:42:38.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vzkdx" for this suite.
Feb 13 21:43:00.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:43:00.383: INFO: namespace: e2e-tests-downward-api-vzkdx, resource: bindings, ignored listing per whitelist
Feb 13 21:43:00.414: INFO: namespace e2e-tests-downward-api-vzkdx deletion completed in 22.050503438s

• [SLOW TEST:28.731 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:43:00.415: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-kxg4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kxg4x
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 13 21:43:00.564: INFO: Found 0 stateful pods, waiting for 3
Feb 13 21:43:10.566: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:43:10.566: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:43:10.566: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 21:43:10.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-kxg4x ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:43:10.687: INFO: stderr: ""
Feb 13 21:43:10.687: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:43:10.687: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 13 21:43:20.708: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 13 21:43:30.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-kxg4x ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:43:30.819: INFO: stderr: ""
Feb 13 21:43:30.819: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:43:30.819: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:43:40.828: INFO: Waiting for StatefulSet e2e-tests-statefulset-kxg4x/ss2 to complete update
Feb 13 21:43:40.828: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 21:43:40.828: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 21:43:40.828: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 21:43:50.832: INFO: Waiting for StatefulSet e2e-tests-statefulset-kxg4x/ss2 to complete update
Feb 13 21:43:50.832: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 21:43:50.832: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 13 21:44:00.832: INFO: Waiting for StatefulSet e2e-tests-statefulset-kxg4x/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 13 21:44:10.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-kxg4x ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 21:44:10.963: INFO: stderr: ""
Feb 13 21:44:10.963: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 21:44:10.963: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 21:44:20.984: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 13 21:44:31.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-kxg4x ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 21:44:31.146: INFO: stderr: ""
Feb 13 21:44:31.146: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 21:44:31.146: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 21:44:41.156: INFO: Waiting for StatefulSet e2e-tests-statefulset-kxg4x/ss2 to complete update
Feb 13 21:44:41.156: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 21:44:41.156: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 21:44:41.156: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 21:44:51.160: INFO: Waiting for StatefulSet e2e-tests-statefulset-kxg4x/ss2 to complete update
Feb 13 21:44:51.160: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 21:44:51.160: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 13 21:45:01.160: INFO: Waiting for StatefulSet e2e-tests-statefulset-kxg4x/ss2 to complete update
Feb 13 21:45:01.160: INFO: Waiting for Pod e2e-tests-statefulset-kxg4x/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 21:45:11.160: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kxg4x
Feb 13 21:45:11.162: INFO: Scaling statefulset ss2 to 0
Feb 13 21:45:21.170: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 21:45:21.171: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:45:21.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kxg4x" for this suite.
Feb 13 21:45:27.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:45:27.211: INFO: namespace: e2e-tests-statefulset-kxg4x, resource: bindings, ignored listing per whitelist
Feb 13 21:45:27.230: INFO: namespace e2e-tests-statefulset-kxg4x deletion completed in 6.048185513s

• [SLOW TEST:146.816 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:45:27.231: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-ndszs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:45:27.364: INFO: Creating deployment "nginx-deployment"
Feb 13 21:45:27.367: INFO: Waiting for observed generation 1
Feb 13 21:45:29.375: INFO: Waiting for all required pods to come up
Feb 13 21:45:29.380: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 13 21:45:31.389: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 13 21:45:31.392: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 13 21:45:31.396: INFO: Updating deployment nginx-deployment
Feb 13 21:45:31.397: INFO: Waiting for observed generation 2
Feb 13 21:45:33.407: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 13 21:45:33.408: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 13 21:45:33.409: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 13 21:45:33.411: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 13 21:45:33.411: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 13 21:45:33.412: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 13 21:45:33.414: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 13 21:45:33.414: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 13 21:45:33.418: INFO: Updating deployment nginx-deployment
Feb 13 21:45:33.418: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 13 21:45:33.424: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 13 21:45:33.442: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 21:45:33.468: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-ndszs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ndszs/deployments/nginx-deployment,UID:ad039ce3-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266789,Generation:3,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-02-13 21:45:31 +0000 UTC 2019-02-13 21:45:27 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-02-13 21:45:33 +0000 UTC 2019-02-13 21:45:33 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 13 21:45:33.487: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-ndszs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ndszs/replicasets/nginx-deployment-7dc8f79789,UID:af6ad01e-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266769,Generation:3,CreationTimestamp:2019-02-13 21:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment ad039ce3-2fd8-11e9-8578-0050569e397b 0xc420b412d7 0xc420b412d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 21:45:33.489: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 13 21:45:33.490: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-ndszs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ndszs/replicasets/nginx-deployment-7f9675fb8b,UID:ad047b6b-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266767,Generation:3,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment ad039ce3-2fd8-11e9-8578-0050569e397b 0xc420b41557 0xc420b41558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 13 21:45:33.510: INFO: Pod "nginx-deployment-7dc8f79789-442mz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-442mz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-442mz,UID:b0a9c275-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266815,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc4209247c7 0xc4209247c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420924980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4209249a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.510: INFO: Pod "nginx-deployment-7dc8f79789-45jl7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-45jl7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-45jl7,UID:af6c29ee-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266759,Generation:0,CreationTimestamp:2019-02-13 21:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.104/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc420924a40 0xc420924a41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420924ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420924b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:,StartTime:2019-02-13 21:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.510: INFO: Pod "nginx-deployment-7dc8f79789-4rx4j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4rx4j,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-4rx4j,UID:af6b50ef-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266751,Generation:0,CreationTimestamp:2019-02-13 21:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.102/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc420924bf7 0xc420924bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420924c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4209251f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:,StartTime:2019-02-13 21:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.510: INFO: Pod "nginx-deployment-7dc8f79789-b9f7z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b9f7z,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-b9f7z,UID:b0a47f01-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266809,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc4209252b7 0xc4209252b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420925360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420925380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.511: INFO: Pod "nginx-deployment-7dc8f79789-cdjhh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cdjhh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-cdjhh,UID:b0a24aea-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266796,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc420925ce7 0xc420925ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420925d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420925d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.511: INFO: Pod "nginx-deployment-7dc8f79789-cs2g7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cs2g7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-cs2g7,UID:b0a267be-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266788,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc420925e77 0xc420925e78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420925ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420925f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.511: INFO: Pod "nginx-deployment-7dc8f79789-dhcnw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dhcnw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-dhcnw,UID:b0a0b62c-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266783,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc420925f77 0xc420925f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f9c710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f9c730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.511: INFO: Pod "nginx-deployment-7dc8f79789-g4g6k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-g4g6k,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-g4g6k,UID:af70a404-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266750,Generation:0,CreationTimestamp:2019-02-13 21:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.38/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc421f9c7d7 0xc421f9c7d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f9c8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f9c8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:,StartTime:2019-02-13 21:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7dc8f79789-gl2b7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gl2b7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-gl2b7,UID:b0a489d7-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266810,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc421f9ca17 0xc421f9ca18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f9cb10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f9cb30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7dc8f79789-hjsl5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hjsl5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-hjsl5,UID:b0a43dd8-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266808,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc421f9cbb7 0xc421f9cbb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f9cc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f9d910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7dc8f79789-p6kch" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-p6kch,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-p6kch,UID:af6c16c1-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266754,Generation:0,CreationTimestamp:2019-02-13 21:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.39/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc421f9dcb7 0xc421f9dcb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f9dd20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f9dd40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:,StartTime:2019-02-13 21:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7dc8f79789-wcvbg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wcvbg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-wcvbg,UID:af71cb20-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266756,Generation:0,CreationTimestamp:2019-02-13 21:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.103/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc4216763e7 0xc4216763e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421676490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4216764c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:31 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:,StartTime:2019-02-13 21:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7dc8f79789-zn877" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zn877,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7dc8f79789-zn877,UID:b0a5428e-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266811,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 af6ad01e-2fd8-11e9-8578-0050569e397b 0xc421676817 0xc421676818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421676890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421676910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7f9675fb8b-8d8tr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8d8tr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-8d8tr,UID:ad09c1ed-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266694,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421676997 0xc421676998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421676ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421676af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:192.168.2.35,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ab8aa3bcf60be96678bbaa8b17770578b210b8132f3fb17faabcdf546fcb7d77}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7f9675fb8b-9srs8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9srs8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-9srs8,UID:b0a5d428-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266816,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421676c57 0xc421676c58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421676cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421676cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.512: INFO: Pod "nginx-deployment-7f9675fb8b-b2gpz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-b2gpz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-b2gpz,UID:b0a25870-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266793,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421676e57 0xc421676e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421676ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421676ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-bbczf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bbczf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-bbczf,UID:b0a5adae-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266820,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc4216770d7 0xc4216770d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421677160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-bf5gb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bf5gb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-bf5gb,UID:ad080e03-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266688,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.34/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc4216771f7 0xc4216771f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421677380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:192.168.2.34,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://02e412baba31e85c3bf46ede5a96d80decfe79b7e6ff587d1571df713211a351}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-c8rw6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c8rw6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-c8rw6,UID:ad07e00f-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266639,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421677767 0xc421677768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4216778a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:192.168.2.33,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://d508272b912f0640bfb64cbecd4ace25af2dea5bee162840206c754f54d7ee18}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-dkkmk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dkkmk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-dkkmk,UID:ad0807be-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266679,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.99/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421677997 0xc421677998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421677a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.99,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://bec82c15a7684c70a6b02c36a292eb399dbd8f182e3b433e68cc439a2c34305c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-mj2d5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mj2d5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-mj2d5,UID:b0a5ba77-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266817,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421677b57 0xc421677b58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421677cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-p259w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-p259w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-p259w,UID:ad09dbcc-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266685,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421677d37 0xc421677d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421677dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:192.168.2.36,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://907f3c3b63c9953a911460b783f4ba499b63969ef3d231502473752373256013}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-rn99g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rn99g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-rn99g,UID:b0a261e0-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266804,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421677f37 0xc421677f38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421677fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421677fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-rwzdw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rwzdw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-rwzdw,UID:ad09ce03-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266676,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.100/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc4214941c7 0xc4214941c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421494230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.100,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://3215a71a712cc51bad7bbc1a301bc241c3d94d6ab06c1661673e7f7dc8eccb13}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.513: INFO: Pod "nginx-deployment-7f9675fb8b-snh7l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-snh7l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-snh7l,UID:b0a25a95-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266798,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494397 0xc421494398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421494400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.514: INFO: Pod "nginx-deployment-7f9675fb8b-svpz6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-svpz6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-svpz6,UID:ad080154-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266673,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.98/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494577 0xc421494578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214945e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.98,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://a9c4fda9104a3b1025eeeec0aa60022278aec19fbaa7663168c6ab42c7492d21}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.515: INFO: Pod "nginx-deployment-7f9675fb8b-tt86j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tt86j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-tt86j,UID:b0a5b458-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266818,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc4214947c7 0xc4214947c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214948b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214948d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.515: INFO: Pod "nginx-deployment-7f9675fb8b-v2cqk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-v2cqk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-v2cqk,UID:b0a5a4ca-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266819,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494947 0xc421494948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214949b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.515: INFO: Pod "nginx-deployment-7f9675fb8b-wz48b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wz48b,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-wz48b,UID:b0a097c0-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266777,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494ab7 0xc421494ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421494b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.515: INFO: Pod "nginx-deployment-7f9675fb8b-xndj7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xndj7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-xndj7,UID:ad05ef11-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266636,Generation:0,CreationTimestamp:2019-02-13 21:45:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.97/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494d17 0xc421494d18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421494d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:27 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.97,StartTime:2019-02-13 21:45:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-13 21:45:21 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://4d184d67ddc21b38993fa999697a4475e0cbc76def2a3d6a699f34754aee4c64}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.515: INFO: Pod "nginx-deployment-7f9675fb8b-xpjhx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xpjhx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-xpjhx,UID:b0a09370-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266778,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494e67 0xc421494e68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421494ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421494ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.515: INFO: Pod "nginx-deployment-7f9675fb8b-zpdwh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zpdwh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-zpdwh,UID:b0a2733c-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266797,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421494f77 0xc421494f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421494fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421495000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 13 21:45:33.516: INFO: Pod "nginx-deployment-7f9675fb8b-zqfs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zqfs7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-ndszs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ndszs/pods/nginx-deployment-7f9675fb8b-zqfs7,UID:b09fa93f-2fd8-11e9-8578-0050569e397b,ResourceVersion:1266806,Generation:0,CreationTimestamp:2019-02-13 21:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b ad047b6b-2fd8-11e9-8578-0050569e397b 0xc421495077 0xc421495078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wxz45 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wxz45,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wxz45 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-workerdf4199ef27,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214950e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421495100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 21:45:33 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.38,PodIP:,StartTime:2019-02-13 21:45:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:45:33.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ndszs" for this suite.
Feb 13 21:45:39.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:45:39.567: INFO: namespace: e2e-tests-deployment-ndszs, resource: bindings, ignored listing per whitelist
Feb 13 21:45:39.587: INFO: namespace e2e-tests-deployment-ndszs deletion completed in 6.056657725s

• [SLOW TEST:12.356 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:45:39.588: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-5qc9q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 13 21:45:39.728: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5qc9q,SelfLink:/api/v1/namespaces/e2e-tests-watch-5qc9q/configmaps/e2e-watch-test-watch-closed,UID:b4616a9f-2fd8-11e9-8578-0050569e397b,ResourceVersion:1267095,Generation:0,CreationTimestamp:2019-02-13 21:45:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 21:45:39.728: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5qc9q,SelfLink:/api/v1/namespaces/e2e-tests-watch-5qc9q/configmaps/e2e-watch-test-watch-closed,UID:b4616a9f-2fd8-11e9-8578-0050569e397b,ResourceVersion:1267096,Generation:0,CreationTimestamp:2019-02-13 21:45:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 13 21:45:39.737: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5qc9q,SelfLink:/api/v1/namespaces/e2e-tests-watch-5qc9q/configmaps/e2e-watch-test-watch-closed,UID:b4616a9f-2fd8-11e9-8578-0050569e397b,ResourceVersion:1267097,Generation:0,CreationTimestamp:2019-02-13 21:45:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 21:45:39.737: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-5qc9q,SelfLink:/api/v1/namespaces/e2e-tests-watch-5qc9q/configmaps/e2e-watch-test-watch-closed,UID:b4616a9f-2fd8-11e9-8578-0050569e397b,ResourceVersion:1267098,Generation:0,CreationTimestamp:2019-02-13 21:45:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:45:39.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5qc9q" for this suite.
Feb 13 21:45:45.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:45:45.781: INFO: namespace: e2e-tests-watch-5qc9q, resource: bindings, ignored listing per whitelist
Feb 13 21:45:45.785: INFO: namespace e2e-tests-watch-5qc9q deletion completed in 6.045226109s

• [SLOW TEST:6.198 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:45:45.786: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-k2mpd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0213 21:45:55.957290      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 21:45:55.957: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:45:55.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k2mpd" for this suite.
Feb 13 21:46:01.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:46:01.979: INFO: namespace: e2e-tests-gc-k2mpd, resource: bindings, ignored listing per whitelist
Feb 13 21:46:02.011: INFO: namespace e2e-tests-gc-k2mpd deletion completed in 6.052153032s

• [SLOW TEST:16.225 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:46:02.012: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-j5xrd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j5xrd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 21:46:02.146: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 21:46:26.192: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.1.121:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j5xrd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 21:46:26.192: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 21:46:26.284: INFO: Found all expected endpoints: [netserver-0]
Feb 13 21:46:26.286: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.2.56:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j5xrd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 21:46:26.286: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 21:46:26.345: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:46:26.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j5xrd" for this suite.
Feb 13 21:46:48.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:46:48.390: INFO: namespace: e2e-tests-pod-network-test-j5xrd, resource: bindings, ignored listing per whitelist
Feb 13 21:46:48.400: INFO: namespace e2e-tests-pod-network-test-j5xrd deletion completed in 22.052729227s

• [SLOW TEST:46.389 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:46:48.401: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-586d8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 13 21:46:50.549: INFO: Pod pod-hostip-dd6565f6-2fd8-11e9-829f-22a36399a92d has hostIP: 10.10.100.39
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:46:50.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-586d8" for this suite.
Feb 13 21:47:12.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:47:12.599: INFO: namespace: e2e-tests-pods-586d8, resource: bindings, ignored listing per whitelist
Feb 13 21:47:12.600: INFO: namespace e2e-tests-pods-586d8 deletion completed in 22.049595803s

• [SLOW TEST:24.199 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:47:12.601: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mqkft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 13 21:47:12.742: INFO: Waiting up to 5m0s for pod "pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-mqkft" to be "success or failure"
Feb 13 21:47:12.748: INFO: Pod "pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.79248ms
Feb 13 21:47:14.750: INFO: Pod "pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007431363s
STEP: Saw pod success
Feb 13 21:47:14.750: INFO: Pod "pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:47:14.751: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:47:14.765: INFO: Waiting for pod pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d to disappear
Feb 13 21:47:14.766: INFO: Pod pod-ebd23f7f-2fd8-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:47:14.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mqkft" for this suite.
Feb 13 21:47:20.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:47:20.807: INFO: namespace: e2e-tests-emptydir-mqkft, resource: bindings, ignored listing per whitelist
Feb 13 21:47:20.814: INFO: namespace e2e-tests-emptydir-mqkft deletion completed in 6.046256989s

• [SLOW TEST:8.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:47:20.815: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kx59k
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 13 21:47:20.951: INFO: Waiting up to 5m0s for pod "pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-kx59k" to be "success or failure"
Feb 13 21:47:20.955: INFO: Pod "pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.922074ms
Feb 13 21:47:22.971: INFO: Pod "pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019605064s
STEP: Saw pod success
Feb 13 21:47:22.971: INFO: Pod "pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:47:22.972: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:47:22.991: INFO: Waiting for pod pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d to disappear
Feb 13 21:47:22.992: INFO: Pod pod-f0b6e24b-2fd8-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:47:22.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kx59k" for this suite.
Feb 13 21:47:28.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:47:29.012: INFO: namespace: e2e-tests-emptydir-kx59k, resource: bindings, ignored listing per whitelist
Feb 13 21:47:29.037: INFO: namespace e2e-tests-emptydir-kx59k deletion completed in 6.044068942s

• [SLOW TEST:8.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:47:29.038: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-c64hr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cqd4g in namespace e2e-tests-proxy-c64hr
I0213 21:47:29.189611      16 runners.go:180] Created replication controller with name: proxy-service-cqd4g, namespace: e2e-tests-proxy-c64hr, replica count: 1
I0213 21:47:30.239861      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 21:47:31.240006      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 21:47:32.240210      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 21:47:33.240392      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:34.240602      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:35.240760      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:36.241078      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:37.241287      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:38.241429      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:39.241707      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0213 21:47:40.242063      16 runners.go:180] proxy-service-cqd4g Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 21:47:40.243: INFO: setup took 11.071480553s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 13 21:47:40.248: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 4.460228ms)
Feb 13 21:47:40.256: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 10.646775ms)
Feb 13 21:47:40.256: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 11.087435ms)
Feb 13 21:47:40.256: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 10.357842ms)
Feb 13 21:47:40.256: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 10.666002ms)
Feb 13 21:47:40.256: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 11.460826ms)
Feb 13 21:47:40.259: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 12.795428ms)
Feb 13 21:47:40.266: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 22.236224ms)
Feb 13 21:47:40.267: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 22.422134ms)
Feb 13 21:47:40.267: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 22.28863ms)
Feb 13 21:47:40.275: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 31.304653ms)
Feb 13 21:47:40.275: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 28.768836ms)
Feb 13 21:47:40.275: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 31.606602ms)
Feb 13 21:47:40.276: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 31.533392ms)
Feb 13 21:47:40.276: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 31.215708ms)
Feb 13 21:47:40.276: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 31.063897ms)
Feb 13 21:47:40.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 4.110209ms)
Feb 13 21:47:40.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 4.232253ms)
Feb 13 21:47:40.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 3.675014ms)
Feb 13 21:47:40.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 4.167677ms)
Feb 13 21:47:40.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 4.100432ms)
Feb 13 21:47:40.286: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.480059ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 5.748227ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.898759ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 7.668751ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 6.608435ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 7.639908ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.489101ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.554856ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.627208ms)
Feb 13 21:47:40.287: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 6.679297ms)
Feb 13 21:47:40.288: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 7.562878ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 8.958798ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 9.022064ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 9.128042ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.032105ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 9.111503ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.056472ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 9.096273ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 9.18396ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 9.156055ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 9.34366ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 9.321107ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 9.235657ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 9.343081ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 9.517056ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 9.481643ms)
Feb 13 21:47:40.297: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 9.569627ms)
Feb 13 21:47:40.303: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 5.197189ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 8.241311ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 8.177211ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 8.101566ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 8.199775ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 8.217958ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 8.460931ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 8.346618ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 8.466846ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 8.680205ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 8.631919ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 8.528295ms)
Feb 13 21:47:40.306: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 8.634451ms)
Feb 13 21:47:40.307: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 9.292405ms)
Feb 13 21:47:40.307: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.578398ms)
Feb 13 21:47:40.308: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.758878ms)
Feb 13 21:47:40.314: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 6.430868ms)
Feb 13 21:47:40.314: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.445726ms)
Feb 13 21:47:40.314: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.613074ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 6.804991ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.613678ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 6.705797ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 6.430742ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.638104ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.479653ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.47546ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 7.175991ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.993523ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.828099ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 7.083738ms)
Feb 13 21:47:40.315: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 7.298446ms)
Feb 13 21:47:40.316: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 7.727678ms)
Feb 13 21:47:40.320: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 3.961203ms)
Feb 13 21:47:40.320: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 4.046569ms)
Feb 13 21:47:40.321: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.693498ms)
Feb 13 21:47:40.321: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 4.819521ms)
Feb 13 21:47:40.321: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 4.740532ms)
Feb 13 21:47:40.321: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.717569ms)
Feb 13 21:47:40.321: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 4.660288ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 6.782801ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 7.070175ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 7.045373ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 7.04465ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 7.086331ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 7.202712ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 7.15428ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 7.207775ms)
Feb 13 21:47:40.323: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 7.511969ms)
Feb 13 21:47:40.326: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 2.568073ms)
Feb 13 21:47:40.327: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 3.115057ms)
Feb 13 21:47:40.327: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 3.436032ms)
Feb 13 21:47:40.327: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 3.192888ms)
Feb 13 21:47:40.332: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 8.140387ms)
Feb 13 21:47:40.333: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.897659ms)
Feb 13 21:47:40.334: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 9.808939ms)
Feb 13 21:47:40.334: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 9.904252ms)
Feb 13 21:47:40.334: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.88951ms)
Feb 13 21:47:40.334: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 9.83125ms)
Feb 13 21:47:40.335: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 11.189587ms)
Feb 13 21:47:40.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 12.234878ms)
Feb 13 21:47:40.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 12.593917ms)
Feb 13 21:47:40.336: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 12.676192ms)
Feb 13 21:47:40.337: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 13.243761ms)
Feb 13 21:47:40.338: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 14.264345ms)
Feb 13 21:47:40.346: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 8.192495ms)
Feb 13 21:47:40.347: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 8.420672ms)
Feb 13 21:47:40.347: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 8.471405ms)
Feb 13 21:47:40.347: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 8.493545ms)
Feb 13 21:47:40.347: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.082212ms)
Feb 13 21:47:40.347: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 9.273612ms)
Feb 13 21:47:40.347: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 9.270952ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 9.383209ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 9.590957ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 9.579889ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 9.561937ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.691001ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 9.675106ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 9.646285ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 9.678523ms)
Feb 13 21:47:40.348: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 9.784296ms)
Feb 13 21:47:40.353: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 4.571738ms)
Feb 13 21:47:40.353: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 4.60742ms)
Feb 13 21:47:40.353: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.660617ms)
Feb 13 21:47:40.353: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 4.681642ms)
Feb 13 21:47:40.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.472368ms)
Feb 13 21:47:40.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.663267ms)
Feb 13 21:47:40.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.948805ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 7.109527ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 7.304292ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 7.382025ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 7.510975ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 7.445515ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 7.66766ms)
Feb 13 21:47:40.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 7.782358ms)
Feb 13 21:47:40.357: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 8.906775ms)
Feb 13 21:47:40.358: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 9.201749ms)
Feb 13 21:47:40.361: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 3.453936ms)
Feb 13 21:47:40.361: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 3.291003ms)
Feb 13 21:47:40.362: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 4.287702ms)
Feb 13 21:47:40.363: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.487442ms)
Feb 13 21:47:40.363: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.563231ms)
Feb 13 21:47:40.363: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 4.658312ms)
Feb 13 21:47:40.364: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 5.493816ms)
Feb 13 21:47:40.364: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 5.653645ms)
Feb 13 21:47:40.364: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.177546ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 6.759035ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 6.714042ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 6.936428ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.799203ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.782945ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.766985ms)
Feb 13 21:47:40.365: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 6.966557ms)
Feb 13 21:47:40.369: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 3.657551ms)
Feb 13 21:47:40.369: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 3.865518ms)
Feb 13 21:47:40.369: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 3.770068ms)
Feb 13 21:47:40.369: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 3.82987ms)
Feb 13 21:47:40.370: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.070138ms)
Feb 13 21:47:40.370: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 4.474406ms)
Feb 13 21:47:40.370: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 4.285908ms)
Feb 13 21:47:40.371: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 5.245508ms)
Feb 13 21:47:40.372: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 5.519414ms)
Feb 13 21:47:40.372: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 5.902394ms)
Feb 13 21:47:40.372: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 5.706152ms)
Feb 13 21:47:40.372: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.458075ms)
Feb 13 21:47:40.372: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 5.857794ms)
Feb 13 21:47:40.373: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 7.467486ms)
Feb 13 21:47:40.373: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 6.967497ms)
Feb 13 21:47:40.374: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 7.748124ms)
Feb 13 21:47:40.377: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 3.551966ms)
Feb 13 21:47:40.378: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 3.601646ms)
Feb 13 21:47:40.378: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 4.366059ms)
Feb 13 21:47:40.378: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 4.301904ms)
Feb 13 21:47:40.378: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.274944ms)
Feb 13 21:47:40.379: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 5.240751ms)
Feb 13 21:47:40.379: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 4.939387ms)
Feb 13 21:47:40.379: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 4.990357ms)
Feb 13 21:47:40.380: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.01045ms)
Feb 13 21:47:40.380: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 5.929204ms)
Feb 13 21:47:40.380: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 5.909194ms)
Feb 13 21:47:40.380: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 5.51568ms)
Feb 13 21:47:40.381: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.627779ms)
Feb 13 21:47:40.381: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.488148ms)
Feb 13 21:47:40.381: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.897682ms)
Feb 13 21:47:40.381: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 7.175256ms)
Feb 13 21:47:40.387: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.081464ms)
Feb 13 21:47:40.387: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.058267ms)
Feb 13 21:47:40.387: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 6.10348ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 6.095908ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 5.989876ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.010942ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 6.250498ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.056823ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 6.437824ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.343705ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 6.384257ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 6.705095ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 6.410338ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.601519ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.460882ms)
Feb 13 21:47:40.388: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.568295ms)
Feb 13 21:47:40.392: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 3.705006ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 6.070842ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 5.832489ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.636601ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 6.476522ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 6.496533ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 6.47679ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 6.244061ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.660436ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 6.806181ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.947778ms)
Feb 13 21:47:40.395: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 6.623497ms)
Feb 13 21:47:40.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.85084ms)
Feb 13 21:47:40.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.713563ms)
Feb 13 21:47:40.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.591123ms)
Feb 13 21:47:40.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.679945ms)
Feb 13 21:47:40.399: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 3.224853ms)
Feb 13 21:47:40.400: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 3.583618ms)
Feb 13 21:47:40.400: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 3.756201ms)
Feb 13 21:47:40.400: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 3.76131ms)
Feb 13 21:47:40.400: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 3.966776ms)
Feb 13 21:47:40.401: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 4.93617ms)
Feb 13 21:47:40.401: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 5.043965ms)
Feb 13 21:47:40.401: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 5.208439ms)
Feb 13 21:47:40.402: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 5.593076ms)
Feb 13 21:47:40.402: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 5.360504ms)
Feb 13 21:47:40.402: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 5.313359ms)
Feb 13 21:47:40.402: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.00487ms)
Feb 13 21:47:40.402: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 6.03741ms)
Feb 13 21:47:40.403: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.50313ms)
Feb 13 21:47:40.403: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.676975ms)
Feb 13 21:47:40.404: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 7.890969ms)
Feb 13 21:47:40.407: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 3.230293ms)
Feb 13 21:47:40.407: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 3.285078ms)
Feb 13 21:47:40.407: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 3.484581ms)
Feb 13 21:47:40.408: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 4.046126ms)
Feb 13 21:47:40.408: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 4.545195ms)
Feb 13 21:47:40.409: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 5.085775ms)
Feb 13 21:47:40.409: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 5.135147ms)
Feb 13 21:47:40.409: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 4.940588ms)
Feb 13 21:47:40.410: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 5.631963ms)
Feb 13 21:47:40.410: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 5.631626ms)
Feb 13 21:47:40.410: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 5.538238ms)
Feb 13 21:47:40.411: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 6.452101ms)
Feb 13 21:47:40.411: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.427155ms)
Feb 13 21:47:40.411: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.542662ms)
Feb 13 21:47:40.411: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 6.624503ms)
Feb 13 21:47:40.411: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 6.689839ms)
Feb 13 21:47:40.412: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 1.577669ms)
Feb 13 21:47:40.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 7.860244ms)
Feb 13 21:47:40.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 8.143527ms)
Feb 13 21:47:40.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 8.264252ms)
Feb 13 21:47:40.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 8.392532ms)
Feb 13 21:47:40.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 8.37591ms)
Feb 13 21:47:40.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 8.161431ms)
Feb 13 21:47:40.420: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 8.408209ms)
Feb 13 21:47:40.420: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 8.481849ms)
Feb 13 21:47:40.420: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 8.561891ms)
Feb 13 21:47:40.420: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 8.728703ms)
Feb 13 21:47:40.420: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 8.704061ms)
Feb 13 21:47:40.420: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 8.668927ms)
Feb 13 21:47:40.421: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 9.310617ms)
Feb 13 21:47:40.421: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.465966ms)
Feb 13 21:47:40.421: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.479433ms)
Feb 13 21:47:40.425: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 3.695362ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 4.915417ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 4.786202ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 4.93663ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 5.187555ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 5.107291ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 5.216972ms)
Feb 13 21:47:40.426: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 5.447873ms)
Feb 13 21:47:40.428: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.8788ms)
Feb 13 21:47:40.428: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 7.013664ms)
Feb 13 21:47:40.428: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 7.005991ms)
Feb 13 21:47:40.430: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.119019ms)
Feb 13 21:47:40.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 9.654185ms)
Feb 13 21:47:40.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 9.400315ms)
Feb 13 21:47:40.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 9.253435ms)
Feb 13 21:47:40.431: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.291042ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 7.07975ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 7.449938ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 8.348268ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 7.587309ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 7.54827ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 7.448822ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 7.596556ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 7.515599ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 8.350088ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 7.822631ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 7.597493ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 7.608683ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 7.603559ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 7.603423ms)
Feb 13 21:47:40.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 7.649331ms)
Feb 13 21:47:40.440: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.540707ms)
Feb 13 21:47:40.446: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:462/proxy/: tls qux (200; 5.622382ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:1080/proxy/... (200; 5.749232ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.144423ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:1080/proxy/rewri... (200; 5.960236ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 5.960885ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn:160/proxy/: foo (200; 6.087384ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/http:proxy-service-cqd4g-trdbn:162/proxy/: bar (200; 6.196032ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:443/proxy/... (200; 6.415136ms)
Feb 13 21:47:40.447: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/https:proxy-service-cqd4g-trdbn:460/proxy/: tls baz (200; 6.36638ms)
Feb 13 21:47:40.448: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-c64hr/pods/proxy-service-cqd4g-trdbn/proxy/rewriteme"... (200; 6.384537ms)
Feb 13 21:47:40.449: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname2/proxy/: bar (200; 8.318147ms)
Feb 13 21:47:40.449: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname2/proxy/: tls qux (200; 8.429879ms)
Feb 13 21:47:40.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/https:proxy-service-cqd4g:tlsportname1/proxy/: tls baz (200; 9.312806ms)
Feb 13 21:47:40.450: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/http:proxy-service-cqd4g:portname1/proxy/: foo (200; 9.849096ms)
Feb 13 21:47:40.451: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname1/proxy/: foo (200; 9.98418ms)
Feb 13 21:47:40.452: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-c64hr/services/proxy-service-cqd4g:portname2/proxy/: bar (200; 10.874397ms)
STEP: deleting { ReplicationController} proxy-service-cqd4g in namespace e2e-tests-proxy-c64hr, will wait for the garbage collector to delete the pods
Feb 13 21:47:40.507: INFO: Deleting { ReplicationController} proxy-service-cqd4g took: 4.12001ms
Feb 13 21:47:40.607: INFO: Terminating { ReplicationController} proxy-service-cqd4g pods took: 100.125279ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:47:44.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-c64hr" for this suite.
Feb 13 21:47:50.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:47:50.852: INFO: namespace: e2e-tests-proxy-c64hr, resource: bindings, ignored listing per whitelist
Feb 13 21:47:50.854: INFO: namespace e2e-tests-proxy-c64hr deletion completed in 6.043898868s

• [SLOW TEST:21.815 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:47:50.854: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-zvs62
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-029ee220-2fd9-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:47:51.003: INFO: Waiting up to 5m0s for pod "pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-zvs62" to be "success or failure"
Feb 13 21:47:51.004: INFO: Pod "pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.135291ms
Feb 13 21:47:53.006: INFO: Pod "pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002991085s
STEP: Saw pod success
Feb 13 21:47:53.006: INFO: Pod "pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:47:53.007: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:47:53.017: INFO: Waiting for pod pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:47:53.018: INFO: Pod pod-secrets-02a01ddf-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:47:53.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zvs62" for this suite.
Feb 13 21:47:59.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:47:59.061: INFO: namespace: e2e-tests-secrets-zvs62, resource: bindings, ignored listing per whitelist
Feb 13 21:47:59.065: INFO: namespace e2e-tests-secrets-zvs62 deletion completed in 6.045149701s

• [SLOW TEST:8.211 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:47:59.065: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6ttpq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:47:59.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-6ttpq" to be "success or failure"
Feb 13 21:47:59.206: INFO: Pod "downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.19231ms
Feb 13 21:48:01.208: INFO: Pod "downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.004753849s
Feb 13 21:48:03.209: INFO: Pod "downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006352207s
STEP: Saw pod success
Feb 13 21:48:03.209: INFO: Pod "downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:48:03.211: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:48:03.223: INFO: Waiting for pod downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:48:03.224: INFO: Pod downwardapi-volume-0783db27-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:48:03.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6ttpq" for this suite.
Feb 13 21:48:09.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:48:09.257: INFO: namespace: e2e-tests-projected-6ttpq, resource: bindings, ignored listing per whitelist
Feb 13 21:48:09.270: INFO: namespace e2e-tests-projected-6ttpq deletion completed in 6.044155986s

• [SLOW TEST:10.205 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:48:09.271: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-g9qkj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-g9qkj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 21:48:09.403: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 21:48:29.455: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.131:8080/dial?request=hostName&protocol=udp&host=192.168.1.130&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-g9qkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 21:48:29.455: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 21:48:29.519: INFO: Waiting for endpoints: map[]
Feb 13 21:48:29.521: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.131:8080/dial?request=hostName&protocol=udp&host=192.168.2.57&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-g9qkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 21:48:29.521: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 21:48:29.570: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:48:29.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-g9qkj" for this suite.
Feb 13 21:48:51.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:48:51.586: INFO: namespace: e2e-tests-pod-network-test-g9qkj, resource: bindings, ignored listing per whitelist
Feb 13 21:48:51.618: INFO: namespace e2e-tests-pod-network-test-g9qkj deletion completed in 22.044872651s

• [SLOW TEST:42.347 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:48:51.620: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-v6hqc
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:48:51.756: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:48:52.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-v6hqc" for this suite.
Feb 13 21:48:58.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:48:58.855: INFO: namespace: e2e-tests-custom-resource-definition-v6hqc, resource: bindings, ignored listing per whitelist
Feb 13 21:48:58.880: INFO: namespace e2e-tests-custom-resource-definition-v6hqc deletion completed in 6.049914653s

• [SLOW TEST:7.261 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:48:58.881: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4qjd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 21:48:59.019: INFO: Waiting up to 5m0s for pod "downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-4qjd6" to be "success or failure"
Feb 13 21:48:59.023: INFO: Pod "downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.869142ms
Feb 13 21:49:01.025: INFO: Pod "downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00594105s
STEP: Saw pod success
Feb 13 21:49:01.025: INFO: Pod "downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:49:01.027: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 21:49:01.040: INFO: Waiting for pod downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:49:01.041: INFO: Pod downward-api-2b2aad6f-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:49:01.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4qjd6" for this suite.
Feb 13 21:49:07.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:07.055: INFO: namespace: e2e-tests-downward-api-4qjd6, resource: bindings, ignored listing per whitelist
Feb 13 21:49:07.089: INFO: namespace e2e-tests-downward-api-4qjd6 deletion completed in 6.046324854s

• [SLOW TEST:8.209 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:49:07.090: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5qltz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:49:07.249: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-5qltz" to be "success or failure"
Feb 13 21:49:07.255: INFO: Pod "downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.600364ms
Feb 13 21:49:09.257: INFO: Pod "downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.008348011s
Feb 13 21:49:11.259: INFO: Pod "downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009891021s
STEP: Saw pod success
Feb 13 21:49:11.259: INFO: Pod "downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:49:11.260: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:49:11.275: INFO: Waiting for pod downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:49:11.276: INFO: Pod downwardapi-volume-30128afd-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:49:11.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5qltz" for this suite.
Feb 13 21:49:17.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:49:17.304: INFO: namespace: e2e-tests-projected-5qltz, resource: bindings, ignored listing per whitelist
Feb 13 21:49:17.324: INFO: namespace e2e-tests-projected-5qltz deletion completed in 6.046743506s

• [SLOW TEST:10.235 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:49:17.325: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wxdrj
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3629e25e-2fd9-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3629e25e-2fd9-11e9-829f-22a36399a92d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:50:37.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wxdrj" for this suite.
Feb 13 21:50:59.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:50:59.756: INFO: namespace: e2e-tests-configmap-wxdrj, resource: bindings, ignored listing per whitelist
Feb 13 21:50:59.786: INFO: namespace e2e-tests-configmap-wxdrj deletion completed in 22.045284709s

• [SLOW TEST:102.461 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:50:59.787: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2h8xv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-l46t
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 21:50:59.936: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-l46t" in namespace "e2e-tests-subpath-2h8xv" to be "success or failure"
Feb 13 21:50:59.940: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27782ms
Feb 13 21:51:01.942: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00532876s
Feb 13 21:51:03.943: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 4.006741277s
Feb 13 21:51:05.945: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 6.008723875s
Feb 13 21:51:07.947: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 8.010577877s
Feb 13 21:51:09.949: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 10.012490035s
Feb 13 21:51:11.951: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 12.014527552s
Feb 13 21:51:13.953: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 14.016334236s
Feb 13 21:51:15.954: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 16.018184134s
Feb 13 21:51:17.956: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 18.019860811s
Feb 13 21:51:19.958: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 20.021823281s
Feb 13 21:51:21.960: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Running", Reason="", readiness=false. Elapsed: 22.023700078s
Feb 13 21:51:23.968: INFO: Pod "pod-subpath-test-secret-l46t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.03198545s
STEP: Saw pod success
Feb 13 21:51:23.968: INFO: Pod "pod-subpath-test-secret-l46t" satisfied condition "success or failure"
Feb 13 21:51:23.970: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-subpath-test-secret-l46t container test-container-subpath-secret-l46t: <nil>
STEP: delete the pod
Feb 13 21:51:23.993: INFO: Waiting for pod pod-subpath-test-secret-l46t to disappear
Feb 13 21:51:24.002: INFO: Pod pod-subpath-test-secret-l46t no longer exists
STEP: Deleting pod pod-subpath-test-secret-l46t
Feb 13 21:51:24.002: INFO: Deleting pod "pod-subpath-test-secret-l46t" in namespace "e2e-tests-subpath-2h8xv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:51:24.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2h8xv" for this suite.
Feb 13 21:51:30.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:30.024: INFO: namespace: e2e-tests-subpath-2h8xv, resource: bindings, ignored listing per whitelist
Feb 13 21:51:30.051: INFO: namespace e2e-tests-subpath-2h8xv deletion completed in 6.046060412s

• [SLOW TEST:30.264 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:51:30.052: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vpn2v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-vpn2v/configmap-test-854545bd-2fd9-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 21:51:30.190: INFO: Waiting up to 5m0s for pod "pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-vpn2v" to be "success or failure"
Feb 13 21:51:30.192: INFO: Pod "pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.66678ms
Feb 13 21:51:32.194: INFO: Pod "pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004263086s
STEP: Saw pod success
Feb 13 21:51:32.194: INFO: Pod "pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:51:32.195: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d container env-test: <nil>
STEP: delete the pod
Feb 13 21:51:32.206: INFO: Waiting for pod pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:51:32.207: INFO: Pod pod-configmaps-85458a1b-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:51:32.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vpn2v" for this suite.
Feb 13 21:51:38.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:51:38.236: INFO: namespace: e2e-tests-configmap-vpn2v, resource: bindings, ignored listing per whitelist
Feb 13 21:51:38.256: INFO: namespace e2e-tests-configmap-vpn2v deletion completed in 6.047019147s

• [SLOW TEST:8.205 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:51:38.257: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v78n4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 21:51:38.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-v78n4'
Feb 13 21:51:38.692: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 21:51:38.692: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb 13 21:51:40.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-v78n4'
Feb 13 21:51:40.781: INFO: stderr: ""
Feb 13 21:51:40.781: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:51:40.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v78n4" for this suite.
Feb 13 21:52:00.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:52:00.806: INFO: namespace: e2e-tests-kubectl-v78n4, resource: bindings, ignored listing per whitelist
Feb 13 21:52:00.831: INFO: namespace e2e-tests-kubectl-v78n4 deletion completed in 20.046649911s

• [SLOW TEST:22.574 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:52:00.832: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xx6vs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 13 21:52:00.973: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 13 21:52:00.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:01.136: INFO: stderr: ""
Feb 13 21:52:01.136: INFO: stdout: "service/redis-slave created\n"
Feb 13 21:52:01.136: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 13 21:52:01.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:01.299: INFO: stderr: ""
Feb 13 21:52:01.299: INFO: stdout: "service/redis-master created\n"
Feb 13 21:52:01.299: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 13 21:52:01.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:01.443: INFO: stderr: ""
Feb 13 21:52:01.443: INFO: stdout: "service/frontend created\n"
Feb 13 21:52:01.443: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 13 21:52:01.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:01.592: INFO: stderr: ""
Feb 13 21:52:01.592: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 13 21:52:01.593: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 13 21:52:01.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:01.857: INFO: stderr: ""
Feb 13 21:52:01.857: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 13 21:52:01.858: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 13 21:52:01.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:02.022: INFO: stderr: ""
Feb 13 21:52:02.022: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 13 21:52:02.022: INFO: Waiting for all frontend pods to be Running.
Feb 13 21:52:27.072: INFO: Waiting for frontend to serve content.
Feb 13 21:52:27.083: INFO: Trying to add a new entry to the guestbook.
Feb 13 21:52:27.091: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 13 21:52:27.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:27.186: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:52:27.186: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 21:52:27.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:27.280: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:52:27.280: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 21:52:27.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:27.369: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:52:27.369: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 21:52:27.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:27.438: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:52:27.438: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 21:52:27.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:27.509: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:52:27.509: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 13 21:52:27.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx6vs'
Feb 13 21:52:27.590: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:52:27.590: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:52:27.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xx6vs" for this suite.
Feb 13 21:53:05.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:05.627: INFO: namespace: e2e-tests-kubectl-xx6vs, resource: bindings, ignored listing per whitelist
Feb 13 21:53:05.648: INFO: namespace e2e-tests-kubectl-xx6vs deletion completed in 38.047670134s

• [SLOW TEST:64.817 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:53:05.650: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-gjrqd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-4v2h
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 21:53:05.799: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4v2h" in namespace "e2e-tests-subpath-gjrqd" to be "success or failure"
Feb 13 21:53:05.802: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Pending", Reason="", readiness=false. Elapsed: 1.961963ms
Feb 13 21:53:07.806: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006237056s
Feb 13 21:53:09.812: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 4.012403293s
Feb 13 21:53:11.814: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 6.014492776s
Feb 13 21:53:13.816: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 8.015933641s
Feb 13 21:53:15.817: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 10.017584271s
Feb 13 21:53:17.819: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 12.019420597s
Feb 13 21:53:19.821: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 14.021057252s
Feb 13 21:53:21.822: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 16.022697282s
Feb 13 21:53:23.824: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 18.024701694s
Feb 13 21:53:25.826: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 20.026648458s
Feb 13 21:53:27.829: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Running", Reason="", readiness=false. Elapsed: 22.028889781s
Feb 13 21:53:29.831: INFO: Pod "pod-subpath-test-configmap-4v2h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.031029165s
STEP: Saw pod success
Feb 13 21:53:29.831: INFO: Pod "pod-subpath-test-configmap-4v2h" satisfied condition "success or failure"
Feb 13 21:53:29.832: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-subpath-test-configmap-4v2h container test-container-subpath-configmap-4v2h: <nil>
STEP: delete the pod
Feb 13 21:53:29.847: INFO: Waiting for pod pod-subpath-test-configmap-4v2h to disappear
Feb 13 21:53:29.848: INFO: Pod pod-subpath-test-configmap-4v2h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4v2h
Feb 13 21:53:29.848: INFO: Deleting pod "pod-subpath-test-configmap-4v2h" in namespace "e2e-tests-subpath-gjrqd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:53:29.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gjrqd" for this suite.
Feb 13 21:53:35.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:35.881: INFO: namespace: e2e-tests-subpath-gjrqd, resource: bindings, ignored listing per whitelist
Feb 13 21:53:35.896: INFO: namespace e2e-tests-subpath-gjrqd deletion completed in 6.044687256s

• [SLOW TEST:30.246 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:53:35.896: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tk9kt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d0489494-2fd9-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:53:36.040: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-tk9kt" to be "success or failure"
Feb 13 21:53:36.046: INFO: Pod "pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.208594ms
Feb 13 21:53:38.048: INFO: Pod "pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008115157s
STEP: Saw pod success
Feb 13 21:53:38.048: INFO: Pod "pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:53:38.049: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:53:38.061: INFO: Waiting for pod pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:53:38.062: INFO: Pod pod-projected-secrets-d048ece6-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:53:38.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tk9kt" for this suite.
Feb 13 21:53:44.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:53:44.100: INFO: namespace: e2e-tests-projected-tk9kt, resource: bindings, ignored listing per whitelist
Feb 13 21:53:44.107: INFO: namespace e2e-tests-projected-tk9kt deletion completed in 6.042606043s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:53:44.107: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-2m84j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:53:46.272: INFO: Waiting up to 5m0s for pod "client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d" in namespace "e2e-tests-pods-2m84j" to be "success or failure"
Feb 13 21:53:46.277: INFO: Pod "client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.396592ms
Feb 13 21:53:48.279: INFO: Pod "client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007216371s
STEP: Saw pod success
Feb 13 21:53:48.279: INFO: Pod "client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:53:48.280: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d container env3cont: <nil>
STEP: delete the pod
Feb 13 21:53:48.289: INFO: Waiting for pod client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d to disappear
Feb 13 21:53:48.291: INFO: Pod client-envvars-d66246e9-2fd9-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:53:48.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2m84j" for this suite.
Feb 13 21:54:26.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:54:26.321: INFO: namespace: e2e-tests-pods-2m84j, resource: bindings, ignored listing per whitelist
Feb 13 21:54:26.345: INFO: namespace e2e-tests-pods-2m84j deletion completed in 38.052107989s

• [SLOW TEST:42.238 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:54:26.346: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-s4g6b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-s4g6b
Feb 13 21:54:28.492: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-s4g6b
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 21:54:28.494: INFO: Initial restart count of pod liveness-exec is 0
Feb 13 21:55:14.544: INFO: Restart count of pod e2e-tests-container-probe-s4g6b/liveness-exec is now 1 (46.050617418s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:55:14.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s4g6b" for this suite.
Feb 13 21:55:20.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:55:20.572: INFO: namespace: e2e-tests-container-probe-s4g6b, resource: bindings, ignored listing per whitelist
Feb 13 21:55:20.603: INFO: namespace e2e-tests-container-probe-s4g6b deletion completed in 6.050325062s

• [SLOW TEST:54.258 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:55:20.604: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-kvbfm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4gm2f
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-hz46f
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:55:26.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kvbfm" for this suite.
Feb 13 21:55:33.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:55:33.021: INFO: namespace: e2e-tests-namespaces-kvbfm, resource: bindings, ignored listing per whitelist
Feb 13 21:55:33.044: INFO: namespace e2e-tests-namespaces-kvbfm deletion completed in 6.049958732s
STEP: Destroying namespace "e2e-tests-nsdeletetest-4gm2f" for this suite.
Feb 13 21:55:33.045: INFO: Namespace e2e-tests-nsdeletetest-4gm2f was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-hz46f" for this suite.
Feb 13 21:55:39.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:55:39.075: INFO: namespace: e2e-tests-nsdeletetest-hz46f, resource: bindings, ignored listing per whitelist
Feb 13 21:55:39.091: INFO: namespace e2e-tests-nsdeletetest-hz46f deletion completed in 6.045417627s

• [SLOW TEST:18.487 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:55:39.091: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vrmff
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-19b6bfbf-2fda-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:55:41.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vrmff" for this suite.
Feb 13 21:56:03.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:56:03.285: INFO: namespace: e2e-tests-configmap-vrmff, resource: bindings, ignored listing per whitelist
Feb 13 21:56:03.301: INFO: namespace e2e-tests-configmap-vrmff deletion completed in 22.048248942s

• [SLOW TEST:24.210 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:56:03.301: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rbn95
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 21:56:03.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-rbn95" to be "success or failure"
Feb 13 21:56:03.446: INFO: Pod "downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.9018ms
Feb 13 21:56:05.448: INFO: Pod "downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.00579488s
Feb 13 21:56:07.449: INFO: Pod "downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007515295s
STEP: Saw pod success
Feb 13 21:56:07.449: INFO: Pod "downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:56:07.451: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 21:56:07.461: INFO: Waiting for pod downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 21:56:07.464: INFO: Pod downwardapi-volume-2824a3e6-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:56:07.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rbn95" for this suite.
Feb 13 21:56:13.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:56:13.512: INFO: namespace: e2e-tests-downward-api-rbn95, resource: bindings, ignored listing per whitelist
Feb 13 21:56:13.516: INFO: namespace e2e-tests-downward-api-rbn95 deletion completed in 6.05068149s

• [SLOW TEST:10.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:56:13.516: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mn7p8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2e3b66b2-2fda-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 21:56:13.659: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-mn7p8" to be "success or failure"
Feb 13 21:56:13.665: INFO: Pod "pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.824051ms
Feb 13 21:56:15.667: INFO: Pod "pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007623946s
Feb 13 21:56:17.669: INFO: Pod "pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009459752s
STEP: Saw pod success
Feb 13 21:56:17.669: INFO: Pod "pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:56:17.670: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 21:56:17.681: INFO: Waiting for pod pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 21:56:17.682: INFO: Pod pod-projected-configmaps-2e3bb76e-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:56:17.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mn7p8" for this suite.
Feb 13 21:56:23.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:56:23.727: INFO: namespace: e2e-tests-projected-mn7p8, resource: bindings, ignored listing per whitelist
Feb 13 21:56:23.730: INFO: namespace e2e-tests-projected-mn7p8 deletion completed in 6.045348872s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:56:23.731: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8bm5s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-34516e11-2fda-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 21:56:23.872: INFO: Waiting up to 5m0s for pod "pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-8bm5s" to be "success or failure"
Feb 13 21:56:23.878: INFO: Pod "pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.995213ms
Feb 13 21:56:25.879: INFO: Pod "pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007425769s
STEP: Saw pod success
Feb 13 21:56:25.880: INFO: Pod "pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:56:25.881: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 21:56:25.893: INFO: Waiting for pod pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 21:56:25.894: INFO: Pod pod-secrets-3451c15a-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:56:25.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8bm5s" for this suite.
Feb 13 21:56:31.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:56:31.924: INFO: namespace: e2e-tests-secrets-8bm5s, resource: bindings, ignored listing per whitelist
Feb 13 21:56:31.958: INFO: namespace e2e-tests-secrets-8bm5s deletion completed in 6.06106637s

• [SLOW TEST:8.227 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:56:31.958: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8wszb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:56:32.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 version --client'
Feb 13 21:56:32.233: INFO: stderr: ""
Feb 13 21:56:32.233: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 13 21:56:32.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-8wszb'
Feb 13 21:56:32.392: INFO: stderr: ""
Feb 13 21:56:32.392: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 13 21:56:32.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-8wszb'
Feb 13 21:56:32.548: INFO: stderr: ""
Feb 13 21:56:32.548: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 21:56:33.596: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:56:33.596: INFO: Found 0 / 1
Feb 13 21:56:34.549: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:56:34.549: INFO: Found 1 / 1
Feb 13 21:56:34.549: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 21:56:34.550: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 21:56:34.550: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 21:56:34.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 describe pod redis-master-frfc4 --namespace=e2e-tests-kubectl-8wszb'
Feb 13 21:56:34.620: INFO: stderr: ""
Feb 13 21:56:34.620: INFO: stdout: "Name:               redis-master-frfc4\nNamespace:          e2e-tests-kubectl-8wszb\nPriority:           0\nPriorityClassName:  <none>\nNode:               alex-300-cp3-vsp1-worker71a62db265/10.10.100.39\nStart Time:         Wed, 13 Feb 2019 21:56:25 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.1.154/32\nStatus:             Running\nIP:                 192.168.1.154\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://baad57c484821e044b0ed37dc834e50d3ffa2dc3291c306a25d061917e54370c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 13 Feb 2019 21:56:26 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fjq52 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fjq52:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fjq52\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                         Message\n  ----    ------     ----  ----                                         -------\n  Normal  Pulled     8s    kubelet, alex-300-cp3-vsp1-worker71a62db265  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    8s    kubelet, alex-300-cp3-vsp1-worker71a62db265  Created container\n  Normal  Started    8s    kubelet, alex-300-cp3-vsp1-worker71a62db265  Started container\n  Normal  Scheduled  2s    default-scheduler                            Successfully assigned e2e-tests-kubectl-8wszb/redis-master-frfc4 to alex-300-cp3-vsp1-worker71a62db265\n"
Feb 13 21:56:34.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 describe rc redis-master --namespace=e2e-tests-kubectl-8wszb'
Feb 13 21:56:34.697: INFO: stderr: ""
Feb 13 21:56:34.697: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-8wszb\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-frfc4\n"
Feb 13 21:56:34.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 describe service redis-master --namespace=e2e-tests-kubectl-8wszb'
Feb 13 21:56:34.775: INFO: stderr: ""
Feb 13 21:56:34.775: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-8wszb\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.37.102\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.1.154:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 13 21:56:34.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 describe node alex-300-cp3-vsp1-master39c69945b7'
Feb 13 21:56:35.039: INFO: stderr: ""
Feb 13 21:56:35.039: INFO: stdout: "Name:               alex-300-cp3-vsp1-master39c69945b7\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=alex-300-cp3-vsp1-master39c69945b7\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.100.37/22\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 05 Feb 2019 19:06:17 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 13 Feb 2019 21:56:25 +0000   Tue, 05 Feb 2019 19:06:13 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 13 Feb 2019 21:56:25 +0000   Tue, 05 Feb 2019 19:06:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 13 Feb 2019 21:56:25 +0000   Tue, 05 Feb 2019 19:06:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 13 Feb 2019 21:56:25 +0000   Tue, 05 Feb 2019 19:06:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 13 Feb 2019 21:56:25 +0000   Tue, 05 Feb 2019 19:06:47 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  10.10.100.50\n  InternalIP:  10.10.100.37\n  InternalIP:  10.10.100.50\n  Hostname:    alex-300-cp3-vsp1-master39c69945b7\nCapacity:\n cpu:                2\n ephemeral-storage:  40470732Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16426372Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37297826550\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16323972Ki\n pods:               110\nSystem Info:\n Machine ID:                 9764c916563140109cb7a2f765d28887\n System UUID:                421ED973-1278-C418-6D72-3B48FF158AE9\n Boot ID:                    5fc52da9-3b2c-4246-aa2a-1de196417300\n Kernel Version:             4.15.0-43-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     192.168.0.0/24\nProviderID:                  vsphere://421ed973-1278-c418-6d72-3b48ff158ae9\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                          ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-27a6138aa30842ff                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-kqwxd       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-4jlzj                                             250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                coredns-f698cc5df-8kplp                                       100m (5%)     0 (0%)      70Mi (0%)        170Mi (1%)\n  kube-system                coredns-f698cc5df-qfvjz                                       100m (5%)     0 (0%)      70Mi (0%)        170Mi (1%)\n  kube-system                etcd-alex-300-cp3-vsp1-master39c69945b7                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-alex-300-cp3-vsp1-master39c69945b7             250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-alex-300-cp3-vsp1-master39c69945b7    200m (10%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-99k67                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-alex-300-cp3-vsp1-master39c69945b7             100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                tiller-deploy-5f96fb458f-6x924                                0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       1 (50%)     0 (0%)\n  memory    140Mi (0%)  340Mi (2%)\nEvents:     <none>\n"
Feb 13 21:56:35.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 describe namespace e2e-tests-kubectl-8wszb'
Feb 13 21:56:35.117: INFO: stderr: ""
Feb 13 21:56:35.117: INFO: stdout: "Name:         e2e-tests-kubectl-8wszb\nLabels:       e2e-framework=kubectl\n              e2e-run=ff1076d2-2fd4-11e9-829f-22a36399a92d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:56:35.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8wszb" for this suite.
Feb 13 21:56:57.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:56:57.212: INFO: namespace: e2e-tests-kubectl-8wszb, resource: bindings, ignored listing per whitelist
Feb 13 21:56:57.224: INFO: namespace e2e-tests-kubectl-8wszb deletion completed in 22.065034402s

• [SLOW TEST:25.266 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:56:57.224: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xjhq9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:56:57.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 version'
Feb 13 21:56:57.429: INFO: stderr: ""
Feb 13 21:56:57.429: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:56:57.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xjhq9" for this suite.
Feb 13 21:57:03.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:57:03.483: INFO: namespace: e2e-tests-kubectl-xjhq9, resource: bindings, ignored listing per whitelist
Feb 13 21:57:03.485: INFO: namespace e2e-tests-kubectl-xjhq9 deletion completed in 6.053385406s

• [SLOW TEST:6.261 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:57:03.485: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sckqp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 13 21:57:03.624: INFO: Waiting up to 5m0s for pod "pod-4c03c044-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-sckqp" to be "success or failure"
Feb 13 21:57:03.629: INFO: Pod "pod-4c03c044-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.63249ms
Feb 13 21:57:05.630: INFO: Pod "pod-4c03c044-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006091934s
STEP: Saw pod success
Feb 13 21:57:05.630: INFO: Pod "pod-4c03c044-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:57:05.631: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-4c03c044-2fda-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:57:05.643: INFO: Waiting for pod pod-4c03c044-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 21:57:05.644: INFO: Pod pod-4c03c044-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:57:05.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sckqp" for this suite.
Feb 13 21:57:11.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:57:11.667: INFO: namespace: e2e-tests-emptydir-sckqp, resource: bindings, ignored listing per whitelist
Feb 13 21:57:11.708: INFO: namespace e2e-tests-emptydir-sckqp deletion completed in 6.061953706s

• [SLOW TEST:8.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:57:11.709: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-xg8zh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:58:11.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xg8zh" for this suite.
Feb 13 21:58:33.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:58:33.905: INFO: namespace: e2e-tests-container-probe-xg8zh, resource: bindings, ignored listing per whitelist
Feb 13 21:58:33.911: INFO: namespace e2e-tests-container-probe-xg8zh deletion completed in 22.056217532s

• [SLOW TEST:82.203 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:58:33.911: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6wd7k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 13 21:58:34.056: INFO: Waiting up to 5m0s for pod "pod-81ea9fa3-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-6wd7k" to be "success or failure"
Feb 13 21:58:34.058: INFO: Pod "pod-81ea9fa3-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205899ms
Feb 13 21:58:36.060: INFO: Pod "pod-81ea9fa3-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004664886s
STEP: Saw pod success
Feb 13 21:58:36.060: INFO: Pod "pod-81ea9fa3-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 21:58:36.062: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-81ea9fa3-2fda-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 21:58:36.074: INFO: Waiting for pod pod-81ea9fa3-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 21:58:36.075: INFO: Pod pod-81ea9fa3-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:58:36.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6wd7k" for this suite.
Feb 13 21:58:42.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:58:42.117: INFO: namespace: e2e-tests-emptydir-6wd7k, resource: bindings, ignored listing per whitelist
Feb 13 21:58:42.119: INFO: namespace e2e-tests-emptydir-6wd7k deletion completed in 6.041170096s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:58:42.119: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-cfmgz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-4wps
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 21:58:42.265: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4wps" in namespace "e2e-tests-subpath-cfmgz" to be "success or failure"
Feb 13 21:58:42.270: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Pending", Reason="", readiness=false. Elapsed: 4.969508ms
Feb 13 21:58:44.272: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007190041s
Feb 13 21:58:46.275: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 4.009364674s
Feb 13 21:58:48.277: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 6.011704016s
Feb 13 21:58:50.279: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 8.013708911s
Feb 13 21:58:52.281: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 10.015835498s
Feb 13 21:58:54.283: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 12.01774579s
Feb 13 21:58:56.285: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 14.019794379s
Feb 13 21:58:58.287: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 16.021953692s
Feb 13 21:59:00.289: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 18.023886435s
Feb 13 21:59:02.292: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 20.026273937s
Feb 13 21:59:04.294: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Running", Reason="", readiness=false. Elapsed: 22.028246111s
Feb 13 21:59:06.296: INFO: Pod "pod-subpath-test-projected-4wps": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.03037881s
STEP: Saw pod success
Feb 13 21:59:06.296: INFO: Pod "pod-subpath-test-projected-4wps" satisfied condition "success or failure"
Feb 13 21:59:06.301: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-subpath-test-projected-4wps container test-container-subpath-projected-4wps: <nil>
STEP: delete the pod
Feb 13 21:59:06.333: INFO: Waiting for pod pod-subpath-test-projected-4wps to disappear
Feb 13 21:59:06.338: INFO: Pod pod-subpath-test-projected-4wps no longer exists
STEP: Deleting pod pod-subpath-test-projected-4wps
Feb 13 21:59:06.338: INFO: Deleting pod "pod-subpath-test-projected-4wps" in namespace "e2e-tests-subpath-cfmgz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:59:06.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cfmgz" for this suite.
Feb 13 21:59:12.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:59:12.390: INFO: namespace: e2e-tests-subpath-cfmgz, resource: bindings, ignored listing per whitelist
Feb 13 21:59:12.397: INFO: namespace e2e-tests-subpath-cfmgz deletion completed in 6.056877374s

• [SLOW TEST:30.278 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:59:12.398: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zksbw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb 13 21:59:12.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:12.666: INFO: stderr: ""
Feb 13 21:59:12.666: INFO: stdout: "pod/pause created\n"
Feb 13 21:59:12.666: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 13 21:59:12.666: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-zksbw" to be "running and ready"
Feb 13 21:59:12.671: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.494931ms
Feb 13 21:59:14.672: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006229853s
Feb 13 21:59:14.672: INFO: Pod "pause" satisfied condition "running and ready"
Feb 13 21:59:14.672: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 13 21:59:14.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:14.749: INFO: stderr: ""
Feb 13 21:59:14.749: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 13 21:59:14.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pod pause -L testing-label --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:14.823: INFO: stderr: ""
Feb 13 21:59:14.823: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 13 21:59:14.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 label pods pause testing-label- --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:14.912: INFO: stderr: ""
Feb 13 21:59:14.912: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 13 21:59:14.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pod pause -L testing-label --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:14.992: INFO: stderr: ""
Feb 13 21:59:14.992: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb 13 21:59:14.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:15.075: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 21:59:15.075: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 13 21:59:15.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-zksbw'
Feb 13 21:59:15.147: INFO: stderr: "No resources found.\n"
Feb 13 21:59:15.147: INFO: stdout: ""
Feb 13 21:59:15.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -l name=pause --namespace=e2e-tests-kubectl-zksbw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 21:59:15.220: INFO: stderr: ""
Feb 13 21:59:15.220: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:59:15.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zksbw" for this suite.
Feb 13 21:59:21.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 21:59:21.255: INFO: namespace: e2e-tests-kubectl-zksbw, resource: bindings, ignored listing per whitelist
Feb 13 21:59:21.274: INFO: namespace e2e-tests-kubectl-zksbw deletion completed in 6.051305297s

• [SLOW TEST:8.876 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 21:59:21.275: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-mm2lk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 21:59:39.414: INFO: Container started at 2019-02-13 21:59:15 +0000 UTC, pod became ready at 2019-02-13 21:59:31 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 21:59:39.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mm2lk" for this suite.
Feb 13 22:00:01.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:01.427: INFO: namespace: e2e-tests-container-probe-mm2lk, resource: bindings, ignored listing per whitelist
Feb 13 22:00:01.464: INFO: namespace e2e-tests-container-probe-mm2lk deletion completed in 22.048560354s

• [SLOW TEST:40.190 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:00:01.465: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-x8h74
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0213 22:00:07.622155      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 22:00:07.622: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:00:07.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-x8h74" for this suite.
Feb 13 22:00:13.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:13.663: INFO: namespace: e2e-tests-gc-x8h74, resource: bindings, ignored listing per whitelist
Feb 13 22:00:13.678: INFO: namespace e2e-tests-gc-x8h74 deletion completed in 6.053483645s

• [SLOW TEST:12.213 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:00:13.678: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pbfn5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:00:13.913: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-pbfn5" to be "success or failure"
Feb 13 22:00:13.916: INFO: Pod "downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41895ms
Feb 13 22:00:15.918: INFO: Pod "downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005105555s
STEP: Saw pod success
Feb 13 22:00:15.918: INFO: Pod "downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:00:15.919: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:00:15.933: INFO: Waiting for pod downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 22:00:15.934: INFO: Pod downwardapi-volume-bd6f57a6-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:00:15.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pbfn5" for this suite.
Feb 13 22:00:21.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:21.974: INFO: namespace: e2e-tests-downward-api-pbfn5, resource: bindings, ignored listing per whitelist
Feb 13 22:00:21.979: INFO: namespace e2e-tests-downward-api-pbfn5 deletion completed in 6.043426474s

• [SLOW TEST:8.301 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:00:21.979: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-fhh5q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 13 22:00:22.118: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fhh5q,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhh5q/configmaps/e2e-watch-test-label-changed,UID:c2532780-2fda-11e9-8578-0050569e397b,ResourceVersion:1270527,Generation:0,CreationTimestamp:2019-02-13 22:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 13 22:00:22.118: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fhh5q,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhh5q/configmaps/e2e-watch-test-label-changed,UID:c2532780-2fda-11e9-8578-0050569e397b,ResourceVersion:1270528,Generation:0,CreationTimestamp:2019-02-13 22:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 13 22:00:22.118: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fhh5q,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhh5q/configmaps/e2e-watch-test-label-changed,UID:c2532780-2fda-11e9-8578-0050569e397b,ResourceVersion:1270529,Generation:0,CreationTimestamp:2019-02-13 22:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 13 22:00:32.131: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fhh5q,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhh5q/configmaps/e2e-watch-test-label-changed,UID:c2532780-2fda-11e9-8578-0050569e397b,ResourceVersion:1270550,Generation:0,CreationTimestamp:2019-02-13 22:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 13 22:00:32.131: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fhh5q,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhh5q/configmaps/e2e-watch-test-label-changed,UID:c2532780-2fda-11e9-8578-0050569e397b,ResourceVersion:1270551,Generation:0,CreationTimestamp:2019-02-13 22:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 13 22:00:32.131: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fhh5q,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhh5q/configmaps/e2e-watch-test-label-changed,UID:c2532780-2fda-11e9-8578-0050569e397b,ResourceVersion:1270552,Generation:0,CreationTimestamp:2019-02-13 22:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:00:32.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fhh5q" for this suite.
Feb 13 22:00:38.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:38.160: INFO: namespace: e2e-tests-watch-fhh5q, resource: bindings, ignored listing per whitelist
Feb 13 22:00:38.177: INFO: namespace e2e-tests-watch-fhh5q deletion completed in 6.043996335s

• [SLOW TEST:16.198 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:00:38.178: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-llspq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cbfc305f-2fda-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:00:38.325: INFO: Waiting up to 5m0s for pod "pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-llspq" to be "success or failure"
Feb 13 22:00:38.327: INFO: Pod "pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.285586ms
Feb 13 22:00:40.329: INFO: Pod "pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003254563s
STEP: Saw pod success
Feb 13 22:00:40.329: INFO: Pod "pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:00:40.333: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:00:40.349: INFO: Waiting for pod pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 22:00:40.350: INFO: Pod pod-configmaps-cbfc8ac9-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:00:40.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-llspq" for this suite.
Feb 13 22:00:46.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:46.376: INFO: namespace: e2e-tests-configmap-llspq, resource: bindings, ignored listing per whitelist
Feb 13 22:00:46.402: INFO: namespace e2e-tests-configmap-llspq deletion completed in 6.048044448s

• [SLOW TEST:8.224 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:00:46.402: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-9xwsj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 13 22:00:46.540: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 22:00:46.545: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 22:00:46.546: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp3-vsp1-worker71a62db265 before test
Feb 13 22:00:46.551: INFO: nginx-ingress-controller-zg2sn from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.551: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:00:46.551: INFO: ccp-monitor-prometheus-kube-state-metrics-78dc9f46d4-wsrkg from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.551: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Feb 13 22:00:46.552: INFO: ccp-efk-elasticsearch-curator-1549846800-4rsp5 from ccp started at 2019-02-11 00:59:57 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 22:00:46.552: INFO: calico-typha-785658b69-2ddnl from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:00:46.552: INFO: nginx-ingress-default-backend-765bbc8b9d-j86sx from ccp started at 2019-02-05 19:07:30 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb 13 22:00:46.552: INFO: calico-node-hk7rf from kube-system started at 2019-02-05 19:06:38 +0000 UTC (2 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:00:46.552: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:00:46.552: INFO: metallb-speaker-jg54f from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:00:46.552: INFO: ccp-monitor-prometheus-node-exporter-4nmw9 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:00:46.552: INFO: ccp-monitor-prometheus-server-6bddddb9cc-d8k6p from ccp started at 2019-02-05 19:07:34 +0000 UTC (2 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container prometheus-server ready: true, restart count 0
Feb 13 22:00:46.552: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Feb 13 22:00:46.552: INFO: fluentd-es-v2.0.2-sbv67 from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:00:46.552: INFO: sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-nzdld from heptio-sonobuoy started at 2019-02-13 21:18:37 +0000 UTC (2 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 22:00:46.552: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 22:00:46.552: INFO: kubernetes-dashboard-65dc48675f-4cffw from ccp started at 2019-02-05 19:07:32 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 13 22:00:46.552: INFO: ccp-efk-elasticsearch-curator-1550019600-r5f2q from ccp started at 2019-02-13 00:59:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.552: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 22:00:46.553: INFO: kube-proxy-9zq7t from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.553: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:00:46.553: INFO: ccp-efk-elasticsearch-curator-1549933200-h87dw from ccp started at 2019-02-12 00:59:57 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.553: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 22:00:46.553: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 21:18:28 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.553: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 22:00:46.553: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp3-vsp1-workerdf4199ef27 before test
Feb 13 22:00:46.562: INFO: fluentd-es-v2.0.2-dhjg4 from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:00:46.562: INFO: sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-zrxgv from heptio-sonobuoy started at 2019-02-13 21:18:37 +0000 UTC (2 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 13 22:00:46.562: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 13 22:00:46.562: INFO: calico-node-xdz82 from kube-system started at 2019-02-05 19:06:38 +0000 UTC (2 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:00:46.562: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:00:46.562: INFO: calico-typha-785658b69-48jm5 from kube-system started at 2019-02-05 19:06:48 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:00:46.562: INFO: nginx-ingress-controller-6xl6l from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:00:46.562: INFO: ccp-monitor-prometheus-node-exporter-6vlbz from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:00:46.562: INFO: ccp-monitor-grafana-577f9c8c7c-wshx8 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container grafana ready: true, restart count 0
Feb 13 22:00:46.562: INFO: kube-proxy-25b5j from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.562: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:00:46.562: INFO: metallb-controller-56fd5dc6c8-bf86h from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container controller ready: true, restart count 0
Feb 13 22:00:46.563: INFO: ccp-monitor-prometheus-pushgateway-5c4f64c9d8-lc5m5 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
Feb 13 22:00:46.563: INFO: ccp-efk-kibana-56784656d5-8sffs from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container kibana ready: true, restart count 0
Feb 13 22:00:46.563: INFO: cert-manager-897586cc6-rxv6p from ccp started at 2019-02-05 19:07:30 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container cert-manager ready: true, restart count 1
Feb 13 22:00:46.563: INFO: ccp-monitor-prometheus-alertmanager-5cbfbfcc66-jqz5z from ccp started at 2019-02-05 19:07:36 +0000 UTC (2 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Feb 13 22:00:46.563: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
Feb 13 22:00:46.563: INFO: metallb-speaker-nl4pl from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:00:46.563: INFO: elasticsearch-logging-0 from ccp started at 2019-02-05 19:07:36 +0000 UTC (1 container statuses recorded)
Feb 13 22:00:46.563: INFO: 	Container elasticsearch-logging ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node alex-300-cp3-vsp1-worker71a62db265
STEP: verifying the node has the label node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod ccp-efk-kibana-56784656d5-8sffs requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-grafana-577f9c8c7c-wshx8 requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-prometheus-alertmanager-5cbfbfcc66-jqz5z requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-prometheus-kube-state-metrics-78dc9f46d4-wsrkg requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-prometheus-node-exporter-4nmw9 requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-prometheus-node-exporter-6vlbz requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-prometheus-pushgateway-5c4f64c9d8-lc5m5 requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod ccp-monitor-prometheus-server-6bddddb9cc-d8k6p requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod cert-manager-897586cc6-rxv6p requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod elasticsearch-logging-0 requesting resource cpu=100m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod fluentd-es-v2.0.2-dhjg4 requesting resource cpu=100m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod fluentd-es-v2.0.2-sbv67 requesting resource cpu=100m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod kubernetes-dashboard-65dc48675f-4cffw requesting resource cpu=100m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod metallb-controller-56fd5dc6c8-bf86h requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod metallb-speaker-jg54f requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod metallb-speaker-nl4pl requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod nginx-ingress-controller-6xl6l requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod nginx-ingress-controller-zg2sn requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod nginx-ingress-default-backend-765bbc8b9d-j86sx requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod sonobuoy requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-nzdld requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-zrxgv requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod calico-node-hk7rf requesting resource cpu=250m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod calico-node-xdz82 requesting resource cpu=250m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod calico-typha-785658b69-2ddnl requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
Feb 13 22:00:46.591: INFO: Pod calico-typha-785658b69-48jm5 requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod kube-proxy-25b5j requesting resource cpu=0m on Node alex-300-cp3-vsp1-workerdf4199ef27
Feb 13 22:00:46.591: INFO: Pod kube-proxy-9zq7t requesting resource cpu=0m on Node alex-300-cp3-vsp1-worker71a62db265
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0ea8b09-2fda-11e9-829f-22a36399a92d.15830b68ac6f9e1c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0ea8b09-2fda-11e9-829f-22a36399a92d.15830b68b0a366a5], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0ea8b09-2fda-11e9-829f-22a36399a92d.15830b68b9494edd], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0ea8b09-2fda-11e9-829f-22a36399a92d.15830b69fd7da350], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9xwsj/filler-pod-d0ea8b09-2fda-11e9-829f-22a36399a92d to alex-300-cp3-vsp1-workerdf4199ef27]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0eb4363-2fda-11e9-829f-22a36399a92d.15830b6898ae2511], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0eb4363-2fda-11e9-829f-22a36399a92d.15830b689d211502], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0eb4363-2fda-11e9-829f-22a36399a92d.15830b68a87b609c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d0eb4363-2fda-11e9-829f-22a36399a92d.15830b69fdd42109], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9xwsj/filler-pod-d0eb4363-2fda-11e9-829f-22a36399a92d to alex-300-cp3-vsp1-worker71a62db265]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15830b6aed31ce96], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node alex-300-cp3-vsp1-worker71a62db265
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node alex-300-cp3-vsp1-workerdf4199ef27
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:00:51.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9xwsj" for this suite.
Feb 13 22:00:57.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:00:57.683: INFO: namespace: e2e-tests-sched-pred-9xwsj, resource: bindings, ignored listing per whitelist
Feb 13 22:00:57.709: INFO: namespace e2e-tests-sched-pred-9xwsj deletion completed in 6.053838669s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.308 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:00:57.711: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-njw79
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 22:00:57.850: INFO: Waiting up to 5m0s for pod "downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-njw79" to be "success or failure"
Feb 13 22:00:57.853: INFO: Pod "downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.809349ms
Feb 13 22:00:59.854: INFO: Pod "downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004066539s
STEP: Saw pod success
Feb 13 22:00:59.854: INFO: Pod "downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:00:59.855: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:00:59.870: INFO: Waiting for pod downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 22:00:59.872: INFO: Pod downward-api-d79ff46a-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:00:59.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-njw79" for this suite.
Feb 13 22:01:05.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:05.890: INFO: namespace: e2e-tests-downward-api-njw79, resource: bindings, ignored listing per whitelist
Feb 13 22:01:05.938: INFO: namespace e2e-tests-downward-api-njw79 deletion completed in 6.063707506s

• [SLOW TEST:8.228 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:01:05.938: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-z8kst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:01:06.128: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb 13 22:01:06.130: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-z8kst/daemonsets","resourceVersion":"1270736"},"items":null}

Feb 13 22:01:06.131: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-z8kst/pods","resourceVersion":"1270736"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:01:06.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-z8kst" for this suite.
Feb 13 22:01:12.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:12.161: INFO: namespace: e2e-tests-daemonsets-z8kst, resource: bindings, ignored listing per whitelist
Feb 13 22:01:12.183: INFO: namespace e2e-tests-daemonsets-z8kst deletion completed in 6.047254498s

S [SKIPPING] [6.245 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 13 22:01:06.128: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:01:12.184: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vdfrm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e0409687-2fda-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:01:12.337: INFO: Waiting up to 5m0s for pod "pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-vdfrm" to be "success or failure"
Feb 13 22:01:12.341: INFO: Pod "pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.985466ms
Feb 13 22:01:14.342: INFO: Pod "pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004869235s
STEP: Saw pod success
Feb 13 22:01:14.343: INFO: Pod "pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:01:14.344: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d container secret-env-test: <nil>
STEP: delete the pod
Feb 13 22:01:14.361: INFO: Waiting for pod pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d to disappear
Feb 13 22:01:14.363: INFO: Pod pod-secrets-e0410507-2fda-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:01:14.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vdfrm" for this suite.
Feb 13 22:01:20.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:20.400: INFO: namespace: e2e-tests-secrets-vdfrm, resource: bindings, ignored listing per whitelist
Feb 13 22:01:20.414: INFO: namespace e2e-tests-secrets-vdfrm deletion completed in 6.049286453s

• [SLOW TEST:8.231 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:01:20.415: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-76z4w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 13 22:01:21.061: INFO: created pod pod-service-account-defaultsa
Feb 13 22:01:21.061: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 13 22:01:21.067: INFO: created pod pod-service-account-mountsa
Feb 13 22:01:21.067: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 13 22:01:21.073: INFO: created pod pod-service-account-nomountsa
Feb 13 22:01:21.073: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 13 22:01:21.080: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 13 22:01:21.080: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 13 22:01:21.090: INFO: created pod pod-service-account-mountsa-mountspec
Feb 13 22:01:21.090: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 13 22:01:21.093: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 13 22:01:21.093: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 13 22:01:21.102: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 13 22:01:21.102: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 13 22:01:21.111: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 13 22:01:21.111: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 13 22:01:21.117: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 13 22:01:21.117: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:01:21.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-76z4w" for this suite.
Feb 13 22:01:27.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:27.160: INFO: namespace: e2e-tests-svcaccounts-76z4w, resource: bindings, ignored listing per whitelist
Feb 13 22:01:27.174: INFO: namespace e2e-tests-svcaccounts-76z4w deletion completed in 6.052279493s

• [SLOW TEST:6.759 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:01:27.175: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9wr58
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:01:27.317: INFO: (0) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 3.028197ms)
Feb 13 22:01:27.319: INFO: (1) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.135993ms)
Feb 13 22:01:27.321: INFO: (2) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.970416ms)
Feb 13 22:01:27.323: INFO: (3) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.961881ms)
Feb 13 22:01:27.325: INFO: (4) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.944692ms)
Feb 13 22:01:27.327: INFO: (5) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.181495ms)
Feb 13 22:01:27.329: INFO: (6) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.717438ms)
Feb 13 22:01:27.330: INFO: (7) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.616733ms)
Feb 13 22:01:27.332: INFO: (8) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.813097ms)
Feb 13 22:01:27.334: INFO: (9) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.634189ms)
Feb 13 22:01:27.336: INFO: (10) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.83257ms)
Feb 13 22:01:27.338: INFO: (11) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.843023ms)
Feb 13 22:01:27.339: INFO: (12) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.763781ms)
Feb 13 22:01:27.342: INFO: (13) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 2.011682ms)
Feb 13 22:01:27.343: INFO: (14) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.652928ms)
Feb 13 22:01:27.345: INFO: (15) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.853168ms)
Feb 13 22:01:27.347: INFO: (16) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.601505ms)
Feb 13 22:01:27.349: INFO: (17) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.83544ms)
Feb 13 22:01:27.350: INFO: (18) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.653592ms)
Feb 13 22:01:27.352: INFO: (19) /api/v1/nodes/alex-300-cp3-vsp1-worker71a62db265/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href... (200; 1.642316ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:01:27.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9wr58" for this suite.
Feb 13 22:01:33.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:33.372: INFO: namespace: e2e-tests-proxy-9wr58, resource: bindings, ignored listing per whitelist
Feb 13 22:01:33.408: INFO: namespace e2e-tests-proxy-9wr58 deletion completed in 6.054225816s

• [SLOW TEST:6.233 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:01:33.409: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rxgf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ece6f7f9-2fda-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ece6f7f9-2fda-11e9-829f-22a36399a92d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:01:37.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rxgf7" for this suite.
Feb 13 22:01:59.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:01:59.605: INFO: namespace: e2e-tests-projected-rxgf7, resource: bindings, ignored listing per whitelist
Feb 13 22:01:59.620: INFO: namespace e2e-tests-projected-rxgf7 deletion completed in 22.045067759s

• [SLOW TEST:26.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:01:59.621: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-rd6fm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:01:59.760: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 13 22:01:59.764: INFO: Number of nodes with available pods: 0
Feb 13 22:01:59.764: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 13 22:01:59.789: INFO: Number of nodes with available pods: 0
Feb 13 22:01:59.789: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:00.790: INFO: Number of nodes with available pods: 0
Feb 13 22:02:00.790: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:01.790: INFO: Number of nodes with available pods: 1
Feb 13 22:02:01.790: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 13 22:02:01.806: INFO: Number of nodes with available pods: 1
Feb 13 22:02:01.806: INFO: Number of running nodes: 0, number of available pods: 1
Feb 13 22:02:02.808: INFO: Number of nodes with available pods: 0
Feb 13 22:02:02.808: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 13 22:02:02.817: INFO: Number of nodes with available pods: 0
Feb 13 22:02:02.817: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:03.820: INFO: Number of nodes with available pods: 0
Feb 13 22:02:03.820: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:04.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:04.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:05.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:05.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:06.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:06.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:07.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:07.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:08.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:08.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:09.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:09.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:10.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:10.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:11.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:11.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:12.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:12.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:13.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:13.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:14.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:14.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:15.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:15.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:16.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:16.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:17.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:17.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:18.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:18.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:19.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:19.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:20.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:20.820: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:21.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:21.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:22.823: INFO: Number of nodes with available pods: 0
Feb 13 22:02:22.823: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:23.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:23.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:24.820: INFO: Number of nodes with available pods: 0
Feb 13 22:02:24.820: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:25.820: INFO: Number of nodes with available pods: 0
Feb 13 22:02:25.820: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:26.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:26.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:27.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:27.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:28.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:28.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:29.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:29.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:30.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:30.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:31.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:31.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:32.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:32.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:33.820: INFO: Number of nodes with available pods: 0
Feb 13 22:02:33.820: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:34.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:34.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:35.819: INFO: Number of nodes with available pods: 0
Feb 13 22:02:35.819: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:36.820: INFO: Number of nodes with available pods: 0
Feb 13 22:02:36.820: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:02:37.820: INFO: Number of nodes with available pods: 1
Feb 13 22:02:37.820: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rd6fm, will wait for the garbage collector to delete the pods
Feb 13 22:02:37.879: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.536035ms
Feb 13 22:02:37.979: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.136981ms
Feb 13 22:03:14.881: INFO: Number of nodes with available pods: 0
Feb 13 22:03:14.882: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 22:03:14.883: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rd6fm/daemonsets","resourceVersion":"1271198"},"items":null}

Feb 13 22:03:14.884: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rd6fm/pods","resourceVersion":"1271198"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:03:14.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rd6fm" for this suite.
Feb 13 22:03:20.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:03:20.940: INFO: namespace: e2e-tests-daemonsets-rd6fm, resource: bindings, ignored listing per whitelist
Feb 13 22:03:20.944: INFO: namespace e2e-tests-daemonsets-rd6fm deletion completed in 6.043534538s

• [SLOW TEST:81.324 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:03:20.944: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-7bt9c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-7bt9c/secret-test-2cfeb78c-2fdb-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:03:21.081: INFO: Waiting up to 5m0s for pod "pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-7bt9c" to be "success or failure"
Feb 13 22:03:21.084: INFO: Pod "pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.421908ms
Feb 13 22:03:23.087: INFO: Pod "pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005945777s
STEP: Saw pod success
Feb 13 22:03:23.088: INFO: Pod "pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:03:23.089: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d container env-test: <nil>
STEP: delete the pod
Feb 13 22:03:23.107: INFO: Waiting for pod pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:03:23.110: INFO: Pod pod-configmaps-2cff16b4-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:03:23.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7bt9c" for this suite.
Feb 13 22:03:29.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:03:29.134: INFO: namespace: e2e-tests-secrets-7bt9c, resource: bindings, ignored listing per whitelist
Feb 13 22:03:29.163: INFO: namespace e2e-tests-secrets-7bt9c deletion completed in 6.050031727s

• [SLOW TEST:8.219 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:03:29.165: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-mgn86
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 13 22:03:33.319: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.319: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.369: INFO: Exec stderr: ""
Feb 13 22:03:33.369: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.369: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.437: INFO: Exec stderr: ""
Feb 13 22:03:33.437: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.437: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.498: INFO: Exec stderr: ""
Feb 13 22:03:33.498: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.498: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.557: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 13 22:03:33.557: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.557: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.616: INFO: Exec stderr: ""
Feb 13 22:03:33.616: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.616: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.676: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 13 22:03:33.676: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.677: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.739: INFO: Exec stderr: ""
Feb 13 22:03:33.739: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.739: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.799: INFO: Exec stderr: ""
Feb 13 22:03:33.799: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.799: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.843: INFO: Exec stderr: ""
Feb 13 22:03:33.843: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mgn86 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:03:33.843: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:03:33.913: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:03:33.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-mgn86" for this suite.
Feb 13 22:04:17.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:17.946: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-mgn86, resource: bindings, ignored listing per whitelist
Feb 13 22:04:17.959: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-mgn86 deletion completed in 44.044135696s

• [SLOW TEST:48.794 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:04:17.960: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-j4m8t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4efb5ee6-2fdb-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:04:18.102: INFO: Waiting up to 5m0s for pod "pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-j4m8t" to be "success or failure"
Feb 13 22:04:18.106: INFO: Pod "pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26925ms
Feb 13 22:04:20.107: INFO: Pod "pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004770408s
STEP: Saw pod success
Feb 13 22:04:20.107: INFO: Pod "pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:04:20.109: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:04:20.124: INFO: Waiting for pod pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:04:20.125: INFO: Pod pod-configmaps-4efbc069-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:04:20.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j4m8t" for this suite.
Feb 13 22:04:26.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:26.158: INFO: namespace: e2e-tests-configmap-j4m8t, resource: bindings, ignored listing per whitelist
Feb 13 22:04:26.171: INFO: namespace e2e-tests-configmap-j4m8t deletion completed in 6.043829183s

• [SLOW TEST:8.211 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:04:26.171: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h86j4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-53e01552-2fdb-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:04:26.311: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-h86j4" to be "success or failure"
Feb 13 22:04:26.314: INFO: Pod "pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.406757ms
Feb 13 22:04:28.316: INFO: Pod "pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005470717s
STEP: Saw pod success
Feb 13 22:04:28.316: INFO: Pod "pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:04:28.318: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:04:28.334: INFO: Waiting for pod pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:04:28.337: INFO: Pod pod-projected-secrets-53e0711c-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:04:28.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h86j4" for this suite.
Feb 13 22:04:34.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:34.363: INFO: namespace: e2e-tests-projected-h86j4, resource: bindings, ignored listing per whitelist
Feb 13 22:04:34.382: INFO: namespace e2e-tests-projected-h86j4 deletion completed in 6.042429038s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:04:34.383: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qh784
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 13 22:04:34.522: INFO: Waiting up to 5m0s for pod "pod-58c5589c-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-qh784" to be "success or failure"
Feb 13 22:04:34.524: INFO: Pod "pod-58c5589c-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.65021ms
Feb 13 22:04:36.526: INFO: Pod "pod-58c5589c-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004200748s
STEP: Saw pod success
Feb 13 22:04:36.526: INFO: Pod "pod-58c5589c-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:04:36.527: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-58c5589c-2fdb-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:04:36.538: INFO: Waiting for pod pod-58c5589c-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:04:36.539: INFO: Pod pod-58c5589c-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:04:36.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qh784" for this suite.
Feb 13 22:04:42.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:04:42.578: INFO: namespace: e2e-tests-emptydir-qh784, resource: bindings, ignored listing per whitelist
Feb 13 22:04:42.591: INFO: namespace e2e-tests-emptydir-qh784 deletion completed in 6.049273993s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:04:42.591: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vdfkf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 22:04:45.251: INFO: Successfully updated pod "labelsupdate5da9d70c-2fdb-11e9-829f-22a36399a92d"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:04:47.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vdfkf" for this suite.
Feb 13 22:05:09.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:05:09.302: INFO: namespace: e2e-tests-projected-vdfkf, resource: bindings, ignored listing per whitelist
Feb 13 22:05:09.307: INFO: namespace e2e-tests-projected-vdfkf deletion completed in 22.042371062s

• [SLOW TEST:26.716 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:05:09.308: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-bdvvk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:05:09.441: INFO: Creating ReplicaSet my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d
Feb 13 22:05:09.446: INFO: Pod name my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d: Found 0 pods out of 1
Feb 13 22:05:14.447: INFO: Pod name my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d: Found 1 pods out of 1
Feb 13 22:05:14.447: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d" is running
Feb 13 22:05:14.448: INFO: Pod "my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d-mqvs2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:05:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:05:03 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:05:03 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:05:09 +0000 UTC Reason: Message:}])
Feb 13 22:05:14.448: INFO: Trying to dial the pod
Feb 13 22:05:19.454: INFO: Controller my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d: Got expected result from replica 1 [my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d-mqvs2]: "my-hostname-basic-6d962cae-2fdb-11e9-829f-22a36399a92d-mqvs2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:05:19.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-bdvvk" for this suite.
Feb 13 22:05:25.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:05:25.492: INFO: namespace: e2e-tests-replicaset-bdvvk, resource: bindings, ignored listing per whitelist
Feb 13 22:05:25.500: INFO: namespace e2e-tests-replicaset-bdvvk deletion completed in 6.044059551s

• [SLOW TEST:16.192 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:05:25.500: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-sbgwv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-sbgwv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 22:05:25.636: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 22:05:45.684: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.2.71 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sbgwv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:05:45.684: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:05:46.749: INFO: Found all expected endpoints: [netserver-0]
Feb 13 22:05:46.750: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.1.187 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sbgwv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:05:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:05:47.823: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:05:47.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-sbgwv" for this suite.
Feb 13 22:06:09.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:06:09.860: INFO: namespace: e2e-tests-pod-network-test-sbgwv, resource: bindings, ignored listing per whitelist
Feb 13 22:06:09.870: INFO: namespace e2e-tests-pod-network-test-sbgwv deletion completed in 22.044599783s

• [SLOW TEST:44.370 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:06:09.871: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jbs2b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:06:10.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-jbs2b" to be "success or failure"
Feb 13 22:06:10.015: INFO: Pod "downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.327854ms
Feb 13 22:06:12.017: INFO: Pod "downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00628107s
STEP: Saw pod success
Feb 13 22:06:12.017: INFO: Pod "downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:06:12.018: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:06:12.031: INFO: Waiting for pod downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:06:12.032: INFO: Pod downwardapi-volume-91afb8c0-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:06:12.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jbs2b" for this suite.
Feb 13 22:06:18.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:06:18.076: INFO: namespace: e2e-tests-downward-api-jbs2b, resource: bindings, ignored listing per whitelist
Feb 13 22:06:18.085: INFO: namespace e2e-tests-downward-api-jbs2b deletion completed in 6.050983007s

• [SLOW TEST:8.214 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:06:18.085: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-cf9dx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 13 22:06:22.245: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 22:06:22.248: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 22:06:24.248: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 22:06:24.249: INFO: Pod pod-with-prestop-http-hook still exists
Feb 13 22:06:26.248: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 13 22:06:26.250: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:06:26.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-cf9dx" for this suite.
Feb 13 22:06:48.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:06:48.296: INFO: namespace: e2e-tests-container-lifecycle-hook-cf9dx, resource: bindings, ignored listing per whitelist
Feb 13 22:06:48.302: INFO: namespace e2e-tests-container-lifecycle-hook-cf9dx deletion completed in 22.045147311s

• [SLOW TEST:30.217 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:06:48.304: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k6v5t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 22:06:48.460: INFO: Waiting up to 5m0s for pod "downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-k6v5t" to be "success or failure"
Feb 13 22:06:48.463: INFO: Pod "downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646531ms
Feb 13 22:06:50.465: INFO: Pod "downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004720685s
STEP: Saw pod success
Feb 13 22:06:50.465: INFO: Pod "downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:06:50.466: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:06:50.479: INFO: Waiting for pod downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:06:50.480: INFO: Pod downward-api-a89a8222-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:06:50.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k6v5t" for this suite.
Feb 13 22:06:56.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:06:56.505: INFO: namespace: e2e-tests-downward-api-k6v5t, resource: bindings, ignored listing per whitelist
Feb 13 22:06:56.526: INFO: namespace e2e-tests-downward-api-k6v5t deletion completed in 6.043762722s

• [SLOW TEST:8.222 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:06:56.527: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-mzj2n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 22:06:56.668: INFO: PodSpec: initContainers in spec.initContainers
Feb 13 22:07:42.327: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ad7fb0af-2fdb-11e9-829f-22a36399a92d", GenerateName:"", Namespace:"e2e-tests-init-container-mzj2n", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-mzj2n/pods/pod-init-ad7fb0af-2fdb-11e9-829f-22a36399a92d", UID:"ad7ffb69-2fdb-11e9-8578-0050569e397b", ResourceVersion:"1272148", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685692416, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"668097427"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.193/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-lqp9l", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42208b600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lqp9l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lqp9l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-lqp9l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421b89158), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"alex-300-cp3-vsp1-worker71a62db265", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422577800), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421b891d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421b891f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421b891f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685692409, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685692409, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685692409, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685692416, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.100.39", PodIP:"192.168.1.193", StartTime:(*v1.Time)(0xc421807d20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4230c7880)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4230c78f0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://381db675baab9706ee493f6106c9a87a5fb6d69356f36347fd3779990a0ec236"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421807d60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421807d40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:07:42.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mzj2n" for this suite.
Feb 13 22:08:04.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:08:04.368: INFO: namespace: e2e-tests-init-container-mzj2n, resource: bindings, ignored listing per whitelist
Feb 13 22:08:04.390: INFO: namespace e2e-tests-init-container-mzj2n deletion completed in 22.05323516s

• [SLOW TEST:67.864 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:08:04.392: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wvqll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 13 22:08:04.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-wvqll'
Feb 13 22:08:04.908: INFO: stderr: ""
Feb 13 22:08:04.908: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 13 22:08:05.911: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:08:05.911: INFO: Found 0 / 1
Feb 13 22:08:06.909: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:08:06.909: INFO: Found 1 / 1
Feb 13 22:08:06.909: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 13 22:08:06.911: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:08:06.911: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 13 22:08:06.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 patch pod redis-master-6z2x7 --namespace=e2e-tests-kubectl-wvqll -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 13 22:08:06.983: INFO: stderr: ""
Feb 13 22:08:06.983: INFO: stdout: "pod/redis-master-6z2x7 patched\n"
STEP: checking annotations
Feb 13 22:08:06.985: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:08:06.985: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:08:06.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wvqll" for this suite.
Feb 13 22:08:28.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:08:29.029: INFO: namespace: e2e-tests-kubectl-wvqll, resource: bindings, ignored listing per whitelist
Feb 13 22:08:29.042: INFO: namespace e2e-tests-kubectl-wvqll deletion completed in 22.054977614s

• [SLOW TEST:24.651 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:08:29.043: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jpc4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 13 22:08:29.189: INFO: Waiting up to 5m0s for pod "downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-jpc4p" to be "success or failure"
Feb 13 22:08:29.192: INFO: Pod "downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.504631ms
Feb 13 22:08:31.194: INFO: Pod "downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005155884s
STEP: Saw pod success
Feb 13 22:08:31.194: INFO: Pod "downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:08:31.196: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:08:31.214: INFO: Waiting for pod downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:08:31.216: INFO: Pod downward-api-e4a463d6-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:08:31.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jpc4p" for this suite.
Feb 13 22:08:37.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:08:37.253: INFO: namespace: e2e-tests-downward-api-jpc4p, resource: bindings, ignored listing per whitelist
Feb 13 22:08:37.267: INFO: namespace e2e-tests-downward-api-jpc4p deletion completed in 6.049304357s

• [SLOW TEST:8.224 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:08:37.268: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7dzcv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:08:37.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-7dzcv" to be "success or failure"
Feb 13 22:08:37.416: INFO: Pod "downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.244285ms
Feb 13 22:08:39.418: INFO: Pod "downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00703684s
STEP: Saw pod success
Feb 13 22:08:39.418: INFO: Pod "downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:08:39.419: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:08:39.429: INFO: Waiting for pod downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d to disappear
Feb 13 22:08:39.431: INFO: Pod downwardapi-volume-e98ae4ff-2fdb-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:08:39.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7dzcv" for this suite.
Feb 13 22:08:45.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:08:45.472: INFO: namespace: e2e-tests-projected-7dzcv, resource: bindings, ignored listing per whitelist
Feb 13 22:08:45.485: INFO: namespace e2e-tests-projected-7dzcv deletion completed in 6.051312826s

• [SLOW TEST:8.217 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:08:45.485: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-s27kl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 13 22:08:48.137: INFO: Successfully updated pod "pod-update-activedeadlineseconds-ee705026-2fdb-11e9-829f-22a36399a92d"
Feb 13 22:08:48.137: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-ee705026-2fdb-11e9-829f-22a36399a92d" in namespace "e2e-tests-pods-s27kl" to be "terminated due to deadline exceeded"
Feb 13 22:08:48.139: INFO: Pod "pod-update-activedeadlineseconds-ee705026-2fdb-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 1.528349ms
Feb 13 22:08:50.141: INFO: Pod "pod-update-activedeadlineseconds-ee705026-2fdb-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.003344556s
Feb 13 22:08:52.142: INFO: Pod "pod-update-activedeadlineseconds-ee705026-2fdb-11e9-829f-22a36399a92d": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.004891555s
Feb 13 22:08:52.142: INFO: Pod "pod-update-activedeadlineseconds-ee705026-2fdb-11e9-829f-22a36399a92d" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:08:52.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-s27kl" for this suite.
Feb 13 22:08:58.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:08:58.194: INFO: namespace: e2e-tests-pods-s27kl, resource: bindings, ignored listing per whitelist
Feb 13 22:08:58.197: INFO: namespace e2e-tests-pods-s27kl deletion completed in 6.047616565s

• [SLOW TEST:12.712 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:08:58.197: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-kzqxc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:08:58.337: INFO: Creating deployment "test-recreate-deployment"
Feb 13 22:08:58.340: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 13 22:08:58.343: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 13 22:09:00.346: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 13 22:09:00.347: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 13 22:09:00.351: INFO: Updating deployment test-recreate-deployment
Feb 13 22:09:00.351: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 22:09:00.395: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-kzqxc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kzqxc/deployments/test-recreate-deployment,UID:f60513a6-2fdb-11e9-8578-0050569e397b,ResourceVersion:1272473,Generation:2,CreationTimestamp:2019-02-13 22:08:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-13 22:09:00 +0000 UTC 2019-02-13 22:09:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-13 22:09:00 +0000 UTC 2019-02-13 22:08:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 13 22:09:00.401: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-kzqxc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kzqxc/replicasets/test-recreate-deployment-7cf749666b,UID:f73b7fac-2fdb-11e9-8578-0050569e397b,ResourceVersion:1272472,Generation:1,CreationTimestamp:2019-02-13 22:09:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f60513a6-2fdb-11e9-8578-0050569e397b 0xc4220d1ab7 0xc4220d1ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 22:09:00.401: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 13 22:09:00.401: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-kzqxc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kzqxc/replicasets/test-recreate-deployment-79f694ff59,UID:f605d019-2fdb-11e9-8578-0050569e397b,ResourceVersion:1272463,Generation:2,CreationTimestamp:2019-02-13 22:08:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f60513a6-2fdb-11e9-8578-0050569e397b 0xc4220d19f7 0xc4220d19f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 22:09:00.403: INFO: Pod "test-recreate-deployment-7cf749666b-hwncx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-hwncx,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-kzqxc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kzqxc/pods/test-recreate-deployment-7cf749666b-hwncx,UID:f73bb077-2fdb-11e9-8578-0050569e397b,ResourceVersion:1272474,Generation:0,CreationTimestamp:2019-02-13 22:09:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b f73b7fac-2fdb-11e9-8578-0050569e397b 0xc422e98b47 0xc422e98b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2tj9l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2tj9l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2tj9l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e98bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e98bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:08:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:08:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:08:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:09:00 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:,StartTime:2019-02-13 22:08:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:09:00.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kzqxc" for this suite.
Feb 13 22:09:06.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:09:06.455: INFO: namespace: e2e-tests-deployment-kzqxc, resource: bindings, ignored listing per whitelist
Feb 13 22:09:06.457: INFO: namespace e2e-tests-deployment-kzqxc deletion completed in 6.052272342s

• [SLOW TEST:8.259 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:09:06.458: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-4jql5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 13 22:09:10.627: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:10.628: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:12.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:12.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:14.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:14.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:16.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:16.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:18.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:18.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:20.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:20.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:22.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:22.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:24.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:24.630: INFO: Pod pod-with-poststart-http-hook still exists
Feb 13 22:09:26.628: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 13 22:09:26.630: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:09:26.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4jql5" for this suite.
Feb 13 22:09:48.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:09:48.697: INFO: namespace: e2e-tests-container-lifecycle-hook-4jql5, resource: bindings, ignored listing per whitelist
Feb 13 22:09:48.706: INFO: namespace e2e-tests-container-lifecycle-hook-4jql5 deletion completed in 22.073269985s

• [SLOW TEST:42.248 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:09:48.706: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-s7s4h
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1420ff58-2fdc-11e9-829f-22a36399a92d
STEP: Creating secret with name s-test-opt-upd-1420ff90-2fdc-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1420ff58-2fdc-11e9-829f-22a36399a92d
STEP: Updating secret s-test-opt-upd-1420ff90-2fdc-11e9-829f-22a36399a92d
STEP: Creating secret with name s-test-opt-create-1420fff2-2fdc-11e9-829f-22a36399a92d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:11:01.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s7s4h" for this suite.
Feb 13 22:11:23.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:11:23.190: INFO: namespace: e2e-tests-secrets-s7s4h, resource: bindings, ignored listing per whitelist
Feb 13 22:11:23.202: INFO: namespace e2e-tests-secrets-s7s4h deletion completed in 22.071582783s

• [SLOW TEST:94.496 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:11:23.202: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-t67q8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t67q8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 13 22:11:23.369: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 13 22:11:43.412: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.204:8080/dial?request=hostName&protocol=http&host=192.168.2.72&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t67q8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:11:43.412: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:11:43.479: INFO: Waiting for endpoints: map[]
Feb 13 22:11:43.481: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.204:8080/dial?request=hostName&protocol=http&host=192.168.1.203&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-t67q8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 13 22:11:43.481: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
Feb 13 22:11:43.541: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:11:43.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t67q8" for this suite.
Feb 13 22:11:59.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:11:59.574: INFO: namespace: e2e-tests-pod-network-test-t67q8, resource: bindings, ignored listing per whitelist
Feb 13 22:11:59.587: INFO: namespace e2e-tests-pod-network-test-t67q8 deletion completed in 16.042789088s

• [SLOW TEST:36.385 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:11:59.587: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fvz2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-62221a4e-2fdc-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:11:59.728: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-fvz2d" to be "success or failure"
Feb 13 22:11:59.730: INFO: Pod "pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.515386ms
Feb 13 22:12:01.732: INFO: Pod "pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003493508s
STEP: Saw pod success
Feb 13 22:12:01.732: INFO: Pod "pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:12:01.733: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:12:01.745: INFO: Waiting for pod pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d to disappear
Feb 13 22:12:01.746: INFO: Pod pod-projected-secrets-62227896-2fdc-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:12:01.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fvz2d" for this suite.
Feb 13 22:12:07.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:12:07.767: INFO: namespace: e2e-tests-projected-fvz2d, resource: bindings, ignored listing per whitelist
Feb 13 22:12:07.800: INFO: namespace e2e-tests-projected-fvz2d deletion completed in 6.051788402s

• [SLOW TEST:8.212 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:12:07.800: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2xrt4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-nbf7
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 22:12:07.943: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nbf7" in namespace "e2e-tests-subpath-2xrt4" to be "success or failure"
Feb 13 22:12:07.949: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.538401ms
Feb 13 22:12:09.951: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008612531s
Feb 13 22:12:11.954: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 4.01122105s
Feb 13 22:12:13.956: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 6.013446664s
Feb 13 22:12:15.958: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 8.015346289s
Feb 13 22:12:17.960: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 10.017488464s
Feb 13 22:12:19.962: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 12.019243268s
Feb 13 22:12:21.964: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 14.02115025s
Feb 13 22:12:23.966: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 16.022959914s
Feb 13 22:12:25.967: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 18.024349821s
Feb 13 22:12:27.969: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 20.026167081s
Feb 13 22:12:29.971: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Running", Reason="", readiness=false. Elapsed: 22.02822975s
Feb 13 22:12:31.974: INFO: Pod "pod-subpath-test-configmap-nbf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.031185413s
STEP: Saw pod success
Feb 13 22:12:31.974: INFO: Pod "pod-subpath-test-configmap-nbf7" satisfied condition "success or failure"
Feb 13 22:12:31.976: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-subpath-test-configmap-nbf7 container test-container-subpath-configmap-nbf7: <nil>
STEP: delete the pod
Feb 13 22:12:31.993: INFO: Waiting for pod pod-subpath-test-configmap-nbf7 to disappear
Feb 13 22:12:31.994: INFO: Pod pod-subpath-test-configmap-nbf7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nbf7
Feb 13 22:12:31.994: INFO: Deleting pod "pod-subpath-test-configmap-nbf7" in namespace "e2e-tests-subpath-2xrt4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:12:31.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2xrt4" for this suite.
Feb 13 22:12:38.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:12:38.036: INFO: namespace: e2e-tests-subpath-2xrt4, resource: bindings, ignored listing per whitelist
Feb 13 22:12:38.052: INFO: namespace e2e-tests-subpath-2xrt4 deletion completed in 6.053936924s

• [SLOW TEST:30.252 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:12:38.053: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t8pww
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 13 22:12:38.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 cluster-info'
Feb 13 22:12:38.249: INFO: stderr: ""
Feb 13 22:12:38.249: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:12:38.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t8pww" for this suite.
Feb 13 22:12:44.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:12:44.295: INFO: namespace: e2e-tests-kubectl-t8pww, resource: bindings, ignored listing per whitelist
Feb 13 22:12:44.298: INFO: namespace e2e-tests-kubectl-t8pww deletion completed in 6.045729336s

• [SLOW TEST:6.245 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:12:44.298: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-pgn4f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-pgn4f
I0213 22:12:44.434284      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-pgn4f, replica count: 1
I0213 22:12:45.484657      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0213 22:12:46.484796      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 13 22:12:46.600: INFO: Created: latency-svc-mhhgr
Feb 13 22:12:46.604: INFO: Got endpoints: latency-svc-mhhgr [19.810174ms]
Feb 13 22:12:46.622: INFO: Created: latency-svc-sgbm7
Feb 13 22:12:46.624: INFO: Got endpoints: latency-svc-sgbm7 [20.032086ms]
Feb 13 22:12:46.637: INFO: Created: latency-svc-76xbv
Feb 13 22:12:46.637: INFO: Got endpoints: latency-svc-76xbv [31.808644ms]
Feb 13 22:12:46.653: INFO: Created: latency-svc-mgvf7
Feb 13 22:12:46.656: INFO: Got endpoints: latency-svc-mgvf7 [49.61356ms]
Feb 13 22:12:46.666: INFO: Created: latency-svc-4c6rg
Feb 13 22:12:46.670: INFO: Got endpoints: latency-svc-4c6rg [63.556653ms]
Feb 13 22:12:46.680: INFO: Created: latency-svc-6rrkt
Feb 13 22:12:46.682: INFO: Got endpoints: latency-svc-6rrkt [75.217502ms]
Feb 13 22:12:46.696: INFO: Created: latency-svc-tllqd
Feb 13 22:12:46.704: INFO: Got endpoints: latency-svc-tllqd [97.292755ms]
Feb 13 22:12:46.715: INFO: Created: latency-svc-mptmg
Feb 13 22:12:46.715: INFO: Got endpoints: latency-svc-mptmg [108.644145ms]
Feb 13 22:12:46.727: INFO: Created: latency-svc-4hk98
Feb 13 22:12:46.727: INFO: Got endpoints: latency-svc-4hk98 [120.330422ms]
Feb 13 22:12:46.734: INFO: Created: latency-svc-vv22w
Feb 13 22:12:46.739: INFO: Got endpoints: latency-svc-vv22w [132.045259ms]
Feb 13 22:12:46.820: INFO: Created: latency-svc-676jf
Feb 13 22:12:46.820: INFO: Got endpoints: latency-svc-676jf [213.004054ms]
Feb 13 22:12:46.854: INFO: Created: latency-svc-76qxl
Feb 13 22:12:46.854: INFO: Got endpoints: latency-svc-76qxl [246.784496ms]
Feb 13 22:12:46.865: INFO: Created: latency-svc-7qxfn
Feb 13 22:12:46.868: INFO: Got endpoints: latency-svc-7qxfn [261.436219ms]
Feb 13 22:12:46.869: INFO: Created: latency-svc-6gmq9
Feb 13 22:12:46.871: INFO: Got endpoints: latency-svc-6gmq9 [264.168267ms]
Feb 13 22:12:46.881: INFO: Created: latency-svc-bk8b9
Feb 13 22:12:46.883: INFO: Got endpoints: latency-svc-bk8b9 [276.164648ms]
Feb 13 22:12:46.894: INFO: Created: latency-svc-9ddw6
Feb 13 22:12:46.898: INFO: Got endpoints: latency-svc-9ddw6 [290.902876ms]
Feb 13 22:12:46.912: INFO: Created: latency-svc-dp86t
Feb 13 22:12:46.912: INFO: Got endpoints: latency-svc-dp86t [287.37877ms]
Feb 13 22:12:46.921: INFO: Created: latency-svc-hh8xr
Feb 13 22:12:46.921: INFO: Got endpoints: latency-svc-hh8xr [283.694151ms]
Feb 13 22:12:46.938: INFO: Created: latency-svc-7x2fx
Feb 13 22:12:46.947: INFO: Got endpoints: latency-svc-7x2fx [290.706493ms]
Feb 13 22:12:46.951: INFO: Created: latency-svc-gxm2w
Feb 13 22:12:46.956: INFO: Got endpoints: latency-svc-gxm2w [286.309409ms]
Feb 13 22:12:46.966: INFO: Created: latency-svc-tqk7r
Feb 13 22:12:46.967: INFO: Got endpoints: latency-svc-tqk7r [285.656281ms]
Feb 13 22:12:46.980: INFO: Created: latency-svc-pvb4q
Feb 13 22:12:46.988: INFO: Got endpoints: latency-svc-pvb4q [284.141487ms]
Feb 13 22:12:47.008: INFO: Created: latency-svc-hz5bv
Feb 13 22:12:47.008: INFO: Got endpoints: latency-svc-hz5bv [292.355385ms]
Feb 13 22:12:47.013: INFO: Created: latency-svc-29xff
Feb 13 22:12:47.017: INFO: Got endpoints: latency-svc-29xff [289.683928ms]
Feb 13 22:12:47.029: INFO: Created: latency-svc-l2p9q
Feb 13 22:12:47.031: INFO: Got endpoints: latency-svc-l2p9q [292.358098ms]
Feb 13 22:12:47.045: INFO: Created: latency-svc-9z6pz
Feb 13 22:12:47.045: INFO: Got endpoints: latency-svc-9z6pz [224.802804ms]
Feb 13 22:12:47.056: INFO: Created: latency-svc-bmmd7
Feb 13 22:12:47.057: INFO: Got endpoints: latency-svc-bmmd7 [203.51638ms]
Feb 13 22:12:47.069: INFO: Created: latency-svc-wjjm7
Feb 13 22:12:47.069: INFO: Got endpoints: latency-svc-wjjm7 [201.09525ms]
Feb 13 22:12:47.080: INFO: Created: latency-svc-c7mvf
Feb 13 22:12:47.086: INFO: Got endpoints: latency-svc-c7mvf [214.806808ms]
Feb 13 22:12:47.095: INFO: Created: latency-svc-ccqbq
Feb 13 22:12:47.099: INFO: Got endpoints: latency-svc-ccqbq [216.205825ms]
Feb 13 22:12:47.108: INFO: Created: latency-svc-zfx47
Feb 13 22:12:47.111: INFO: Got endpoints: latency-svc-zfx47 [213.353285ms]
Feb 13 22:12:47.124: INFO: Created: latency-svc-vfxpd
Feb 13 22:12:47.125: INFO: Got endpoints: latency-svc-vfxpd [212.763653ms]
Feb 13 22:12:47.135: INFO: Created: latency-svc-lxd2s
Feb 13 22:12:47.138: INFO: Got endpoints: latency-svc-lxd2s [216.835668ms]
Feb 13 22:12:47.151: INFO: Created: latency-svc-khv6n
Feb 13 22:12:47.159: INFO: Got endpoints: latency-svc-khv6n [212.117638ms]
Feb 13 22:12:47.174: INFO: Created: latency-svc-qd887
Feb 13 22:12:47.174: INFO: Got endpoints: latency-svc-qd887 [217.225349ms]
Feb 13 22:12:47.181: INFO: Created: latency-svc-2mndw
Feb 13 22:12:47.181: INFO: Got endpoints: latency-svc-2mndw [214.055615ms]
Feb 13 22:12:47.196: INFO: Created: latency-svc-fwm5g
Feb 13 22:12:47.196: INFO: Got endpoints: latency-svc-fwm5g [207.576157ms]
Feb 13 22:12:47.201: INFO: Created: latency-svc-bbgsb
Feb 13 22:12:47.202: INFO: Got endpoints: latency-svc-bbgsb [194.564169ms]
Feb 13 22:12:47.209: INFO: Created: latency-svc-qrsgb
Feb 13 22:12:47.216: INFO: Got endpoints: latency-svc-qrsgb [199.246484ms]
Feb 13 22:12:47.223: INFO: Created: latency-svc-z8fjz
Feb 13 22:12:47.226: INFO: Got endpoints: latency-svc-z8fjz [194.860331ms]
Feb 13 22:12:47.239: INFO: Created: latency-svc-ntgwj
Feb 13 22:12:47.240: INFO: Got endpoints: latency-svc-ntgwj [195.250977ms]
Feb 13 22:12:47.255: INFO: Created: latency-svc-2xzv5
Feb 13 22:12:47.255: INFO: Got endpoints: latency-svc-2xzv5 [197.407005ms]
Feb 13 22:12:47.261: INFO: Created: latency-svc-8867s
Feb 13 22:12:47.262: INFO: Got endpoints: latency-svc-8867s [192.865608ms]
Feb 13 22:12:47.283: INFO: Created: latency-svc-kmlbt
Feb 13 22:12:47.290: INFO: Created: latency-svc-sjj95
Feb 13 22:12:47.303: INFO: Created: latency-svc-7ncvn
Feb 13 22:12:47.307: INFO: Got endpoints: latency-svc-kmlbt [221.040753ms]
Feb 13 22:12:47.330: INFO: Created: latency-svc-r6xms
Feb 13 22:12:47.343: INFO: Created: latency-svc-qgfxw
Feb 13 22:12:47.354: INFO: Got endpoints: latency-svc-sjj95 [254.520442ms]
Feb 13 22:12:47.354: INFO: Created: latency-svc-jrn78
Feb 13 22:12:47.364: INFO: Created: latency-svc-vhplx
Feb 13 22:12:47.379: INFO: Created: latency-svc-2tjnr
Feb 13 22:12:47.393: INFO: Created: latency-svc-2trbx
Feb 13 22:12:47.403: INFO: Got endpoints: latency-svc-7ncvn [291.859659ms]
Feb 13 22:12:47.404: INFO: Created: latency-svc-zsq6j
Feb 13 22:12:47.414: INFO: Created: latency-svc-f7cgp
Feb 13 22:12:47.430: INFO: Created: latency-svc-8scsz
Feb 13 22:12:47.436: INFO: Created: latency-svc-c2nqr
Feb 13 22:12:47.445: INFO: Created: latency-svc-h48q7
Feb 13 22:12:47.458: INFO: Created: latency-svc-lgwbt
Feb 13 22:12:47.458: INFO: Got endpoints: latency-svc-r6xms [333.679724ms]
Feb 13 22:12:47.470: INFO: Created: latency-svc-k6hjz
Feb 13 22:12:47.480: INFO: Created: latency-svc-nqrcr
Feb 13 22:12:47.499: INFO: Created: latency-svc-kh8z6
Feb 13 22:12:47.504: INFO: Got endpoints: latency-svc-qgfxw [366.492121ms]
Feb 13 22:12:47.513: INFO: Created: latency-svc-rzrth
Feb 13 22:12:47.519: INFO: Created: latency-svc-lmdbq
Feb 13 22:12:47.552: INFO: Got endpoints: latency-svc-jrn78 [393.134993ms]
Feb 13 22:12:47.564: INFO: Created: latency-svc-rqbp7
Feb 13 22:12:47.606: INFO: Got endpoints: latency-svc-vhplx [432.454357ms]
Feb 13 22:12:47.617: INFO: Created: latency-svc-x2gdp
Feb 13 22:12:47.652: INFO: Got endpoints: latency-svc-2tjnr [469.854057ms]
Feb 13 22:12:47.663: INFO: Created: latency-svc-snrtr
Feb 13 22:12:47.701: INFO: Got endpoints: latency-svc-2trbx [505.56494ms]
Feb 13 22:12:47.716: INFO: Created: latency-svc-sdxlz
Feb 13 22:12:47.752: INFO: Got endpoints: latency-svc-zsq6j [549.321385ms]
Feb 13 22:12:47.763: INFO: Created: latency-svc-trgn7
Feb 13 22:12:47.801: INFO: Got endpoints: latency-svc-f7cgp [584.912141ms]
Feb 13 22:12:47.813: INFO: Created: latency-svc-fbr5m
Feb 13 22:12:47.851: INFO: Got endpoints: latency-svc-8scsz [625.155272ms]
Feb 13 22:12:47.864: INFO: Created: latency-svc-sphwg
Feb 13 22:12:47.902: INFO: Got endpoints: latency-svc-c2nqr [661.959486ms]
Feb 13 22:12:47.915: INFO: Created: latency-svc-vsw5s
Feb 13 22:12:47.952: INFO: Got endpoints: latency-svc-h48q7 [697.694142ms]
Feb 13 22:12:47.966: INFO: Created: latency-svc-mgzh8
Feb 13 22:12:48.002: INFO: Got endpoints: latency-svc-lgwbt [739.641813ms]
Feb 13 22:12:48.025: INFO: Created: latency-svc-2bvvn
Feb 13 22:12:48.054: INFO: Got endpoints: latency-svc-k6hjz [746.472403ms]
Feb 13 22:12:48.070: INFO: Created: latency-svc-d2jhs
Feb 13 22:12:48.102: INFO: Got endpoints: latency-svc-nqrcr [748.051564ms]
Feb 13 22:12:48.118: INFO: Created: latency-svc-tcgvj
Feb 13 22:12:48.152: INFO: Got endpoints: latency-svc-kh8z6 [748.473858ms]
Feb 13 22:12:48.164: INFO: Created: latency-svc-zr8hh
Feb 13 22:12:48.201: INFO: Got endpoints: latency-svc-rzrth [742.63139ms]
Feb 13 22:12:48.215: INFO: Created: latency-svc-zwktn
Feb 13 22:12:48.252: INFO: Got endpoints: latency-svc-lmdbq [747.564813ms]
Feb 13 22:12:48.263: INFO: Created: latency-svc-hk5cw
Feb 13 22:12:48.301: INFO: Got endpoints: latency-svc-rqbp7 [749.229125ms]
Feb 13 22:12:48.314: INFO: Created: latency-svc-xns99
Feb 13 22:12:48.353: INFO: Got endpoints: latency-svc-x2gdp [746.460285ms]
Feb 13 22:12:48.364: INFO: Created: latency-svc-768hr
Feb 13 22:12:48.402: INFO: Got endpoints: latency-svc-snrtr [749.692114ms]
Feb 13 22:12:48.413: INFO: Created: latency-svc-dwskh
Feb 13 22:12:48.453: INFO: Got endpoints: latency-svc-sdxlz [751.484129ms]
Feb 13 22:12:48.470: INFO: Created: latency-svc-x525h
Feb 13 22:12:48.501: INFO: Got endpoints: latency-svc-trgn7 [749.375272ms]
Feb 13 22:12:48.512: INFO: Created: latency-svc-xx67d
Feb 13 22:12:48.552: INFO: Got endpoints: latency-svc-fbr5m [750.666973ms]
Feb 13 22:12:48.569: INFO: Created: latency-svc-g8ch2
Feb 13 22:12:48.601: INFO: Got endpoints: latency-svc-sphwg [749.629558ms]
Feb 13 22:12:48.617: INFO: Created: latency-svc-4s6gb
Feb 13 22:12:48.654: INFO: Got endpoints: latency-svc-vsw5s [751.727246ms]
Feb 13 22:12:48.673: INFO: Created: latency-svc-q6558
Feb 13 22:12:48.701: INFO: Got endpoints: latency-svc-mgzh8 [748.809546ms]
Feb 13 22:12:48.713: INFO: Created: latency-svc-7v4z7
Feb 13 22:12:48.752: INFO: Got endpoints: latency-svc-2bvvn [750.095665ms]
Feb 13 22:12:48.762: INFO: Created: latency-svc-42cbj
Feb 13 22:12:48.802: INFO: Got endpoints: latency-svc-d2jhs [748.740086ms]
Feb 13 22:12:48.815: INFO: Created: latency-svc-f5x9w
Feb 13 22:12:48.852: INFO: Got endpoints: latency-svc-tcgvj [749.628918ms]
Feb 13 22:12:48.863: INFO: Created: latency-svc-zm7r8
Feb 13 22:12:48.907: INFO: Got endpoints: latency-svc-zr8hh [755.687727ms]
Feb 13 22:12:48.919: INFO: Created: latency-svc-jnt4q
Feb 13 22:12:48.951: INFO: Got endpoints: latency-svc-zwktn [750.133792ms]
Feb 13 22:12:48.960: INFO: Created: latency-svc-qkqnv
Feb 13 22:12:49.002: INFO: Got endpoints: latency-svc-hk5cw [750.423017ms]
Feb 13 22:12:49.019: INFO: Created: latency-svc-qz6l9
Feb 13 22:12:49.052: INFO: Got endpoints: latency-svc-xns99 [750.278926ms]
Feb 13 22:12:49.067: INFO: Created: latency-svc-rcqkl
Feb 13 22:12:49.103: INFO: Got endpoints: latency-svc-768hr [750.309242ms]
Feb 13 22:12:49.116: INFO: Created: latency-svc-xj689
Feb 13 22:12:49.153: INFO: Got endpoints: latency-svc-dwskh [751.209853ms]
Feb 13 22:12:49.165: INFO: Created: latency-svc-dtzfm
Feb 13 22:12:49.206: INFO: Got endpoints: latency-svc-x525h [752.551262ms]
Feb 13 22:12:49.219: INFO: Created: latency-svc-n2l8h
Feb 13 22:12:49.252: INFO: Got endpoints: latency-svc-xx67d [750.328813ms]
Feb 13 22:12:49.266: INFO: Created: latency-svc-4mwv4
Feb 13 22:12:49.301: INFO: Got endpoints: latency-svc-g8ch2 [749.394691ms]
Feb 13 22:12:49.317: INFO: Created: latency-svc-z7xbh
Feb 13 22:12:49.356: INFO: Got endpoints: latency-svc-4s6gb [754.688811ms]
Feb 13 22:12:49.495: INFO: Got endpoints: latency-svc-7v4z7 [793.314033ms]
Feb 13 22:12:49.495: INFO: Got endpoints: latency-svc-q6558 [841.031513ms]
Feb 13 22:12:49.502: INFO: Created: latency-svc-z82sh
Feb 13 22:12:49.502: INFO: Got endpoints: latency-svc-42cbj [749.572954ms]
Feb 13 22:12:49.514: INFO: Created: latency-svc-92nkq
Feb 13 22:12:49.524: INFO: Created: latency-svc-7vnsr
Feb 13 22:12:49.532: INFO: Created: latency-svc-7qzbc
Feb 13 22:12:49.551: INFO: Got endpoints: latency-svc-f5x9w [748.797055ms]
Feb 13 22:12:49.564: INFO: Created: latency-svc-rjntb
Feb 13 22:12:49.602: INFO: Got endpoints: latency-svc-zm7r8 [749.844362ms]
Feb 13 22:12:49.614: INFO: Created: latency-svc-qdnm4
Feb 13 22:12:49.656: INFO: Got endpoints: latency-svc-jnt4q [748.456672ms]
Feb 13 22:12:49.669: INFO: Created: latency-svc-n95vp
Feb 13 22:12:49.702: INFO: Got endpoints: latency-svc-qkqnv [750.80817ms]
Feb 13 22:12:49.715: INFO: Created: latency-svc-s6m2r
Feb 13 22:12:49.751: INFO: Got endpoints: latency-svc-qz6l9 [748.343548ms]
Feb 13 22:12:49.762: INFO: Created: latency-svc-ftfsc
Feb 13 22:12:49.801: INFO: Got endpoints: latency-svc-rcqkl [749.397145ms]
Feb 13 22:12:49.816: INFO: Created: latency-svc-6wz59
Feb 13 22:12:49.852: INFO: Got endpoints: latency-svc-xj689 [748.920686ms]
Feb 13 22:12:49.862: INFO: Created: latency-svc-hvm8z
Feb 13 22:12:49.901: INFO: Got endpoints: latency-svc-dtzfm [747.892698ms]
Feb 13 22:12:49.917: INFO: Created: latency-svc-p6kks
Feb 13 22:12:49.952: INFO: Got endpoints: latency-svc-n2l8h [746.267669ms]
Feb 13 22:12:49.964: INFO: Created: latency-svc-njpgr
Feb 13 22:12:50.001: INFO: Got endpoints: latency-svc-4mwv4 [749.720376ms]
Feb 13 22:12:50.011: INFO: Created: latency-svc-4knlx
Feb 13 22:12:50.052: INFO: Got endpoints: latency-svc-z7xbh [750.470289ms]
Feb 13 22:12:50.061: INFO: Created: latency-svc-f6d4r
Feb 13 22:12:50.106: INFO: Got endpoints: latency-svc-z82sh [749.91448ms]
Feb 13 22:12:50.116: INFO: Created: latency-svc-lpxtp
Feb 13 22:12:50.151: INFO: Got endpoints: latency-svc-92nkq [656.617405ms]
Feb 13 22:12:50.163: INFO: Created: latency-svc-hgmxq
Feb 13 22:12:50.203: INFO: Got endpoints: latency-svc-7vnsr [708.436591ms]
Feb 13 22:12:50.214: INFO: Created: latency-svc-8vl44
Feb 13 22:12:50.251: INFO: Got endpoints: latency-svc-7qzbc [748.947694ms]
Feb 13 22:12:50.263: INFO: Created: latency-svc-zq5nk
Feb 13 22:12:50.304: INFO: Got endpoints: latency-svc-rjntb [752.552955ms]
Feb 13 22:12:50.314: INFO: Created: latency-svc-gdfdr
Feb 13 22:12:50.353: INFO: Got endpoints: latency-svc-qdnm4 [751.099708ms]
Feb 13 22:12:50.364: INFO: Created: latency-svc-xtlhd
Feb 13 22:12:50.404: INFO: Got endpoints: latency-svc-n95vp [747.726139ms]
Feb 13 22:12:50.420: INFO: Created: latency-svc-cxsnl
Feb 13 22:12:50.462: INFO: Got endpoints: latency-svc-s6m2r [759.902104ms]
Feb 13 22:12:50.476: INFO: Created: latency-svc-7mv4f
Feb 13 22:12:50.501: INFO: Got endpoints: latency-svc-ftfsc [749.77967ms]
Feb 13 22:12:50.512: INFO: Created: latency-svc-q5zh8
Feb 13 22:12:50.552: INFO: Got endpoints: latency-svc-6wz59 [750.65852ms]
Feb 13 22:12:50.571: INFO: Created: latency-svc-5phv7
Feb 13 22:12:50.602: INFO: Got endpoints: latency-svc-hvm8z [750.068167ms]
Feb 13 22:12:50.614: INFO: Created: latency-svc-8v52j
Feb 13 22:12:50.652: INFO: Got endpoints: latency-svc-p6kks [750.860433ms]
Feb 13 22:12:50.668: INFO: Created: latency-svc-gw2vz
Feb 13 22:12:50.702: INFO: Got endpoints: latency-svc-njpgr [750.113188ms]
Feb 13 22:12:50.714: INFO: Created: latency-svc-7rzfh
Feb 13 22:12:50.751: INFO: Got endpoints: latency-svc-4knlx [749.912361ms]
Feb 13 22:12:50.765: INFO: Created: latency-svc-q7bqz
Feb 13 22:12:50.803: INFO: Got endpoints: latency-svc-f6d4r [751.522337ms]
Feb 13 22:12:50.822: INFO: Created: latency-svc-t8zb4
Feb 13 22:12:50.851: INFO: Got endpoints: latency-svc-lpxtp [745.534556ms]
Feb 13 22:12:50.862: INFO: Created: latency-svc-2cjnx
Feb 13 22:12:50.903: INFO: Got endpoints: latency-svc-hgmxq [751.334714ms]
Feb 13 22:12:50.917: INFO: Created: latency-svc-qtgcb
Feb 13 22:12:50.952: INFO: Got endpoints: latency-svc-8vl44 [748.475339ms]
Feb 13 22:12:50.961: INFO: Created: latency-svc-wb9jc
Feb 13 22:12:51.000: INFO: Got endpoints: latency-svc-zq5nk [749.500439ms]
Feb 13 22:12:51.015: INFO: Created: latency-svc-qn7rq
Feb 13 22:12:51.052: INFO: Got endpoints: latency-svc-gdfdr [747.622468ms]
Feb 13 22:12:51.063: INFO: Created: latency-svc-fl24l
Feb 13 22:12:51.106: INFO: Got endpoints: latency-svc-xtlhd [753.309332ms]
Feb 13 22:12:51.115: INFO: Created: latency-svc-kzf9s
Feb 13 22:12:51.152: INFO: Got endpoints: latency-svc-cxsnl [748.133418ms]
Feb 13 22:12:51.167: INFO: Created: latency-svc-q6j9g
Feb 13 22:12:51.203: INFO: Got endpoints: latency-svc-7mv4f [741.314426ms]
Feb 13 22:12:51.218: INFO: Created: latency-svc-fj9vb
Feb 13 22:12:51.251: INFO: Got endpoints: latency-svc-q5zh8 [750.516453ms]
Feb 13 22:12:51.261: INFO: Created: latency-svc-dnzss
Feb 13 22:12:51.304: INFO: Got endpoints: latency-svc-5phv7 [752.49343ms]
Feb 13 22:12:51.324: INFO: Created: latency-svc-582g2
Feb 13 22:12:51.350: INFO: Got endpoints: latency-svc-8v52j [747.874463ms]
Feb 13 22:12:51.362: INFO: Created: latency-svc-ncnvv
Feb 13 22:12:51.401: INFO: Got endpoints: latency-svc-gw2vz [749.201042ms]
Feb 13 22:12:51.420: INFO: Created: latency-svc-lstpt
Feb 13 22:12:51.453: INFO: Got endpoints: latency-svc-7rzfh [751.008219ms]
Feb 13 22:12:51.465: INFO: Created: latency-svc-2tr2k
Feb 13 22:12:51.504: INFO: Got endpoints: latency-svc-q7bqz [752.661699ms]
Feb 13 22:12:51.522: INFO: Created: latency-svc-5vsxw
Feb 13 22:12:51.551: INFO: Got endpoints: latency-svc-t8zb4 [747.831801ms]
Feb 13 22:12:51.564: INFO: Created: latency-svc-zpnfv
Feb 13 22:12:51.602: INFO: Got endpoints: latency-svc-2cjnx [750.708026ms]
Feb 13 22:12:51.616: INFO: Created: latency-svc-4gr89
Feb 13 22:12:51.652: INFO: Got endpoints: latency-svc-qtgcb [749.517451ms]
Feb 13 22:12:51.665: INFO: Created: latency-svc-w48w6
Feb 13 22:12:51.702: INFO: Got endpoints: latency-svc-wb9jc [750.286285ms]
Feb 13 22:12:51.712: INFO: Created: latency-svc-gpx49
Feb 13 22:12:51.751: INFO: Got endpoints: latency-svc-qn7rq [750.80643ms]
Feb 13 22:12:51.767: INFO: Created: latency-svc-bjqlb
Feb 13 22:12:51.802: INFO: Got endpoints: latency-svc-fl24l [749.97705ms]
Feb 13 22:12:51.815: INFO: Created: latency-svc-7qzvq
Feb 13 22:12:51.857: INFO: Got endpoints: latency-svc-kzf9s [750.874308ms]
Feb 13 22:12:51.869: INFO: Created: latency-svc-lnwgm
Feb 13 22:12:51.908: INFO: Got endpoints: latency-svc-q6j9g [755.702468ms]
Feb 13 22:12:51.920: INFO: Created: latency-svc-zgbqv
Feb 13 22:12:51.951: INFO: Got endpoints: latency-svc-fj9vb [747.422912ms]
Feb 13 22:12:51.967: INFO: Created: latency-svc-xkrzz
Feb 13 22:12:52.002: INFO: Got endpoints: latency-svc-dnzss [750.645883ms]
Feb 13 22:12:52.015: INFO: Created: latency-svc-8r72f
Feb 13 22:12:52.052: INFO: Got endpoints: latency-svc-582g2 [747.122261ms]
Feb 13 22:12:52.063: INFO: Created: latency-svc-nl7t5
Feb 13 22:12:52.102: INFO: Got endpoints: latency-svc-ncnvv [752.168621ms]
Feb 13 22:12:52.112: INFO: Created: latency-svc-2gqhf
Feb 13 22:12:52.150: INFO: Got endpoints: latency-svc-lstpt [748.812629ms]
Feb 13 22:12:52.163: INFO: Created: latency-svc-spbkn
Feb 13 22:12:52.201: INFO: Got endpoints: latency-svc-2tr2k [748.007502ms]
Feb 13 22:12:52.214: INFO: Created: latency-svc-g7dhr
Feb 13 22:12:52.252: INFO: Got endpoints: latency-svc-5vsxw [747.9502ms]
Feb 13 22:12:52.269: INFO: Created: latency-svc-w98j4
Feb 13 22:12:52.302: INFO: Got endpoints: latency-svc-zpnfv [751.19202ms]
Feb 13 22:12:52.316: INFO: Created: latency-svc-t8hcn
Feb 13 22:12:52.354: INFO: Got endpoints: latency-svc-4gr89 [752.403668ms]
Feb 13 22:12:52.384: INFO: Created: latency-svc-9fk46
Feb 13 22:12:52.403: INFO: Got endpoints: latency-svc-w48w6 [750.720772ms]
Feb 13 22:12:52.416: INFO: Created: latency-svc-zncdn
Feb 13 22:12:52.452: INFO: Got endpoints: latency-svc-gpx49 [749.871535ms]
Feb 13 22:12:52.465: INFO: Created: latency-svc-jtvsc
Feb 13 22:12:52.503: INFO: Got endpoints: latency-svc-bjqlb [751.814884ms]
Feb 13 22:12:52.517: INFO: Created: latency-svc-7ffbz
Feb 13 22:12:52.552: INFO: Got endpoints: latency-svc-7qzvq [750.154774ms]
Feb 13 22:12:52.564: INFO: Created: latency-svc-6jdgf
Feb 13 22:12:52.604: INFO: Got endpoints: latency-svc-lnwgm [746.626267ms]
Feb 13 22:12:52.620: INFO: Created: latency-svc-8vxc6
Feb 13 22:12:52.654: INFO: Got endpoints: latency-svc-zgbqv [746.008126ms]
Feb 13 22:12:52.667: INFO: Created: latency-svc-shmh9
Feb 13 22:12:52.703: INFO: Got endpoints: latency-svc-xkrzz [752.409088ms]
Feb 13 22:12:52.719: INFO: Created: latency-svc-wnx2x
Feb 13 22:12:52.753: INFO: Got endpoints: latency-svc-8r72f [751.33853ms]
Feb 13 22:12:52.769: INFO: Created: latency-svc-qlxwt
Feb 13 22:12:52.804: INFO: Got endpoints: latency-svc-nl7t5 [752.234096ms]
Feb 13 22:12:52.825: INFO: Created: latency-svc-k5v8q
Feb 13 22:12:52.852: INFO: Got endpoints: latency-svc-2gqhf [749.498041ms]
Feb 13 22:12:52.865: INFO: Created: latency-svc-rz4jw
Feb 13 22:12:52.902: INFO: Got endpoints: latency-svc-spbkn [751.388872ms]
Feb 13 22:12:52.917: INFO: Created: latency-svc-gj4jr
Feb 13 22:12:52.953: INFO: Got endpoints: latency-svc-g7dhr [751.763487ms]
Feb 13 22:12:52.965: INFO: Created: latency-svc-t7wpl
Feb 13 22:12:53.001: INFO: Got endpoints: latency-svc-w98j4 [749.293603ms]
Feb 13 22:12:53.016: INFO: Created: latency-svc-mrnq8
Feb 13 22:12:53.054: INFO: Got endpoints: latency-svc-t8hcn [751.772372ms]
Feb 13 22:12:53.088: INFO: Created: latency-svc-prpqk
Feb 13 22:12:53.105: INFO: Got endpoints: latency-svc-9fk46 [750.774054ms]
Feb 13 22:12:53.120: INFO: Created: latency-svc-jsttj
Feb 13 22:12:53.165: INFO: Got endpoints: latency-svc-zncdn [762.046274ms]
Feb 13 22:12:53.186: INFO: Created: latency-svc-z2g4p
Feb 13 22:12:53.205: INFO: Got endpoints: latency-svc-jtvsc [753.259622ms]
Feb 13 22:12:53.222: INFO: Created: latency-svc-jwgm2
Feb 13 22:12:53.253: INFO: Got endpoints: latency-svc-7ffbz [750.159918ms]
Feb 13 22:12:53.287: INFO: Created: latency-svc-rd8nf
Feb 13 22:12:53.303: INFO: Got endpoints: latency-svc-6jdgf [751.300714ms]
Feb 13 22:12:53.328: INFO: Created: latency-svc-nwlzb
Feb 13 22:12:53.351: INFO: Got endpoints: latency-svc-8vxc6 [747.115741ms]
Feb 13 22:12:53.394: INFO: Created: latency-svc-5bqv6
Feb 13 22:12:53.403: INFO: Got endpoints: latency-svc-shmh9 [749.726425ms]
Feb 13 22:12:53.419: INFO: Created: latency-svc-4vwhn
Feb 13 22:12:53.455: INFO: Got endpoints: latency-svc-wnx2x [751.989742ms]
Feb 13 22:12:53.471: INFO: Created: latency-svc-x68gb
Feb 13 22:12:53.503: INFO: Got endpoints: latency-svc-qlxwt [749.789996ms]
Feb 13 22:12:53.518: INFO: Created: latency-svc-4rfwk
Feb 13 22:12:53.554: INFO: Got endpoints: latency-svc-k5v8q [749.589987ms]
Feb 13 22:12:53.569: INFO: Created: latency-svc-dd5tc
Feb 13 22:12:53.603: INFO: Got endpoints: latency-svc-rz4jw [751.411543ms]
Feb 13 22:12:53.618: INFO: Created: latency-svc-kf2ck
Feb 13 22:12:53.653: INFO: Got endpoints: latency-svc-gj4jr [750.654123ms]
Feb 13 22:12:53.665: INFO: Created: latency-svc-l8799
Feb 13 22:12:53.703: INFO: Got endpoints: latency-svc-t7wpl [750.043258ms]
Feb 13 22:12:53.718: INFO: Created: latency-svc-p89gz
Feb 13 22:12:53.754: INFO: Got endpoints: latency-svc-mrnq8 [752.361482ms]
Feb 13 22:12:53.852: INFO: Got endpoints: latency-svc-prpqk [797.029613ms]
Feb 13 22:12:53.905: INFO: Got endpoints: latency-svc-jsttj [799.792138ms]
Feb 13 22:12:53.924: INFO: Got endpoints: latency-svc-z2g4p [758.366691ms]
Feb 13 22:12:53.925: INFO: Created: latency-svc-gk5bx
Feb 13 22:12:53.942: INFO: Created: latency-svc-tkw2r
Feb 13 22:12:53.957: INFO: Created: latency-svc-d58d4
Feb 13 22:12:53.957: INFO: Got endpoints: latency-svc-jwgm2 [752.058087ms]
Feb 13 22:12:53.973: INFO: Created: latency-svc-6xpwj
Feb 13 22:12:53.985: INFO: Created: latency-svc-sdsdp
Feb 13 22:12:54.018: INFO: Got endpoints: latency-svc-rd8nf [764.770982ms]
Feb 13 22:12:54.055: INFO: Created: latency-svc-fp7p8
Feb 13 22:12:54.059: INFO: Got endpoints: latency-svc-nwlzb [755.805591ms]
Feb 13 22:12:54.077: INFO: Created: latency-svc-t7kgn
Feb 13 22:12:54.106: INFO: Got endpoints: latency-svc-5bqv6 [754.17852ms]
Feb 13 22:12:54.128: INFO: Created: latency-svc-h59mn
Feb 13 22:12:54.152: INFO: Got endpoints: latency-svc-4vwhn [748.12686ms]
Feb 13 22:12:54.168: INFO: Created: latency-svc-7bn72
Feb 13 22:12:54.202: INFO: Got endpoints: latency-svc-x68gb [746.139944ms]
Feb 13 22:12:54.213: INFO: Created: latency-svc-9ghnb
Feb 13 22:12:54.252: INFO: Got endpoints: latency-svc-4rfwk [748.899604ms]
Feb 13 22:12:54.269: INFO: Created: latency-svc-zjmst
Feb 13 22:12:54.303: INFO: Got endpoints: latency-svc-dd5tc [748.569372ms]
Feb 13 22:12:54.320: INFO: Created: latency-svc-dct9d
Feb 13 22:12:54.352: INFO: Got endpoints: latency-svc-kf2ck [748.953598ms]
Feb 13 22:12:54.381: INFO: Created: latency-svc-4k6r5
Feb 13 22:12:54.403: INFO: Got endpoints: latency-svc-l8799 [750.38175ms]
Feb 13 22:12:54.416: INFO: Created: latency-svc-xx28z
Feb 13 22:12:54.453: INFO: Got endpoints: latency-svc-p89gz [749.624156ms]
Feb 13 22:12:54.503: INFO: Got endpoints: latency-svc-gk5bx [748.774702ms]
Feb 13 22:12:54.555: INFO: Got endpoints: latency-svc-tkw2r [703.029697ms]
Feb 13 22:12:54.603: INFO: Got endpoints: latency-svc-d58d4 [697.847709ms]
Feb 13 22:12:54.653: INFO: Got endpoints: latency-svc-6xpwj [728.816753ms]
Feb 13 22:12:54.703: INFO: Got endpoints: latency-svc-sdsdp [745.482015ms]
Feb 13 22:12:54.755: INFO: Got endpoints: latency-svc-fp7p8 [736.713033ms]
Feb 13 22:12:54.804: INFO: Got endpoints: latency-svc-t7kgn [744.295302ms]
Feb 13 22:12:54.853: INFO: Got endpoints: latency-svc-h59mn [746.679909ms]
Feb 13 22:12:54.903: INFO: Got endpoints: latency-svc-7bn72 [750.929731ms]
Feb 13 22:12:54.952: INFO: Got endpoints: latency-svc-9ghnb [749.672985ms]
Feb 13 22:12:55.004: INFO: Got endpoints: latency-svc-zjmst [750.864313ms]
Feb 13 22:12:55.051: INFO: Got endpoints: latency-svc-dct9d [747.901359ms]
Feb 13 22:12:55.103: INFO: Got endpoints: latency-svc-4k6r5 [750.764939ms]
Feb 13 22:12:55.151: INFO: Got endpoints: latency-svc-xx28z [747.677258ms]
Feb 13 22:12:55.151: INFO: Latencies: [20.032086ms 31.808644ms 49.61356ms 63.556653ms 75.217502ms 97.292755ms 108.644145ms 120.330422ms 132.045259ms 192.865608ms 194.564169ms 194.860331ms 195.250977ms 197.407005ms 199.246484ms 201.09525ms 203.51638ms 207.576157ms 212.117638ms 212.763653ms 213.004054ms 213.353285ms 214.055615ms 214.806808ms 216.205825ms 216.835668ms 217.225349ms 221.040753ms 224.802804ms 246.784496ms 254.520442ms 261.436219ms 264.168267ms 276.164648ms 283.694151ms 284.141487ms 285.656281ms 286.309409ms 287.37877ms 289.683928ms 290.706493ms 290.902876ms 291.859659ms 292.355385ms 292.358098ms 333.679724ms 366.492121ms 393.134993ms 432.454357ms 469.854057ms 505.56494ms 549.321385ms 584.912141ms 625.155272ms 656.617405ms 661.959486ms 697.694142ms 697.847709ms 703.029697ms 708.436591ms 728.816753ms 736.713033ms 739.641813ms 741.314426ms 742.63139ms 744.295302ms 745.482015ms 745.534556ms 746.008126ms 746.139944ms 746.267669ms 746.460285ms 746.472403ms 746.626267ms 746.679909ms 747.115741ms 747.122261ms 747.422912ms 747.564813ms 747.622468ms 747.677258ms 747.726139ms 747.831801ms 747.874463ms 747.892698ms 747.901359ms 747.9502ms 748.007502ms 748.051564ms 748.12686ms 748.133418ms 748.343548ms 748.456672ms 748.473858ms 748.475339ms 748.569372ms 748.740086ms 748.774702ms 748.797055ms 748.809546ms 748.812629ms 748.899604ms 748.920686ms 748.947694ms 748.953598ms 749.201042ms 749.229125ms 749.293603ms 749.375272ms 749.394691ms 749.397145ms 749.498041ms 749.500439ms 749.517451ms 749.572954ms 749.589987ms 749.624156ms 749.628918ms 749.629558ms 749.672985ms 749.692114ms 749.720376ms 749.726425ms 749.77967ms 749.789996ms 749.844362ms 749.871535ms 749.912361ms 749.91448ms 749.97705ms 750.043258ms 750.068167ms 750.095665ms 750.113188ms 750.133792ms 750.154774ms 750.159918ms 750.278926ms 750.286285ms 750.309242ms 750.328813ms 750.38175ms 750.423017ms 750.470289ms 750.516453ms 750.645883ms 750.654123ms 750.65852ms 750.666973ms 750.708026ms 750.720772ms 750.764939ms 750.774054ms 750.80643ms 750.80817ms 750.860433ms 750.864313ms 750.874308ms 750.929731ms 751.008219ms 751.099708ms 751.19202ms 751.209853ms 751.300714ms 751.334714ms 751.33853ms 751.388872ms 751.411543ms 751.484129ms 751.522337ms 751.727246ms 751.763487ms 751.772372ms 751.814884ms 751.989742ms 752.058087ms 752.168621ms 752.234096ms 752.361482ms 752.403668ms 752.409088ms 752.49343ms 752.551262ms 752.552955ms 752.661699ms 753.259622ms 753.309332ms 754.17852ms 754.688811ms 755.687727ms 755.702468ms 755.805591ms 758.366691ms 759.902104ms 762.046274ms 764.770982ms 793.314033ms 797.029613ms 799.792138ms 841.031513ms]
Feb 13 22:12:55.151: INFO: 50 %ile: 748.812629ms
Feb 13 22:12:55.151: INFO: 90 %ile: 752.409088ms
Feb 13 22:12:55.151: INFO: 99 %ile: 799.792138ms
Feb 13 22:12:55.151: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:12:55.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-pgn4f" for this suite.
Feb 13 22:13:17.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:17.211: INFO: namespace: e2e-tests-svc-latency-pgn4f, resource: bindings, ignored listing per whitelist
Feb 13 22:13:17.226: INFO: namespace e2e-tests-svc-latency-pgn4f deletion completed in 22.067980469s

• [SLOW TEST:32.929 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:13:17.227: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-cglmm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d
Feb 13 22:13:17.384: INFO: Pod name my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d: Found 0 pods out of 1
Feb 13 22:13:22.390: INFO: Pod name my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d: Found 1 pods out of 1
Feb 13 22:13:22.390: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d" are running
Feb 13 22:13:22.391: INFO: Pod "my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d-6r8np" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:13:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:13:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:13:11 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-13 22:13:17 +0000 UTC Reason: Message:}])
Feb 13 22:13:22.391: INFO: Trying to dial the pod
Feb 13 22:13:27.396: INFO: Controller my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d: Got expected result from replica 1 [my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d-6r8np]: "my-hostname-basic-906bb44e-2fdc-11e9-829f-22a36399a92d-6r8np", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:13:27.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-cglmm" for this suite.
Feb 13 22:13:33.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:33.427: INFO: namespace: e2e-tests-replication-controller-cglmm, resource: bindings, ignored listing per whitelist
Feb 13 22:13:33.447: INFO: namespace e2e-tests-replication-controller-cglmm deletion completed in 6.047907114s

• [SLOW TEST:16.220 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:13:33.447: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-2xs6c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 13 22:13:33.587: INFO: Waiting up to 5m0s for pod "client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d" in namespace "e2e-tests-containers-2xs6c" to be "success or failure"
Feb 13 22:13:33.591: INFO: Pod "client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.98975ms
Feb 13 22:13:35.593: INFO: Pod "client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005883718s
Feb 13 22:13:37.622: INFO: Pod "client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035262074s
STEP: Saw pod success
Feb 13 22:13:37.622: INFO: Pod "client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:13:37.627: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:13:37.639: INFO: Waiting for pod client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d to disappear
Feb 13 22:13:37.640: INFO: Pod client-containers-9a1404d8-2fdc-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:13:37.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2xs6c" for this suite.
Feb 13 22:13:43.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:13:43.685: INFO: namespace: e2e-tests-containers-2xs6c, resource: bindings, ignored listing per whitelist
Feb 13 22:13:43.689: INFO: namespace e2e-tests-containers-2xs6c deletion completed in 6.048092902s

• [SLOW TEST:10.242 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:13:43.691: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-krxzw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a0303cb1-2fdc-11e9-829f-22a36399a92d
STEP: Creating configMap with name cm-test-opt-upd-a0303cde-2fdc-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a0303cb1-2fdc-11e9-829f-22a36399a92d
STEP: Updating configmap cm-test-opt-upd-a0303cde-2fdc-11e9-829f-22a36399a92d
STEP: Creating configMap with name cm-test-opt-create-a0303ced-2fdc-11e9-829f-22a36399a92d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:15:16.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-krxzw" for this suite.
Feb 13 22:15:38.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:38.253: INFO: namespace: e2e-tests-configmap-krxzw, resource: bindings, ignored listing per whitelist
Feb 13 22:15:38.258: INFO: namespace e2e-tests-configmap-krxzw deletion completed in 22.045556154s

• [SLOW TEST:114.568 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:15:38.259: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fzjb9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 13 22:15:38.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 --namespace=e2e-tests-kubectl-fzjb9 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 13 22:15:40.350: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 13 22:15:40.350: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:15:42.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fzjb9" for this suite.
Feb 13 22:15:48.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:48.393: INFO: namespace: e2e-tests-kubectl-fzjb9, resource: bindings, ignored listing per whitelist
Feb 13 22:15:48.414: INFO: namespace e2e-tests-kubectl-fzjb9 deletion completed in 6.059586231s

• [SLOW TEST:10.155 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:15:48.417: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-vrtgz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 13 22:15:48.556: INFO: Waiting up to 5m0s for pod "client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d" in namespace "e2e-tests-containers-vrtgz" to be "success or failure"
Feb 13 22:15:48.559: INFO: Pod "client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.941495ms
Feb 13 22:15:50.561: INFO: Pod "client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00471011s
STEP: Saw pod success
Feb 13 22:15:50.561: INFO: Pod "client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:15:50.563: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:15:50.575: INFO: Waiting for pod client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d to disappear
Feb 13 22:15:50.576: INFO: Pod client-containers-ea86b0fe-2fdc-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:15:50.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vrtgz" for this suite.
Feb 13 22:15:56.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:15:56.604: INFO: namespace: e2e-tests-containers-vrtgz, resource: bindings, ignored listing per whitelist
Feb 13 22:15:56.625: INFO: namespace e2e-tests-containers-vrtgz deletion completed in 6.046297369s

• [SLOW TEST:8.208 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:15:56.625: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-298f2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-298f2.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-298f2.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-298f2.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-298f2.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-298f2.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-298f2.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 13 22:16:22.804: INFO: DNS probes using e2e-tests-dns-298f2/dns-test-ef6b00e2-2fdc-11e9-829f-22a36399a92d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:16:22.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-298f2" for this suite.
Feb 13 22:16:28.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:28.854: INFO: namespace: e2e-tests-dns-298f2, resource: bindings, ignored listing per whitelist
Feb 13 22:16:28.867: INFO: namespace e2e-tests-dns-298f2 deletion completed in 6.050571941s

• [SLOW TEST:32.242 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:16:28.868: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hsbjh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:16:29.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-hsbjh" to be "success or failure"
Feb 13 22:16:29.014: INFO: Pod "downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.829951ms
Feb 13 22:16:31.015: INFO: Pod "downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008473157s
STEP: Saw pod success
Feb 13 22:16:31.015: INFO: Pod "downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:16:31.017: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:16:31.047: INFO: Waiting for pod downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:16:31.049: INFO: Pod downwardapi-volume-02a2f310-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:16:31.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hsbjh" for this suite.
Feb 13 22:16:37.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:37.075: INFO: namespace: e2e-tests-projected-hsbjh, resource: bindings, ignored listing per whitelist
Feb 13 22:16:37.097: INFO: namespace e2e-tests-projected-hsbjh deletion completed in 6.046406394s

• [SLOW TEST:8.229 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:16:37.098: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cwtdm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-078a75cd-2fdd-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:16:37.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-cwtdm" to be "success or failure"
Feb 13 22:16:37.241: INFO: Pod "pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42729ms
Feb 13 22:16:39.243: INFO: Pod "pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006356814s
STEP: Saw pod success
Feb 13 22:16:39.243: INFO: Pod "pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:16:39.244: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:16:39.260: INFO: Waiting for pod pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:16:39.262: INFO: Pod pod-projected-configmaps-078ac701-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:16:39.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cwtdm" for this suite.
Feb 13 22:16:45.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:45.289: INFO: namespace: e2e-tests-projected-cwtdm, resource: bindings, ignored listing per whitelist
Feb 13 22:16:45.307: INFO: namespace e2e-tests-projected-cwtdm deletion completed in 6.04277906s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:16:45.308: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-7w49p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 13 22:16:45.445: INFO: Waiting up to 5m0s for pod "var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-var-expansion-7w49p" to be "success or failure"
Feb 13 22:16:45.448: INFO: Pod "var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.004185ms
Feb 13 22:16:47.450: INFO: Pod "var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004717555s
STEP: Saw pod success
Feb 13 22:16:47.450: INFO: Pod "var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:16:47.451: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:16:47.463: INFO: Waiting for pod var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:16:47.465: INFO: Pod var-expansion-0c6f50fc-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:16:47.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7w49p" for this suite.
Feb 13 22:16:53.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:16:53.501: INFO: namespace: e2e-tests-var-expansion-7w49p, resource: bindings, ignored listing per whitelist
Feb 13 22:16:53.515: INFO: namespace e2e-tests-var-expansion-7w49p deletion completed in 6.047420529s

• [SLOW TEST:8.206 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:16:53.515: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4wn5x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0213 22:17:24.180208      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 22:17:24.180: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:17:24.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4wn5x" for this suite.
Feb 13 22:17:30.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:17:30.221: INFO: namespace: e2e-tests-gc-4wn5x, resource: bindings, ignored listing per whitelist
Feb 13 22:17:30.226: INFO: namespace e2e-tests-gc-4wn5x deletion completed in 6.044538517s

• [SLOW TEST:36.712 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:17:30.228: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lr5cx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 13 22:17:30.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 api-versions'
Feb 13 22:17:30.444: INFO: stderr: ""
Feb 13 22:17:30.444: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:17:30.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lr5cx" for this suite.
Feb 13 22:17:36.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:17:36.483: INFO: namespace: e2e-tests-kubectl-lr5cx, resource: bindings, ignored listing per whitelist
Feb 13 22:17:36.490: INFO: namespace e2e-tests-kubectl-lr5cx deletion completed in 6.043235001s

• [SLOW TEST:6.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:17:36.490: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bbfpw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:17:36.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-bbfpw" to be "success or failure"
Feb 13 22:17:36.632: INFO: Pod "downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.044451ms
Feb 13 22:17:38.634: INFO: Pod "downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006678243s
STEP: Saw pod success
Feb 13 22:17:38.634: INFO: Pod "downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:17:38.635: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:17:38.648: INFO: Waiting for pod downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:17:38.649: INFO: Pod downwardapi-volume-2af09d51-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:17:38.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bbfpw" for this suite.
Feb 13 22:17:44.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:17:44.668: INFO: namespace: e2e-tests-projected-bbfpw, resource: bindings, ignored listing per whitelist
Feb 13 22:17:44.694: INFO: namespace e2e-tests-projected-bbfpw deletion completed in 6.041442424s

• [SLOW TEST:8.204 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:17:44.695: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-z6dhs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 13 22:17:44.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:44.973: INFO: stderr: ""
Feb 13 22:17:44.973: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:17:44.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:45.078: INFO: stderr: ""
Feb 13 22:17:45.079: INFO: stdout: "update-demo-nautilus-gns8w update-demo-nautilus-w6ks9 "
Feb 13 22:17:45.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-gns8w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:45.138: INFO: stderr: ""
Feb 13 22:17:45.138: INFO: stdout: ""
Feb 13 22:17:45.138: INFO: update-demo-nautilus-gns8w is created but not running
Feb 13 22:17:50.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:50.214: INFO: stderr: ""
Feb 13 22:17:50.214: INFO: stdout: "update-demo-nautilus-gns8w update-demo-nautilus-w6ks9 "
Feb 13 22:17:50.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-gns8w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:50.269: INFO: stderr: ""
Feb 13 22:17:50.269: INFO: stdout: "true"
Feb 13 22:17:50.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-gns8w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:50.353: INFO: stderr: ""
Feb 13 22:17:50.353: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 22:17:50.353: INFO: validating pod update-demo-nautilus-gns8w
Feb 13 22:17:50.355: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:17:50.355: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:17:50.356: INFO: update-demo-nautilus-gns8w is verified up and running
Feb 13 22:17:50.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-w6ks9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:50.413: INFO: stderr: ""
Feb 13 22:17:50.413: INFO: stdout: "true"
Feb 13 22:17:50.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-w6ks9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:17:50.473: INFO: stderr: ""
Feb 13 22:17:50.473: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 22:17:50.473: INFO: validating pod update-demo-nautilus-w6ks9
Feb 13 22:17:50.476: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:17:50.476: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:17:50.476: INFO: update-demo-nautilus-w6ks9 is verified up and running
STEP: rolling-update to new replication controller
Feb 13 22:17:50.476: INFO: scanned /root for discovery docs: <nil>
Feb 13 22:17:50.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:18:12.841: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 13 22:18:12.841: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:18:12.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:18:13.068: INFO: stderr: ""
Feb 13 22:18:13.068: INFO: stdout: "update-demo-kitten-5q5v8 update-demo-kitten-6smrm "
Feb 13 22:18:13.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-kitten-5q5v8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:18:13.123: INFO: stderr: ""
Feb 13 22:18:13.123: INFO: stdout: "true"
Feb 13 22:18:13.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-kitten-5q5v8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:18:13.183: INFO: stderr: ""
Feb 13 22:18:13.183: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 13 22:18:13.183: INFO: validating pod update-demo-kitten-5q5v8
Feb 13 22:18:13.187: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 13 22:18:13.187: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 13 22:18:13.187: INFO: update-demo-kitten-5q5v8 is verified up and running
Feb 13 22:18:13.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-kitten-6smrm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:18:13.261: INFO: stderr: ""
Feb 13 22:18:13.261: INFO: stdout: "true"
Feb 13 22:18:13.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-kitten-6smrm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z6dhs'
Feb 13 22:18:13.333: INFO: stderr: ""
Feb 13 22:18:13.333: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 13 22:18:13.333: INFO: validating pod update-demo-kitten-6smrm
Feb 13 22:18:13.336: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 13 22:18:13.336: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 13 22:18:13.336: INFO: update-demo-kitten-6smrm is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:18:13.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z6dhs" for this suite.
Feb 13 22:18:35.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:18:35.359: INFO: namespace: e2e-tests-kubectl-z6dhs, resource: bindings, ignored listing per whitelist
Feb 13 22:18:35.385: INFO: namespace e2e-tests-kubectl-z6dhs deletion completed in 22.047291223s

• [SLOW TEST:50.691 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:18:35.386: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lqzkd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lqzkd
Feb 13 22:18:37.529: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lqzkd
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:18:37.531: INFO: Initial restart count of pod liveness-http is 0
Feb 13 22:18:55.550: INFO: Restart count of pod e2e-tests-container-probe-lqzkd/liveness-http is now 1 (18.01899498s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:18:55.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lqzkd" for this suite.
Feb 13 22:19:01.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:01.604: INFO: namespace: e2e-tests-container-probe-lqzkd, resource: bindings, ignored listing per whitelist
Feb 13 22:19:01.605: INFO: namespace e2e-tests-container-probe-lqzkd deletion completed in 6.046160574s

• [SLOW TEST:26.219 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:01.605: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cwsbw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:19:01.744: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-cwsbw" to be "success or failure"
Feb 13 22:19:01.747: INFO: Pod "downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.678072ms
Feb 13 22:19:03.749: INFO: Pod "downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005156778s
STEP: Saw pod success
Feb 13 22:19:03.749: INFO: Pod "downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:19:03.750: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:19:03.761: INFO: Waiting for pod downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:19:03.764: INFO: Pod downwardapi-volume-5dacda3e-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:03.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cwsbw" for this suite.
Feb 13 22:19:09.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:09.784: INFO: namespace: e2e-tests-downward-api-cwsbw, resource: bindings, ignored listing per whitelist
Feb 13 22:19:09.823: INFO: namespace e2e-tests-downward-api-cwsbw deletion completed in 6.055856717s

• [SLOW TEST:8.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:09.824: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-t5mgq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-62939c60-2fdd-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:19:09.971: INFO: Waiting up to 5m0s for pod "pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-t5mgq" to be "success or failure"
Feb 13 22:19:09.973: INFO: Pod "pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04637ms
Feb 13 22:19:11.975: INFO: Pod "pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003898938s
STEP: Saw pod success
Feb 13 22:19:11.975: INFO: Pod "pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:19:11.976: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:11.989: INFO: Waiting for pod pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:19:11.991: INFO: Pod pod-configmaps-6293ee1c-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:11.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t5mgq" for this suite.
Feb 13 22:19:17.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:18.031: INFO: namespace: e2e-tests-configmap-t5mgq, resource: bindings, ignored listing per whitelist
Feb 13 22:19:18.042: INFO: namespace e2e-tests-configmap-t5mgq deletion completed in 6.048279344s

• [SLOW TEST:8.218 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:18.044: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mxks9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-6779b903-2fdd-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:19:18.188: INFO: Waiting up to 5m0s for pod "pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-mxks9" to be "success or failure"
Feb 13 22:19:18.195: INFO: Pod "pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335307ms
Feb 13 22:19:20.196: INFO: Pod "pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007996124s
STEP: Saw pod success
Feb 13 22:19:20.196: INFO: Pod "pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:19:20.198: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:20.210: INFO: Waiting for pod pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:19:20.211: INFO: Pod pod-secrets-677a2286-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:20.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mxks9" for this suite.
Feb 13 22:19:26.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:26.254: INFO: namespace: e2e-tests-secrets-mxks9, resource: bindings, ignored listing per whitelist
Feb 13 22:19:26.260: INFO: namespace e2e-tests-secrets-mxks9 deletion completed in 6.0466928s

• [SLOW TEST:8.216 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:26.260: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-vb5gn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 13 22:19:26.405: INFO: Waiting up to 5m0s for pod "client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-containers-vb5gn" to be "success or failure"
Feb 13 22:19:26.408: INFO: Pod "client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.426308ms
Feb 13 22:19:28.410: INFO: Pod "client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005177152s
STEP: Saw pod success
Feb 13 22:19:28.410: INFO: Pod "client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:19:28.411: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:19:28.424: INFO: Waiting for pod client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:19:28.425: INFO: Pod client-containers-6c5fb454-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:28.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vb5gn" for this suite.
Feb 13 22:19:34.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:34.466: INFO: namespace: e2e-tests-containers-vb5gn, resource: bindings, ignored listing per whitelist
Feb 13 22:19:34.472: INFO: namespace e2e-tests-containers-vb5gn deletion completed in 6.045063856s

• [SLOW TEST:8.213 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:34.473: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sd7lv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-71445d24-2fdd-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:19:34.616: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-sd7lv" to be "success or failure"
Feb 13 22:19:34.622: INFO: Pod "pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.631491ms
Feb 13 22:19:36.624: INFO: Pod "pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007592621s
STEP: Saw pod success
Feb 13 22:19:36.624: INFO: Pod "pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:19:36.626: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:36.643: INFO: Waiting for pod pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:19:36.644: INFO: Pod pod-projected-configmaps-7144ab46-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:36.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sd7lv" for this suite.
Feb 13 22:19:42.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:42.672: INFO: namespace: e2e-tests-projected-sd7lv, resource: bindings, ignored listing per whitelist
Feb 13 22:19:42.697: INFO: namespace e2e-tests-projected-sd7lv deletion completed in 6.051348779s

• [SLOW TEST:8.224 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:42.699: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4fbww
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-762b052d-2fdd-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:19:42.837: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-4fbww" to be "success or failure"
Feb 13 22:19:42.841: INFO: Pod "pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.557449ms
Feb 13 22:19:44.843: INFO: Pod "pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006240797s
STEP: Saw pod success
Feb 13 22:19:44.843: INFO: Pod "pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:19:44.844: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:19:44.855: INFO: Waiting for pod pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d to disappear
Feb 13 22:19:44.857: INFO: Pod pod-projected-configmaps-762b58b8-2fdd-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:44.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4fbww" for this suite.
Feb 13 22:19:50.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:19:50.886: INFO: namespace: e2e-tests-projected-4fbww, resource: bindings, ignored listing per whitelist
Feb 13 22:19:50.909: INFO: namespace e2e-tests-projected-4fbww deletion completed in 6.049769696s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:19:50.910: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9j278
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 22:19:53.572: INFO: Successfully updated pod "labelsupdate7b1147f5-2fdd-11e9-829f-22a36399a92d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:19:55.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9j278" for this suite.
Feb 13 22:20:17.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:20:17.618: INFO: namespace: e2e-tests-downward-api-9j278, resource: bindings, ignored listing per whitelist
Feb 13 22:20:17.634: INFO: namespace e2e-tests-downward-api-9j278 deletion completed in 22.047113644s

• [SLOW TEST:26.724 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:20:17.635: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-hwrg4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hwrg4
Feb 13 22:20:19.779: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hwrg4
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:20:19.780: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:24:20.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hwrg4" for this suite.
Feb 13 22:24:26.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:24:26.068: INFO: namespace: e2e-tests-container-probe-hwrg4, resource: bindings, ignored listing per whitelist
Feb 13 22:24:26.077: INFO: namespace e2e-tests-container-probe-hwrg4 deletion completed in 6.045828452s

• [SLOW TEST:248.442 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:24:26.078: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-5289q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 13 22:24:28.222: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-1f1329e3-2fde-11e9-829f-22a36399a92d,GenerateName:,Namespace:e2e-tests-events-5289q,SelfLink:/api/v1/namespaces/e2e-tests-events-5289q/pods/send-events-1f1329e3-2fde-11e9-829f-22a36399a92d,UID:1f13712e-2fde-11e9-8578-0050569e397b,ResourceVersion:1276530,Generation:0,CreationTimestamp:2019-02-13 22:24:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 210560314,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.230/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6bfws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6bfws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-6bfws true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42324e500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42324e530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:24:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:24:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:24:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:24:26 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.230,StartTime:2019-02-13 22:24:19 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-13 22:24:20 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d58b5a935868f55cc68bd869ad27f02965719c764bbb6c1c4987f8f8baf7a73c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 13 22:24:30.224: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 13 22:24:32.226: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:24:32.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-5289q" for this suite.
Feb 13 22:25:16.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:16.266: INFO: namespace: e2e-tests-events-5289q, resource: bindings, ignored listing per whitelist
Feb 13 22:25:16.283: INFO: namespace e2e-tests-events-5289q deletion completed in 44.049972782s

• [SLOW TEST:50.205 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:25:16.283: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-rxw2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:25:16.428: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 13 22:25:21.430: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 13 22:25:21.430: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 13 22:25:23.432: INFO: Creating deployment "test-rollover-deployment"
Feb 13 22:25:23.436: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 13 22:25:25.440: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 13 22:25:25.443: INFO: Ensure that both replica sets have 1 created replica
Feb 13 22:25:25.446: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 13 22:25:25.450: INFO: Updating deployment test-rollover-deployment
Feb 13 22:25:25.450: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 13 22:25:27.457: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 13 22:25:27.459: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 13 22:25:27.462: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 22:25:27.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693526, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 22:25:29.465: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 22:25:29.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693526, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 22:25:31.465: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 22:25:31.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693526, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 22:25:33.464: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 22:25:33.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693526, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 22:25:35.465: INFO: all replica sets need to contain the pod-template-hash label
Feb 13 22:25:35.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693526, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685693523, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 13 22:25:37.465: INFO: 
Feb 13 22:25:37.465: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 22:25:37.469: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-rxw2p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rxw2p/deployments/test-rollover-deployment,UID:412e951b-2fde-11e9-8578-0050569e397b,ResourceVersion:1276744,Generation:2,CreationTimestamp:2019-02-13 22:25:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-13 22:25:23 +0000 UTC 2019-02-13 22:25:23 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-13 22:25:36 +0000 UTC 2019-02-13 22:25:23 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 22:25:37.470: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-rxw2p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rxw2p/replicasets/test-rollover-deployment-5b76ff8c4,UID:426278d9-2fde-11e9-8578-0050569e397b,ResourceVersion:1276735,Generation:2,CreationTimestamp:2019-02-13 22:25:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 412e951b-2fde-11e9-8578-0050569e397b 0xc420a7dd37 0xc420a7dd38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 13 22:25:37.470: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 13 22:25:37.470: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-rxw2p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rxw2p/replicasets/test-rollover-controller,UID:3d011955-2fde-11e9-8578-0050569e397b,ResourceVersion:1276743,Generation:2,CreationTimestamp:2019-02-13 22:25:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 412e951b-2fde-11e9-8578-0050569e397b 0xc420a7dabe 0xc420a7dabf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 22:25:37.470: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-rxw2p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rxw2p/replicasets/test-rollover-deployment-6975f4fb87,UID:412ffb73-2fde-11e9-8578-0050569e397b,ResourceVersion:1276703,Generation:2,CreationTimestamp:2019-02-13 22:25:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 412e951b-2fde-11e9-8578-0050569e397b 0xc4204acb47 0xc4204acb48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 13 22:25:37.472: INFO: Pod "test-rollover-deployment-5b76ff8c4-zpwx4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-zpwx4,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-rxw2p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rxw2p/pods/test-rollover-deployment-5b76ff8c4-zpwx4,UID:4265cedf-2fde-11e9-8578-0050569e397b,ResourceVersion:1276714,Generation:0,CreationTimestamp:2019-02-13 22:25:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.233/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 426278d9-2fde-11e9-8578-0050569e397b 0xc4209bd230 0xc4209bd231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zsttw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zsttw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zsttw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4209bd290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4209bd2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:25:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:25:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:25:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:25:25 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.233,StartTime:2019-02-13 22:25:18 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-13 22:25:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1db8ec8277ee0741059ada32fe39592425a0b25449144d38b9953d9b7a98462a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:25:37.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rxw2p" for this suite.
Feb 13 22:25:43.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:43.501: INFO: namespace: e2e-tests-deployment-rxw2p, resource: bindings, ignored listing per whitelist
Feb 13 22:25:43.516: INFO: namespace e2e-tests-deployment-rxw2p deletion completed in 6.042000166s

• [SLOW TEST:27.233 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:25:43.516: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7wncb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4d3b85e7-2fde-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:25:43.662: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-7wncb" to be "success or failure"
Feb 13 22:25:43.668: INFO: Pod "pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.562796ms
Feb 13 22:25:45.675: INFO: Pod "pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013414017s
STEP: Saw pod success
Feb 13 22:25:45.675: INFO: Pod "pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:25:45.677: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:25:45.689: INFO: Waiting for pod pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:25:45.691: INFO: Pod pod-projected-configmaps-4d3bdb03-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:25:45.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7wncb" for this suite.
Feb 13 22:25:51.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:25:51.713: INFO: namespace: e2e-tests-projected-7wncb, resource: bindings, ignored listing per whitelist
Feb 13 22:25:51.747: INFO: namespace e2e-tests-projected-7wncb deletion completed in 6.054233911s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:25:51.747: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5f6d8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:25:51.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-5f6d8" to be "success or failure"
Feb 13 22:25:51.885: INFO: Pod "downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.427189ms
Feb 13 22:25:53.887: INFO: Pod "downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d": Phase="Running", Reason="", readiness=true. Elapsed: 2.004239149s
Feb 13 22:25:55.889: INFO: Pod "downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006295385s
STEP: Saw pod success
Feb 13 22:25:55.889: INFO: Pod "downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:25:55.890: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:25:55.903: INFO: Waiting for pod downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:25:55.906: INFO: Pod downwardapi-volume-52233234-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:25:55.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5f6d8" for this suite.
Feb 13 22:26:01.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:01.923: INFO: namespace: e2e-tests-downward-api-5f6d8, resource: bindings, ignored listing per whitelist
Feb 13 22:26:01.959: INFO: namespace e2e-tests-downward-api-5f6d8 deletion completed in 6.050776885s

• [SLOW TEST:10.212 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:26:01.960: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rsc6q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 22:26:02.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-rsc6q'
Feb 13 22:26:02.183: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 13 22:26:02.183: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 13 22:26:02.200: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-gp84v]
Feb 13 22:26:02.200: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-gp84v" in namespace "e2e-tests-kubectl-rsc6q" to be "running and ready"
Feb 13 22:26:02.206: INFO: Pod "e2e-test-nginx-rc-gp84v": Phase="Pending", Reason="", readiness=false. Elapsed: 5.928689ms
Feb 13 22:26:04.208: INFO: Pod "e2e-test-nginx-rc-gp84v": Phase="Running", Reason="", readiness=true. Elapsed: 2.007993263s
Feb 13 22:26:04.208: INFO: Pod "e2e-test-nginx-rc-gp84v" satisfied condition "running and ready"
Feb 13 22:26:04.209: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-gp84v]
Feb 13 22:26:04.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rsc6q'
Feb 13 22:26:04.286: INFO: stderr: ""
Feb 13 22:26:04.286: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb 13 22:26:04.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rsc6q'
Feb 13 22:26:04.358: INFO: stderr: ""
Feb 13 22:26:04.358: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:26:04.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rsc6q" for this suite.
Feb 13 22:26:10.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:10.401: INFO: namespace: e2e-tests-kubectl-rsc6q, resource: bindings, ignored listing per whitelist
Feb 13 22:26:10.408: INFO: namespace e2e-tests-kubectl-rsc6q deletion completed in 6.043880801s

• [SLOW TEST:8.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:26:10.409: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-z5ct7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 13 22:26:10.545: INFO: Waiting up to 5m0s for pod "pod-5d42b948-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-z5ct7" to be "success or failure"
Feb 13 22:26:10.550: INFO: Pod "pod-5d42b948-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.150608ms
Feb 13 22:26:12.552: INFO: Pod "pod-5d42b948-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00699447s
STEP: Saw pod success
Feb 13 22:26:12.552: INFO: Pod "pod-5d42b948-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:26:12.553: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-5d42b948-2fde-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:26:12.567: INFO: Waiting for pod pod-5d42b948-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:26:12.568: INFO: Pod pod-5d42b948-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:26:12.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z5ct7" for this suite.
Feb 13 22:26:18.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:18.605: INFO: namespace: e2e-tests-emptydir-z5ct7, resource: bindings, ignored listing per whitelist
Feb 13 22:26:18.622: INFO: namespace e2e-tests-emptydir-z5ct7 deletion completed in 6.050365491s

• [SLOW TEST:8.213 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:26:18.622: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-n7p6k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:26:18.766: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-downward-api-n7p6k" to be "success or failure"
Feb 13 22:26:18.774: INFO: Pod "downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.771129ms
Feb 13 22:26:20.776: INFO: Pod "downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009726558s
STEP: Saw pod success
Feb 13 22:26:20.776: INFO: Pod "downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:26:20.777: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:26:20.792: INFO: Waiting for pod downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:26:20.794: INFO: Pod downwardapi-volume-6228eccf-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:26:20.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n7p6k" for this suite.
Feb 13 22:26:26.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:26.820: INFO: namespace: e2e-tests-downward-api-n7p6k, resource: bindings, ignored listing per whitelist
Feb 13 22:26:26.841: INFO: namespace e2e-tests-downward-api-n7p6k deletion completed in 6.044757625s

• [SLOW TEST:8.219 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:26:26.841: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j6l9v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-670dde17-2fde-11e9-829f-22a36399a92d
STEP: Creating secret with name secret-projected-all-test-volume-670dde0a-2fde-11e9-829f-22a36399a92d
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 13 22:26:26.980: INFO: Waiting up to 5m0s for pod "projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-j6l9v" to be "success or failure"
Feb 13 22:26:26.985: INFO: Pod "projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.430323ms
Feb 13 22:26:28.986: INFO: Pod "projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00628982s
STEP: Saw pod success
Feb 13 22:26:28.986: INFO: Pod "projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:26:28.988: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 13 22:26:29.006: INFO: Waiting for pod projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:26:29.008: INFO: Pod projected-volume-670ddd16-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:26:29.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j6l9v" for this suite.
Feb 13 22:26:35.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:35.046: INFO: namespace: e2e-tests-projected-j6l9v, resource: bindings, ignored listing per whitelist
Feb 13 22:26:35.055: INFO: namespace e2e-tests-projected-j6l9v deletion completed in 6.04435106s

• [SLOW TEST:8.214 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:26:35.055: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sr4lt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6bf3f9d5-2fde-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:26:35.196: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-sr4lt" to be "success or failure"
Feb 13 22:26:35.203: INFO: Pod "pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.692231ms
Feb 13 22:26:37.205: INFO: Pod "pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009607507s
STEP: Saw pod success
Feb 13 22:26:37.205: INFO: Pod "pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:26:37.207: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:26:37.226: INFO: Waiting for pod pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:26:37.227: INFO: Pod pod-projected-secrets-6bf4707c-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:26:37.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sr4lt" for this suite.
Feb 13 22:26:43.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:26:43.270: INFO: namespace: e2e-tests-projected-sr4lt, resource: bindings, ignored listing per whitelist
Feb 13 22:26:43.279: INFO: namespace e2e-tests-projected-sr4lt deletion completed in 6.049345162s

• [SLOW TEST:8.224 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:26:43.280: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-nlr2r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-46lg
STEP: Creating a pod to test atomic-volume-subpath
Feb 13 22:26:43.424: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-46lg" in namespace "e2e-tests-subpath-nlr2r" to be "success or failure"
Feb 13 22:26:43.429: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.939008ms
Feb 13 22:26:45.433: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008713069s
Feb 13 22:26:47.435: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 4.010793575s
Feb 13 22:26:49.437: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 6.012556458s
Feb 13 22:26:51.439: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 8.014523726s
Feb 13 22:26:53.441: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 10.016284656s
Feb 13 22:26:55.443: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 12.018315193s
Feb 13 22:26:57.445: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 14.020334228s
Feb 13 22:26:59.447: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 16.022473052s
Feb 13 22:27:01.448: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 18.024204078s
Feb 13 22:27:03.451: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 20.026668214s
Feb 13 22:27:05.453: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Running", Reason="", readiness=false. Elapsed: 22.028512055s
Feb 13 22:27:07.455: INFO: Pod "pod-subpath-test-downwardapi-46lg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.030259269s
STEP: Saw pod success
Feb 13 22:27:07.455: INFO: Pod "pod-subpath-test-downwardapi-46lg" satisfied condition "success or failure"
Feb 13 22:27:07.456: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-subpath-test-downwardapi-46lg container test-container-subpath-downwardapi-46lg: <nil>
STEP: delete the pod
Feb 13 22:27:07.470: INFO: Waiting for pod pod-subpath-test-downwardapi-46lg to disappear
Feb 13 22:27:07.471: INFO: Pod pod-subpath-test-downwardapi-46lg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-46lg
Feb 13 22:27:07.471: INFO: Deleting pod "pod-subpath-test-downwardapi-46lg" in namespace "e2e-tests-subpath-nlr2r"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:27:07.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nlr2r" for this suite.
Feb 13 22:27:13.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:13.511: INFO: namespace: e2e-tests-subpath-nlr2r, resource: bindings, ignored listing per whitelist
Feb 13 22:27:13.531: INFO: namespace e2e-tests-subpath-nlr2r deletion completed in 6.056909641s

• [SLOW TEST:30.252 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:27:13.532: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5hdhz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-82e2cc1b-2fde-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:27:13.673: INFO: Waiting up to 5m0s for pod "pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-5hdhz" to be "success or failure"
Feb 13 22:27:13.680: INFO: Pod "pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.727039ms
Feb 13 22:27:15.682: INFO: Pod "pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009546984s
STEP: Saw pod success
Feb 13 22:27:15.682: INFO: Pod "pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:27:15.684: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:27:15.698: INFO: Waiting for pod pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:27:15.699: INFO: Pod pod-configmaps-82e32c21-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:27:15.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5hdhz" for this suite.
Feb 13 22:27:21.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:21.738: INFO: namespace: e2e-tests-configmap-5hdhz, resource: bindings, ignored listing per whitelist
Feb 13 22:27:21.744: INFO: namespace e2e-tests-configmap-5hdhz deletion completed in 6.042355902s

• [SLOW TEST:8.212 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:27:21.745: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-7dh5z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7dh5z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7dh5z to expose endpoints map[]
Feb 13 22:27:21.888: INFO: Get endpoints failed (2.337012ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 13 22:27:22.889: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7dh5z exposes endpoints map[] (1.004015252s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7dh5z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7dh5z to expose endpoints map[pod1:[80]]
Feb 13 22:27:24.906: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7dh5z exposes endpoints map[pod1:[80]] (2.012907628s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7dh5z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7dh5z to expose endpoints map[pod1:[80] pod2:[80]]
Feb 13 22:27:26.925: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7dh5z exposes endpoints map[pod2:[80] pod1:[80]] (2.015307301s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7dh5z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7dh5z to expose endpoints map[pod2:[80]]
Feb 13 22:27:26.937: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7dh5z exposes endpoints map[pod2:[80]] (7.407888ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7dh5z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7dh5z to expose endpoints map[]
Feb 13 22:27:26.945: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7dh5z exposes endpoints map[] (4.595907ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:27:26.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7dh5z" for this suite.
Feb 13 22:27:48.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:49.000: INFO: namespace: e2e-tests-services-7dh5z, resource: bindings, ignored listing per whitelist
Feb 13 22:27:49.011: INFO: namespace e2e-tests-services-7dh5z deletion completed in 22.045895255s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.267 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:27:49.012: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-4m2ws
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 13 22:27:49.150: INFO: Waiting up to 5m0s for pod "client-containers-9808b88b-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-containers-4m2ws" to be "success or failure"
Feb 13 22:27:49.151: INFO: Pod "client-containers-9808b88b-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.373209ms
Feb 13 22:27:51.153: INFO: Pod "client-containers-9808b88b-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.002890968s
STEP: Saw pod success
Feb 13 22:27:51.153: INFO: Pod "client-containers-9808b88b-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:27:51.154: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod client-containers-9808b88b-2fde-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:27:51.169: INFO: Waiting for pod client-containers-9808b88b-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:27:51.170: INFO: Pod client-containers-9808b88b-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:27:51.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4m2ws" for this suite.
Feb 13 22:27:57.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:27:57.184: INFO: namespace: e2e-tests-containers-4m2ws, resource: bindings, ignored listing per whitelist
Feb 13 22:27:57.219: INFO: namespace e2e-tests-containers-4m2ws deletion completed in 6.047351999s

• [SLOW TEST:8.208 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:27:57.219: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vrwc7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9cecd246-2fde-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:27:57.359: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-configmap-vrwc7" to be "success or failure"
Feb 13 22:27:57.363: INFO: Pod "pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.917744ms
Feb 13 22:27:59.365: INFO: Pod "pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00587369s
STEP: Saw pod success
Feb 13 22:27:59.365: INFO: Pod "pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:27:59.366: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:27:59.380: INFO: Waiting for pod pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:27:59.381: INFO: Pod pod-configmaps-9ced2d64-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:27:59.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vrwc7" for this suite.
Feb 13 22:28:05.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:05.400: INFO: namespace: e2e-tests-configmap-vrwc7, resource: bindings, ignored listing per whitelist
Feb 13 22:28:05.436: INFO: namespace e2e-tests-configmap-vrwc7 deletion completed in 6.053296332s

• [SLOW TEST:8.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:28:05.437: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-jgnmg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 13 22:28:05.570: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:28:08.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jgnmg" for this suite.
Feb 13 22:28:14.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:14.537: INFO: namespace: e2e-tests-init-container-jgnmg, resource: bindings, ignored listing per whitelist
Feb 13 22:28:14.539: INFO: namespace e2e-tests-init-container-jgnmg deletion completed in 6.050170873s

• [SLOW TEST:9.102 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:28:14.539: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-chzh4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:28:14.679: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 13 22:28:19.681: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 13 22:28:19.681: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 13 22:28:21.704: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-chzh4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-chzh4/deployments/test-cleanup-deployment,UID:aa3c5a43-2fde-11e9-8578-0050569e397b,ResourceVersion:1277551,Generation:1,CreationTimestamp:2019-02-13 22:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-13 22:28:19 +0000 UTC 2019-02-13 22:28:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-13 22:28:21 +0000 UTC 2019-02-13 22:28:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 13 22:28:21.706: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-chzh4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-chzh4/replicasets/test-cleanup-deployment-755f6b95cc,UID:aa3ed030-2fde-11e9-8578-0050569e397b,ResourceVersion:1277542,Generation:1,CreationTimestamp:2019-02-13 22:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment aa3c5a43-2fde-11e9-8578-0050569e397b 0xc42294fac7 0xc42294fac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 13 22:28:21.708: INFO: Pod "test-cleanup-deployment-755f6b95cc-f5d9w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-f5d9w,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-chzh4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-chzh4/pods/test-cleanup-deployment-755f6b95cc-f5d9w,UID:aa3f3366-2fde-11e9-8578-0050569e397b,ResourceVersion:1277541,Generation:0,CreationTimestamp:2019-02-13 22:28:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.249/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc aa3ed030-2fde-11e9-8578-0050569e397b 0xc422970417 0xc422970418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-h8mfs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h8mfs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-h8mfs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:alex-300-cp3-vsp1-worker71a62db265,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422970480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229704a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:28:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:28:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:28:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:28:19 +0000 UTC  }],Message:,Reason:,HostIP:10.10.100.39,PodIP:192.168.1.249,StartTime:2019-02-13 22:28:12 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-13 22:28:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://fd1399d66418ff010ad9e624e1662246c61feb1d09428c6b7a81af898bed5e16}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:28:21.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-chzh4" for this suite.
Feb 13 22:28:27.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:27.734: INFO: namespace: e2e-tests-deployment-chzh4, resource: bindings, ignored listing per whitelist
Feb 13 22:28:27.755: INFO: namespace e2e-tests-deployment-chzh4 deletion completed in 6.044899911s

• [SLOW TEST:13.216 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:28:27.756: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-6kfj9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 13 22:28:27.898: INFO: Waiting up to 5m0s for pod "var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d" in namespace "e2e-tests-var-expansion-6kfj9" to be "success or failure"
Feb 13 22:28:27.900: INFO: Pod "var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.405734ms
Feb 13 22:28:29.902: INFO: Pod "var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004026693s
STEP: Saw pod success
Feb 13 22:28:29.902: INFO: Pod "var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:28:29.903: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d container dapi-container: <nil>
STEP: delete the pod
Feb 13 22:28:29.921: INFO: Waiting for pod var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d to disappear
Feb 13 22:28:29.922: INFO: Pod var-expansion-af20fd79-2fde-11e9-829f-22a36399a92d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:28:29.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6kfj9" for this suite.
Feb 13 22:28:35.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:35.971: INFO: namespace: e2e-tests-var-expansion-6kfj9, resource: bindings, ignored listing per whitelist
Feb 13 22:28:35.984: INFO: namespace e2e-tests-var-expansion-6kfj9 deletion completed in 6.058741138s

• [SLOW TEST:8.228 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:28:35.984: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bktgx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 13 22:28:36.142: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b40a395d-2fde-11e9-8578-0050569e397b", Controller:(*bool)(0xc422804e42), BlockOwnerDeletion:(*bool)(0xc422804e43)}}
Feb 13 22:28:36.145: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b4089d84-2fde-11e9-8578-0050569e397b", Controller:(*bool)(0xc4230ce35a), BlockOwnerDeletion:(*bool)(0xc4230ce35b)}}
Feb 13 22:28:36.149: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b409879f-2fde-11e9-8578-0050569e397b", Controller:(*bool)(0xc422805022), BlockOwnerDeletion:(*bool)(0xc422805023)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:28:41.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bktgx" for this suite.
Feb 13 22:28:47.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:28:47.189: INFO: namespace: e2e-tests-gc-bktgx, resource: bindings, ignored listing per whitelist
Feb 13 22:28:47.197: INFO: namespace e2e-tests-gc-bktgx deletion completed in 6.040439118s

• [SLOW TEST:11.213 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:28:47.197: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-24tmr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-24tmr;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-24tmr.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-24tmr.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-24tmr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 162.114.98.10.in-addr.arpa. PTR)" && echo OK > /results/10.98.114.162_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 162.114.98.10.in-addr.arpa. PTR)" && echo OK > /results/10.98.114.162_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-24tmr;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-24tmr;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-24tmr.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-24tmr.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-24tmr.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-24tmr.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-24tmr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 162.114.98.10.in-addr.arpa. PTR)" && echo OK > /results/10.98.114.162_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 162.114.98.10.in-addr.arpa. PTR)" && echo OK > /results/10.98.114.162_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 13 22:29:01.382: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.384: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.385: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.387: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.389: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.390: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.391: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.392: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.413: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.415: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.416: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.418: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.419: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.420: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.425: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.427: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:01.436: INFO: Lookups using e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-24tmr wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr wheezy_udp@dns-test-service.e2e-tests-dns-24tmr.svc wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-24tmr jessie_tcp@dns-test-service.e2e-tests-dns-24tmr jessie_udp@dns-test-service.e2e-tests-dns-24tmr.svc jessie_tcp@dns-test-service.e2e-tests-dns-24tmr.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc]

Feb 13 22:29:11.379: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.381: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.382: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.386: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.387: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.389: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.390: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.392: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.401: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.403: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.405: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.406: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-24tmr from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.408: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.409: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.411: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.412: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc from pod e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d: the server could not find the requested resource (get pods dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d)
Feb 13 22:29:11.420: INFO: Lookups using e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-24tmr wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr wheezy_udp@dns-test-service.e2e-tests-dns-24tmr.svc wheezy_tcp@dns-test-service.e2e-tests-dns-24tmr.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-24tmr jessie_tcp@dns-test-service.e2e-tests-dns-24tmr jessie_udp@dns-test-service.e2e-tests-dns-24tmr.svc jessie_tcp@dns-test-service.e2e-tests-dns-24tmr.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-24tmr.svc]

Feb 13 22:29:21.421: INFO: DNS probes using e2e-tests-dns-24tmr/dns-test-babb1e9e-2fde-11e9-829f-22a36399a92d succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:29:21.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-24tmr" for this suite.
Feb 13 22:29:27.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:29:27.517: INFO: namespace: e2e-tests-dns-24tmr, resource: bindings, ignored listing per whitelist
Feb 13 22:29:27.519: INFO: namespace e2e-tests-dns-24tmr deletion completed in 6.047401546s

• [SLOW TEST:40.321 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:29:27.519: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-4sf7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 13 22:29:27.658: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 13 22:29:27.662: INFO: Waiting for terminating namespaces to be deleted...
Feb 13 22:29:27.663: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp3-vsp1-worker71a62db265 before test
Feb 13 22:29:27.668: INFO: ccp-efk-elasticsearch-curator-1549933200-h87dw from ccp started at 2019-02-12 00:59:57 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 22:29:27.668: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-13 21:18:28 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 13 22:29:27.668: INFO: kube-proxy-9zq7t from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:29:27.668: INFO: ccp-monitor-prometheus-kube-state-metrics-78dc9f46d4-wsrkg from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container prometheus-kube-state-metrics ready: true, restart count 0
Feb 13 22:29:27.668: INFO: nginx-ingress-controller-zg2sn from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:29:27.668: INFO: ccp-efk-elasticsearch-curator-1549846800-4rsp5 from ccp started at 2019-02-11 00:59:57 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 22:29:27.668: INFO: calico-typha-785658b69-2ddnl from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:29:27.668: INFO: calico-node-hk7rf from kube-system started at 2019-02-05 19:06:38 +0000 UTC (2 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:29:27.668: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:29:27.668: INFO: metallb-speaker-jg54f from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.668: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:29:27.669: INFO: ccp-monitor-prometheus-node-exporter-4nmw9 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:29:27.669: INFO: nginx-ingress-default-backend-765bbc8b9d-j86sx from ccp started at 2019-02-05 19:07:30 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Feb 13 22:29:27.669: INFO: fluentd-es-v2.0.2-sbv67 from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:29:27.669: INFO: sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-nzdld from heptio-sonobuoy started at 2019-02-13 21:18:37 +0000 UTC (2 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 22:29:27.669: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 13 22:29:27.669: INFO: ccp-monitor-prometheus-server-6bddddb9cc-d8k6p from ccp started at 2019-02-05 19:07:34 +0000 UTC (2 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container prometheus-server ready: true, restart count 0
Feb 13 22:29:27.669: INFO: 	Container prometheus-server-configmap-reload ready: true, restart count 0
Feb 13 22:29:27.669: INFO: ccp-efk-elasticsearch-curator-1550019600-r5f2q from ccp started at 2019-02-13 00:59:58 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container elasticsearch-curator ready: false, restart count 0
Feb 13 22:29:27.669: INFO: kubernetes-dashboard-65dc48675f-4cffw from ccp started at 2019-02-05 19:07:32 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.669: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 13 22:29:27.669: INFO: 
Logging pods the kubelet thinks is on node alex-300-cp3-vsp1-workerdf4199ef27 before test
Feb 13 22:29:27.675: INFO: metallb-speaker-nl4pl from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container speaker ready: true, restart count 0
Feb 13 22:29:27.675: INFO: elasticsearch-logging-0 from ccp started at 2019-02-05 19:07:36 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Feb 13 22:29:27.675: INFO: fluentd-es-v2.0.2-dhjg4 from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container fluentd-es ready: true, restart count 0
Feb 13 22:29:27.675: INFO: sonobuoy-systemd-logs-daemon-set-fc7e6cef4e6e4a80-zrxgv from heptio-sonobuoy started at 2019-02-13 21:18:37 +0000 UTC (2 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 13 22:29:27.675: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 13 22:29:27.675: INFO: calico-node-xdz82 from kube-system started at 2019-02-05 19:06:38 +0000 UTC (2 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container calico-node ready: true, restart count 0
Feb 13 22:29:27.675: INFO: 	Container install-cni ready: true, restart count 0
Feb 13 22:29:27.675: INFO: calico-typha-785658b69-48jm5 from kube-system started at 2019-02-05 19:06:48 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container calico-typha ready: true, restart count 0
Feb 13 22:29:27.675: INFO: nginx-ingress-controller-6xl6l from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 13 22:29:27.675: INFO: ccp-monitor-prometheus-node-exporter-6vlbz from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container prometheus-node-exporter ready: true, restart count 0
Feb 13 22:29:27.675: INFO: ccp-monitor-grafana-577f9c8c7c-wshx8 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container grafana ready: true, restart count 0
Feb 13 22:29:27.675: INFO: kube-proxy-25b5j from kube-system started at 2019-02-05 19:06:38 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 13 22:29:27.675: INFO: metallb-controller-56fd5dc6c8-bf86h from ccp started at 2019-02-05 19:07:31 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container controller ready: true, restart count 0
Feb 13 22:29:27.675: INFO: ccp-monitor-prometheus-pushgateway-5c4f64c9d8-lc5m5 from ccp started at 2019-02-05 19:07:34 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container prometheus-pushgateway ready: true, restart count 0
Feb 13 22:29:27.675: INFO: ccp-efk-kibana-56784656d5-8sffs from ccp started at 2019-02-05 19:07:35 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container kibana ready: true, restart count 0
Feb 13 22:29:27.675: INFO: cert-manager-897586cc6-rxv6p from ccp started at 2019-02-05 19:07:30 +0000 UTC (1 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container cert-manager ready: true, restart count 1
Feb 13 22:29:27.675: INFO: ccp-monitor-prometheus-alertmanager-5cbfbfcc66-jqz5z from ccp started at 2019-02-05 19:07:36 +0000 UTC (2 container statuses recorded)
Feb 13 22:29:27.675: INFO: 	Container prometheus-alertmanager ready: true, restart count 0
Feb 13 22:29:27.675: INFO: 	Container prometheus-alertmanager-configmap-reload ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15830cfab6565264], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:29:28.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4sf7r" for this suite.
Feb 13 22:29:34.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:29:34.715: INFO: namespace: e2e-tests-sched-pred-4sf7r, resource: bindings, ignored listing per whitelist
Feb 13 22:29:34.747: INFO: namespace e2e-tests-sched-pred-4sf7r deletion completed in 6.05087763s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.228 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:29:34.748: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bjdfp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 13 22:29:34.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:35.297: INFO: stderr: ""
Feb 13 22:29:35.297: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 13 22:29:35.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:35.381: INFO: stderr: ""
Feb 13 22:29:35.381: INFO: stdout: "update-demo-nautilus-jcp9s update-demo-nautilus-wq2r4 "
Feb 13 22:29:35.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-jcp9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:35.440: INFO: stderr: ""
Feb 13 22:29:35.440: INFO: stdout: ""
Feb 13 22:29:35.440: INFO: update-demo-nautilus-jcp9s is created but not running
Feb 13 22:29:40.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.514: INFO: stderr: ""
Feb 13 22:29:40.514: INFO: stdout: "update-demo-nautilus-jcp9s update-demo-nautilus-wq2r4 "
Feb 13 22:29:40.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-jcp9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.576: INFO: stderr: ""
Feb 13 22:29:40.576: INFO: stdout: "true"
Feb 13 22:29:40.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-jcp9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.657: INFO: stderr: ""
Feb 13 22:29:40.657: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 22:29:40.657: INFO: validating pod update-demo-nautilus-jcp9s
Feb 13 22:29:40.660: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:29:40.660: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:29:40.660: INFO: update-demo-nautilus-jcp9s is verified up and running
Feb 13 22:29:40.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-wq2r4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.724: INFO: stderr: ""
Feb 13 22:29:40.724: INFO: stdout: "true"
Feb 13 22:29:40.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods update-demo-nautilus-wq2r4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.795: INFO: stderr: ""
Feb 13 22:29:40.795: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 13 22:29:40.795: INFO: validating pod update-demo-nautilus-wq2r4
Feb 13 22:29:40.797: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 13 22:29:40.797: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 13 22:29:40.797: INFO: update-demo-nautilus-wq2r4 is verified up and running
STEP: using delete to clean up resources
Feb 13 22:29:40.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.858: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:29:40.858: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 13 22:29:40.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bjdfp'
Feb 13 22:29:40.929: INFO: stderr: "No resources found.\n"
Feb 13 22:29:40.929: INFO: stdout: ""
Feb 13 22:29:40.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bjdfp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 22:29:40.998: INFO: stderr: ""
Feb 13 22:29:40.998: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:29:40.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bjdfp" for this suite.
Feb 13 22:29:47.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:29:47.025: INFO: namespace: e2e-tests-kubectl-bjdfp, resource: bindings, ignored listing per whitelist
Feb 13 22:29:47.059: INFO: namespace e2e-tests-kubectl-bjdfp deletion completed in 6.057589697s

• [SLOW TEST:12.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:29:47.060: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-lxvkx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lxvkx
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-lxvkx
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-lxvkx
Feb 13 22:29:47.209: INFO: Found 0 stateful pods, waiting for 1
Feb 13 22:29:57.211: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 13 22:29:57.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 22:29:57.337: INFO: stderr: ""
Feb 13 22:29:57.337: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 22:29:57.337: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 22:29:57.339: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 13 22:30:07.341: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 22:30:07.341: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 22:30:07.347: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:07.347: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:07.347: INFO: 
Feb 13 22:30:07.347: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 13 22:30:08.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997907368s
Feb 13 22:30:09.351: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.996252018s
Feb 13 22:30:10.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.994000947s
Feb 13 22:30:11.356: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.991780401s
Feb 13 22:30:12.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.989574751s
Feb 13 22:30:13.360: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.987483749s
Feb 13 22:30:14.362: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.985330433s
Feb 13 22:30:15.365: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.983134439s
Feb 13 22:30:16.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 980.204278ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-lxvkx
Feb 13 22:30:17.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 22:30:17.499: INFO: stderr: ""
Feb 13 22:30:17.499: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 22:30:17.499: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 22:30:17.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 22:30:17.652: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 13 22:30:17.652: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 22:30:17.652: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 22:30:17.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 13 22:30:17.782: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 13 22:30:17.782: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 13 22:30:17.782: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 13 22:30:17.784: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:30:17.784: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 13 22:30:17.784: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 13 22:30:17.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 22:30:17.904: INFO: stderr: ""
Feb 13 22:30:17.904: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 22:30:17.904: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 22:30:17.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 22:30:18.048: INFO: stderr: ""
Feb 13 22:30:18.048: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 22:30:18.048: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 22:30:18.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 exec --namespace=e2e-tests-statefulset-lxvkx ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 13 22:30:18.175: INFO: stderr: ""
Feb 13 22:30:18.175: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 13 22:30:18.175: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 13 22:30:18.175: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 22:30:18.176: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 13 22:30:28.180: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 22:30:28.180: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 22:30:28.180: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 13 22:30:28.187: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:28.187: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:28.187: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:28.187: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:28.187: INFO: 
Feb 13 22:30:28.187: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:29.190: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:29.190: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:29.190: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:29.190: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:29.190: INFO: 
Feb 13 22:30:29.190: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:30.195: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:30.195: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:30.195: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:30.195: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:30.195: INFO: 
Feb 13 22:30:30.195: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:31.202: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:31.202: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:31.202: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:31.202: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:31.202: INFO: 
Feb 13 22:30:31.202: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:32.204: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:32.204: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:32.205: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:32.205: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:32.205: INFO: 
Feb 13 22:30:32.205: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:33.207: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:33.207: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:33.207: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:33.207: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:33.207: INFO: 
Feb 13 22:30:33.207: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:34.209: INFO: POD   NODE                                PHASE    GRACE  CONDITIONS
Feb 13 22:30:34.209: INFO: ss-0  alex-300-cp3-vsp1-worker71a62db265  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:29:47 +0000 UTC  }]
Feb 13 22:30:34.209: INFO: ss-1  alex-300-cp3-vsp1-workerdf4199ef27  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:34.209: INFO: ss-2  alex-300-cp3-vsp1-worker71a62db265  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-13 22:30:07 +0000 UTC  }]
Feb 13 22:30:34.209: INFO: 
Feb 13 22:30:34.209: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 13 22:30:35.211: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.976485047s
Feb 13 22:30:36.213: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.973805591s
Feb 13 22:30:37.218: INFO: Verifying statefulset ss doesn't scale past 0 for another 970.764002ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-lxvkx
Feb 13 22:30:38.220: INFO: Scaling statefulset ss to 0
Feb 13 22:30:38.224: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 13 22:30:38.225: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lxvkx
Feb 13 22:30:38.226: INFO: Scaling statefulset ss to 0
Feb 13 22:30:38.229: INFO: Waiting for statefulset status.replicas updated to 0
Feb 13 22:30:38.230: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:30:38.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lxvkx" for this suite.
Feb 13 22:30:44.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:30:44.261: INFO: namespace: e2e-tests-statefulset-lxvkx, resource: bindings, ignored listing per whitelist
Feb 13 22:30:44.292: INFO: namespace e2e-tests-statefulset-lxvkx deletion completed in 6.047701845s

• [SLOW TEST:57.232 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:30:44.293: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jwpsb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 13 22:30:44.440: INFO: Waiting up to 5m0s for pod "pod-0083e7d4-2fdf-11e9-829f-22a36399a92d" in namespace "e2e-tests-emptydir-jwpsb" to be "success or failure"
Feb 13 22:30:44.444: INFO: Pod "pod-0083e7d4-2fdf-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441899ms
Feb 13 22:30:46.446: INFO: Pod "pod-0083e7d4-2fdf-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005699672s
STEP: Saw pod success
Feb 13 22:30:46.446: INFO: Pod "pod-0083e7d4-2fdf-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:30:46.448: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-0083e7d4-2fdf-11e9-829f-22a36399a92d container test-container: <nil>
STEP: delete the pod
Feb 13 22:30:46.463: INFO: Waiting for pod pod-0083e7d4-2fdf-11e9-829f-22a36399a92d to disappear
Feb 13 22:30:46.464: INFO: Pod pod-0083e7d4-2fdf-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:30:46.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jwpsb" for this suite.
Feb 13 22:30:52.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:30:52.490: INFO: namespace: e2e-tests-emptydir-jwpsb, resource: bindings, ignored listing per whitelist
Feb 13 22:30:52.511: INFO: namespace e2e-tests-emptydir-jwpsb deletion completed in 6.043852846s

• [SLOW TEST:8.219 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:30:52.513: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dnlt6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0568b99c-2fdf-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume configMaps
Feb 13 22:30:52.662: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-dnlt6" to be "success or failure"
Feb 13 22:30:52.666: INFO: Pod "pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.611526ms
Feb 13 22:30:54.668: INFO: Pod "pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00542468s
STEP: Saw pod success
Feb 13 22:30:54.668: INFO: Pod "pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:30:54.669: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 13 22:30:54.682: INFO: Waiting for pod pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d to disappear
Feb 13 22:30:54.683: INFO: Pod pod-projected-configmaps-056929ca-2fdf-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:30:54.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dnlt6" for this suite.
Feb 13 22:31:00.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:00.704: INFO: namespace: e2e-tests-projected-dnlt6, resource: bindings, ignored listing per whitelist
Feb 13 22:31:00.737: INFO: namespace e2e-tests-projected-dnlt6 deletion completed in 6.052634698s

• [SLOW TEST:8.225 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:31:00.738: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rrptg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 13 22:31:05.399: INFO: Successfully updated pod "annotationupdate0a501da4-2fdf-11e9-829f-22a36399a92d"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:31:07.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rrptg" for this suite.
Feb 13 22:31:29.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:29.436: INFO: namespace: e2e-tests-projected-rrptg, resource: bindings, ignored listing per whitelist
Feb 13 22:31:29.457: INFO: namespace e2e-tests-projected-rrptg deletion completed in 22.043326307s

• [SLOW TEST:28.718 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:31:29.457: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kbqv7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1b6e312d-2fdf-11e9-829f-22a36399a92d
STEP: Creating secret with name s-test-opt-upd-1b6e3161-2fdf-11e9-829f-22a36399a92d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1b6e312d-2fdf-11e9-829f-22a36399a92d
STEP: Updating secret s-test-opt-upd-1b6e3161-2fdf-11e9-829f-22a36399a92d
STEP: Creating secret with name s-test-opt-create-1b6e3171-2fdf-11e9-829f-22a36399a92d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:31:33.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kbqv7" for this suite.
Feb 13 22:31:55.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:31:55.686: INFO: namespace: e2e-tests-projected-kbqv7, resource: bindings, ignored listing per whitelist
Feb 13 22:31:55.699: INFO: namespace e2e-tests-projected-kbqv7 deletion completed in 22.050138161s

• [SLOW TEST:26.242 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:31:55.700: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l5vc6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb 13 22:31:55.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 create -f - --namespace=e2e-tests-kubectl-l5vc6'
Feb 13 22:31:55.995: INFO: stderr: ""
Feb 13 22:31:55.995: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 13 22:31:56.997: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:31:56.997: INFO: Found 0 / 1
Feb 13 22:31:57.997: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:31:57.997: INFO: Found 1 / 1
Feb 13 22:31:57.997: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 13 22:31:57.999: INFO: Selector matched 1 pods for map[app:redis]
Feb 13 22:31:57.999: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 13 22:31:57.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 logs redis-master-zh9n8 redis-master --namespace=e2e-tests-kubectl-l5vc6'
Feb 13 22:31:58.094: INFO: stderr: ""
Feb 13 22:31:58.094: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 22:31:50.151 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 22:31:50.151 # Server started, Redis version 3.2.12\n1:M 13 Feb 22:31:50.151 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 22:31:50.151 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 13 22:31:58.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 log redis-master-zh9n8 redis-master --namespace=e2e-tests-kubectl-l5vc6 --tail=1'
Feb 13 22:31:58.170: INFO: stderr: ""
Feb 13 22:31:58.170: INFO: stdout: "1:M 13 Feb 22:31:50.151 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 13 22:31:58.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 log redis-master-zh9n8 redis-master --namespace=e2e-tests-kubectl-l5vc6 --limit-bytes=1'
Feb 13 22:31:58.237: INFO: stderr: ""
Feb 13 22:31:58.237: INFO: stdout: " "
STEP: exposing timestamps
Feb 13 22:31:58.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 log redis-master-zh9n8 redis-master --namespace=e2e-tests-kubectl-l5vc6 --tail=1 --timestamps'
Feb 13 22:31:58.298: INFO: stderr: ""
Feb 13 22:31:58.298: INFO: stdout: "2019-02-13T22:31:50.154339171Z 1:M 13 Feb 22:31:50.151 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 13 22:32:00.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 log redis-master-zh9n8 redis-master --namespace=e2e-tests-kubectl-l5vc6 --since=1s'
Feb 13 22:32:00.873: INFO: stderr: ""
Feb 13 22:32:00.873: INFO: stdout: ""
Feb 13 22:32:00.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 log redis-master-zh9n8 redis-master --namespace=e2e-tests-kubectl-l5vc6 --since=24h'
Feb 13 22:32:00.940: INFO: stderr: ""
Feb 13 22:32:00.940: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 Feb 22:31:50.151 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Feb 22:31:50.151 # Server started, Redis version 3.2.12\n1:M 13 Feb 22:31:50.151 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Feb 22:31:50.151 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb 13 22:32:00.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l5vc6'
Feb 13 22:32:01.002: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 13 22:32:01.002: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 13 22:32:01.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-l5vc6'
Feb 13 22:32:01.079: INFO: stderr: "No resources found.\n"
Feb 13 22:32:01.079: INFO: stdout: ""
Feb 13 22:32:01.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pods -l name=nginx --namespace=e2e-tests-kubectl-l5vc6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 13 22:32:01.152: INFO: stderr: ""
Feb 13 22:32:01.152: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:32:01.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l5vc6" for this suite.
Feb 13 22:32:07.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:07.204: INFO: namespace: e2e-tests-kubectl-l5vc6, resource: bindings, ignored listing per whitelist
Feb 13 22:32:07.224: INFO: namespace e2e-tests-kubectl-l5vc6 deletion completed in 6.069701144s

• [SLOW TEST:11.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:32:07.225: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kjrns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0213 22:32:17.375707      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 13 22:32:17.375: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:32:17.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kjrns" for this suite.
Feb 13 22:32:23.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:32:23.405: INFO: namespace: e2e-tests-gc-kjrns, resource: bindings, ignored listing per whitelist
Feb 13 22:32:23.440: INFO: namespace e2e-tests-gc-kjrns deletion completed in 6.062472349s

• [SLOW TEST:16.215 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:32:23.440: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-jbgkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-jbgkp
Feb 13 22:32:25.590: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-jbgkp
STEP: checking the pod's current state and verifying that restartCount is present
Feb 13 22:32:25.592: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:36:25.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jbgkp" for this suite.
Feb 13 22:36:31.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:31.967: INFO: namespace: e2e-tests-container-probe-jbgkp, resource: bindings, ignored listing per whitelist
Feb 13 22:36:31.983: INFO: namespace e2e-tests-container-probe-jbgkp deletion completed in 6.039972336s

• [SLOW TEST:248.543 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:36:31.984: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xdszz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 13 22:36:34.638: INFO: Successfully updated pod "pod-update-cfc04b1a-2fdf-11e9-829f-22a36399a92d"
STEP: verifying the updated pod is in kubernetes
Feb 13 22:36:34.640: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:36:34.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xdszz" for this suite.
Feb 13 22:36:56.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:36:56.658: INFO: namespace: e2e-tests-pods-xdszz, resource: bindings, ignored listing per whitelist
Feb 13 22:36:56.689: INFO: namespace e2e-tests-pods-xdszz deletion completed in 22.047067436s

• [SLOW TEST:24.706 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:36:56.690: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-74bvj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-de79edc1-2fdf-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:36:56.832: INFO: Waiting up to 5m0s for pod "pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-74bvj" to be "success or failure"
Feb 13 22:36:56.836: INFO: Pod "pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.657439ms
Feb 13 22:36:58.838: INFO: Pod "pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006565663s
STEP: Saw pod success
Feb 13 22:36:58.838: INFO: Pod "pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:36:58.840: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:36:58.855: INFO: Waiting for pod pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d to disappear
Feb 13 22:36:58.856: INFO: Pod pod-secrets-de7a3d10-2fdf-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:36:58.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-74bvj" for this suite.
Feb 13 22:37:04.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:37:04.884: INFO: namespace: e2e-tests-secrets-74bvj, resource: bindings, ignored listing per whitelist
Feb 13 22:37:04.907: INFO: namespace e2e-tests-secrets-74bvj deletion completed in 6.048738086s

• [SLOW TEST:8.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:37:04.908: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-4f7vj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 13 22:37:05.047: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:05.048: INFO: Number of nodes with available pods: 0
Feb 13 22:37:05.048: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:37:06.050: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:06.052: INFO: Number of nodes with available pods: 0
Feb 13 22:37:06.052: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:37:07.050: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:07.052: INFO: Number of nodes with available pods: 1
Feb 13 22:37:07.052: INFO: Node alex-300-cp3-vsp1-workerdf4199ef27 is running more than one daemon pod
Feb 13 22:37:08.050: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:08.052: INFO: Number of nodes with available pods: 2
Feb 13 22:37:08.052: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 13 22:37:08.066: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:08.072: INFO: Number of nodes with available pods: 1
Feb 13 22:37:08.072: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:37:09.076: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:09.077: INFO: Number of nodes with available pods: 1
Feb 13 22:37:09.077: INFO: Node alex-300-cp3-vsp1-worker71a62db265 is running more than one daemon pod
Feb 13 22:37:10.076: INFO: DaemonSet pods can't tolerate node alex-300-cp3-vsp1-master39c69945b7 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 13 22:37:10.078: INFO: Number of nodes with available pods: 2
Feb 13 22:37:10.078: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-4f7vj, will wait for the garbage collector to delete the pods
Feb 13 22:37:10.137: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.76125ms
Feb 13 22:37:10.237: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.148119ms
Feb 13 22:37:54.839: INFO: Number of nodes with available pods: 0
Feb 13 22:37:54.839: INFO: Number of running nodes: 0, number of available pods: 0
Feb 13 22:37:54.840: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4f7vj/daemonsets","resourceVersion":"1279344"},"items":null}

Feb 13 22:37:54.841: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4f7vj/pods","resourceVersion":"1279344"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:37:54.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4f7vj" for this suite.
Feb 13 22:38:00.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:38:00.868: INFO: namespace: e2e-tests-daemonsets-4f7vj, resource: bindings, ignored listing per whitelist
Feb 13 22:38:00.900: INFO: namespace e2e-tests-daemonsets-4f7vj deletion completed in 6.051814009s

• [SLOW TEST:55.993 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:38:00.902: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q8v7w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 13 22:38:01.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-q8v7w'
Feb 13 22:38:01.107: INFO: stderr: ""
Feb 13 22:38:01.107: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 13 22:38:06.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-q8v7w -o json'
Feb 13 22:38:06.245: INFO: stderr: ""
Feb 13 22:38:06.245: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.1.21/32\"\n        },\n        \"creationTimestamp\": \"2019-02-13T22:38:01Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-q8v7w\",\n        \"resourceVersion\": \"1279398\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-q8v7w/pods/e2e-test-nginx-pod\",\n        \"uid\": \"04c942e5-2fe0-11e9-8578-0050569e397b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4vzpf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"alex-300-cp3-vsp1-worker71a62db265\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4vzpf\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4vzpf\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:37:54Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:37:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:37:55Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-13T22:38:01Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://6dd5ff28a4841c2bbdd1aee0270e2b5f15eb25b3d619174ec98d71d31abfbf35\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-13T22:37:55Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.100.39\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.1.21\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-13T22:37:54Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 13 22:38:06.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 replace -f - --namespace=e2e-tests-kubectl-q8v7w'
Feb 13 22:38:06.451: INFO: stderr: ""
Feb 13 22:38:06.451: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb 13 22:38:06.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-495519211 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-q8v7w'
Feb 13 22:38:14.747: INFO: stderr: ""
Feb 13 22:38:14.747: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:38:14.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q8v7w" for this suite.
Feb 13 22:38:20.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:38:20.784: INFO: namespace: e2e-tests-kubectl-q8v7w, resource: bindings, ignored listing per whitelist
Feb 13 22:38:20.797: INFO: namespace e2e-tests-kubectl-q8v7w deletion completed in 6.046716831s

• [SLOW TEST:19.895 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:38:20.798: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s22nw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 13 22:38:20.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d" in namespace "e2e-tests-projected-s22nw" to be "success or failure"
Feb 13 22:38:20.942: INFO: Pod "downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239774ms
Feb 13 22:38:22.944: INFO: Pod "downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00424232s
STEP: Saw pod success
Feb 13 22:38:22.944: INFO: Pod "downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:38:22.945: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d container client-container: <nil>
STEP: delete the pod
Feb 13 22:38:22.958: INFO: Waiting for pod downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d to disappear
Feb 13 22:38:22.959: INFO: Pod downwardapi-volume-109ba1af-2fe0-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:38:22.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s22nw" for this suite.
Feb 13 22:38:28.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:38:28.997: INFO: namespace: e2e-tests-projected-s22nw, resource: bindings, ignored listing per whitelist
Feb 13 22:38:29.005: INFO: namespace e2e-tests-projected-s22nw deletion completed in 6.04393485s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 13 22:38:29.005: INFO: >>> kubeConfig: /tmp/kubeconfig-495519211
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vmkvf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-157f9ea8-2fe0-11e9-829f-22a36399a92d
STEP: Creating a pod to test consume secrets
Feb 13 22:38:29.143: INFO: Waiting up to 5m0s for pod "pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d" in namespace "e2e-tests-secrets-vmkvf" to be "success or failure"
Feb 13 22:38:29.146: INFO: Pod "pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.473914ms
Feb 13 22:38:31.148: INFO: Pod "pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004200001s
STEP: Saw pod success
Feb 13 22:38:31.148: INFO: Pod "pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d" satisfied condition "success or failure"
Feb 13 22:38:31.149: INFO: Trying to get logs from node alex-300-cp3-vsp1-worker71a62db265 pod pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d container secret-volume-test: <nil>
STEP: delete the pod
Feb 13 22:38:31.163: INFO: Waiting for pod pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d to disappear
Feb 13 22:38:31.164: INFO: Pod pod-secrets-157fed3d-2fe0-11e9-829f-22a36399a92d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 13 22:38:31.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vmkvf" for this suite.
Feb 13 22:38:37.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 13 22:38:37.185: INFO: namespace: e2e-tests-secrets-vmkvf, resource: bindings, ignored listing per whitelist
Feb 13 22:38:37.216: INFO: namespace e2e-tests-secrets-vmkvf deletion completed in 6.048955542s

• [SLOW TEST:8.211 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSFeb 13 22:38:37.216: INFO: Running AfterSuite actions on all node
Feb 13 22:38:37.216: INFO: Running AfterSuite actions on node 1
Feb 13 22:38:37.216: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4769.425 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h19m30.311376875s
Test Suite Passed
