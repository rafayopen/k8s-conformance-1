Feb 19 11:42:47.966: INFO: Overriding default scale value of zero to 1
Feb 19 11:42:47.966: INFO: Overriding default milliseconds value of zero to 5000
I0219 11:42:48.551295      17 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-879726862
I0219 11:42:48.551482      17 e2e.go:304] Starting e2e run "7ac05347-343b-11e9-af36-92091ca56148" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550576567 - Will randomize all specs
Will run 188 of 1814 specs

Feb 19 11:42:48.764: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 11:42:48.768: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 19 11:42:48.784: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 19 11:42:48.837: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 19 11:42:48.837: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Feb 19 11:42:48.837: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 19 11:42:48.847: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Feb 19 11:42:48.847: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 19 11:42:48.847: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
Feb 19 11:42:48.847: INFO: e2e test version: v1.12.1
Feb 19 11:42:48.849: INFO: kube-apiserver version: v1.12.3
SSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:42:48.849: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
Feb 19 11:42:48.967: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 19 11:42:48.980: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dlqvc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-4rclg
STEP: Creating secret with name secret-test-7b7c7a55-343b-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 11:42:49.292: INFO: Waiting up to 5m0s for pod "pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-dlqvc" to be "success or failure"
Feb 19 11:42:49.299: INFO: Pod "pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.158416ms
Feb 19 11:42:51.305: INFO: Pod "pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01270185s
Feb 19 11:42:53.311: INFO: Pod "pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018442892s
Feb 19 11:42:55.316: INFO: Pod "pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023749118s
STEP: Saw pod success
Feb 19 11:42:55.316: INFO: Pod "pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:42:55.320: INFO: Trying to get logs from node kube-node-20-104 pod pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 11:42:55.352: INFO: Waiting for pod pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:42:55.356: INFO: Pod pod-secrets-7b9809dc-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:42:55.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dlqvc" for this suite.
Feb 19 11:43:01.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:43:01.535: INFO: namespace: e2e-tests-secrets-dlqvc, resource: bindings, ignored listing per whitelist
Feb 19 11:43:01.546: INFO: namespace e2e-tests-secrets-dlqvc deletion completed in 6.176689377s
STEP: Destroying namespace "e2e-tests-secret-namespace-4rclg" for this suite.
Feb 19 11:43:07.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:43:07.696: INFO: namespace: e2e-tests-secret-namespace-4rclg, resource: bindings, ignored listing per whitelist
Feb 19 11:43:07.736: INFO: namespace e2e-tests-secret-namespace-4rclg deletion completed in 6.187121712s

• [SLOW TEST:18.886 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:43:07.736: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gvv8f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 11:43:14.548: INFO: Successfully updated pod "annotationupdate86bde78f-343b-11e9-af36-92091ca56148"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:43:16.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gvv8f" for this suite.
Feb 19 11:43:38.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:43:38.688: INFO: namespace: e2e-tests-projected-gvv8f, resource: bindings, ignored listing per whitelist
Feb 19 11:43:38.779: INFO: namespace e2e-tests-projected-gvv8f deletion completed in 22.197334914s

• [SLOW TEST:31.043 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:43:38.779: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vsfjx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0219 11:43:49.049802      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 11:43:49.049: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:43:49.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vsfjx" for this suite.
Feb 19 11:43:55.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:43:55.140: INFO: namespace: e2e-tests-gc-vsfjx, resource: bindings, ignored listing per whitelist
Feb 19 11:43:55.242: INFO: namespace e2e-tests-gc-vsfjx deletion completed in 6.186360998s

• [SLOW TEST:16.462 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:43:55.242: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s7kgq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 19 11:43:55.480: INFO: Waiting up to 5m0s for pod "pod-a30b928d-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-s7kgq" to be "success or failure"
Feb 19 11:43:55.484: INFO: Pod "pod-a30b928d-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.383876ms
Feb 19 11:43:57.491: INFO: Pod "pod-a30b928d-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011500629s
Feb 19 11:43:59.497: INFO: Pod "pod-a30b928d-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017505615s
Feb 19 11:44:01.504: INFO: Pod "pod-a30b928d-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024259797s
STEP: Saw pod success
Feb 19 11:44:01.504: INFO: Pod "pod-a30b928d-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:44:01.513: INFO: Trying to get logs from node kube-node-20-104 pod pod-a30b928d-343b-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 11:44:01.541: INFO: Waiting for pod pod-a30b928d-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:44:01.545: INFO: Pod pod-a30b928d-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:44:01.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s7kgq" for this suite.
Feb 19 11:44:07.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:44:07.678: INFO: namespace: e2e-tests-emptydir-s7kgq, resource: bindings, ignored listing per whitelist
Feb 19 11:44:07.718: INFO: namespace e2e-tests-emptydir-s7kgq deletion completed in 6.166461821s

• [SLOW TEST:12.476 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:44:07.718: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pmpn4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 19 11:44:07.946: INFO: Waiting up to 5m0s for pod "pod-aa79eed8-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-pmpn4" to be "success or failure"
Feb 19 11:44:07.952: INFO: Pod "pod-aa79eed8-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.889184ms
Feb 19 11:44:09.959: INFO: Pod "pod-aa79eed8-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011247581s
Feb 19 11:44:12.016: INFO: Pod "pod-aa79eed8-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068750732s
Feb 19 11:44:14.022: INFO: Pod "pod-aa79eed8-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.074314493s
STEP: Saw pod success
Feb 19 11:44:14.022: INFO: Pod "pod-aa79eed8-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:44:14.028: INFO: Trying to get logs from node kube-node-20-105 pod pod-aa79eed8-343b-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 11:44:14.064: INFO: Waiting for pod pod-aa79eed8-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:44:14.071: INFO: Pod pod-aa79eed8-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:44:14.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pmpn4" for this suite.
Feb 19 11:44:20.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:44:20.172: INFO: namespace: e2e-tests-emptydir-pmpn4, resource: bindings, ignored listing per whitelist
Feb 19 11:44:20.280: INFO: namespace e2e-tests-emptydir-pmpn4 deletion completed in 6.201811777s

• [SLOW TEST:12.562 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:44:20.280: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-t2b8t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 19 11:44:20.521: INFO: Waiting up to 5m0s for pod "client-containers-b1f889f7-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-containers-t2b8t" to be "success or failure"
Feb 19 11:44:20.524: INFO: Pod "client-containers-b1f889f7-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 3.898955ms
Feb 19 11:44:22.530: INFO: Pod "client-containers-b1f889f7-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009481368s
Feb 19 11:44:24.536: INFO: Pod "client-containers-b1f889f7-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015496572s
Feb 19 11:44:26.542: INFO: Pod "client-containers-b1f889f7-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021722514s
STEP: Saw pod success
Feb 19 11:44:26.542: INFO: Pod "client-containers-b1f889f7-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:44:26.547: INFO: Trying to get logs from node kube-node-20-104 pod client-containers-b1f889f7-343b-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 11:44:26.575: INFO: Waiting for pod client-containers-b1f889f7-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:44:26.580: INFO: Pod client-containers-b1f889f7-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:44:26.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-t2b8t" for this suite.
Feb 19 11:44:32.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:44:32.667: INFO: namespace: e2e-tests-containers-t2b8t, resource: bindings, ignored listing per whitelist
Feb 19 11:44:32.772: INFO: namespace e2e-tests-containers-t2b8t deletion completed in 6.184283344s

• [SLOW TEST:12.492 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:44:32.772: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-xrvmp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 19 11:44:47.061: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:47.071: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:44:49.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:49.079: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:44:51.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:51.078: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:44:53.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:53.079: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:44:55.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:55.079: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:44:57.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:57.080: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:44:59.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:44:59.078: INFO: Pod pod-with-prestop-http-hook still exists
Feb 19 11:45:01.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 19 11:45:01.079: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:45:01.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xrvmp" for this suite.
Feb 19 11:45:23.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:45:23.150: INFO: namespace: e2e-tests-container-lifecycle-hook-xrvmp, resource: bindings, ignored listing per whitelist
Feb 19 11:45:23.278: INFO: namespace e2e-tests-container-lifecycle-hook-xrvmp deletion completed in 22.178501115s

• [SLOW TEST:50.507 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:45:23.279: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rw66q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 11:45:23.535: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-rw66q" to be "success or failure"
Feb 19 11:45:23.540: INFO: Pod "downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.480093ms
Feb 19 11:45:25.546: INFO: Pod "downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010886732s
Feb 19 11:45:27.551: INFO: Pod "downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016278045s
Feb 19 11:45:29.557: INFO: Pod "downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022036632s
STEP: Saw pod success
Feb 19 11:45:29.557: INFO: Pod "downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:45:29.562: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 11:45:29.598: INFO: Waiting for pod downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:45:29.603: INFO: Pod downwardapi-volume-d787c4d9-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:45:29.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rw66q" for this suite.
Feb 19 11:45:35.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:45:35.712: INFO: namespace: e2e-tests-downward-api-rw66q, resource: bindings, ignored listing per whitelist
Feb 19 11:45:35.781: INFO: namespace e2e-tests-downward-api-rw66q deletion completed in 6.172386093s

• [SLOW TEST:12.502 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:45:35.781: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8qc9b
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-defa572a-343b-11e9-af36-92091ca56148
STEP: Creating configMap with name cm-test-opt-upd-defa57db-343b-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-defa572a-343b-11e9-af36-92091ca56148
STEP: Updating configmap cm-test-opt-upd-defa57db-343b-11e9-af36-92091ca56148
STEP: Creating configMap with name cm-test-opt-create-defa5800-343b-11e9-af36-92091ca56148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:45:52.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8qc9b" for this suite.
Feb 19 11:46:14.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:46:14.213: INFO: namespace: e2e-tests-configmap-8qc9b, resource: bindings, ignored listing per whitelist
Feb 19 11:46:14.345: INFO: namespace e2e-tests-configmap-8qc9b deletion completed in 22.170270542s

• [SLOW TEST:38.564 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:46:14.346: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-szddd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f5f6e710-343b-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 11:46:14.602: INFO: Waiting up to 5m0s for pod "pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-szddd" to be "success or failure"
Feb 19 11:46:14.607: INFO: Pod "pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.201463ms
Feb 19 11:46:16.619: INFO: Pod "pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016146858s
Feb 19 11:46:18.625: INFO: Pod "pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022792409s
Feb 19 11:46:20.632: INFO: Pod "pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029325991s
STEP: Saw pod success
Feb 19 11:46:20.632: INFO: Pod "pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:46:20.636: INFO: Trying to get logs from node kube-node-20-105 pod pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 11:46:20.665: INFO: Waiting for pod pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:46:20.669: INFO: Pod pod-secrets-f5f7da58-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:46:20.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-szddd" for this suite.
Feb 19 11:46:26.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:46:26.744: INFO: namespace: e2e-tests-secrets-szddd, resource: bindings, ignored listing per whitelist
Feb 19 11:46:26.852: INFO: namespace e2e-tests-secrets-szddd deletion completed in 6.174682665s

• [SLOW TEST:12.506 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:46:26.852: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-fgd5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 19 11:46:27.102: INFO: Waiting up to 5m0s for pod "pod-fd6b5b3c-343b-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-fgd5b" to be "success or failure"
Feb 19 11:46:27.107: INFO: Pod "pod-fd6b5b3c-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.240902ms
Feb 19 11:46:29.113: INFO: Pod "pod-fd6b5b3c-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011183413s
Feb 19 11:46:31.119: INFO: Pod "pod-fd6b5b3c-343b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017642139s
Feb 19 11:46:33.125: INFO: Pod "pod-fd6b5b3c-343b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023266029s
STEP: Saw pod success
Feb 19 11:46:33.125: INFO: Pod "pod-fd6b5b3c-343b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:46:33.129: INFO: Trying to get logs from node kube-node-20-104 pod pod-fd6b5b3c-343b-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 11:46:33.162: INFO: Waiting for pod pod-fd6b5b3c-343b-11e9-af36-92091ca56148 to disappear
Feb 19 11:46:33.167: INFO: Pod pod-fd6b5b3c-343b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:46:33.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fgd5b" for this suite.
Feb 19 11:46:39.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:46:39.309: INFO: namespace: e2e-tests-emptydir-fgd5b, resource: bindings, ignored listing per whitelist
Feb 19 11:46:39.334: INFO: namespace e2e-tests-emptydir-fgd5b deletion completed in 6.161972354s

• [SLOW TEST:12.482 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:46:39.335: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mrv2l
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-04db4125-343c-11e9-af36-92091ca56148
STEP: Creating secret with name s-test-opt-upd-04db4189-343c-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-04db4125-343c-11e9-af36-92091ca56148
STEP: Updating secret s-test-opt-upd-04db4189-343c-11e9-af36-92091ca56148
STEP: Creating secret with name s-test-opt-create-04db41ad-343c-11e9-af36-92091ca56148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:48:20.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mrv2l" for this suite.
Feb 19 11:48:42.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:48:42.424: INFO: namespace: e2e-tests-secrets-mrv2l, resource: bindings, ignored listing per whitelist
Feb 19 11:48:42.540: INFO: namespace e2e-tests-secrets-mrv2l deletion completed in 22.189694797s

• [SLOW TEST:123.205 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:48:42.540: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-wxq6z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 11:48:42.816: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 11:48:42.834: INFO: Number of nodes with available pods: 0
Feb 19 11:48:42.834: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:48:43.847: INFO: Number of nodes with available pods: 0
Feb 19 11:48:43.847: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:48:44.846: INFO: Number of nodes with available pods: 0
Feb 19 11:48:44.846: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:48:45.849: INFO: Number of nodes with available pods: 0
Feb 19 11:48:45.849: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:48:46.848: INFO: Number of nodes with available pods: 0
Feb 19 11:48:46.848: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:48:47.847: INFO: Number of nodes with available pods: 0
Feb 19 11:48:47.847: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:48:48.848: INFO: Number of nodes with available pods: 4
Feb 19 11:48:48.848: INFO: Node kube-master-20-103 is running more than one daemon pod
Feb 19 11:48:49.846: INFO: Number of nodes with available pods: 5
Feb 19 11:48:49.846: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 19 11:48:49.887: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:49.887: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:49.887: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:49.887: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:49.887: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:50.902: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:50.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:50.902: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:50.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:50.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:51.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:51.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:51.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:51.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:51.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:52.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:52.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:52.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:52.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:52.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:53.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:53.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:53.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:53.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:53.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:54.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:54.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:54.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:54.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:54.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:55.902: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:55.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:55.902: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:55.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:55.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:56.903: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:56.903: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:56.903: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:56.903: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:56.903: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:57.902: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:57.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:57.902: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:57.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:57.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:58.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:58.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:58.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:58.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:58.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:59.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:59.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:59.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:59.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:48:59.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:00.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:00.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:00.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:00.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:00.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:01.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:01.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:01.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:01.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:01.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:02.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:02.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:02.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:02.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:02.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:03.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:03.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:03.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:03.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:03.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:04.902: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:04.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:04.902: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:04.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:04.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:05.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:05.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:05.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:05.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:05.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:06.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:06.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:06.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:06.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:06.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:07.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:07.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:07.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:07.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:07.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:08.904: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:08.904: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:08.904: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:08.904: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:08.904: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:09.898: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:09.898: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:09.898: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:09.898: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:09.898: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:10.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:10.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:10.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:10.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:10.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:11.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:11.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:11.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:11.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:11.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:12.926: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:12.926: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:12.926: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:12.926: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:12.926: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:13.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:13.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:13.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:13.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:13.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:14.901: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:14.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:14.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:14.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:14.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:15.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:15.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:15.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:15.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:15.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:16.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:16.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:16.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:16.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:16.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:17.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:17.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:17.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:17.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:17.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:18.900: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:18.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:18.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:18.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:18.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:19.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:19.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:19.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:19.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:19.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:20.899: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:20.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:20.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:20.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:20.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:21.898: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:21.898: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:21.898: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:21.898: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:21.898: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:22.901: INFO: Wrong image for pod: daemon-set-hhcjs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:22.901: INFO: Pod daemon-set-hhcjs is not available
Feb 19 11:49:22.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:22.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:22.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:22.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:23.900: INFO: Pod daemon-set-d9675 is not available
Feb 19 11:49:23.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:23.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:23.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:23.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:24.900: INFO: Pod daemon-set-d9675 is not available
Feb 19 11:49:24.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:24.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:24.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:24.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:25.899: INFO: Pod daemon-set-d9675 is not available
Feb 19 11:49:25.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:25.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:25.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:25.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:26.900: INFO: Pod daemon-set-d9675 is not available
Feb 19 11:49:26.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:26.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:26.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:26.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:27.900: INFO: Pod daemon-set-d9675 is not available
Feb 19 11:49:27.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:27.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:27.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:27.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:28.900: INFO: Pod daemon-set-d9675 is not available
Feb 19 11:49:28.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:28.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:28.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:28.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:29.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:29.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:29.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:29.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:30.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:30.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:30.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:30.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:31.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:31.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:31.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:31.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:32.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:32.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:32.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:32.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:33.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:33.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:33.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:33.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:34.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:34.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:34.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:34.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:35.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:35.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:35.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:35.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:36.898: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:36.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:36.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:36.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:37.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:37.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:37.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:37.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:38.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:38.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:38.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:38.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:39.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:39.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:39.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:39.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:40.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:40.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:40.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:40.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:41.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:41.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:41.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:41.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:42.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:42.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:42.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:42.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:43.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:43.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:43.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:43.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:44.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:44.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:44.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:44.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:45.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:45.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:45.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:45.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:46.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:46.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:46.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:46.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:47.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:47.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:47.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:47.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:48.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:48.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:48.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:48.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:49.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:49.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:49.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:49.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:50.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:50.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:50.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:50.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:51.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:51.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:51.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:51.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:52.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:52.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:52.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:52.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:53.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:53.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:53.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:53.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:54.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:54.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:54.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:54.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:55.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:55.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:55.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:55.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:56.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:56.899: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:56.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:56.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:57.903: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:57.903: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:57.904: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:57.904: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:58.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:58.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:58.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:58.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:59.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:59.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:59.901: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:49:59.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:49:59.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:00.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:00.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:00.900: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:00.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:00.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:01.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:01.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:01.901: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:01.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:01.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:02.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:02.902: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:02.902: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:02.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:02.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:03.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:03.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:03.900: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:03.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:03.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:04.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:04.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:04.901: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:04.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:04.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:05.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:05.901: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:05.901: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:05.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:05.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:06.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:06.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:06.900: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:06.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:06.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:07.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:07.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:07.900: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:07.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:07.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:08.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:08.900: INFO: Wrong image for pod: daemon-set-hw4l2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:08.900: INFO: Pod daemon-set-hw4l2 is not available
Feb 19 11:50:08.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:08.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:09.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:09.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:09.900: INFO: Pod daemon-set-wl5cl is not available
Feb 19 11:50:09.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:10.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:10.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:10.900: INFO: Pod daemon-set-wl5cl is not available
Feb 19 11:50:10.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:11.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:11.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:11.900: INFO: Pod daemon-set-wl5cl is not available
Feb 19 11:50:11.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:12.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:12.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:12.901: INFO: Pod daemon-set-wl5cl is not available
Feb 19 11:50:12.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:13.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:13.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:13.899: INFO: Pod daemon-set-wl5cl is not available
Feb 19 11:50:13.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:14.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:14.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:14.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:15.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:15.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:15.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:16.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:16.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:16.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:17.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:17.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:17.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:18.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:18.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:18.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:19.906: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:19.906: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:19.906: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:20.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:20.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:20.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:21.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:21.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:21.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:22.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:22.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:22.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:23.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:23.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:23.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:24.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:24.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:24.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:25.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:25.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:25.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:26.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:26.903: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:26.903: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:27.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:27.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:27.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:28.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:28.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:28.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:29.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:29.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:29.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:30.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:30.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:30.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:31.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:31.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:31.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:32.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:32.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:32.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:33.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:33.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:33.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:34.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:34.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:34.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:35.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:35.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:35.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:36.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:36.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:36.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:37.903: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:37.903: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:37.903: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:38.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:38.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:38.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:39.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:39.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:39.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:40.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:40.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:40.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:41.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:41.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:41.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:42.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:42.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:42.902: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:43.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:43.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:43.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:44.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:44.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:44.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:45.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:45.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:45.900: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:45.900: INFO: Pod daemon-set-z5ncj is not available
Feb 19 11:50:46.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:46.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:46.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:46.901: INFO: Pod daemon-set-z5ncj is not available
Feb 19 11:50:47.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:47.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:47.901: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:47.901: INFO: Pod daemon-set-z5ncj is not available
Feb 19 11:50:48.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:48.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:48.899: INFO: Wrong image for pod: daemon-set-z5ncj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:48.899: INFO: Pod daemon-set-z5ncj is not available
Feb 19 11:50:49.900: INFO: Pod daemon-set-5k96f is not available
Feb 19 11:50:49.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:49.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:50.900: INFO: Pod daemon-set-5k96f is not available
Feb 19 11:50:50.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:50.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:51.900: INFO: Pod daemon-set-5k96f is not available
Feb 19 11:50:51.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:51.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:52.900: INFO: Pod daemon-set-5k96f is not available
Feb 19 11:50:52.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:52.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:53.899: INFO: Pod daemon-set-5k96f is not available
Feb 19 11:50:53.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:53.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:54.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:54.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:55.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:55.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:56.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:56.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:57.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:57.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:58.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:58.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:59.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:50:59.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:00.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:00.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:01.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:01.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:02.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:02.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:03.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:03.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:04.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:04.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:05.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:05.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:06.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:06.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:07.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:07.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:08.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:08.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:09.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:09.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:10.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:10.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:11.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:11.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:12.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:12.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:13.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:13.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:14.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:14.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:15.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:15.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:16.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:16.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:17.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:17.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:18.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:18.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:19.903: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:19.903: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:20.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:20.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:21.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:21.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:22.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:22.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:23.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:23.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:24.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:24.900: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:25.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:25.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:25.901: INFO: Pod daemon-set-vqhkz is not available
Feb 19 11:51:26.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:26.899: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:26.899: INFO: Pod daemon-set-vqhkz is not available
Feb 19 11:51:27.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:27.902: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:27.902: INFO: Pod daemon-set-vqhkz is not available
Feb 19 11:51:28.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:28.901: INFO: Wrong image for pod: daemon-set-vqhkz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:28.901: INFO: Pod daemon-set-vqhkz is not available
Feb 19 11:51:29.900: INFO: Pod daemon-set-dhgxc is not available
Feb 19 11:51:29.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:30.899: INFO: Pod daemon-set-dhgxc is not available
Feb 19 11:51:30.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:31.899: INFO: Pod daemon-set-dhgxc is not available
Feb 19 11:51:31.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:32.899: INFO: Pod daemon-set-dhgxc is not available
Feb 19 11:51:32.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:33.900: INFO: Pod daemon-set-dhgxc is not available
Feb 19 11:51:33.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:34.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:35.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:36.905: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:37.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:38.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:39.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:40.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:41.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:42.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:43.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:44.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:45.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:46.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:47.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:48.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:49.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:50.898: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:51.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:52.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:53.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:54.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:55.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:56.901: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:57.903: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:58.902: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:51:59.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:00.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:01.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:02.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:03.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:04.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:05.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:05.900: INFO: Pod daemon-set-hkvvq is not available
Feb 19 11:52:06.899: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:06.899: INFO: Pod daemon-set-hkvvq is not available
Feb 19 11:52:07.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:07.900: INFO: Pod daemon-set-hkvvq is not available
Feb 19 11:52:08.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:08.900: INFO: Pod daemon-set-hkvvq is not available
Feb 19 11:52:09.900: INFO: Wrong image for pod: daemon-set-hkvvq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 19 11:52:09.900: INFO: Pod daemon-set-hkvvq is not available
Feb 19 11:52:10.901: INFO: Pod daemon-set-2blht is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 19 11:52:10.918: INFO: Number of nodes with available pods: 4
Feb 19 11:52:10.918: INFO: Node kube-node-20-105 is running more than one daemon pod
Feb 19 11:52:11.931: INFO: Number of nodes with available pods: 4
Feb 19 11:52:11.931: INFO: Node kube-node-20-105 is running more than one daemon pod
Feb 19 11:52:12.932: INFO: Number of nodes with available pods: 4
Feb 19 11:52:12.932: INFO: Node kube-node-20-105 is running more than one daemon pod
Feb 19 11:52:13.932: INFO: Number of nodes with available pods: 4
Feb 19 11:52:13.932: INFO: Node kube-node-20-105 is running more than one daemon pod
Feb 19 11:52:14.935: INFO: Number of nodes with available pods: 4
Feb 19 11:52:14.935: INFO: Node kube-node-20-105 is running more than one daemon pod
Feb 19 11:52:15.930: INFO: Number of nodes with available pods: 5
Feb 19 11:52:15.930: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-wxq6z, will wait for the garbage collector to delete the pods
Feb 19 11:52:16.024: INFO: Deleting {extensions DaemonSet} daemon-set took: 14.696891ms
Feb 19 11:52:16.124: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.295679ms
Feb 19 11:52:30.531: INFO: Number of nodes with available pods: 0
Feb 19 11:52:30.531: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 11:52:30.535: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wxq6z/daemonsets","resourceVersion":"938316"},"items":null}

Feb 19 11:52:30.540: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wxq6z/pods","resourceVersion":"938316"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:52:30.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wxq6z" for this suite.
Feb 19 11:52:36.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:52:36.646: INFO: namespace: e2e-tests-daemonsets-wxq6z, resource: bindings, ignored listing per whitelist
Feb 19 11:52:36.759: INFO: namespace e2e-tests-daemonsets-wxq6z deletion completed in 6.187088762s

• [SLOW TEST:234.219 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:52:36.760: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-5w826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 11:52:36.985: INFO: Creating deployment "test-recreate-deployment"
Feb 19 11:52:36.998: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 19 11:52:37.008: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 19 11:52:39.020: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 19 11:52:39.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 11:52:41.030: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686173957, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 11:52:43.030: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 19 11:52:43.041: INFO: Updating deployment test-recreate-deployment
Feb 19 11:52:43.041: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 11:52:43.161: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-5w826,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5w826/deployments/test-recreate-deployment,UID:d9e540ba-343c-11e9-b551-525400c68782,ResourceVersion:938383,Generation:2,CreationTimestamp:2019-02-19 11:52:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-19 11:52:43 +0000 UTC 2019-02-19 11:52:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-19 11:52:43 +0000 UTC 2019-02-19 11:52:37 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 19 11:52:43.173: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-5w826,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5w826/replicasets/test-recreate-deployment-7cf749666b,UID:dd87a4af-343c-11e9-a5f4-5254000cc78a,ResourceVersion:938381,Generation:1,CreationTimestamp:2019-02-19 11:52:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d9e540ba-343c-11e9-b551-525400c68782 0xc4227ad147 0xc4227ad148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 11:52:43.173: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 19 11:52:43.173: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-5w826,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5w826/replicasets/test-recreate-deployment-79f694ff59,UID:d9e81d94-343c-11e9-a5f4-5254000cc78a,ResourceVersion:938373,Generation:2,CreationTimestamp:2019-02-19 11:52:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d9e540ba-343c-11e9-b551-525400c68782 0xc4227ad087 0xc4227ad088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 11:52:43.179: INFO: Pod "test-recreate-deployment-7cf749666b-ph72d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-ph72d,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-5w826,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5w826/pods/test-recreate-deployment-7cf749666b-ph72d,UID:dd891f5e-343c-11e9-a5f4-5254000cc78a,ResourceVersion:938382,Generation:0,CreationTimestamp:2019-02-19 11:52:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b dd87a4af-343c-11e9-a5f4-5254000cc78a 0xc420a14d27 0xc420a14d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kv42c {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kv42c,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kv42c true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-105,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 11:52:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 11:52:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 11:52:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 11:52:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.105,PodIP:,StartTime:2019-02-19 11:52:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:52:43.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5w826" for this suite.
Feb 19 11:52:49.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:52:49.329: INFO: namespace: e2e-tests-deployment-5w826, resource: bindings, ignored listing per whitelist
Feb 19 11:52:49.346: INFO: namespace e2e-tests-deployment-5w826 deletion completed in 6.16125939s

• [SLOW TEST:12.587 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:52:49.347: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-txz7q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 19 11:52:49.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:52:50.123: INFO: stderr: ""
Feb 19 11:52:50.123: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 11:52:50.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:52:50.262: INFO: stderr: ""
Feb 19 11:52:50.262: INFO: stdout: "update-demo-nautilus-ctsw6 update-demo-nautilus-wbsv5 "
Feb 19 11:52:50.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:52:50.385: INFO: stderr: ""
Feb 19 11:52:50.385: INFO: stdout: ""
Feb 19 11:52:50.385: INFO: update-demo-nautilus-ctsw6 is created but not running
Feb 19 11:52:55.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:52:55.535: INFO: stderr: ""
Feb 19 11:52:55.535: INFO: stdout: "update-demo-nautilus-ctsw6 update-demo-nautilus-wbsv5 "
Feb 19 11:52:55.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:52:55.661: INFO: stderr: ""
Feb 19 11:52:55.661: INFO: stdout: ""
Feb 19 11:52:55.661: INFO: update-demo-nautilus-ctsw6 is created but not running
Feb 19 11:53:00.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:00.806: INFO: stderr: ""
Feb 19 11:53:00.806: INFO: stdout: "update-demo-nautilus-ctsw6 update-demo-nautilus-wbsv5 "
Feb 19 11:53:00.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:00.921: INFO: stderr: ""
Feb 19 11:53:00.921: INFO: stdout: ""
Feb 19 11:53:00.921: INFO: update-demo-nautilus-ctsw6 is created but not running
Feb 19 11:53:05.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:06.064: INFO: stderr: ""
Feb 19 11:53:06.064: INFO: stdout: "update-demo-nautilus-ctsw6 update-demo-nautilus-wbsv5 "
Feb 19 11:53:06.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:06.204: INFO: stderr: ""
Feb 19 11:53:06.204: INFO: stdout: ""
Feb 19 11:53:06.204: INFO: update-demo-nautilus-ctsw6 is created but not running
Feb 19 11:53:11.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:11.350: INFO: stderr: ""
Feb 19 11:53:11.350: INFO: stdout: "update-demo-nautilus-ctsw6 update-demo-nautilus-wbsv5 "
Feb 19 11:53:11.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:11.483: INFO: stderr: ""
Feb 19 11:53:11.483: INFO: stdout: ""
Feb 19 11:53:11.483: INFO: update-demo-nautilus-ctsw6 is created but not running
Feb 19 11:53:16.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:16.623: INFO: stderr: ""
Feb 19 11:53:16.623: INFO: stdout: "update-demo-nautilus-ctsw6 update-demo-nautilus-wbsv5 "
Feb 19 11:53:16.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:16.780: INFO: stderr: ""
Feb 19 11:53:16.780: INFO: stdout: "true"
Feb 19 11:53:16.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-ctsw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:16.897: INFO: stderr: ""
Feb 19 11:53:16.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 11:53:16.897: INFO: validating pod update-demo-nautilus-ctsw6
Feb 19 11:53:16.914: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 11:53:16.914: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 11:53:16.914: INFO: update-demo-nautilus-ctsw6 is verified up and running
Feb 19 11:53:16.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-wbsv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:17.029: INFO: stderr: ""
Feb 19 11:53:17.030: INFO: stdout: "true"
Feb 19 11:53:17.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-wbsv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:17.143: INFO: stderr: ""
Feb 19 11:53:17.143: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 11:53:17.143: INFO: validating pod update-demo-nautilus-wbsv5
Feb 19 11:53:17.153: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 11:53:17.153: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 11:53:17.153: INFO: update-demo-nautilus-wbsv5 is verified up and running
STEP: rolling-update to new replication controller
Feb 19 11:53:17.155: INFO: scanned /root for discovery docs: <nil>
Feb 19 11:53:17.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:44.867: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 19 11:53:44.867: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 11:53:44.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:45.017: INFO: stderr: ""
Feb 19 11:53:45.017: INFO: stdout: "update-demo-kitten-7tcnx update-demo-kitten-d9djp "
Feb 19 11:53:45.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-kitten-7tcnx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:45.134: INFO: stderr: ""
Feb 19 11:53:45.134: INFO: stdout: "true"
Feb 19 11:53:45.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-kitten-7tcnx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:45.253: INFO: stderr: ""
Feb 19 11:53:45.253: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 19 11:53:45.253: INFO: validating pod update-demo-kitten-7tcnx
Feb 19 11:53:45.263: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 19 11:53:45.263: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 19 11:53:45.263: INFO: update-demo-kitten-7tcnx is verified up and running
Feb 19 11:53:45.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-kitten-d9djp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:45.382: INFO: stderr: ""
Feb 19 11:53:45.382: INFO: stdout: "true"
Feb 19 11:53:45.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-kitten-d9djp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-txz7q'
Feb 19 11:53:45.503: INFO: stderr: ""
Feb 19 11:53:45.503: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 19 11:53:45.503: INFO: validating pod update-demo-kitten-d9djp
Feb 19 11:53:45.511: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 19 11:53:45.511: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 19 11:53:45.511: INFO: update-demo-kitten-d9djp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:53:45.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-txz7q" for this suite.
Feb 19 11:54:07.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:54:07.635: INFO: namespace: e2e-tests-kubectl-txz7q, resource: bindings, ignored listing per whitelist
Feb 19 11:54:07.703: INFO: namespace e2e-tests-kubectl-txz7q deletion completed in 22.184856576s

• [SLOW TEST:78.356 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:54:07.703: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-q7rcw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 19 11:54:08.487: INFO: created pod pod-service-account-defaultsa
Feb 19 11:54:08.487: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 19 11:54:08.497: INFO: created pod pod-service-account-mountsa
Feb 19 11:54:08.497: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 19 11:54:08.508: INFO: created pod pod-service-account-nomountsa
Feb 19 11:54:08.508: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 19 11:54:08.527: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 19 11:54:08.527: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 19 11:54:08.539: INFO: created pod pod-service-account-mountsa-mountspec
Feb 19 11:54:08.539: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 19 11:54:08.551: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 19 11:54:08.551: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 19 11:54:08.570: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 19 11:54:08.570: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 19 11:54:08.593: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 19 11:54:08.594: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 19 11:54:08.616: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 19 11:54:08.616: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:54:08.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-q7rcw" for this suite.
Feb 19 11:54:32.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:54:32.667: INFO: namespace: e2e-tests-svcaccounts-q7rcw, resource: bindings, ignored listing per whitelist
Feb 19 11:54:32.804: INFO: namespace e2e-tests-svcaccounts-q7rcw deletion completed in 24.180077795s

• [SLOW TEST:25.101 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:54:32.805: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-lcn5m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 19 11:55:25.572: INFO: Successfully updated pod "pod-update-1f0ef640-343d-11e9-af36-92091ca56148"
STEP: verifying the updated pod is in kubernetes
Feb 19 11:55:25.580: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:55:25.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lcn5m" for this suite.
Feb 19 11:55:47.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:55:47.646: INFO: namespace: e2e-tests-pods-lcn5m, resource: bindings, ignored listing per whitelist
Feb 19 11:55:47.770: INFO: namespace e2e-tests-pods-lcn5m deletion completed in 22.183723911s

• [SLOW TEST:74.966 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:55:47.770: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-4vgmx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4vgmx
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 11:55:48.008: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 11:56:18.200: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.65.157 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4vgmx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 11:56:18.200: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 11:56:19.329: INFO: Found all expected endpoints: [netserver-0]
Feb 19 11:56:19.334: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.68.158 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4vgmx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 11:56:19.334: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 11:56:20.462: INFO: Found all expected endpoints: [netserver-1]
Feb 19 11:56:20.467: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.66.152 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4vgmx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 11:56:20.467: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 11:56:21.595: INFO: Found all expected endpoints: [netserver-2]
Feb 19 11:56:21.602: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.67.224 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4vgmx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 11:56:21.602: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 11:56:22.736: INFO: Found all expected endpoints: [netserver-3]
Feb 19 11:56:22.741: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.64.10 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4vgmx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 11:56:22.741: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 11:56:23.888: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:56:23.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4vgmx" for this suite.
Feb 19 11:56:43.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:56:43.936: INFO: namespace: e2e-tests-pod-network-test-4vgmx, resource: bindings, ignored listing per whitelist
Feb 19 11:56:44.074: INFO: namespace e2e-tests-pod-network-test-4vgmx deletion completed in 20.180063578s

• [SLOW TEST:56.304 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:56:44.075: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nn2hs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 11:56:44.327: INFO: Waiting up to 5m0s for pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-nn2hs" to be "success or failure"
Feb 19 11:56:44.331: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 3.773501ms
Feb 19 11:56:46.337: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010345149s
Feb 19 11:56:48.343: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0163109s
Feb 19 11:56:50.349: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022285447s
Feb 19 11:56:52.356: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028629582s
Feb 19 11:56:54.361: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.033971028s
Feb 19 11:56:56.367: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.040567849s
Feb 19 11:56:58.374: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.047136325s
Feb 19 11:57:00.381: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.053771911s
Feb 19 11:57:02.386: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.059612028s
Feb 19 11:57:04.393: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.066026094s
Feb 19 11:57:06.400: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.073128555s
Feb 19 11:57:08.406: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.079251619s
Feb 19 11:57:10.413: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.085995833s
Feb 19 11:57:12.419: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 28.092615355s
Feb 19 11:57:14.426: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 30.098731692s
Feb 19 11:57:16.431: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 32.104086299s
Feb 19 11:57:18.437: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 34.109976189s
Feb 19 11:57:20.443: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 36.11585246s
Feb 19 11:57:22.450: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 38.122835636s
Feb 19 11:57:24.456: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 40.128897303s
Feb 19 11:57:26.463: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 42.136495827s
Feb 19 11:57:28.470: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 44.142893007s
STEP: Saw pod success
Feb 19 11:57:28.470: INFO: Pod "downward-api-6d5051d8-343d-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:57:28.474: INFO: Trying to get logs from node kube-node-20-104 pod downward-api-6d5051d8-343d-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 11:57:28.516: INFO: Waiting for pod downward-api-6d5051d8-343d-11e9-af36-92091ca56148 to disappear
Feb 19 11:57:28.521: INFO: Pod downward-api-6d5051d8-343d-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:57:28.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nn2hs" for this suite.
Feb 19 11:57:34.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:57:34.641: INFO: namespace: e2e-tests-downward-api-nn2hs, resource: bindings, ignored listing per whitelist
Feb 19 11:57:34.714: INFO: namespace e2e-tests-downward-api-nn2hs deletion completed in 6.186070921s

• [SLOW TEST:50.639 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:57:34.714: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5f5cm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-5f5cm/secret-test-8b7eb6b0-343d-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 11:57:34.972: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-5f5cm" to be "success or failure"
Feb 19 11:57:34.977: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.199719ms
Feb 19 11:57:36.983: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01127388s
Feb 19 11:57:38.990: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017934569s
Feb 19 11:57:40.996: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024036512s
Feb 19 11:57:43.003: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031683256s
Feb 19 11:57:45.009: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037633656s
Feb 19 11:57:47.016: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.043893097s
Feb 19 11:57:49.021: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.049695493s
Feb 19 11:57:51.028: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056158326s
Feb 19 11:57:53.034: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.062449173s
Feb 19 11:57:55.042: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.070121807s
Feb 19 11:57:57.049: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.077235255s
Feb 19 11:57:59.055: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.083663832s
Feb 19 11:58:01.061: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.089081118s
Feb 19 11:58:03.068: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 28.095971124s
Feb 19 11:58:05.083: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 30.111699293s
Feb 19 11:58:07.090: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 32.11835425s
Feb 19 11:58:09.097: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 34.125339328s
Feb 19 11:58:11.103: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 36.131520854s
Feb 19 11:58:13.109: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 38.137369993s
Feb 19 11:58:15.117: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 40.144814832s
Feb 19 11:58:17.124: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 42.15197722s
Feb 19 11:58:19.133: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 44.161101413s
Feb 19 11:58:21.139: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 46.167235894s
Feb 19 11:58:23.145: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 48.173186893s
Feb 19 11:58:25.151: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 50.178991127s
Feb 19 11:58:27.157: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 52.185271007s
Feb 19 11:58:29.163: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 54.191205125s
Feb 19 11:58:31.170: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 56.198348134s
Feb 19 11:58:33.176: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 58.204267469s
Feb 19 11:58:35.182: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.210238003s
Feb 19 11:58:37.188: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.216601216s
Feb 19 11:58:39.195: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.222826776s
Feb 19 11:58:41.201: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.229511224s
Feb 19 11:58:43.208: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.236146675s
Feb 19 11:58:45.218: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m10.246181852s
STEP: Saw pod success
Feb 19 11:58:45.218: INFO: Pod "pod-configmaps-8b801404-343d-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 11:58:45.223: INFO: Trying to get logs from node kube-node-20-105 pod pod-configmaps-8b801404-343d-11e9-af36-92091ca56148 container env-test: <nil>
STEP: delete the pod
Feb 19 11:58:45.256: INFO: Waiting for pod pod-configmaps-8b801404-343d-11e9-af36-92091ca56148 to disappear
Feb 19 11:58:45.261: INFO: Pod pod-configmaps-8b801404-343d-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 11:58:45.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5f5cm" for this suite.
Feb 19 11:58:51.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 11:58:51.300: INFO: namespace: e2e-tests-secrets-5f5cm, resource: bindings, ignored listing per whitelist
Feb 19 11:58:51.435: INFO: namespace e2e-tests-secrets-5f5cm deletion completed in 6.166596486s

• [SLOW TEST:76.721 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 11:58:51.435: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-xwwzl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 11:58:51.718: INFO: Number of nodes with available pods: 0
Feb 19 11:58:51.718: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:52.730: INFO: Number of nodes with available pods: 0
Feb 19 11:58:52.730: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:53.734: INFO: Number of nodes with available pods: 0
Feb 19 11:58:53.734: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:54.732: INFO: Number of nodes with available pods: 0
Feb 19 11:58:54.732: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:55.733: INFO: Number of nodes with available pods: 0
Feb 19 11:58:55.733: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:56.732: INFO: Number of nodes with available pods: 0
Feb 19 11:58:56.732: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:57.732: INFO: Number of nodes with available pods: 4
Feb 19 11:58:57.732: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 11:58:58.735: INFO: Number of nodes with available pods: 5
Feb 19 11:58:58.735: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 19 11:58:58.780: INFO: Number of nodes with available pods: 4
Feb 19 11:58:58.780: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:58:59.793: INFO: Number of nodes with available pods: 4
Feb 19 11:58:59.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:00.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:00.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:01.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:01.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:02.792: INFO: Number of nodes with available pods: 4
Feb 19 11:59:02.792: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:03.799: INFO: Number of nodes with available pods: 4
Feb 19 11:59:03.799: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:04.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:04.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:05.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:05.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:06.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:06.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:07.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:07.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:08.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:08.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:09.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:09.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:10.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:10.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:11.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:11.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:12.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:12.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:13.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:13.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:14.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:14.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:15.796: INFO: Number of nodes with available pods: 4
Feb 19 11:59:15.796: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:16.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:16.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:17.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:17.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:18.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:18.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:19.792: INFO: Number of nodes with available pods: 4
Feb 19 11:59:19.792: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:20.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:20.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:21.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:21.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:22.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:22.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:23.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:23.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:24.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:24.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:25.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:25.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:26.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:26.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:27.792: INFO: Number of nodes with available pods: 4
Feb 19 11:59:27.792: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:28.796: INFO: Number of nodes with available pods: 4
Feb 19 11:59:28.796: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:29.792: INFO: Number of nodes with available pods: 4
Feb 19 11:59:29.792: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:30.792: INFO: Number of nodes with available pods: 4
Feb 19 11:59:30.792: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:31.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:31.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:32.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:32.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:33.799: INFO: Number of nodes with available pods: 4
Feb 19 11:59:33.799: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:34.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:34.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:35.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:35.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:36.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:36.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:37.796: INFO: Number of nodes with available pods: 4
Feb 19 11:59:37.796: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:38.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:38.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:39.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:39.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:40.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:40.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:41.795: INFO: Number of nodes with available pods: 4
Feb 19 11:59:41.795: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:42.794: INFO: Number of nodes with available pods: 4
Feb 19 11:59:42.794: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:43.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:43.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:44.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:44.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:45.793: INFO: Number of nodes with available pods: 4
Feb 19 11:59:45.793: INFO: Node kube-node-20-104 is running more than one daemon pod
Feb 19 11:59:46.793: INFO: Number of nodes with available pods: 5
Feb 19 11:59:46.793: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-xwwzl, will wait for the garbage collector to delete the pods
Feb 19 11:59:46.865: INFO: Deleting {extensions DaemonSet} daemon-set took: 13.100281ms
Feb 19 11:59:46.966: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.330574ms
Feb 19 12:00:30.272: INFO: Number of nodes with available pods: 0
Feb 19 12:00:30.272: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 12:00:30.276: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xwwzl/daemonsets","resourceVersion":"939657"},"items":null}

Feb 19 12:00:30.280: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xwwzl/pods","resourceVersion":"939657"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:00:30.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xwwzl" for this suite.
Feb 19 12:00:36.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:00:36.427: INFO: namespace: e2e-tests-daemonsets-xwwzl, resource: bindings, ignored listing per whitelist
Feb 19 12:00:36.496: INFO: namespace e2e-tests-daemonsets-xwwzl deletion completed in 6.182663754s

• [SLOW TEST:105.061 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:00:36.497: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6mdr6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:00:36.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-6mdr6" to be "success or failure"
Feb 19 12:00:36.744: INFO: Pod "downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040204ms
Feb 19 12:00:38.751: INFO: Pod "downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01082509s
Feb 19 12:00:40.759: INFO: Pod "downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019724183s
Feb 19 12:00:42.767: INFO: Pod "downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026916752s
STEP: Saw pod success
Feb 19 12:00:42.767: INFO: Pod "downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:00:42.771: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:00:42.800: INFO: Waiting for pod downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148 to disappear
Feb 19 12:00:42.804: INFO: Pod downwardapi-volume-f7d796b5-343d-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:00:42.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6mdr6" for this suite.
Feb 19 12:00:48.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:00:48.914: INFO: namespace: e2e-tests-downward-api-6mdr6, resource: bindings, ignored listing per whitelist
Feb 19 12:00:48.983: INFO: namespace e2e-tests-downward-api-6mdr6 deletion completed in 6.172176401s

• [SLOW TEST:12.486 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:00:48.984: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-pdrf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 19 12:00:49.232: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-pdrf7" to be "success or failure"
Feb 19 12:00:49.239: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.045464ms
Feb 19 12:00:51.245: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013609912s
Feb 19 12:00:53.252: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019815419s
Feb 19 12:00:55.258: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026218412s
Feb 19 12:00:57.264: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032138206s
Feb 19 12:00:59.272: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.039727832s
STEP: Saw pod success
Feb 19 12:00:59.272: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 19 12:00:59.277: INFO: Trying to get logs from node kube-node-20-105 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 19 12:00:59.306: INFO: Waiting for pod pod-host-path-test to disappear
Feb 19 12:00:59.312: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:00:59.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-pdrf7" for this suite.
Feb 19 12:01:05.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:01:05.395: INFO: namespace: e2e-tests-hostpath-pdrf7, resource: bindings, ignored listing per whitelist
Feb 19 12:01:05.476: INFO: namespace e2e-tests-hostpath-pdrf7 deletion completed in 6.158215196s

• [SLOW TEST:16.493 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:01:05.477: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-t7k8c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:01:05.719: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 19 12:01:10.725: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 12:02:24.736: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 19 12:02:26.743: INFO: Creating deployment "test-rollover-deployment"
Feb 19 12:02:26.763: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 19 12:02:28.774: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 19 12:02:28.783: INFO: Ensure that both replica sets have 1 created replica
Feb 19 12:02:28.792: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 19 12:02:28.806: INFO: Updating deployment test-rollover-deployment
Feb 19 12:02:28.806: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 19 12:02:30.815: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 19 12:02:30.824: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 19 12:02:30.834: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:30.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174548, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:32.847: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:32.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174548, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:34.846: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:34.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174548, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:36.845: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:36.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174555, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:38.847: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:38.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174555, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:40.845: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:40.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174555, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:42.845: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:42.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174555, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:44.848: INFO: all replica sets need to contain the pod-template-hash label
Feb 19 12:02:44.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174555, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:02:46.845: INFO: 
Feb 19 12:02:46.845: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 12:02:46.863: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-t7k8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t7k8c/deployments/test-rollover-deployment,UID:396b3a41-343e-11e9-b551-525400c68782,ResourceVersion:940022,Generation:2,CreationTimestamp:2019-02-19 12:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-19 12:02:26 +0000 UTC 2019-02-19 12:02:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-19 12:02:45 +0000 UTC 2019-02-19 12:02:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 19 12:02:46.868: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-t7k8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t7k8c/replicasets/test-rollover-deployment-5b76ff8c4,UID:3aa623c8-343e-11e9-a5f4-5254000cc78a,ResourceVersion:940015,Generation:2,CreationTimestamp:2019-02-19 12:02:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 396b3a41-343e-11e9-b551-525400c68782 0xc4226f3e57 0xc4226f3e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 12:02:46.868: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 19 12:02:46.868: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-t7k8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t7k8c/replicasets/test-rollover-controller,UID:091e0f10-343e-11e9-b551-525400c68782,ResourceVersion:940021,Generation:2,CreationTimestamp:2019-02-19 12:01:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 396b3a41-343e-11e9-b551-525400c68782 0xc4226f3d8e 0xc4226f3d8f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 12:02:46.868: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-t7k8c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t7k8c/replicasets/test-rollover-deployment-6975f4fb87,UID:39702312-343e-11e9-a5f4-5254000cc78a,ResourceVersion:939972,Generation:2,CreationTimestamp:2019-02-19 12:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 396b3a41-343e-11e9-b551-525400c68782 0xc4226f3fe7 0xc4226f3fe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 12:02:46.873: INFO: Pod "test-rollover-deployment-5b76ff8c4-wbxzq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-wbxzq,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-t7k8c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t7k8c/pods/test-rollover-deployment-5b76ff8c4-wbxzq,UID:3aac742e-343e-11e9-a5f4-5254000cc78a,ResourceVersion:939992,Generation:0,CreationTimestamp:2019-02-19 12:02:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.67.230/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 3aa623c8-343e-11e9-a5f4-5254000cc78a 0xc4227addf0 0xc4227addf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mq6qr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mq6qr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mq6qr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:02:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:02:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:02:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:02:28 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.104,PodIP:192.168.67.230,StartTime:2019-02-19 12:02:28 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-19 12:02:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0513adfac130d10387ca8f628bb2916d5ed49ec6a8fa15598f475f060712fc6e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:02:46.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-t7k8c" for this suite.
Feb 19 12:02:52.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:02:52.937: INFO: namespace: e2e-tests-deployment-t7k8c, resource: bindings, ignored listing per whitelist
Feb 19 12:02:53.090: INFO: namespace e2e-tests-deployment-t7k8c deletion completed in 6.209594372s

• [SLOW TEST:107.613 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:02:53.090: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b4cmb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 19 12:02:53.309: INFO: namespace e2e-tests-kubectl-b4cmb
Feb 19 12:02:53.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-b4cmb'
Feb 19 12:02:53.791: INFO: stderr: ""
Feb 19 12:02:53.792: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 12:02:54.798: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:54.798: INFO: Found 0 / 1
Feb 19 12:02:55.798: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:55.798: INFO: Found 0 / 1
Feb 19 12:02:56.798: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:56.798: INFO: Found 0 / 1
Feb 19 12:02:57.799: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:57.799: INFO: Found 0 / 1
Feb 19 12:02:58.800: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:58.800: INFO: Found 0 / 1
Feb 19 12:02:59.799: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:59.799: INFO: Found 1 / 1
Feb 19 12:02:59.799: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 12:02:59.803: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:02:59.803: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 12:02:59.803: INFO: wait on redis-master startup in e2e-tests-kubectl-b4cmb 
Feb 19 12:02:59.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 logs redis-master-rpsz9 redis-master --namespace=e2e-tests-kubectl-b4cmb'
Feb 19 12:03:00.011: INFO: stderr: ""
Feb 19 12:03:00.011: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 12:02:59.025 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 12:02:59.025 # Server started, Redis version 3.2.12\n1:M 19 Feb 12:02:59.026 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 12:02:59.026 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 19 12:03:00.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-b4cmb'
Feb 19 12:03:00.175: INFO: stderr: ""
Feb 19 12:03:00.176: INFO: stdout: "service/rm2 exposed\n"
Feb 19 12:03:00.182: INFO: Service rm2 in namespace e2e-tests-kubectl-b4cmb found.
STEP: exposing service
Feb 19 12:03:02.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-b4cmb'
Feb 19 12:03:02.359: INFO: stderr: ""
Feb 19 12:03:02.359: INFO: stdout: "service/rm3 exposed\n"
Feb 19 12:03:02.364: INFO: Service rm3 in namespace e2e-tests-kubectl-b4cmb found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:03:04.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b4cmb" for this suite.
Feb 19 12:03:26.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:03:26.466: INFO: namespace: e2e-tests-kubectl-b4cmb, resource: bindings, ignored listing per whitelist
Feb 19 12:03:26.576: INFO: namespace e2e-tests-kubectl-b4cmb deletion completed in 22.195469985s

• [SLOW TEST:33.486 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:03:26.577: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-tsbmp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 19 12:04:14.844: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-5d371ed4-343e-11e9-af36-92091ca56148", GenerateName:"", Namespace:"e2e-tests-pods-tsbmp", SelfLink:"/api/v1/namespaces/e2e-tests-pods-tsbmp/pods/pod-submit-remove-5d371ed4-343e-11e9-af36-92091ca56148", UID:"5d390a25-343e-11e9-b551-525400c68782", ResourceVersion:"940254", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686174606, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"802113749"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.67.231/32", "kubernetes.io/psp":"00-privileged"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jpc65", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420b51000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jpc65", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420bea388), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube-node-20-104", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4218a57a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174606, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174653, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174653, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686174606, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.20.104", PodIP:"192.168.67.231", StartTime:(*v1.Time)(0xc421b87e60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421b87ea0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://aeb2c7fc063c8b5830b94ac4475ebc5f483d79f8c24af64e25e4eb0295732c15"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:04:20.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tsbmp" for this suite.
Feb 19 12:04:26.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:04:26.381: INFO: namespace: e2e-tests-pods-tsbmp, resource: bindings, ignored listing per whitelist
Feb 19 12:04:26.467: INFO: namespace e2e-tests-pods-tsbmp deletion completed in 6.18817786s

• [SLOW TEST:59.890 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:04:26.468: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-gmjhq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-5p2zl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-w68xn
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:04:33.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-gmjhq" for this suite.
Feb 19 12:04:39.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:04:39.114: INFO: namespace: e2e-tests-namespaces-gmjhq, resource: bindings, ignored listing per whitelist
Feb 19 12:04:39.273: INFO: namespace e2e-tests-namespaces-gmjhq deletion completed in 6.214634771s
STEP: Destroying namespace "e2e-tests-nsdeletetest-5p2zl" for this suite.
Feb 19 12:04:39.278: INFO: Namespace e2e-tests-nsdeletetest-5p2zl was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-w68xn" for this suite.
Feb 19 12:04:45.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:04:45.344: INFO: namespace: e2e-tests-nsdeletetest-w68xn, resource: bindings, ignored listing per whitelist
Feb 19 12:04:45.445: INFO: namespace e2e-tests-nsdeletetest-w68xn deletion completed in 6.16668155s

• [SLOW TEST:18.977 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:04:45.446: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-thb74
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 19 12:04:45.680: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940373,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 12:04:45.681: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940373,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 19 12:04:55.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940393,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 19 12:04:55.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940393,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 19 12:05:05.704: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940413,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 12:05:05.704: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940413,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 19 12:05:15.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940434,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 12:05:15.715: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-a,UID:8c3a43eb-343e-11e9-b551-525400c68782,ResourceVersion:940434,Generation:0,CreationTimestamp:2019-02-19 12:04:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 19 12:05:25.727: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-b,UID:a41838fc-343e-11e9-b551-525400c68782,ResourceVersion:940454,Generation:0,CreationTimestamp:2019-02-19 12:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 12:05:25.727: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-b,UID:a41838fc-343e-11e9-b551-525400c68782,ResourceVersion:940454,Generation:0,CreationTimestamp:2019-02-19 12:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 19 12:05:35.743: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-b,UID:a41838fc-343e-11e9-b551-525400c68782,ResourceVersion:940474,Generation:0,CreationTimestamp:2019-02-19 12:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 12:05:35.743: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-thb74,SelfLink:/api/v1/namespaces/e2e-tests-watch-thb74/configmaps/e2e-watch-test-configmap-b,UID:a41838fc-343e-11e9-b551-525400c68782,ResourceVersion:940474,Generation:0,CreationTimestamp:2019-02-19 12:05:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:05:45.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-thb74" for this suite.
Feb 19 12:05:51.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:05:51.825: INFO: namespace: e2e-tests-watch-thb74, resource: bindings, ignored listing per whitelist
Feb 19 12:05:51.922: INFO: namespace e2e-tests-watch-thb74 deletion completed in 6.1708115s

• [SLOW TEST:66.477 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:05:51.923: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9kglh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b3d8761f-343e-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:05:52.161: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-9kglh" to be "success or failure"
Feb 19 12:05:52.166: INFO: Pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.32427ms
Feb 19 12:05:54.172: INFO: Pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010686895s
Feb 19 12:05:56.180: INFO: Pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018853814s
Feb 19 12:05:58.186: INFO: Pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148": Phase="Running", Reason="", readiness=true. Elapsed: 6.025028373s
Feb 19 12:06:00.192: INFO: Pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030813704s
STEP: Saw pod success
Feb 19 12:06:00.192: INFO: Pod "pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:06:00.197: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:06:00.230: INFO: Waiting for pod pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148 to disappear
Feb 19 12:06:00.236: INFO: Pod pod-projected-configmaps-b3d94d48-343e-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:06:00.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9kglh" for this suite.
Feb 19 12:06:06.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:06:06.389: INFO: namespace: e2e-tests-projected-9kglh, resource: bindings, ignored listing per whitelist
Feb 19 12:06:06.427: INFO: namespace e2e-tests-projected-9kglh deletion completed in 6.184040875s

• [SLOW TEST:14.504 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:06:06.428: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-l5dvd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0219 12:06:12.698197      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 12:06:12.698: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:06:12.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l5dvd" for this suite.
Feb 19 12:06:18.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:06:18.822: INFO: namespace: e2e-tests-gc-l5dvd, resource: bindings, ignored listing per whitelist
Feb 19 12:06:18.866: INFO: namespace e2e-tests-gc-l5dvd deletion completed in 6.162712113s

• [SLOW TEST:12.439 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:06:18.867: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x8zbf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 19 12:06:19.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:19.350: INFO: stderr: ""
Feb 19 12:06:19.350: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 12:06:19.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:19.476: INFO: stderr: ""
Feb 19 12:06:19.476: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:19.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:19.605: INFO: stderr: ""
Feb 19 12:06:19.605: INFO: stdout: ""
Feb 19 12:06:19.605: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:24.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:24.740: INFO: stderr: ""
Feb 19 12:06:24.740: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:24.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:24.879: INFO: stderr: ""
Feb 19 12:06:24.879: INFO: stdout: ""
Feb 19 12:06:24.879: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:29.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:30.013: INFO: stderr: ""
Feb 19 12:06:30.013: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:30.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:30.148: INFO: stderr: ""
Feb 19 12:06:30.148: INFO: stdout: ""
Feb 19 12:06:30.148: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:35.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:35.269: INFO: stderr: ""
Feb 19 12:06:35.269: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:35.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:35.409: INFO: stderr: ""
Feb 19 12:06:35.409: INFO: stdout: ""
Feb 19 12:06:35.409: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:40.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:40.555: INFO: stderr: ""
Feb 19 12:06:40.555: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:40.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:40.681: INFO: stderr: ""
Feb 19 12:06:40.681: INFO: stdout: ""
Feb 19 12:06:40.681: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:45.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:45.834: INFO: stderr: ""
Feb 19 12:06:45.834: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:45.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:45.959: INFO: stderr: ""
Feb 19 12:06:45.959: INFO: stdout: ""
Feb 19 12:06:45.959: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:50.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:51.123: INFO: stderr: ""
Feb 19 12:06:51.123: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:51.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:51.277: INFO: stderr: ""
Feb 19 12:06:51.277: INFO: stdout: ""
Feb 19 12:06:51.277: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:06:56.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:56.415: INFO: stderr: ""
Feb 19 12:06:56.415: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:06:56.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:06:56.542: INFO: stderr: ""
Feb 19 12:06:56.542: INFO: stdout: ""
Feb 19 12:06:56.542: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:07:01.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:01.666: INFO: stderr: ""
Feb 19 12:07:01.666: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:07:01.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:01.798: INFO: stderr: ""
Feb 19 12:07:01.798: INFO: stdout: ""
Feb 19 12:07:01.798: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:07:06.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:06.935: INFO: stderr: ""
Feb 19 12:07:06.935: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:07:06.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:07.057: INFO: stderr: ""
Feb 19 12:07:07.057: INFO: stdout: ""
Feb 19 12:07:07.057: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:07:12.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:12.216: INFO: stderr: ""
Feb 19 12:07:12.216: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:07:12.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:12.350: INFO: stderr: ""
Feb 19 12:07:12.351: INFO: stdout: ""
Feb 19 12:07:12.351: INFO: update-demo-nautilus-glcrn is created but not running
Feb 19 12:07:17.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:17.489: INFO: stderr: ""
Feb 19 12:07:17.489: INFO: stdout: "update-demo-nautilus-glcrn update-demo-nautilus-sddd4 "
Feb 19 12:07:17.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:17.622: INFO: stderr: ""
Feb 19 12:07:17.622: INFO: stdout: "true"
Feb 19 12:07:17.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-glcrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:17.747: INFO: stderr: ""
Feb 19 12:07:17.747: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 12:07:17.747: INFO: validating pod update-demo-nautilus-glcrn
Feb 19 12:07:17.759: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 12:07:17.759: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 12:07:17.759: INFO: update-demo-nautilus-glcrn is verified up and running
Feb 19 12:07:17.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-sddd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:17.883: INFO: stderr: ""
Feb 19 12:07:17.883: INFO: stdout: "true"
Feb 19 12:07:17.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-sddd4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:18.010: INFO: stderr: ""
Feb 19 12:07:18.010: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 12:07:18.010: INFO: validating pod update-demo-nautilus-sddd4
Feb 19 12:07:18.021: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 12:07:18.021: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 12:07:18.021: INFO: update-demo-nautilus-sddd4 is verified up and running
STEP: using delete to clean up resources
Feb 19 12:07:18.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:18.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 12:07:18.146: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 19 12:07:18.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-x8zbf'
Feb 19 12:07:18.302: INFO: stderr: "No resources found.\n"
Feb 19 12:07:18.302: INFO: stdout: ""
Feb 19 12:07:18.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -l name=update-demo --namespace=e2e-tests-kubectl-x8zbf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 12:07:18.436: INFO: stderr: ""
Feb 19 12:07:18.436: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:07:18.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x8zbf" for this suite.
Feb 19 12:07:40.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:07:40.616: INFO: namespace: e2e-tests-kubectl-x8zbf, resource: bindings, ignored listing per whitelist
Feb 19 12:07:40.641: INFO: namespace e2e-tests-kubectl-x8zbf deletion completed in 22.197426188s

• [SLOW TEST:81.774 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:07:40.641: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-k4drp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:07:40.863: INFO: Creating deployment "nginx-deployment"
Feb 19 12:07:40.871: INFO: Waiting for observed generation 1
Feb 19 12:07:42.881: INFO: Waiting for all required pods to come up
Feb 19 12:07:42.889: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 19 12:08:50.902: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 19 12:08:50.913: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 19 12:08:50.924: INFO: Updating deployment nginx-deployment
Feb 19 12:08:50.924: INFO: Waiting for observed generation 2
Feb 19 12:08:52.934: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 19 12:08:52.939: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 19 12:08:52.943: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 19 12:08:52.957: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 19 12:08:52.957: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 19 12:08:52.962: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 19 12:08:52.972: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 19 12:08:52.972: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 19 12:08:52.984: INFO: Updating deployment nginx-deployment
Feb 19 12:08:52.984: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 19 12:08:52.992: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 19 12:08:53.002: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 12:08:53.032: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-k4drp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k4drp/deployments/nginx-deployment,UID:f4a621bf-343e-11e9-b551-525400c68782,ResourceVersion:941130,Generation:3,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-02-19 12:08:51 +0000 UTC 2019-02-19 12:07:40 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-02-19 12:08:53 +0000 UTC 2019-02-19 12:08:53 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 19 12:08:53.051: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-k4drp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k4drp/replicasets/nginx-deployment-7dc8f79789,UID:1e689e10-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941127,Generation:3,CreationTimestamp:2019-02-19 12:08:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f4a621bf-343e-11e9-b551-525400c68782 0xc42290d307 0xc42290d308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 12:08:53.051: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 19 12:08:53.051: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-k4drp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k4drp/replicasets/nginx-deployment-7f9675fb8b,UID:f4a87afe-343e-11e9-a5f4-5254000cc78a,ResourceVersion:941126,Generation:3,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f4a621bf-343e-11e9-b551-525400c68782 0xc42290d3c7 0xc42290d3c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 19 12:08:53.088: INFO: Pod "nginx-deployment-7dc8f79789-2txdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2txdd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-2txdd,UID:1faaad81-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941142,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42290dcf7 0xc42290dcf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.088: INFO: Pod "nginx-deployment-7dc8f79789-2zcjx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2zcjx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-2zcjx,UID:1fa7f074-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941146,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42290de80 0xc42290de81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-105,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.089: INFO: Pod "nginx-deployment-7dc8f79789-9qkgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9qkgk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-9qkgk,UID:1fab89b7-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941147,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42290df40 0xc42290df41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.089: INFO: Pod "nginx-deployment-7dc8f79789-g7djl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-g7djl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-g7djl,UID:1e7d1fb5-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941122,Generation:0,CreationTimestamp:2019-02-19 12:08:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.66.158/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216c2b0 0xc42216c2b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.102,PodIP:,StartTime:2019-02-19 12:08:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.092: INFO: Pod "nginx-deployment-7dc8f79789-j9gcm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j9gcm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-j9gcm,UID:1e79de0e-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941121,Generation:0,CreationTimestamp:2019-02-19 12:08:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.65.163/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216c430 0xc42216c431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.103,PodIP:,StartTime:2019-02-19 12:08:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.092: INFO: Pod "nginx-deployment-7dc8f79789-lj5d2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lj5d2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-lj5d2,UID:1e6b6464-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941118,Generation:0,CreationTimestamp:2019-02-19 12:08:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.67.237/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216c7f0 0xc42216c7f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.104,PodIP:,StartTime:2019-02-19 12:08:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.092: INFO: Pod "nginx-deployment-7dc8f79789-qhbpt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qhbpt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-qhbpt,UID:1fab15f1-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941144,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216c9b0 0xc42216c9b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.093: INFO: Pod "nginx-deployment-7dc8f79789-r75qf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-r75qf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-r75qf,UID:1fabdf29-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941149,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216ca50 0xc42216ca51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.093: INFO: Pod "nginx-deployment-7dc8f79789-rk7sx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rk7sx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-rk7sx,UID:1e6c7d44-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941119,Generation:0,CreationTimestamp:2019-02-19 12:08:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.68.171/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216cba0 0xc42216cba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-105,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.105,PodIP:,StartTime:2019-02-19 12:08:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.093: INFO: Pod "nginx-deployment-7dc8f79789-s2hsz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s2hsz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-s2hsz,UID:1fa7bc2c-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941148,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216cd60 0xc42216cd61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.093: INFO: Pod "nginx-deployment-7dc8f79789-wh8tw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wh8tw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-wh8tw,UID:1e6cd307-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941120,Generation:0,CreationTimestamp:2019-02-19 12:08:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.64.16/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216ce20 0xc42216ce21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:50 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.101,PodIP:,StartTime:2019-02-19 12:08:50 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.094: INFO: Pod "nginx-deployment-7dc8f79789-xklwk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xklwk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7dc8f79789-xklwk,UID:1fa54a88-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941134,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1e689e10-343f-11e9-a5f4-5254000cc78a 0xc42216cf90 0xc42216cf91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.094: INFO: Pod "nginx-deployment-7f9675fb8b-5mvbb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5mvbb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-5mvbb,UID:f4b18e01-343e-11e9-a5f4-5254000cc78a,ResourceVersion:941030,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.66.156/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d0d0 0xc42216d0d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.102,PodIP:192.168.66.156,StartTime:2019-02-19 12:07:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:28 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://fad7aa48767baf0249c543a4453ab95dff4b1986df9616767457243596200028}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.095: INFO: Pod "nginx-deployment-7f9675fb8b-8vjvk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8vjvk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-8vjvk,UID:f4b19169-343e-11e9-a5f4-5254000cc78a,ResourceVersion:940971,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.68.169/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d1d7 0xc42216d1d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-105,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.105,PodIP:192.168.68.169,StartTime:2019-02-19 12:07:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1794fd1281613573f1c0b7577752f87139d5180575831d760705228e8fdaa02e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.096: INFO: Pod "nginx-deployment-7f9675fb8b-cfljg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cfljg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-cfljg,UID:1faa3606-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941138,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d3a7 0xc42216d3a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.096: INFO: Pod "nginx-deployment-7f9675fb8b-fdkkb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fdkkb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-fdkkb,UID:f4b0ff79-343e-11e9-a5f4-5254000cc78a,ResourceVersion:941024,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.67.236/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d440 0xc42216d441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.104,PodIP:192.168.67.236,StartTime:2019-02-19 12:07:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://54f5b776505e5a65df212a513fccc63078965f65d3c88b7eceb53826aaab5c4f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.096: INFO: Pod "nginx-deployment-7f9675fb8b-jsr5l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jsr5l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-jsr5l,UID:f4ad1b23-343e-11e9-a5f4-5254000cc78a,ResourceVersion:940988,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.67.235/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d557 0xc42216d558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.104,PodIP:192.168.67.235,StartTime:2019-02-19 12:07:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://af6624820041cb2524fa2fd0af11b973832e5e896038bb6a6332b7c73af2aa73}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.097: INFO: Pod "nginx-deployment-7f9675fb8b-jxwvs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jxwvs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-jxwvs,UID:f4aef1d0-343e-11e9-a5f4-5254000cc78a,ResourceVersion:941005,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.64.15/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d677 0xc42216d678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.101,PodIP:192.168.64.15,StartTime:2019-02-19 12:07:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:21 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://049b28c73e92ee19841dc5389339cd028211bd732ceed05d4952ec6a789f7603}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.097: INFO: Pod "nginx-deployment-7f9675fb8b-l9vkv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-l9vkv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-l9vkv,UID:1fa99aef-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941140,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d777 0xc42216d778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.097: INFO: Pod "nginx-deployment-7f9675fb8b-lpfww" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lpfww,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-lpfww,UID:f4b5f041-343e-11e9-a5f4-5254000cc78a,ResourceVersion:941013,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.65.161/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d810 0xc42216d811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.103,PodIP:192.168.65.161,StartTime:2019-02-19 12:07:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://fe84c9b29267f950c504c36e7acd885fceb59277d412ef31b81711fa19d38b33}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.097: INFO: Pod "nginx-deployment-7f9675fb8b-m95nv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m95nv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-m95nv,UID:1faa668b-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941143,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d917 0xc42216d918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.098: INFO: Pod "nginx-deployment-7f9675fb8b-qjsg2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qjsg2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-qjsg2,UID:1fa420f6-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941131,Generation:0,CreationTimestamp:2019-02-19 12:08:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216d9b0 0xc42216d9b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-101,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.098: INFO: Pod "nginx-deployment-7f9675fb8b-x6zph" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x6zph,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-x6zph,UID:1fa6595e-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941137,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216da60 0xc42216da61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-103,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.098: INFO: Pod "nginx-deployment-7f9675fb8b-xh9f4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xh9f4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-xh9f4,UID:1faa6082-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941141,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216db10 0xc42216db11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.098: INFO: Pod "nginx-deployment-7f9675fb8b-z2mcb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z2mcb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-z2mcb,UID:f4b583f7-343e-11e9-a5f4-5254000cc78a,ResourceVersion:940984,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.66.157/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216dbb0 0xc42216dbb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-master-20-102,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.102,PodIP:192.168.66.157,StartTime:2019-02-19 12:07:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ad9a79f6a5858763f8e129d491f4e84298c0bc00017f9f617a79033f509d2519}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.098: INFO: Pod "nginx-deployment-7f9675fb8b-z4pd5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z4pd5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-z4pd5,UID:1fa6a627-343f-11e9-a5f4-5254000cc78a,ResourceVersion:941139,Generation:0,CreationTimestamp:2019-02-19 12:08:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216dcb7 0xc42216dcb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 19 12:08:53.099: INFO: Pod "nginx-deployment-7f9675fb8b-zhz9j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zhz9j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-k4drp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4drp/pods/nginx-deployment-7f9675fb8b-zhz9j,UID:f4ae9540-343e-11e9-a5f4-5254000cc78a,ResourceVersion:941017,Generation:0,CreationTimestamp:2019-02-19 12:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.68.170/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f4a87afe-343e-11e9-a5f4-5254000cc78a 0xc42216dd70 0xc42216dd71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5475l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5475l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5475l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-105,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:08:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:07:40 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.105,PodIP:192.168.68.170,StartTime:2019-02-19 12:07:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-19 12:08:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://2191d52cced7db22f82cea1681b7c84b106e68a255deeb12b6804c3cd6f6925b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:08:53.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-k4drp" for this suite.
Feb 19 12:09:01.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:09:01.335: INFO: namespace: e2e-tests-deployment-k4drp, resource: bindings, ignored listing per whitelist
Feb 19 12:09:01.338: INFO: namespace e2e-tests-deployment-k4drp deletion completed in 8.198174533s

• [SLOW TEST:80.697 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:09:01.339: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-dwjrp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-24c10dc9-343f-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:09:01.591: INFO: Waiting up to 5m0s for pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-dwjrp" to be "success or failure"
Feb 19 12:09:01.597: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.675589ms
Feb 19 12:09:03.604: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012206512s
Feb 19 12:09:05.612: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020932044s
Feb 19 12:09:07.618: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026210584s
Feb 19 12:09:09.622: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030980305s
Feb 19 12:09:11.629: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038080492s
Feb 19 12:09:13.638: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.047121051s
Feb 19 12:09:15.645: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.053419731s
Feb 19 12:09:17.791: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.199684775s
Feb 19 12:09:19.798: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.206267563s
Feb 19 12:09:21.805: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.213432173s
Feb 19 12:09:23.811: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.220101045s
Feb 19 12:09:25.818: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.226846686s
Feb 19 12:09:27.824: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.232261788s
Feb 19 12:09:29.830: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 28.238882205s
Feb 19 12:09:31.836: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 30.244649747s
Feb 19 12:09:33.842: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 32.250698306s
Feb 19 12:09:35.848: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 34.256817097s
Feb 19 12:09:37.858: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 36.266459773s
Feb 19 12:09:39.865: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 38.273333613s
Feb 19 12:09:41.871: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 40.279473958s
Feb 19 12:09:43.877: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 42.285709442s
Feb 19 12:09:45.883: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 44.292077508s
Feb 19 12:09:47.893: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 46.301750316s
Feb 19 12:09:49.906: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 48.314545041s
Feb 19 12:09:51.912: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 50.321133766s
Feb 19 12:09:53.919: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 52.327618284s
Feb 19 12:09:55.926: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 54.334765272s
Feb 19 12:09:57.933: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 56.341747787s
Feb 19 12:09:59.942: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 58.351018761s
Feb 19 12:10:01.949: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.357776713s
Feb 19 12:10:03.955: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.363704747s
Feb 19 12:10:05.962: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.370787754s
Feb 19 12:10:07.971: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.379449953s
Feb 19 12:10:09.977: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.385637692s
Feb 19 12:10:11.984: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.392818901s
Feb 19 12:10:13.990: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.398355749s
Feb 19 12:10:15.996: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.404555019s
Feb 19 12:10:18.002: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.410533084s
Feb 19 12:10:20.008: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.417009755s
Feb 19 12:10:22.015: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.423627439s
Feb 19 12:10:24.021: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.429242061s
Feb 19 12:10:26.027: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.436112648s
Feb 19 12:10:28.034: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.443056708s
Feb 19 12:10:30.041: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.449195748s
Feb 19 12:10:32.048: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m30.456267984s
STEP: Saw pod success
Feb 19 12:10:32.048: INFO: Pod "pod-configmaps-24c206de-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:10:32.052: INFO: Trying to get logs from node kube-node-20-105 pod pod-configmaps-24c206de-343f-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:10:32.081: INFO: Waiting for pod pod-configmaps-24c206de-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:10:32.090: INFO: Pod pod-configmaps-24c206de-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:10:32.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dwjrp" for this suite.
Feb 19 12:10:38.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:10:38.183: INFO: namespace: e2e-tests-configmap-dwjrp, resource: bindings, ignored listing per whitelist
Feb 19 12:10:38.276: INFO: namespace e2e-tests-configmap-dwjrp deletion completed in 6.173479478s

• [SLOW TEST:96.937 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:10:38.276: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-59s8q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5e86a836-343f-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:10:38.519: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-59s8q" to be "success or failure"
Feb 19 12:10:38.524: INFO: Pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.456777ms
Feb 19 12:10:40.530: INFO: Pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010669152s
Feb 19 12:10:42.536: INFO: Pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016150896s
Feb 19 12:10:44.542: INFO: Pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022970666s
Feb 19 12:10:46.549: INFO: Pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029643001s
STEP: Saw pod success
Feb 19 12:10:46.549: INFO: Pod "pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:10:46.553: INFO: Trying to get logs from node kube-node-20-104 pod pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:10:46.588: INFO: Waiting for pod pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:10:46.592: INFO: Pod pod-configmaps-5e878bb2-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:10:46.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-59s8q" for this suite.
Feb 19 12:10:52.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:10:52.686: INFO: namespace: e2e-tests-configmap-59s8q, resource: bindings, ignored listing per whitelist
Feb 19 12:10:52.781: INFO: namespace e2e-tests-configmap-59s8q deletion completed in 6.182156241s

• [SLOW TEST:14.506 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:10:52.782: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tswfz
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-672c205d-343f-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:11:11.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tswfz" for this suite.
Feb 19 12:11:33.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:11:33.243: INFO: namespace: e2e-tests-configmap-tswfz, resource: bindings, ignored listing per whitelist
Feb 19 12:11:33.247: INFO: namespace e2e-tests-configmap-tswfz deletion completed in 22.174398915s

• [SLOW TEST:40.465 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:11:33.248: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8p2n8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:11:39.538: INFO: Waiting up to 5m0s for pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-pods-8p2n8" to be "success or failure"
Feb 19 12:11:39.549: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 11.615231ms
Feb 19 12:11:41.556: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01800291s
Feb 19 12:11:43.562: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024606076s
Feb 19 12:11:45.569: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031236887s
Feb 19 12:11:47.575: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037470401s
Feb 19 12:11:49.583: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.045432038s
Feb 19 12:11:51.590: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.051795712s
Feb 19 12:11:53.596: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.058094381s
Feb 19 12:11:55.603: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.065101241s
Feb 19 12:11:57.608: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.070277742s
Feb 19 12:11:59.615: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.076804998s
STEP: Saw pod success
Feb 19 12:11:59.615: INFO: Pod "client-envvars-82e4ed24-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:11:59.620: INFO: Trying to get logs from node kube-node-20-105 pod client-envvars-82e4ed24-343f-11e9-af36-92091ca56148 container env3cont: <nil>
STEP: delete the pod
Feb 19 12:11:59.652: INFO: Waiting for pod client-envvars-82e4ed24-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:11:59.662: INFO: Pod client-envvars-82e4ed24-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:11:59.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8p2n8" for this suite.
Feb 19 12:12:39.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:12:39.743: INFO: namespace: e2e-tests-pods-8p2n8, resource: bindings, ignored listing per whitelist
Feb 19 12:12:39.847: INFO: namespace e2e-tests-pods-8p2n8 deletion completed in 40.180176281s

• [SLOW TEST:66.600 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:12:39.848: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zcvlq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-zcvlq/configmap-test-a6fd0a5b-343f-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:12:40.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-zcvlq" to be "success or failure"
Feb 19 12:12:40.096: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.075503ms
Feb 19 12:12:42.101: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011739275s
Feb 19 12:12:44.108: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018032201s
Feb 19 12:12:46.114: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024112375s
Feb 19 12:12:48.120: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030399232s
Feb 19 12:12:50.126: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036159147s
Feb 19 12:12:52.136: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.045990315s
STEP: Saw pod success
Feb 19 12:12:52.136: INFO: Pod "pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:12:52.141: INFO: Trying to get logs from node kube-node-20-104 pod pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148 container env-test: <nil>
STEP: delete the pod
Feb 19 12:12:52.174: INFO: Waiting for pod pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:12:52.180: INFO: Pod pod-configmaps-a6fe16ee-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:12:52.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zcvlq" for this suite.
Feb 19 12:12:58.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:12:58.296: INFO: namespace: e2e-tests-configmap-zcvlq, resource: bindings, ignored listing per whitelist
Feb 19 12:12:58.363: INFO: namespace e2e-tests-configmap-zcvlq deletion completed in 6.174529995s

• [SLOW TEST:18.515 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:12:58.364: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b6ns7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 12:12:58.602: INFO: Waiting up to 5m0s for pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-b6ns7" to be "success or failure"
Feb 19 12:12:58.606: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.182459ms
Feb 19 12:13:00.612: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010167559s
Feb 19 12:13:02.619: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016274334s
Feb 19 12:13:04.625: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022468001s
Feb 19 12:13:06.631: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029186625s
Feb 19 12:13:08.638: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.035352726s
Feb 19 12:13:10.644: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.041352488s
Feb 19 12:13:12.651: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.048635896s
Feb 19 12:13:14.658: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.055283119s
Feb 19 12:13:16.663: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.061121081s
STEP: Saw pod success
Feb 19 12:13:16.663: INFO: Pod "downward-api-b206b88e-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:13:16.668: INFO: Trying to get logs from node kube-node-20-105 pod downward-api-b206b88e-343f-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 12:13:16.703: INFO: Waiting for pod downward-api-b206b88e-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:13:16.709: INFO: Pod downward-api-b206b88e-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:13:16.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b6ns7" for this suite.
Feb 19 12:13:22.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:13:22.874: INFO: namespace: e2e-tests-downward-api-b6ns7, resource: bindings, ignored listing per whitelist
Feb 19 12:13:22.887: INFO: namespace e2e-tests-downward-api-b6ns7 deletion completed in 6.171781128s

• [SLOW TEST:24.524 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:13:22.888: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-l2426
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:13:23.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-l2426" to be "success or failure"
Feb 19 12:13:23.133: INFO: Pod "downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 3.890839ms
Feb 19 12:13:25.138: INFO: Pod "downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009454562s
Feb 19 12:13:27.144: INFO: Pod "downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015115009s
Feb 19 12:13:29.150: INFO: Pod "downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021657061s
STEP: Saw pod success
Feb 19 12:13:29.150: INFO: Pod "downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:13:29.156: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:13:29.186: INFO: Waiting for pod downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:13:29.190: INFO: Pod downwardapi-volume-c0a559fa-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:13:29.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l2426" for this suite.
Feb 19 12:13:35.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:13:35.296: INFO: namespace: e2e-tests-downward-api-l2426, resource: bindings, ignored listing per whitelist
Feb 19 12:13:35.365: INFO: namespace e2e-tests-downward-api-l2426 deletion completed in 6.169509936s

• [SLOW TEST:12.477 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:13:35.366: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-qfq7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0219 12:14:15.665243      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 12:14:15.665: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:14:15.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qfq7h" for this suite.
Feb 19 12:14:23.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:14:23.801: INFO: namespace: e2e-tests-gc-qfq7h, resource: bindings, ignored listing per whitelist
Feb 19 12:14:23.866: INFO: namespace e2e-tests-gc-qfq7h deletion completed in 8.194452046s

• [SLOW TEST:48.501 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:14:23.867: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cp4cf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e4ff2925-343f-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:14:24.120: INFO: Waiting up to 5m0s for pod "pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-cp4cf" to be "success or failure"
Feb 19 12:14:24.124: INFO: Pod "pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 3.946749ms
Feb 19 12:14:26.130: INFO: Pod "pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010099507s
Feb 19 12:14:28.136: INFO: Pod "pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016170723s
Feb 19 12:14:30.146: INFO: Pod "pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02601023s
STEP: Saw pod success
Feb 19 12:14:30.146: INFO: Pod "pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:14:30.152: INFO: Trying to get logs from node kube-node-20-105 pod pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:14:30.183: INFO: Waiting for pod pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:14:30.195: INFO: Pod pod-secrets-e5000ef7-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:14:30.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cp4cf" for this suite.
Feb 19 12:14:36.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:14:36.331: INFO: namespace: e2e-tests-secrets-cp4cf, resource: bindings, ignored listing per whitelist
Feb 19 12:14:36.375: INFO: namespace e2e-tests-secrets-cp4cf deletion completed in 6.174683256s

• [SLOW TEST:12.508 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:14:36.376: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-mdtff
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:14:36.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mdtff" for this suite.
Feb 19 12:14:42.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:14:42.791: INFO: namespace: e2e-tests-services-mdtff, resource: bindings, ignored listing per whitelist
Feb 19 12:14:42.791: INFO: namespace e2e-tests-services-mdtff deletion completed in 6.177030463s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.416 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:14:42.792: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vv849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f045b84c-343f-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:14:43.038: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-vv849" to be "success or failure"
Feb 19 12:14:43.043: INFO: Pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.908459ms
Feb 19 12:14:45.050: INFO: Pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012412052s
Feb 19 12:14:47.056: INFO: Pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018651328s
Feb 19 12:14:49.062: INFO: Pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024911698s
Feb 19 12:14:51.070: INFO: Pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.032087267s
STEP: Saw pod success
Feb 19 12:14:51.070: INFO: Pod "pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:14:51.075: INFO: Trying to get logs from node kube-node-20-104 pod pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:14:51.106: INFO: Waiting for pod pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148 to disappear
Feb 19 12:14:51.111: INFO: Pod pod-projected-configmaps-f04680e8-343f-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:14:51.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vv849" for this suite.
Feb 19 12:14:57.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:14:57.246: INFO: namespace: e2e-tests-projected-vv849, resource: bindings, ignored listing per whitelist
Feb 19 12:14:57.283: INFO: namespace e2e-tests-projected-vv849 deletion completed in 6.164133005s

• [SLOW TEST:14.491 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:14:57.283: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-7hrnr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 19 12:15:09.595: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 12:15:09.600: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 12:15:11.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 12:15:11.606: INFO: Pod pod-with-poststart-http-hook still exists
Feb 19 12:15:13.600: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 19 12:15:13.607: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:15:13.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7hrnr" for this suite.
Feb 19 12:15:35.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:15:35.762: INFO: namespace: e2e-tests-container-lifecycle-hook-7hrnr, resource: bindings, ignored listing per whitelist
Feb 19 12:15:35.795: INFO: namespace e2e-tests-container-lifecycle-hook-7hrnr deletion completed in 22.181199689s

• [SLOW TEST:38.512 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:15:35.796: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-99kc7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0219 12:15:46.133801      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 12:15:46.133: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:15:46.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-99kc7" for this suite.
Feb 19 12:15:52.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:15:52.192: INFO: namespace: e2e-tests-gc-99kc7, resource: bindings, ignored listing per whitelist
Feb 19 12:15:52.333: INFO: namespace e2e-tests-gc-99kc7 deletion completed in 6.194028969s

• [SLOW TEST:16.538 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:15:52.334: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-tvx7g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tvx7g;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tvx7g;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tvx7g.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 46.117.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.117.46_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 46.117.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.117.46_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tvx7g;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tvx7g;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tvx7g.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-tvx7g.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tvx7g.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 46.117.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.117.46_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 46.117.254.10.in-addr.arpa. PTR)" && echo OK > /results/10.254.117.46_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 12:16:32.817: INFO: DNS probes using e2e-tests-dns-tvx7g/dns-test-19c02ac5-3440-11e9-af36-92091ca56148 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:16:32.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tvx7g" for this suite.
Feb 19 12:16:38.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:16:39.009: INFO: namespace: e2e-tests-dns-tvx7g, resource: bindings, ignored listing per whitelist
Feb 19 12:16:39.101: INFO: namespace e2e-tests-dns-tvx7g deletion completed in 6.186891513s

• [SLOW TEST:46.767 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:16:39.101: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-z5mk4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-z5mk4
Feb 19 12:16:47.359: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-z5mk4
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 12:16:47.364: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:20:48.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z5mk4" for this suite.
Feb 19 12:20:54.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:20:54.260: INFO: namespace: e2e-tests-container-probe-z5mk4, resource: bindings, ignored listing per whitelist
Feb 19 12:20:54.375: INFO: namespace e2e-tests-container-probe-z5mk4 deletion completed in 6.182796792s

• [SLOW TEST:255.274 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:20:54.376: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-b5lkj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-b5lkj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 12:20:54.606: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 12:21:26.824: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.68.190:8080/dial?request=hostName&protocol=http&host=192.168.68.189&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-b5lkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 12:21:26.824: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 12:21:26.987: INFO: Waiting for endpoints: map[]
Feb 19 12:21:26.992: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.68.190:8080/dial?request=hostName&protocol=http&host=192.168.67.253&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-b5lkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 12:21:26.992: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 12:21:27.120: INFO: Waiting for endpoints: map[]
Feb 19 12:21:27.126: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.68.190:8080/dial?request=hostName&protocol=http&host=192.168.64.26&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-b5lkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 12:21:27.126: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 12:21:27.269: INFO: Waiting for endpoints: map[]
Feb 19 12:21:27.275: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.68.190:8080/dial?request=hostName&protocol=http&host=192.168.66.165&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-b5lkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 12:21:27.275: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 12:21:27.419: INFO: Waiting for endpoints: map[]
Feb 19 12:21:27.425: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.68.190:8080/dial?request=hostName&protocol=http&host=192.168.65.171&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-b5lkj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 12:21:27.425: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 12:21:27.565: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:21:27.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-b5lkj" for this suite.
Feb 19 12:21:43.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:21:43.667: INFO: namespace: e2e-tests-pod-network-test-b5lkj, resource: bindings, ignored listing per whitelist
Feb 19 12:21:43.758: INFO: namespace e2e-tests-pod-network-test-b5lkj deletion completed in 16.185318176s

• [SLOW TEST:49.382 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:21:43.758: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-stgzt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:21:43.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-stgzt" to be "success or failure"
Feb 19 12:21:44.004: INFO: Pod "downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038323ms
Feb 19 12:21:46.011: INFO: Pod "downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012632863s
Feb 19 12:21:48.016: INFO: Pod "downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018216481s
Feb 19 12:21:50.022: INFO: Pod "downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024069145s
STEP: Saw pod success
Feb 19 12:21:50.022: INFO: Pod "downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:21:50.026: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:21:50.059: INFO: Waiting for pod downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148 to disappear
Feb 19 12:21:50.064: INFO: Pod downwardapi-volume-eb2fa9fb-3440-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:21:50.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-stgzt" for this suite.
Feb 19 12:21:56.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:21:56.158: INFO: namespace: e2e-tests-projected-stgzt, resource: bindings, ignored listing per whitelist
Feb 19 12:21:56.237: INFO: namespace e2e-tests-projected-stgzt deletion completed in 6.164876862s

• [SLOW TEST:12.479 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:21:56.237: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4b65c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 19 12:21:56.463: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-879726862 proxy --unix-socket=/tmp/kubectl-proxy-unix053477141/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:21:56.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4b65c" for this suite.
Feb 19 12:22:02.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:22:02.721: INFO: namespace: e2e-tests-kubectl-4b65c, resource: bindings, ignored listing per whitelist
Feb 19 12:22:02.745: INFO: namespace e2e-tests-kubectl-4b65c deletion completed in 6.157914575s

• [SLOW TEST:6.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:22:02.745: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cglkw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:22:02.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-cglkw" to be "success or failure"
Feb 19 12:22:02.982: INFO: Pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.553002ms
Feb 19 12:22:04.989: INFO: Pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011802436s
Feb 19 12:22:06.996: INFO: Pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019249161s
Feb 19 12:22:09.003: INFO: Pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148": Phase="Running", Reason="", readiness=true. Elapsed: 6.025675494s
Feb 19 12:22:11.009: INFO: Pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.032253788s
STEP: Saw pod success
Feb 19 12:22:11.009: INFO: Pod "downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:22:11.014: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:22:11.043: INFO: Waiting for pod downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148 to disappear
Feb 19 12:22:11.048: INFO: Pod downwardapi-volume-f67fe98a-3440-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:22:11.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cglkw" for this suite.
Feb 19 12:22:17.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:22:17.222: INFO: namespace: e2e-tests-downward-api-cglkw, resource: bindings, ignored listing per whitelist
Feb 19 12:22:17.257: INFO: namespace e2e-tests-downward-api-cglkw deletion completed in 6.20354218s

• [SLOW TEST:14.512 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:22:17.257: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-l8nxn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 19 12:22:17.529: INFO: Number of nodes with available pods: 0
Feb 19 12:22:17.529: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:18.541: INFO: Number of nodes with available pods: 0
Feb 19 12:22:18.541: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:19.542: INFO: Number of nodes with available pods: 0
Feb 19 12:22:19.542: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:20.542: INFO: Number of nodes with available pods: 0
Feb 19 12:22:20.542: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:21.543: INFO: Number of nodes with available pods: 0
Feb 19 12:22:21.543: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:22.541: INFO: Number of nodes with available pods: 0
Feb 19 12:22:22.541: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:23.542: INFO: Number of nodes with available pods: 3
Feb 19 12:22:23.542: INFO: Node kube-master-20-103 is running more than one daemon pod
Feb 19 12:22:24.541: INFO: Number of nodes with available pods: 5
Feb 19 12:22:24.541: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 19 12:22:24.581: INFO: Number of nodes with available pods: 4
Feb 19 12:22:24.582: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:25.596: INFO: Number of nodes with available pods: 4
Feb 19 12:22:25.596: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:26.595: INFO: Number of nodes with available pods: 4
Feb 19 12:22:26.595: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:27.599: INFO: Number of nodes with available pods: 4
Feb 19 12:22:27.600: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:28.596: INFO: Number of nodes with available pods: 4
Feb 19 12:22:28.596: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:29.595: INFO: Number of nodes with available pods: 4
Feb 19 12:22:29.595: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 12:22:30.595: INFO: Number of nodes with available pods: 5
Feb 19 12:22:30.595: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-l8nxn, will wait for the garbage collector to delete the pods
Feb 19 12:22:30.670: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.516583ms
Feb 19 12:22:30.770: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.280971ms
Feb 19 12:23:10.577: INFO: Number of nodes with available pods: 0
Feb 19 12:23:10.577: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 12:23:10.582: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-l8nxn/daemonsets","resourceVersion":"943614"},"items":null}

Feb 19 12:23:10.587: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-l8nxn/pods","resourceVersion":"943614"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:23:10.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-l8nxn" for this suite.
Feb 19 12:23:16.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:23:16.794: INFO: namespace: e2e-tests-daemonsets-l8nxn, resource: bindings, ignored listing per whitelist
Feb 19 12:23:16.804: INFO: namespace e2e-tests-daemonsets-l8nxn deletion completed in 6.183574183s

• [SLOW TEST:59.547 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:23:16.805: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rcq65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 12:23:17.029: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:27:33.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rcq65" for this suite.
Feb 19 12:27:39.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:27:39.287: INFO: namespace: e2e-tests-init-container-rcq65, resource: bindings, ignored listing per whitelist
Feb 19 12:27:39.367: INFO: namespace e2e-tests-init-container-rcq65 deletion completed in 6.182883082s

• [SLOW TEST:262.562 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:27:39.368: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xgwk7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-bf25e237-3441-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:27:39.615: INFO: Waiting up to 5m0s for pod "pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-xgwk7" to be "success or failure"
Feb 19 12:27:39.619: INFO: Pod "pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.205962ms
Feb 19 12:27:41.625: INFO: Pod "pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009857367s
Feb 19 12:27:43.632: INFO: Pod "pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016906253s
Feb 19 12:27:45.637: INFO: Pod "pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022453423s
STEP: Saw pod success
Feb 19 12:27:45.638: INFO: Pod "pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:27:45.647: INFO: Trying to get logs from node kube-node-20-104 pod pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:27:45.684: INFO: Waiting for pod pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:27:45.689: INFO: Pod pod-secrets-bf26f43f-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:27:45.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xgwk7" for this suite.
Feb 19 12:27:51.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:27:51.762: INFO: namespace: e2e-tests-secrets-xgwk7, resource: bindings, ignored listing per whitelist
Feb 19 12:27:51.871: INFO: namespace e2e-tests-secrets-xgwk7 deletion completed in 6.176569398s

• [SLOW TEST:12.503 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:27:51.872: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qt6mm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c69b8eed-3441-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:27:52.132: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-qt6mm" to be "success or failure"
Feb 19 12:27:52.139: INFO: Pod "pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.749832ms
Feb 19 12:27:54.145: INFO: Pod "pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013242805s
Feb 19 12:27:56.152: INFO: Pod "pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01981268s
Feb 19 12:27:58.158: INFO: Pod "pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0257383s
STEP: Saw pod success
Feb 19 12:27:58.158: INFO: Pod "pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:27:58.162: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:27:58.200: INFO: Waiting for pod pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:27:58.205: INFO: Pod pod-projected-secrets-c69cb1fa-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:27:58.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qt6mm" for this suite.
Feb 19 12:28:04.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:28:04.284: INFO: namespace: e2e-tests-projected-qt6mm, resource: bindings, ignored listing per whitelist
Feb 19 12:28:04.404: INFO: namespace e2e-tests-projected-qt6mm deletion completed in 6.193127938s

• [SLOW TEST:12.533 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:28:04.405: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fk9td
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:28:04.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-fk9td" to be "success or failure"
Feb 19 12:28:04.648: INFO: Pod "downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.113302ms
Feb 19 12:28:06.656: INFO: Pod "downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013438712s
Feb 19 12:28:08.665: INFO: Pod "downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022239903s
Feb 19 12:28:10.674: INFO: Pod "downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03145663s
STEP: Saw pod success
Feb 19 12:28:10.674: INFO: Pod "downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:28:10.681: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:28:10.727: INFO: Waiting for pod downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:28:10.735: INFO: Pod downwardapi-volume-ce11c660-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:28:10.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fk9td" for this suite.
Feb 19 12:28:16.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:28:16.807: INFO: namespace: e2e-tests-downward-api-fk9td, resource: bindings, ignored listing per whitelist
Feb 19 12:28:16.908: INFO: namespace e2e-tests-downward-api-fk9td deletion completed in 6.164772718s

• [SLOW TEST:12.504 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:28:16.909: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bqg8v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d584b464-3441-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:28:17.147: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-bqg8v" to be "success or failure"
Feb 19 12:28:17.153: INFO: Pod "pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.923025ms
Feb 19 12:28:19.160: INFO: Pod "pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013117454s
Feb 19 12:28:21.166: INFO: Pod "pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01971131s
Feb 19 12:28:23.173: INFO: Pod "pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025953957s
STEP: Saw pod success
Feb 19 12:28:23.173: INFO: Pod "pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:28:23.177: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:28:23.206: INFO: Waiting for pod pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:28:23.211: INFO: Pod pod-projected-secrets-d585d03c-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:28:23.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bqg8v" for this suite.
Feb 19 12:28:29.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:28:29.402: INFO: namespace: e2e-tests-projected-bqg8v, resource: bindings, ignored listing per whitelist
Feb 19 12:28:29.421: INFO: namespace e2e-tests-projected-bqg8v deletion completed in 6.204786836s

• [SLOW TEST:12.512 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:28:29.422: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5zws6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 19 12:28:29.664: INFO: Waiting up to 5m0s for pod "pod-dcfb8503-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-5zws6" to be "success or failure"
Feb 19 12:28:29.668: INFO: Pod "pod-dcfb8503-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 3.883231ms
Feb 19 12:28:31.675: INFO: Pod "pod-dcfb8503-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010541643s
Feb 19 12:28:33.682: INFO: Pod "pod-dcfb8503-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01766585s
Feb 19 12:28:35.689: INFO: Pod "pod-dcfb8503-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024567572s
Feb 19 12:28:37.695: INFO: Pod "pod-dcfb8503-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.03090515s
STEP: Saw pod success
Feb 19 12:28:37.695: INFO: Pod "pod-dcfb8503-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:28:37.700: INFO: Trying to get logs from node kube-node-20-104 pod pod-dcfb8503-3441-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 12:28:37.731: INFO: Waiting for pod pod-dcfb8503-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:28:37.737: INFO: Pod pod-dcfb8503-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:28:37.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5zws6" for this suite.
Feb 19 12:28:43.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:28:43.922: INFO: namespace: e2e-tests-emptydir-5zws6, resource: bindings, ignored listing per whitelist
Feb 19 12:28:43.927: INFO: namespace e2e-tests-emptydir-5zws6 deletion completed in 6.18285684s

• [SLOW TEST:14.505 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:28:43.927: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fwcz9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:28:44.166: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-fwcz9" to be "success or failure"
Feb 19 12:28:44.171: INFO: Pod "downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.983816ms
Feb 19 12:28:46.178: INFO: Pod "downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011667783s
Feb 19 12:28:48.187: INFO: Pod "downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020677127s
Feb 19 12:28:50.194: INFO: Pod "downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027151417s
STEP: Saw pod success
Feb 19 12:28:50.194: INFO: Pod "downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:28:50.198: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:28:50.232: INFO: Waiting for pod downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:28:50.236: INFO: Pod downwardapi-volume-e5a01f9c-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:28:50.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fwcz9" for this suite.
Feb 19 12:28:56.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:28:56.348: INFO: namespace: e2e-tests-projected-fwcz9, resource: bindings, ignored listing per whitelist
Feb 19 12:28:56.442: INFO: namespace e2e-tests-projected-fwcz9 deletion completed in 6.198721317s

• [SLOW TEST:12.514 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:28:56.442: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vmrbz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:28:56.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-vmrbz" to be "success or failure"
Feb 19 12:28:56.674: INFO: Pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005329ms
Feb 19 12:28:58.680: INFO: Pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010490347s
Feb 19 12:29:00.686: INFO: Pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015836459s
Feb 19 12:29:02.692: INFO: Pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022188499s
Feb 19 12:29:04.698: INFO: Pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028065554s
STEP: Saw pod success
Feb 19 12:29:04.698: INFO: Pod "downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:29:04.704: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:29:04.734: INFO: Waiting for pod downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148 to disappear
Feb 19 12:29:04.738: INFO: Pod downwardapi-volume-ed147f6b-3441-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:29:04.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vmrbz" for this suite.
Feb 19 12:29:10.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:29:10.914: INFO: namespace: e2e-tests-projected-vmrbz, resource: bindings, ignored listing per whitelist
Feb 19 12:29:10.930: INFO: namespace e2e-tests-projected-vmrbz deletion completed in 6.185468139s

• [SLOW TEST:14.488 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:29:10.931: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-mdnwr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 19 12:29:25.227: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:25.232: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:27.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:27.239: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:29.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:29.237: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:31.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:31.241: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:33.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:33.239: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:35.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:35.239: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:37.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:37.238: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:39.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:39.237: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:41.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:41.238: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 19 12:29:43.232: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 19 12:29:43.240: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:29:43.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mdnwr" for this suite.
Feb 19 12:30:05.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:30:05.432: INFO: namespace: e2e-tests-container-lifecycle-hook-mdnwr, resource: bindings, ignored listing per whitelist
Feb 19 12:30:05.437: INFO: namespace e2e-tests-container-lifecycle-hook-mdnwr deletion completed in 22.174993789s

• [SLOW TEST:54.507 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:30:05.438: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5flf4
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 19 12:30:05.686: INFO: Waiting up to 5m0s for pod "pod-1635a5cd-3442-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-5flf4" to be "success or failure"
Feb 19 12:30:05.692: INFO: Pod "pod-1635a5cd-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.637231ms
Feb 19 12:30:07.698: INFO: Pod "pod-1635a5cd-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0119941s
Feb 19 12:30:09.706: INFO: Pod "pod-1635a5cd-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020090857s
Feb 19 12:30:11.712: INFO: Pod "pod-1635a5cd-3442-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026905938s
STEP: Saw pod success
Feb 19 12:30:11.713: INFO: Pod "pod-1635a5cd-3442-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:30:11.719: INFO: Trying to get logs from node kube-node-20-105 pod pod-1635a5cd-3442-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 12:30:11.754: INFO: Waiting for pod pod-1635a5cd-3442-11e9-af36-92091ca56148 to disappear
Feb 19 12:30:11.761: INFO: Pod pod-1635a5cd-3442-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:30:11.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5flf4" for this suite.
Feb 19 12:30:17.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:30:17.825: INFO: namespace: e2e-tests-emptydir-5flf4, resource: bindings, ignored listing per whitelist
Feb 19 12:30:17.942: INFO: namespace e2e-tests-emptydir-5flf4 deletion completed in 6.173993684s

• [SLOW TEST:12.504 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:30:17.942: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-s2bhr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1daa9321-3442-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:30:18.189: INFO: Waiting up to 5m0s for pod "pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-s2bhr" to be "success or failure"
Feb 19 12:30:18.194: INFO: Pod "pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912636ms
Feb 19 12:30:20.200: INFO: Pod "pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011485963s
Feb 19 12:30:22.206: INFO: Pod "pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017284546s
Feb 19 12:30:24.215: INFO: Pod "pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026138526s
STEP: Saw pod success
Feb 19 12:30:24.215: INFO: Pod "pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:30:24.219: INFO: Trying to get logs from node kube-node-20-104 pod pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:30:24.248: INFO: Waiting for pod pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148 to disappear
Feb 19 12:30:24.252: INFO: Pod pod-configmaps-1dab7ff3-3442-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:30:24.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s2bhr" for this suite.
Feb 19 12:30:30.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:30:30.295: INFO: namespace: e2e-tests-configmap-s2bhr, resource: bindings, ignored listing per whitelist
Feb 19 12:30:30.434: INFO: namespace e2e-tests-configmap-s2bhr deletion completed in 6.175305239s

• [SLOW TEST:12.492 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:30:30.434: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hqkz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:30:30.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-hqkz4" to be "success or failure"
Feb 19 12:30:30.683: INFO: Pod "downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.420411ms
Feb 19 12:30:32.691: INFO: Pod "downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016138153s
Feb 19 12:30:34.697: INFO: Pod "downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022846664s
Feb 19 12:30:36.704: INFO: Pod "downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029519395s
STEP: Saw pod success
Feb 19 12:30:36.704: INFO: Pod "downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:30:36.708: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:30:36.742: INFO: Waiting for pod downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148 to disappear
Feb 19 12:30:36.749: INFO: Pod downwardapi-volume-251c4344-3442-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:30:36.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hqkz4" for this suite.
Feb 19 12:30:42.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:30:42.850: INFO: namespace: e2e-tests-projected-hqkz4, resource: bindings, ignored listing per whitelist
Feb 19 12:30:42.953: INFO: namespace e2e-tests-projected-hqkz4 deletion completed in 6.195546962s

• [SLOW TEST:12.518 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:30:42.953: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cw2bt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 12:30:43.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-cw2bt'
Feb 19 12:30:43.589: INFO: stderr: ""
Feb 19 12:30:43.589: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb 19 12:30:43.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-cw2bt'
Feb 19 12:30:45.271: INFO: stderr: ""
Feb 19 12:30:45.271: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:30:45.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cw2bt" for this suite.
Feb 19 12:30:51.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:30:51.431: INFO: namespace: e2e-tests-kubectl-cw2bt, resource: bindings, ignored listing per whitelist
Feb 19 12:30:51.463: INFO: namespace e2e-tests-kubectl-cw2bt deletion completed in 6.184662008s

• [SLOW TEST:8.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:30:51.463: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-mqwtb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:30:51.741: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 19 12:30:51.753: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 19 12:30:56.760: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 12:31:08.771: INFO: Creating deployment "test-rolling-update-deployment"
Feb 19 12:31:08.779: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 19 12:31:08.788: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 19 12:31:10.801: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 19 12:31:10.805: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:31:12.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176268, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 19 12:31:14.811: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 12:31:14.825: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-mqwtb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mqwtb/deployments/test-rolling-update-deployment,UID:3bd3d28f-3442-11e9-b551-525400c68782,ResourceVersion:944854,Generation:1,CreationTimestamp:2019-02-19 12:31:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-19 12:31:08 +0000 UTC 2019-02-19 12:31:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-19 12:31:14 +0000 UTC 2019-02-19 12:31:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 19 12:31:14.830: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-mqwtb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mqwtb/replicasets/test-rolling-update-deployment-65b7695dcf,UID:3bd8ce74-3442-11e9-a5f4-5254000cc78a,ResourceVersion:944847,Generation:1,CreationTimestamp:2019-02-19 12:31:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3bd3d28f-3442-11e9-b551-525400c68782 0xc421bcf667 0xc421bcf668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 19 12:31:14.830: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 19 12:31:14.830: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-mqwtb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mqwtb/replicasets/test-rolling-update-controller,UID:31ad2559-3442-11e9-b551-525400c68782,ResourceVersion:944853,Generation:2,CreationTimestamp:2019-02-19 12:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 3bd3d28f-3442-11e9-b551-525400c68782 0xc421bcf52e 0xc421bcf52f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 19 12:31:14.835: INFO: Pod "test-rolling-update-deployment-65b7695dcf-xng89" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-xng89,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-mqwtb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mqwtb/pods/test-rolling-update-deployment-65b7695dcf-xng89,UID:3bda6ecd-3442-11e9-a5f4-5254000cc78a,ResourceVersion:944846,Generation:0,CreationTimestamp:2019-02-19 12:31:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.67.10/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 3bd8ce74-3442-11e9-a5f4-5254000cc78a 0xc421d16667 0xc421d16668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5qfgc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5qfgc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5qfgc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:31:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:31:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:31:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:31:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.104,PodIP:192.168.67.10,StartTime:2019-02-19 12:31:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-19 12:31:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d48e2ad97ec83a5c471dc68e8c2231503d4eeafa5915a73e1691a638dd12e225}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:31:14.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mqwtb" for this suite.
Feb 19 12:31:20.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:31:20.881: INFO: namespace: e2e-tests-deployment-mqwtb, resource: bindings, ignored listing per whitelist
Feb 19 12:31:21.026: INFO: namespace e2e-tests-deployment-mqwtb deletion completed in 6.1856984s

• [SLOW TEST:29.564 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:31:21.027: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-6g5kl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:31:21.282: INFO: (0) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 12.093624ms)
Feb 19 12:31:21.292: INFO: (1) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 10.068596ms)
Feb 19 12:31:21.298: INFO: (2) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.947083ms)
Feb 19 12:31:21.304: INFO: (3) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.818353ms)
Feb 19 12:31:21.309: INFO: (4) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.063406ms)
Feb 19 12:31:21.314: INFO: (5) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.477125ms)
Feb 19 12:31:21.318: INFO: (6) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.464303ms)
Feb 19 12:31:21.323: INFO: (7) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.921532ms)
Feb 19 12:31:21.331: INFO: (8) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 8.056432ms)
Feb 19 12:31:21.337: INFO: (9) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.461981ms)
Feb 19 12:31:21.342: INFO: (10) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.119183ms)
Feb 19 12:31:21.347: INFO: (11) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.855206ms)
Feb 19 12:31:21.358: INFO: (12) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 10.653712ms)
Feb 19 12:31:21.363: INFO: (13) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.249036ms)
Feb 19 12:31:21.367: INFO: (14) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.416301ms)
Feb 19 12:31:21.373: INFO: (15) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.190904ms)
Feb 19 12:31:21.378: INFO: (16) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.244068ms)
Feb 19 12:31:21.383: INFO: (17) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.904766ms)
Feb 19 12:31:21.388: INFO: (18) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.514766ms)
Feb 19 12:31:21.394: INFO: (19) /api/v1/nodes/kube-master-20-101:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.341049ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:31:21.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6g5kl" for this suite.
Feb 19 12:31:27.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:31:27.443: INFO: namespace: e2e-tests-proxy-6g5kl, resource: bindings, ignored listing per whitelist
Feb 19 12:31:27.562: INFO: namespace e2e-tests-proxy-6g5kl deletion completed in 6.162875875s

• [SLOW TEST:6.535 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:31:27.562: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q4mx5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 12:31:36.342: INFO: Successfully updated pod "labelsupdate47287734-3442-11e9-af36-92091ca56148"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:31:38.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q4mx5" for this suite.
Feb 19 12:32:00.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:32:00.429: INFO: namespace: e2e-tests-downward-api-q4mx5, resource: bindings, ignored listing per whitelist
Feb 19 12:32:00.552: INFO: namespace e2e-tests-downward-api-q4mx5 deletion completed in 22.180266794s

• [SLOW TEST:32.990 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:32:00.552: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-c6ndg
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5ad3c3b4-3442-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-5ad3c3b4-3442-11e9-af36-92091ca56148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:32:08.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c6ndg" for this suite.
Feb 19 12:32:30.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:32:30.899: INFO: namespace: e2e-tests-configmap-c6ndg, resource: bindings, ignored listing per whitelist
Feb 19 12:32:31.044: INFO: namespace e2e-tests-configmap-c6ndg deletion completed in 22.178544254s

• [SLOW TEST:30.492 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:32:31.045: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rzp65
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 12:32:31.300: INFO: Waiting up to 5m0s for pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-rzp65" to be "success or failure"
Feb 19 12:32:31.305: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.328731ms
Feb 19 12:32:33.311: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010659128s
Feb 19 12:32:35.316: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016176337s
Feb 19 12:32:37.323: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022730125s
Feb 19 12:32:39.329: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029012087s
Feb 19 12:32:41.336: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.035212183s
Feb 19 12:32:43.346: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.0456657s
Feb 19 12:32:45.353: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052310348s
Feb 19 12:32:47.359: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.058730715s
Feb 19 12:32:49.365: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.064977186s
STEP: Saw pod success
Feb 19 12:32:49.365: INFO: Pod "downward-api-6d022b56-3442-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:32:49.369: INFO: Trying to get logs from node kube-node-20-105 pod downward-api-6d022b56-3442-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 12:32:49.407: INFO: Waiting for pod downward-api-6d022b56-3442-11e9-af36-92091ca56148 to disappear
Feb 19 12:32:49.412: INFO: Pod downward-api-6d022b56-3442-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:32:49.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rzp65" for this suite.
Feb 19 12:32:55.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:32:55.494: INFO: namespace: e2e-tests-downward-api-rzp65, resource: bindings, ignored listing per whitelist
Feb 19 12:32:55.583: INFO: namespace e2e-tests-downward-api-rzp65 deletion completed in 6.163770919s

• [SLOW TEST:24.538 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:32:55.583: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cv46b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:32:55.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 version'
Feb 19 12:32:56.001: INFO: stderr: ""
Feb 19 12:32:56.001: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:32:56.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cv46b" for this suite.
Feb 19 12:33:02.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:33:02.054: INFO: namespace: e2e-tests-kubectl-cv46b, resource: bindings, ignored listing per whitelist
Feb 19 12:33:02.178: INFO: namespace e2e-tests-kubectl-cv46b deletion completed in 6.169366597s

• [SLOW TEST:6.595 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:33:02.178: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p6f42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:33:02.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 version --client'
Feb 19 12:33:02.740: INFO: stderr: ""
Feb 19 12:33:02.740: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 19 12:33:02.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-p6f42'
Feb 19 12:33:03.149: INFO: stderr: ""
Feb 19 12:33:03.149: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 19 12:33:03.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-p6f42'
Feb 19 12:33:03.415: INFO: stderr: ""
Feb 19 12:33:03.415: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 12:33:04.422: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:04.422: INFO: Found 0 / 1
Feb 19 12:33:05.426: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:05.426: INFO: Found 0 / 1
Feb 19 12:33:06.421: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:06.421: INFO: Found 0 / 1
Feb 19 12:33:07.423: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:07.423: INFO: Found 0 / 1
Feb 19 12:33:08.421: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:08.421: INFO: Found 0 / 1
Feb 19 12:33:09.422: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:09.422: INFO: Found 1 / 1
Feb 19 12:33:09.422: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 12:33:09.426: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 12:33:09.426: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 12:33:09.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 describe pod redis-master-7qpb9 --namespace=e2e-tests-kubectl-p6f42'
Feb 19 12:33:09.587: INFO: stderr: ""
Feb 19 12:33:09.587: INFO: stdout: "Name:           redis-master-7qpb9\nNamespace:      e2e-tests-kubectl-p6f42\nNode:           kube-node-20-104/192.168.20.104\nStart Time:     Tue, 19 Feb 2019 12:33:03 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 192.168.67.12/32\n                kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             192.168.67.12\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1821e277edccf15b7e0c64c890593a2b4e85533aceb27f113c202d04c2364f5f\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 19 Feb 2019 12:33:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-nnkkw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-nnkkw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-nnkkw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                       Message\n  ----    ------     ----  ----                       -------\n  Normal  Scheduled  6s    default-scheduler          Successfully assigned e2e-tests-kubectl-p6f42/redis-master-7qpb9 to kube-node-20-104\n  Normal  Pulling    6s    kubelet, kube-node-20-104  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, kube-node-20-104  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, kube-node-20-104  Created container\n  Normal  Started    1s    kubelet, kube-node-20-104  Started container\n"
Feb 19 12:33:09.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 describe rc redis-master --namespace=e2e-tests-kubectl-p6f42'
Feb 19 12:33:09.744: INFO: stderr: ""
Feb 19 12:33:09.744: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-p6f42\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: redis-master-7qpb9\n"
Feb 19 12:33:09.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 describe service redis-master --namespace=e2e-tests-kubectl-p6f42'
Feb 19 12:33:09.897: INFO: stderr: ""
Feb 19 12:33:09.897: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-p6f42\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.81.102\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.67.12:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 19 12:33:09.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 describe node kube-master-20-101'
Feb 19 12:33:10.071: INFO: stderr: ""
Feb 19 12:33:10.073: INFO: stdout: "Name:               kube-master-20-101\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    caicloud.io/hostname=kube-master-20-101\n                    caicloud.io/nvidia-gpu=false\n                    caicloud.io/role=master\n                    kubernetes.io/hostname=kube-master-20-101\n                    loadbalance.caicloud.io/kube-system.apiserver=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"fa:f0:b9:d0:6f:d6\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.20.101\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 14 Feb 2019 05:17:52 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 19 Feb 2019 12:33:08 +0000   Mon, 18 Feb 2019 07:35:08 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 19 Feb 2019 12:33:08 +0000   Mon, 18 Feb 2019 07:35:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 19 Feb 2019 12:33:08 +0000   Mon, 18 Feb 2019 07:35:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 19 Feb 2019 12:33:08 +0000   Thu, 14 Feb 2019 05:17:52 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 19 Feb 2019 12:33:08 +0000   Mon, 18 Feb 2019 07:35:08 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.20.101\n  Hostname:    kube-master-20-101\nCapacity:\n cpu:                4\n ephemeral-storage:  81880Mi\n hugepages-2Mi:      0\n memory:             8009532Ki\n pods:               110\nAllocatable:\n cpu:                3890m\n ephemeral-storage:  84998828871\n hugepages-2Mi:      0\n memory:             7765820Ki\n pods:               110\nSystem Info:\n Machine ID:                 02ee70fcc8914e889b1a98ca8052df01\n System UUID:                B96C2C92-D96F-4597-A382-F6940A6CAB37\n Boot ID:                    d24c18d4-cf27-4a50-bb70-0c255a2d4d90\n Kernel Version:             3.10.0-862.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.1\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     192.168.64.0/24\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-5tddr    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                apiserver-provider-ipvsdr-preset-59cdc6b987-xq62r          200m (5%)     200m (5%)   50Mi (0%)        50Mi (0%)\n  kube-system                apiserver-proxy-nginx-preset-5b4466959d-8ms5x              100m (2%)     100m (2%)   50Mi (0%)        50Mi (0%)\n  kube-system                canal-qdkqk                                                250m (6%)     0 (0%)      100Mi (1%)       0 (0%)\n  kube-system                kube-apiserver-kube-master-20-101                          250m (6%)     0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kube-controller-manager-kube-master-20-101                 200m (5%)     0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kube-proxy-kube-master-20-101                              100m (2%)     0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kube-scheduler-kube-master-20-101                          100m (2%)     0 (0%)      10Mi (0%)        0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests     Limits\n  --------  --------     ------\n  cpu       1200m (30%)  300m (7%)\n  memory    240Mi (3%)   100Mi (1%)\nEvents:     <none>\n"
Feb 19 12:33:10.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 describe namespace e2e-tests-kubectl-p6f42'
Feb 19 12:33:10.231: INFO: stderr: ""
Feb 19 12:33:10.231: INFO: stdout: "Name:         e2e-tests-kubectl-p6f42\nLabels:       e2e-framework=kubectl\n              e2e-run=7ac05347-343b-11e9-af36-92091ca56148\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:33:10.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p6f42" for this suite.
Feb 19 12:33:32.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:33:32.303: INFO: namespace: e2e-tests-kubectl-p6f42, resource: bindings, ignored listing per whitelist
Feb 19 12:33:32.409: INFO: namespace e2e-tests-kubectl-p6f42 deletion completed in 22.17219304s

• [SLOW TEST:30.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:33:32.410: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-k5qmf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-t25l
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 12:33:32.666: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t25l" in namespace "e2e-tests-subpath-k5qmf" to be "success or failure"
Feb 19 12:33:32.674: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 7.448548ms
Feb 19 12:33:34.679: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012583973s
Feb 19 12:33:36.686: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01921456s
Feb 19 12:33:38.692: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025288939s
Feb 19 12:33:40.697: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031119285s
Feb 19 12:33:42.704: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037305681s
Feb 19 12:33:44.711: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 12.044233831s
Feb 19 12:33:46.717: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 14.050761144s
Feb 19 12:33:48.723: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056403903s
Feb 19 12:33:50.730: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 18.063572189s
Feb 19 12:33:52.736: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Pending", Reason="", readiness=false. Elapsed: 20.069888487s
Feb 19 12:33:54.743: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 22.076900402s
Feb 19 12:33:56.749: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 24.082903005s
Feb 19 12:33:58.756: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 26.089276177s
Feb 19 12:34:00.762: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 28.095371643s
Feb 19 12:34:02.767: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 30.101200181s
Feb 19 12:34:04.774: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 32.10758825s
Feb 19 12:34:06.785: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 34.118821829s
Feb 19 12:34:08.792: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Running", Reason="", readiness=false. Elapsed: 36.125700452s
Feb 19 12:34:10.798: INFO: Pod "pod-subpath-test-configmap-t25l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 38.132101265s
STEP: Saw pod success
Feb 19 12:34:10.798: INFO: Pod "pod-subpath-test-configmap-t25l" satisfied condition "success or failure"
Feb 19 12:34:10.804: INFO: Trying to get logs from node kube-node-20-105 pod pod-subpath-test-configmap-t25l container test-container-subpath-configmap-t25l: <nil>
STEP: delete the pod
Feb 19 12:34:10.837: INFO: Waiting for pod pod-subpath-test-configmap-t25l to disappear
Feb 19 12:34:10.842: INFO: Pod pod-subpath-test-configmap-t25l no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t25l
Feb 19 12:34:10.842: INFO: Deleting pod "pod-subpath-test-configmap-t25l" in namespace "e2e-tests-subpath-k5qmf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:34:10.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-k5qmf" for this suite.
Feb 19 12:34:16.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:34:17.027: INFO: namespace: e2e-tests-subpath-k5qmf, resource: bindings, ignored listing per whitelist
Feb 19 12:34:17.035: INFO: namespace e2e-tests-subpath-k5qmf deletion completed in 6.178263755s

• [SLOW TEST:44.625 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:34:17.036: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-p5pwx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-p5pwx
Feb 19 12:34:23.299: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-p5pwx
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 12:34:23.303: INFO: Initial restart count of pod liveness-http is 0
Feb 19 12:34:45.383: INFO: Restart count of pod e2e-tests-container-probe-p5pwx/liveness-http is now 1 (22.079846758s elapsed)
Feb 19 12:35:05.444: INFO: Restart count of pod e2e-tests-container-probe-p5pwx/liveness-http is now 2 (42.140991666s elapsed)
Feb 19 12:35:23.503: INFO: Restart count of pod e2e-tests-container-probe-p5pwx/liveness-http is now 3 (1m0.200441701s elapsed)
Feb 19 12:35:45.573: INFO: Restart count of pod e2e-tests-container-probe-p5pwx/liveness-http is now 4 (1m22.269937058s elapsed)
Feb 19 12:36:57.799: INFO: Restart count of pod e2e-tests-container-probe-p5pwx/liveness-http is now 5 (2m34.496112868s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:36:57.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p5pwx" for this suite.
Feb 19 12:37:03.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:37:04.043: INFO: namespace: e2e-tests-container-probe-p5pwx, resource: bindings, ignored listing per whitelist
Feb 19 12:37:04.134: INFO: namespace e2e-tests-container-probe-p5pwx deletion completed in 6.30046917s

• [SLOW TEST:167.098 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:37:04.134: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-nkmdv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-nkmdv
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-nkmdv
STEP: Deleting pre-stop pod
Feb 19 12:37:25.485: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:37:25.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-nkmdv" for this suite.
Feb 19 12:38:05.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:38:05.666: INFO: namespace: e2e-tests-prestop-nkmdv, resource: bindings, ignored listing per whitelist
Feb 19 12:38:05.856: INFO: namespace e2e-tests-prestop-nkmdv deletion completed in 40.348082393s

• [SLOW TEST:61.722 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:38:05.857: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-f9hdq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-34a5825c-3443-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:38:06.261: INFO: Waiting up to 5m0s for pod "pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-f9hdq" to be "success or failure"
Feb 19 12:38:06.273: INFO: Pod "pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.583193ms
Feb 19 12:38:08.282: INFO: Pod "pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021082013s
Feb 19 12:38:10.290: INFO: Pod "pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029278134s
Feb 19 12:38:12.301: INFO: Pod "pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039838782s
STEP: Saw pod success
Feb 19 12:38:12.301: INFO: Pod "pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:38:12.309: INFO: Trying to get logs from node kube-node-20-104 pod pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:38:12.391: INFO: Waiting for pod pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148 to disappear
Feb 19 12:38:12.399: INFO: Pod pod-configmaps-34a8323a-3443-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:38:12.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f9hdq" for this suite.
Feb 19 12:38:18.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:38:18.493: INFO: namespace: e2e-tests-configmap-f9hdq, resource: bindings, ignored listing per whitelist
Feb 19 12:38:18.702: INFO: namespace e2e-tests-configmap-f9hdq deletion completed in 6.2936016s

• [SLOW TEST:12.845 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:38:18.702: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4wlwc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 19 12:38:18.987: INFO: Waiting up to 5m0s for pod "pod-3c3e70b1-3443-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-4wlwc" to be "success or failure"
Feb 19 12:38:18.994: INFO: Pod "pod-3c3e70b1-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258751ms
Feb 19 12:38:21.008: INFO: Pod "pod-3c3e70b1-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021086242s
Feb 19 12:38:23.018: INFO: Pod "pod-3c3e70b1-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030590967s
Feb 19 12:38:25.024: INFO: Pod "pod-3c3e70b1-3443-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037229508s
STEP: Saw pod success
Feb 19 12:38:25.024: INFO: Pod "pod-3c3e70b1-3443-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:38:25.031: INFO: Trying to get logs from node kube-node-20-104 pod pod-3c3e70b1-3443-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 12:38:25.076: INFO: Waiting for pod pod-3c3e70b1-3443-11e9-af36-92091ca56148 to disappear
Feb 19 12:38:25.083: INFO: Pod pod-3c3e70b1-3443-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:38:25.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4wlwc" for this suite.
Feb 19 12:38:31.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:38:31.260: INFO: namespace: e2e-tests-emptydir-4wlwc, resource: bindings, ignored listing per whitelist
Feb 19 12:38:31.331: INFO: namespace e2e-tests-emptydir-4wlwc deletion completed in 6.240386744s

• [SLOW TEST:12.629 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:38:31.332: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-tc2wl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 12:38:31.587: INFO: PodSpec: initContainers in spec.initContainers
Feb 19 12:40:12.362: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-43c3f044-3443-11e9-af36-92091ca56148", GenerateName:"", Namespace:"e2e-tests-init-container-tc2wl", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-tc2wl/pods/pod-init-43c3f044-3443-11e9-af36-92091ca56148", UID:"43c65472-3443-11e9-b551-525400c68782", ResourceVersion:"946158", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686176711, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"587865749"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.68.206/32", "kubernetes.io/psp":"00-privileged"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-q6thg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4217a2000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q6thg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q6thg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q6thg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421a9e0a0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube-node-20-105", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4214b2000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176711, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176711, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176711, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686176711, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.20.105", PodIP:"192.168.68.206", StartTime:(*v1.Time)(0xc4220ac040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42217e070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42217e0e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c6ac37b44108865e6760e00e96fa717b40d76b1d9ae39e47d9495fa3d2923854"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4220ac080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4220ac060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:40:12.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tc2wl" for this suite.
Feb 19 12:40:36.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:40:36.620: INFO: namespace: e2e-tests-init-container-tc2wl, resource: bindings, ignored listing per whitelist
Feb 19 12:40:36.677: INFO: namespace e2e-tests-init-container-tc2wl deletion completed in 24.29804083s

• [SLOW TEST:125.345 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:40:36.677: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gmd48
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 12:40:36.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gmd48'
Feb 19 12:40:37.247: INFO: stderr: ""
Feb 19 12:40:37.247: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 19 12:40:52.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gmd48 -o json'
Feb 19 12:40:52.623: INFO: stderr: ""
Feb 19 12:40:52.623: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.67.17/32\",\n            \"kubernetes.io/psp\": \"00-privileged\"\n        },\n        \"creationTimestamp\": \"2019-02-19T12:40:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-gmd48\",\n        \"resourceVersion\": \"946247\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-gmd48/pods/e2e-test-nginx-pod\",\n        \"uid\": \"8ea522df-3443-11e9-8035-5254001beec1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"Always\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-trblb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"kube-node-20-104\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-trblb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-trblb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T12:40:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T12:40:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T12:40:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-19T12:40:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f11c98ad721f4e0405b722c649474403226c2bb0f50b554cd677dd80bc8ff363\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-19T12:40:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.20.104\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.67.17\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-19T12:40:37Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 19 12:40:52.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 replace -f - --namespace=e2e-tests-kubectl-gmd48'
Feb 19 12:40:52.925: INFO: stderr: ""
Feb 19 12:40:52.925: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb 19 12:40:52.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gmd48'
Feb 19 12:41:20.296: INFO: stderr: ""
Feb 19 12:41:20.296: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:41:20.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gmd48" for this suite.
Feb 19 12:41:26.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:41:26.424: INFO: namespace: e2e-tests-kubectl-gmd48, resource: bindings, ignored listing per whitelist
Feb 19 12:41:26.542: INFO: namespace e2e-tests-kubectl-gmd48 deletion completed in 6.234447326s

• [SLOW TEST:49.865 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:41:26.543: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4hr2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ac36fdc6-3443-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:41:26.853: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-4hr2d" to be "success or failure"
Feb 19 12:41:26.864: INFO: Pod "pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 11.612585ms
Feb 19 12:41:28.873: INFO: Pod "pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020309667s
Feb 19 12:41:30.881: INFO: Pod "pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028212096s
Feb 19 12:41:32.891: INFO: Pod "pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037892868s
STEP: Saw pod success
Feb 19 12:41:32.891: INFO: Pod "pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:41:32.896: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:41:32.949: INFO: Waiting for pod pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148 to disappear
Feb 19 12:41:32.957: INFO: Pod pod-projected-secrets-ac385446-3443-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:41:32.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4hr2d" for this suite.
Feb 19 12:41:39.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:41:39.098: INFO: namespace: e2e-tests-projected-4hr2d, resource: bindings, ignored listing per whitelist
Feb 19 12:41:39.288: INFO: namespace e2e-tests-projected-4hr2d deletion completed in 6.32100974s

• [SLOW TEST:12.746 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:41:39.289: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rtk99
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:41:39.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-rtk99" to be "success or failure"
Feb 19 12:41:39.600: INFO: Pod "downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.82264ms
Feb 19 12:41:41.613: INFO: Pod "downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021497705s
Feb 19 12:41:43.621: INFO: Pod "downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029120884s
Feb 19 12:41:45.628: INFO: Pod "downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036374318s
STEP: Saw pod success
Feb 19 12:41:45.628: INFO: Pod "downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:41:45.633: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:41:45.673: INFO: Waiting for pod downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148 to disappear
Feb 19 12:41:45.678: INFO: Pod downwardapi-volume-b3d06440-3443-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:41:45.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rtk99" for this suite.
Feb 19 12:41:51.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:41:51.918: INFO: namespace: e2e-tests-projected-rtk99, resource: bindings, ignored listing per whitelist
Feb 19 12:41:51.972: INFO: namespace e2e-tests-projected-rtk99 deletion completed in 6.285234625s

• [SLOW TEST:12.684 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:41:51.973: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2vnsq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 12:41:52.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-2vnsq'
Feb 19 12:41:52.473: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 12:41:52.473: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 19 12:41:52.483: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 19 12:41:52.509: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 19 12:41:52.525: INFO: scanned /root for discovery docs: <nil>
Feb 19 12:41:52.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-2vnsq'
Feb 19 12:42:29.852: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 19 12:42:29.852: INFO: stdout: "Created e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064\nScaling up e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 19 12:42:29.853: INFO: stdout: "Created e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064\nScaling up e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 19 12:42:29.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2vnsq'
Feb 19 12:42:29.995: INFO: stderr: ""
Feb 19 12:42:29.995: INFO: stdout: "e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064-k9xv9 "
Feb 19 12:42:29.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064-k9xv9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2vnsq'
Feb 19 12:42:30.148: INFO: stderr: ""
Feb 19 12:42:30.148: INFO: stdout: "true"
Feb 19 12:42:30.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064-k9xv9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2vnsq'
Feb 19 12:42:30.270: INFO: stderr: ""
Feb 19 12:42:30.270: INFO: stdout: "nginx:1.14-alpine"
Feb 19 12:42:30.270: INFO: e2e-test-nginx-rc-d1b91fc5d01d747a32cce714c8dff064-k9xv9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb 19 12:42:30.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2vnsq'
Feb 19 12:42:30.451: INFO: stderr: ""
Feb 19 12:42:30.451: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:42:30.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2vnsq" for this suite.
Feb 19 12:42:36.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:42:36.620: INFO: namespace: e2e-tests-kubectl-2vnsq, resource: bindings, ignored listing per whitelist
Feb 19 12:42:36.658: INFO: namespace e2e-tests-kubectl-2vnsq deletion completed in 6.196645892s

• [SLOW TEST:44.685 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:42:36.658: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-zh6nq
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:42:36.888: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:42:43.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-zh6nq" for this suite.
Feb 19 12:42:49.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:42:49.163: INFO: namespace: e2e-tests-custom-resource-definition-zh6nq, resource: bindings, ignored listing per whitelist
Feb 19 12:42:49.225: INFO: namespace e2e-tests-custom-resource-definition-zh6nq deletion completed in 6.177697955s

• [SLOW TEST:12.567 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:42:49.225: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-v5zrn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-dd78d2a3-3443-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:42:49.491: INFO: Waiting up to 5m0s for pod "pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-v5zrn" to be "success or failure"
Feb 19 12:42:49.499: INFO: Pod "pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.979846ms
Feb 19 12:42:51.515: INFO: Pod "pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023825077s
Feb 19 12:42:53.521: INFO: Pod "pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029734762s
Feb 19 12:42:55.528: INFO: Pod "pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036223515s
STEP: Saw pod success
Feb 19 12:42:55.528: INFO: Pod "pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:42:55.533: INFO: Trying to get logs from node kube-node-20-105 pod pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:42:55.568: INFO: Waiting for pod pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148 to disappear
Feb 19 12:42:55.573: INFO: Pod pod-secrets-dd7a3439-3443-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:42:55.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v5zrn" for this suite.
Feb 19 12:43:01.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:43:01.651: INFO: namespace: e2e-tests-secrets-v5zrn, resource: bindings, ignored listing per whitelist
Feb 19 12:43:01.803: INFO: namespace e2e-tests-secrets-v5zrn deletion completed in 6.223165127s

• [SLOW TEST:12.578 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:43:01.803: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-qs9x7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 19 12:43:08.063: INFO: Pod pod-hostip-e4f67e08-3443-11e9-af36-92091ca56148 has hostIP: 192.168.20.104
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:43:08.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qs9x7" for this suite.
Feb 19 12:43:30.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:43:30.112: INFO: namespace: e2e-tests-pods-qs9x7, resource: bindings, ignored listing per whitelist
Feb 19 12:43:30.260: INFO: namespace e2e-tests-pods-qs9x7 deletion completed in 22.189844482s

• [SLOW TEST:28.457 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:43:30.260: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-76x4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-76x4x
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-76x4x
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-76x4x
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-76x4x
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-76x4x
Feb 19 12:45:00.551: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-76x4x, name: ss-0, uid: 2b3de31b-3444-11e9-a5f4-5254000cc78a, status phase: Pending. Waiting for statefulset controller to delete.
Feb 19 12:45:00.926: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-76x4x, name: ss-0, uid: 2b3de31b-3444-11e9-a5f4-5254000cc78a, status phase: Failed. Waiting for statefulset controller to delete.
Feb 19 12:45:00.937: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-76x4x, name: ss-0, uid: 2b3de31b-3444-11e9-a5f4-5254000cc78a, status phase: Failed. Waiting for statefulset controller to delete.
Feb 19 12:45:00.942: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-76x4x
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-76x4x
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-76x4x and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 12:45:39.099: INFO: Deleting all statefulset in ns e2e-tests-statefulset-76x4x
Feb 19 12:45:39.105: INFO: Scaling statefulset ss to 0
Feb 19 12:45:49.134: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 12:45:49.138: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:45:49.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-76x4x" for this suite.
Feb 19 12:45:57.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:45:57.224: INFO: namespace: e2e-tests-statefulset-76x4x, resource: bindings, ignored listing per whitelist
Feb 19 12:45:57.348: INFO: namespace e2e-tests-statefulset-76x4x deletion completed in 8.183562443s

• [SLOW TEST:147.088 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:45:57.348: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-flnfb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 19 12:45:57.588: INFO: Waiting up to 5m0s for pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148" in namespace "e2e-tests-var-expansion-flnfb" to be "success or failure"
Feb 19 12:45:57.592: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116496ms
Feb 19 12:45:59.598: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010531143s
Feb 19 12:46:01.605: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017510002s
Feb 19 12:46:03.611: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023523363s
Feb 19 12:46:05.618: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030128974s
Feb 19 12:46:07.630: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.042353475s
Feb 19 12:46:09.637: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.048926783s
Feb 19 12:46:11.643: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.054841565s
Feb 19 12:46:13.655: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.066962698s
Feb 19 12:46:15.660: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.072418709s
Feb 19 12:46:17.667: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.079072835s
Feb 19 12:46:19.674: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.085961577s
Feb 19 12:46:21.680: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.092016645s
Feb 19 12:46:23.685: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.097775018s
Feb 19 12:46:25.691: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 28.103631454s
Feb 19 12:46:27.698: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 30.110283315s
Feb 19 12:46:29.705: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 32.116962455s
Feb 19 12:46:31.711: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 34.12307496s
Feb 19 12:46:33.717: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 36.129724269s
Feb 19 12:46:35.724: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 38.136325048s
Feb 19 12:46:37.731: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 40.142871812s
Feb 19 12:46:39.736: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 42.148091018s
Feb 19 12:46:41.743: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 44.155265514s
Feb 19 12:46:43.749: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 46.161127306s
Feb 19 12:46:45.755: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 48.167489482s
Feb 19 12:46:47.761: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 50.17345086s
Feb 19 12:46:49.768: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 52.180758328s
Feb 19 12:46:51.778: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 54.190361173s
Feb 19 12:46:53.786: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 56.197958098s
Feb 19 12:46:55.792: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 58.20471089s
Feb 19 12:46:57.799: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.211254597s
Feb 19 12:46:59.806: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.21857413s
Feb 19 12:47:01.813: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.224981476s
Feb 19 12:47:03.818: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.230837498s
Feb 19 12:47:05.825: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.237505454s
Feb 19 12:47:07.831: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.243795258s
Feb 19 12:47:09.838: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.25046912s
Feb 19 12:47:11.844: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.256342132s
Feb 19 12:47:13.850: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.262734216s
Feb 19 12:47:15.859: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.271427193s
Feb 19 12:47:17.866: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.277965607s
Feb 19 12:47:19.872: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.284224389s
Feb 19 12:47:21.878: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.290519505s
Feb 19 12:47:23.885: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.296898541s
Feb 19 12:47:25.891: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.30292308s
Feb 19 12:47:27.897: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.309215782s
Feb 19 12:47:29.905: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.317380213s
Feb 19 12:47:31.911: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.323754898s
Feb 19 12:47:33.917: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m36.329814959s
STEP: Saw pod success
Feb 19 12:47:33.918: INFO: Pod "var-expansion-4d981982-3444-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:47:33.921: INFO: Trying to get logs from node kube-node-20-105 pod var-expansion-4d981982-3444-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 12:47:33.953: INFO: Waiting for pod var-expansion-4d981982-3444-11e9-af36-92091ca56148 to disappear
Feb 19 12:47:33.958: INFO: Pod var-expansion-4d981982-3444-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:47:33.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-flnfb" for this suite.
Feb 19 12:47:39.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:47:40.154: INFO: namespace: e2e-tests-var-expansion-flnfb, resource: bindings, ignored listing per whitelist
Feb 19 12:47:40.154: INFO: namespace e2e-tests-var-expansion-flnfb deletion completed in 6.190719312s

• [SLOW TEST:102.806 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:47:40.155: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zjl2b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:47:40.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-zjl2b" to be "success or failure"
Feb 19 12:47:40.397: INFO: Pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.388459ms
Feb 19 12:47:42.403: INFO: Pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011239324s
Feb 19 12:47:44.409: INFO: Pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017604841s
Feb 19 12:47:46.415: INFO: Pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023822401s
Feb 19 12:47:48.422: INFO: Pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030692686s
STEP: Saw pod success
Feb 19 12:47:48.422: INFO: Pod "downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:47:48.427: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:47:48.464: INFO: Waiting for pod downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148 to disappear
Feb 19 12:47:48.472: INFO: Pod downwardapi-volume-8adeb4bb-3444-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:47:48.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjl2b" for this suite.
Feb 19 12:47:54.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:47:54.685: INFO: namespace: e2e-tests-projected-zjl2b, resource: bindings, ignored listing per whitelist
Feb 19 12:47:54.725: INFO: namespace e2e-tests-projected-zjl2b deletion completed in 6.246209529s

• [SLOW TEST:14.570 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:47:54.725: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-m52qw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 19 12:47:54.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 cluster-info'
Feb 19 12:47:55.124: INFO: stderr: ""
Feb 19 12:47:55.124: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:47:55.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m52qw" for this suite.
Feb 19 12:48:01.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:48:01.224: INFO: namespace: e2e-tests-kubectl-m52qw, resource: bindings, ignored listing per whitelist
Feb 19 12:48:01.311: INFO: namespace e2e-tests-kubectl-m52qw deletion completed in 6.180012137s

• [SLOW TEST:6.586 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:48:01.311: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lntbh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 19 12:48:01.539: INFO: Waiting up to 5m0s for pod "pod-9779125b-3444-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-lntbh" to be "success or failure"
Feb 19 12:48:01.543: INFO: Pod "pod-9779125b-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164285ms
Feb 19 12:48:03.548: INFO: Pod "pod-9779125b-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009675624s
Feb 19 12:48:05.554: INFO: Pod "pod-9779125b-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015785934s
Feb 19 12:48:07.558: INFO: Pod "pod-9779125b-3444-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019712454s
STEP: Saw pod success
Feb 19 12:48:07.558: INFO: Pod "pod-9779125b-3444-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:48:07.562: INFO: Trying to get logs from node kube-node-20-105 pod pod-9779125b-3444-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 12:48:07.596: INFO: Waiting for pod pod-9779125b-3444-11e9-af36-92091ca56148 to disappear
Feb 19 12:48:07.600: INFO: Pod pod-9779125b-3444-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:48:07.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lntbh" for this suite.
Feb 19 12:48:13.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:48:13.651: INFO: namespace: e2e-tests-emptydir-lntbh, resource: bindings, ignored listing per whitelist
Feb 19 12:48:13.783: INFO: namespace e2e-tests-emptydir-lntbh deletion completed in 6.174671072s

• [SLOW TEST:12.472 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:48:13.784: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-dvpzs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 19 12:48:14.005: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 12:48:14.017: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 12:48:14.022: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-101 before test
Feb 19 12:48:14.034: INFO: kube-scheduler-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.034: INFO: canal-qdkqk from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.034: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:48:14.034: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:48:14.034: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:48:14.034: INFO: apiserver-proxy-nginx-preset-5b4466959d-8ms5x from kube-system started at 2019-02-18 07:35:39 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.034: INFO: 	Container proxy ready: true, restart count 0
Feb 19 12:48:14.034: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:48:14.034: INFO: kube-controller-manager-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.034: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-xq62r from kube-system started at 2019-02-18 07:35:13 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.034: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 12:48:14.034: INFO: kube-proxy-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.034: INFO: kube-apiserver-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.034: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-5tddr from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.034: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:48:14.034: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:48:14.034: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-102 before test
Feb 19 12:48:14.047: INFO: kube-scheduler-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.047: INFO: kube-controller-manager-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.047: INFO: apiserver-proxy-nginx-preset-5b4466959d-fxx54 from kube-system started at 2019-02-14 05:19:03 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.047: INFO: 	Container proxy ready: true, restart count 0
Feb 19 12:48:14.047: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:48:14.047: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pkrq6 from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.047: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:48:14.047: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:48:14.047: INFO: kube-apiserver-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.047: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-jd6vk from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.047: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 12:48:14.047: INFO: kube-dns-autoscaler-v22-656c98d7b5-gfrdp from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.047: INFO: 	Container autoscaler ready: true, restart count 0
Feb 19 12:48:14.047: INFO: kube-proxy-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.047: INFO: canal-mfnnl from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.047: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:48:14.047: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:48:14.047: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:48:14.047: INFO: kube-dns-v22-55c6fb7579-54jkj from kube-system started at 2019-02-14 05:19:03 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.047: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 19 12:48:14.047: INFO: 	Container kubedns ready: true, restart count 0
Feb 19 12:48:14.047: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:48:14.047: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-103 before test
Feb 19 12:48:14.060: INFO: kube-scheduler-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.060: INFO: canal-xffd7 from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.060: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:48:14.060: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:48:14.060: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:48:14.060: INFO: kube-apiserver-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.060: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-5l2kt from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.060: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 12:48:14.060: INFO: kube-controller-manager-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.060: INFO: default-http-backend-65bd46965-cdcjr from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.060: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 19 12:48:14.060: INFO: apiserver-proxy-nginx-preset-5b4466959d-4pj2p from kube-system started at 2019-02-14 05:19:03 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.060: INFO: 	Container proxy ready: true, restart count 0
Feb 19 12:48:14.060: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:48:14.060: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pz27f from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.060: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:48:14.060: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:48:14.060: INFO: kube-proxy-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:48:14.060: INFO: kube-dns-v22-55c6fb7579-zrzjg from kube-system started at 2019-02-14 05:19:23 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.060: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 19 12:48:14.060: INFO: 	Container kubedns ready: true, restart count 0
Feb 19 12:48:14.060: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:48:14.060: INFO: 
Logging pods the kubelet thinks is on node kube-node-20-104 before test
Feb 19 12:48:14.069: INFO: canal-8jqlz from kube-system started at 2019-02-14 05:20:10 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.069: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:48:14.069: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:48:14.069: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:48:14.069: INFO: kube-proxy-4pr8w from kube-system started at 2019-02-14 05:20:10 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.069: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 12:48:14.069: INFO: heketi-7f9b67f7f-txk48 from default started at 2019-02-14 05:21:05 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.069: INFO: 	Container heketi ready: true, restart count 0
Feb 19 12:48:14.069: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-19 11:42:36 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.069: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 12:48:14.069: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-mkhbh from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.069: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:48:14.069: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:48:14.069: INFO: 
Logging pods the kubelet thinks is on node kube-node-20-105 before test
Feb 19 12:48:14.077: INFO: sonobuoy-e2e-job-21151d8fb97a4946 from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.077: INFO: 	Container e2e ready: true, restart count 0
Feb 19 12:48:14.077: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 12:48:14.077: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-zv89v from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:48:14.077: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:48:14.077: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:48:14.077: INFO: kube-proxy-b2w22 from kube-system started at 2019-02-14 05:20:10 +0000 UTC (1 container statuses recorded)
Feb 19 12:48:14.077: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 12:48:14.077: INFO: canal-jv9n9 from kube-system started at 2019-02-14 05:20:10 +0000 UTC (3 container statuses recorded)
Feb 19 12:48:14.077: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:48:14.077: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:48:14.077: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node kube-master-20-101
STEP: verifying the node has the label node kube-master-20-102
STEP: verifying the node has the label node kube-master-20-103
STEP: verifying the node has the label node kube-node-20-104
STEP: verifying the node has the label node kube-node-20-105
Feb 19 12:48:14.192: INFO: Pod heketi-7f9b67f7f-txk48 requesting resource cpu=0m on Node kube-node-20-104
Feb 19 12:48:14.192: INFO: Pod sonobuoy requesting resource cpu=0m on Node kube-node-20-104
Feb 19 12:48:14.192: INFO: Pod sonobuoy-e2e-job-21151d8fb97a4946 requesting resource cpu=0m on Node kube-node-20-105
Feb 19 12:48:14.192: INFO: Pod sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-5tddr requesting resource cpu=0m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-mkhbh requesting resource cpu=0m on Node kube-node-20-104
Feb 19 12:48:14.192: INFO: Pod sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pkrq6 requesting resource cpu=0m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pz27f requesting resource cpu=0m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-zv89v requesting resource cpu=0m on Node kube-node-20-105
Feb 19 12:48:14.192: INFO: Pod apiserver-provider-ipvsdr-preset-59cdc6b987-5l2kt requesting resource cpu=200m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod apiserver-provider-ipvsdr-preset-59cdc6b987-jd6vk requesting resource cpu=200m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod apiserver-provider-ipvsdr-preset-59cdc6b987-xq62r requesting resource cpu=200m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod apiserver-proxy-nginx-preset-5b4466959d-4pj2p requesting resource cpu=100m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod apiserver-proxy-nginx-preset-5b4466959d-8ms5x requesting resource cpu=100m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod apiserver-proxy-nginx-preset-5b4466959d-fxx54 requesting resource cpu=100m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod canal-8jqlz requesting resource cpu=250m on Node kube-node-20-104
Feb 19 12:48:14.192: INFO: Pod canal-jv9n9 requesting resource cpu=250m on Node kube-node-20-105
Feb 19 12:48:14.192: INFO: Pod canal-mfnnl requesting resource cpu=250m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod canal-qdkqk requesting resource cpu=250m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod canal-xffd7 requesting resource cpu=250m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod default-http-backend-65bd46965-cdcjr requesting resource cpu=50m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod kube-apiserver-kube-master-20-101 requesting resource cpu=250m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod kube-apiserver-kube-master-20-102 requesting resource cpu=250m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod kube-apiserver-kube-master-20-103 requesting resource cpu=250m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod kube-controller-manager-kube-master-20-101 requesting resource cpu=200m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod kube-controller-manager-kube-master-20-102 requesting resource cpu=200m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod kube-controller-manager-kube-master-20-103 requesting resource cpu=200m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod kube-dns-autoscaler-v22-656c98d7b5-gfrdp requesting resource cpu=20m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod kube-dns-v22-55c6fb7579-54jkj requesting resource cpu=260m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod kube-dns-v22-55c6fb7579-zrzjg requesting resource cpu=260m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod kube-proxy-4pr8w requesting resource cpu=100m on Node kube-node-20-104
Feb 19 12:48:14.192: INFO: Pod kube-proxy-b2w22 requesting resource cpu=100m on Node kube-node-20-105
Feb 19 12:48:14.192: INFO: Pod kube-proxy-kube-master-20-101 requesting resource cpu=100m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod kube-proxy-kube-master-20-102 requesting resource cpu=100m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod kube-proxy-kube-master-20-103 requesting resource cpu=100m on Node kube-master-20-103
Feb 19 12:48:14.192: INFO: Pod kube-scheduler-kube-master-20-101 requesting resource cpu=100m on Node kube-master-20-101
Feb 19 12:48:14.192: INFO: Pod kube-scheduler-kube-master-20-102 requesting resource cpu=100m on Node kube-master-20-102
Feb 19 12:48:14.192: INFO: Pod kube-scheduler-kube-master-20-103 requesting resource cpu=100m on Node kube-master-20-103
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f066d26-3444-11e9-af36-92091ca56148.1584c4be81781d82], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dvpzs/filler-pod-9f066d26-3444-11e9-af36-92091ca56148 to kube-master-20-101]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f066d26-3444-11e9-af36-92091ca56148.1584c4beb4351282], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f066d26-3444-11e9-af36-92091ca56148.1584c4bf8b2606c7], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f066d26-3444-11e9-af36-92091ca56148.1584c4bf8da0facd], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f066d26-3444-11e9-af36-92091ca56148.1584c4bf92e84a56], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f083db9-3444-11e9-af36-92091ca56148.1584c4be82204c6d], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dvpzs/filler-pod-9f083db9-3444-11e9-af36-92091ca56148 to kube-master-20-102]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f083db9-3444-11e9-af36-92091ca56148.1584c4beb6a83e8c], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f083db9-3444-11e9-af36-92091ca56148.1584c4bfad236bf4], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f083db9-3444-11e9-af36-92091ca56148.1584c4bfaf742260], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f083db9-3444-11e9-af36-92091ca56148.1584c4bfb63fab59], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0a5077-3444-11e9-af36-92091ca56148.1584c4be832329ea], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dvpzs/filler-pod-9f0a5077-3444-11e9-af36-92091ca56148 to kube-master-20-103]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0a5077-3444-11e9-af36-92091ca56148.1584c4bebe13e9d6], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0a5077-3444-11e9-af36-92091ca56148.1584c4bfc381e21e], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0a5077-3444-11e9-af36-92091ca56148.1584c4bfcac1bbdd], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0a5077-3444-11e9-af36-92091ca56148.1584c4bfd06ff2c1], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0c86b1-3444-11e9-af36-92091ca56148.1584c4be84100830], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dvpzs/filler-pod-9f0c86b1-3444-11e9-af36-92091ca56148 to kube-node-20-104]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0c86b1-3444-11e9-af36-92091ca56148.1584c4beb4953e1c], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0c86b1-3444-11e9-af36-92091ca56148.1584c4c0086a4a62], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0c86b1-3444-11e9-af36-92091ca56148.1584c4c00a75af78], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0c86b1-3444-11e9-af36-92091ca56148.1584c4c00fa03968], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0dc1f1-3444-11e9-af36-92091ca56148.1584c4be841cec04], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dvpzs/filler-pod-9f0dc1f1-3444-11e9-af36-92091ca56148 to kube-node-20-105]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0dc1f1-3444-11e9-af36-92091ca56148.1584c4beb0577c79], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0dc1f1-3444-11e9-af36-92091ca56148.1584c4bf901713c1], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0dc1f1-3444-11e9-af36-92091ca56148.1584c4bf92c5e64e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9f0dc1f1-3444-11e9-af36-92091ca56148.1584c4bf991172de], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1584c4c063b2b1c0], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 Insufficient cpu.]
STEP: removing the label node off the node kube-node-20-104
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-node-20-105
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-master-20-101
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-master-20-102
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-master-20-103
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:48:23.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-dvpzs" for this suite.
Feb 19 12:48:29.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:48:29.521: INFO: namespace: e2e-tests-sched-pred-dvpzs, resource: bindings, ignored listing per whitelist
Feb 19 12:48:29.629: INFO: namespace e2e-tests-sched-pred-dvpzs deletion completed in 6.180620242s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:15.846 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:48:29.629: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7qdl6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 12:48:29.862: INFO: Waiting up to 5m0s for pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-7qdl6" to be "success or failure"
Feb 19 12:48:29.866: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270311ms
Feb 19 12:48:31.873: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010651702s
Feb 19 12:48:33.879: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016927577s
Feb 19 12:48:35.888: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025755723s
Feb 19 12:48:37.895: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032586163s
Feb 19 12:48:39.900: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037961075s
Feb 19 12:48:41.908: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.045916121s
Feb 19 12:48:43.914: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.051908373s
Feb 19 12:48:45.921: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.059249754s
Feb 19 12:48:47.928: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.065704514s
Feb 19 12:48:49.934: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.07176193s
Feb 19 12:48:51.940: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.077888995s
Feb 19 12:48:53.947: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.084492094s
Feb 19 12:48:55.953: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.09143027s
Feb 19 12:48:57.961: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.098630717s
STEP: Saw pod success
Feb 19 12:48:57.961: INFO: Pod "downward-api-a85b8ff7-3444-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:48:57.965: INFO: Trying to get logs from node kube-node-20-104 pod downward-api-a85b8ff7-3444-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 12:48:58.003: INFO: Waiting for pod downward-api-a85b8ff7-3444-11e9-af36-92091ca56148 to disappear
Feb 19 12:48:58.007: INFO: Pod downward-api-a85b8ff7-3444-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:48:58.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7qdl6" for this suite.
Feb 19 12:49:04.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:49:04.156: INFO: namespace: e2e-tests-downward-api-7qdl6, resource: bindings, ignored listing per whitelist
Feb 19 12:49:04.195: INFO: namespace e2e-tests-downward-api-7qdl6 deletion completed in 6.180409339s

• [SLOW TEST:34.566 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:49:04.195: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-xcgxd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 19 12:49:10.466: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-bcf8a02e-3444-11e9-af36-92091ca56148,GenerateName:,Namespace:e2e-tests-events-xcgxd,SelfLink:/api/v1/namespaces/e2e-tests-events-xcgxd/pods/send-events-bcf8a02e-3444-11e9-af36-92091ca56148,UID:bcf9a9ee-3444-11e9-b551-525400c68782,ResourceVersion:948226,Generation:0,CreationTimestamp:2019-02-19 12:49:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 434188685,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.68.213/32,kubernetes.io/psp: 00-privileged,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7zgzs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7zgzs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-7zgzs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File Always nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-node-20-105,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:49:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:49:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:49:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 12:49:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.20.105,PodIP:192.168.68.213,StartTime:2019-02-19 12:49:04 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-19 12:49:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://8d40dec23e91be37d327460236445d79c2759b1e951730684a7cad244aff9507}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 19 12:49:12.474: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 19 12:49:14.480: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:49:14.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xcgxd" for this suite.
Feb 19 12:49:52.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:49:52.534: INFO: namespace: e2e-tests-events-xcgxd, resource: bindings, ignored listing per whitelist
Feb 19 12:49:52.680: INFO: namespace e2e-tests-events-xcgxd deletion completed in 38.181597886s

• [SLOW TEST:48.485 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:49:52.680: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q2ljd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 19 12:49:52.927: INFO: Waiting up to 5m0s for pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-q2ljd" to be "success or failure"
Feb 19 12:49:52.932: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.661958ms
Feb 19 12:49:54.939: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011555523s
Feb 19 12:49:56.946: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018716022s
Feb 19 12:49:58.952: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02506875s
Feb 19 12:50:00.958: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030510217s
Feb 19 12:50:02.964: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037144662s
Feb 19 12:50:04.971: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.044103957s
Feb 19 12:50:06.978: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.050203181s
Feb 19 12:50:08.984: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056528836s
Feb 19 12:50:10.991: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.063237637s
Feb 19 12:50:12.996: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.068892775s
Feb 19 12:50:15.004: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Running", Reason="", readiness=true. Elapsed: 22.076412571s
Feb 19 12:50:17.010: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.082624296s
STEP: Saw pod success
Feb 19 12:50:17.010: INFO: Pod "downward-api-d9dddd6c-3444-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:50:17.014: INFO: Trying to get logs from node kube-node-20-104 pod downward-api-d9dddd6c-3444-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 12:50:17.046: INFO: Waiting for pod downward-api-d9dddd6c-3444-11e9-af36-92091ca56148 to disappear
Feb 19 12:50:17.056: INFO: Pod downward-api-d9dddd6c-3444-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:50:17.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q2ljd" for this suite.
Feb 19 12:50:23.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:50:23.136: INFO: namespace: e2e-tests-downward-api-q2ljd, resource: bindings, ignored listing per whitelist
Feb 19 12:50:23.236: INFO: namespace e2e-tests-downward-api-q2ljd deletion completed in 6.173522676s

• [SLOW TEST:30.556 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:50:23.237: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-f85s8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:50:23.500: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb 19 12:50:23.508: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-f85s8/daemonsets","resourceVersion":"948401"},"items":null}

Feb 19 12:50:23.513: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-f85s8/pods","resourceVersion":"948401"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:50:23.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-f85s8" for this suite.
Feb 19 12:50:29.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:50:29.755: INFO: namespace: e2e-tests-daemonsets-f85s8, resource: bindings, ignored listing per whitelist
Feb 19 12:50:29.788: INFO: namespace e2e-tests-daemonsets-f85s8 deletion completed in 6.248252148s

S [SKIPPING] [6.552 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 19 12:50:23.500: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:50:29.789: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dkr6l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-effea002-3444-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:50:30.066: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-dkr6l" to be "success or failure"
Feb 19 12:50:30.072: INFO: Pod "pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.136296ms
Feb 19 12:50:32.079: INFO: Pod "pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013294906s
Feb 19 12:50:34.086: INFO: Pod "pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019970747s
Feb 19 12:50:36.092: INFO: Pod "pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02596226s
STEP: Saw pod success
Feb 19 12:50:36.092: INFO: Pod "pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:50:36.096: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:50:36.128: INFO: Waiting for pod pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148 to disappear
Feb 19 12:50:36.133: INFO: Pod pod-projected-configmaps-efffde92-3444-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:50:36.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkr6l" for this suite.
Feb 19 12:50:42.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:50:42.310: INFO: namespace: e2e-tests-projected-dkr6l, resource: bindings, ignored listing per whitelist
Feb 19 12:50:42.319: INFO: namespace e2e-tests-projected-dkr6l deletion completed in 6.180095812s

• [SLOW TEST:12.531 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:50:42.320: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-kvv5j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-9cmt
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 12:50:42.569: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9cmt" in namespace "e2e-tests-subpath-kvv5j" to be "success or failure"
Feb 19 12:50:42.573: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.795628ms
Feb 19 12:50:44.578: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008822361s
Feb 19 12:50:46.584: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014609484s
Feb 19 12:50:48.588: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019206035s
Feb 19 12:50:50.596: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027289974s
Feb 19 12:50:52.602: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 10.033257776s
Feb 19 12:50:54.609: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 12.03968615s
Feb 19 12:50:56.615: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 14.046488541s
Feb 19 12:50:58.623: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 16.053699297s
Feb 19 12:51:00.630: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 18.060952884s
Feb 19 12:51:02.638: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 20.069100342s
Feb 19 12:51:04.645: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 22.076177599s
Feb 19 12:51:06.652: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 24.082818505s
Feb 19 12:51:08.659: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 26.089607276s
Feb 19 12:51:10.665: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 28.096043414s
Feb 19 12:51:12.671: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 30.10213604s
Feb 19 12:51:14.677: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 32.108084511s
Feb 19 12:51:16.684: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 34.115050322s
Feb 19 12:51:18.691: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 36.121830432s
Feb 19 12:51:20.699: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 38.130257187s
Feb 19 12:51:22.707: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 40.138242169s
Feb 19 12:51:24.713: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 42.144482952s
Feb 19 12:51:26.720: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 44.151010891s
Feb 19 12:51:28.727: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 46.157713096s
Feb 19 12:51:30.735: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 48.165701501s
Feb 19 12:51:32.740: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 50.171407418s
Feb 19 12:51:34.747: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 52.177885059s
Feb 19 12:51:36.754: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Pending", Reason="", readiness=false. Elapsed: 54.185238699s
Feb 19 12:51:38.760: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 56.191086245s
Feb 19 12:51:40.766: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 58.197039771s
Feb 19 12:51:42.772: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 1m0.202984093s
Feb 19 12:51:44.779: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 1m2.209691452s
Feb 19 12:51:46.786: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 1m4.217226635s
Feb 19 12:51:48.793: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 1m6.223717189s
Feb 19 12:51:50.799: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Running", Reason="", readiness=false. Elapsed: 1m8.229832103s
Feb 19 12:51:52.806: INFO: Pod "pod-subpath-test-projected-9cmt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m10.236749465s
STEP: Saw pod success
Feb 19 12:51:52.806: INFO: Pod "pod-subpath-test-projected-9cmt" satisfied condition "success or failure"
Feb 19 12:51:52.810: INFO: Trying to get logs from node kube-node-20-104 pod pod-subpath-test-projected-9cmt container test-container-subpath-projected-9cmt: <nil>
STEP: delete the pod
Feb 19 12:51:52.841: INFO: Waiting for pod pod-subpath-test-projected-9cmt to disappear
Feb 19 12:51:52.848: INFO: Pod pod-subpath-test-projected-9cmt no longer exists
STEP: Deleting pod pod-subpath-test-projected-9cmt
Feb 19 12:51:52.848: INFO: Deleting pod "pod-subpath-test-projected-9cmt" in namespace "e2e-tests-subpath-kvv5j"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:51:52.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kvv5j" for this suite.
Feb 19 12:51:58.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:51:59.030: INFO: namespace: e2e-tests-subpath-kvv5j, resource: bindings, ignored listing per whitelist
Feb 19 12:51:59.038: INFO: namespace e2e-tests-subpath-kvv5j deletion completed in 6.178065119s

• [SLOW TEST:76.719 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:51:59.039: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-cb2mh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:51:59.286: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 19 12:52:04.292: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 19 12:53:38.304: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 19 12:53:38.341: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-cb2mh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cb2mh/deployments/test-cleanup-deployment,UID:603758ad-3445-11e9-b551-525400c68782,ResourceVersion:948847,Generation:1,CreationTimestamp:2019-02-19 12:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 19 12:53:38.347: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:53:38.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cb2mh" for this suite.
Feb 19 12:53:44.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:53:44.436: INFO: namespace: e2e-tests-deployment-cb2mh, resource: bindings, ignored listing per whitelist
Feb 19 12:53:44.527: INFO: namespace e2e-tests-deployment-cb2mh deletion completed in 6.168285058s

• [SLOW TEST:105.489 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:53:44.527: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-2xvqf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 12:53:44.762: INFO: Creating ReplicaSet my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148
Feb 19 12:53:44.773: INFO: Pod name my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148: Found 0 pods out of 1
Feb 19 12:53:49.779: INFO: Pod name my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148: Found 1 pods out of 1
Feb 19 12:53:49.779: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148" is running
Feb 19 12:53:51.790: INFO: Pod "my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148-95pw4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 12:53:44 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 12:53:44 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 12:53:44 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 12:53:44 +0000 UTC Reason: Message:}])
Feb 19 12:53:51.790: INFO: Trying to dial the pod
Feb 19 12:53:56.811: INFO: Controller my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148: Got expected result from replica 1 [my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148-95pw4]: "my-hostname-basic-640f432e-3445-11e9-af36-92091ca56148-95pw4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:53:56.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2xvqf" for this suite.
Feb 19 12:54:02.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:54:02.899: INFO: namespace: e2e-tests-replicaset-2xvqf, resource: bindings, ignored listing per whitelist
Feb 19 12:54:03.000: INFO: namespace e2e-tests-replicaset-2xvqf deletion completed in 6.182460536s

• [SLOW TEST:18.473 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:54:03.001: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-jdn5m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 19 12:54:03.242: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 12:54:03.254: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 12:54:03.258: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-101 before test
Feb 19 12:54:03.273: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-xq62r from kube-system started at 2019-02-18 07:35:13 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.273: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 12:54:03.273: INFO: kube-apiserver-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.273: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-5tddr from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.273: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:54:03.273: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:54:03.273: INFO: kube-proxy-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.273: INFO: canal-qdkqk from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.273: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:54:03.273: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:54:03.273: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:54:03.273: INFO: apiserver-proxy-nginx-preset-5b4466959d-8ms5x from kube-system started at 2019-02-18 07:35:39 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.273: INFO: 	Container proxy ready: true, restart count 0
Feb 19 12:54:03.273: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:54:03.273: INFO: kube-scheduler-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.273: INFO: kube-controller-manager-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.273: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-102 before test
Feb 19 12:54:03.289: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pkrq6 from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.289: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:54:03.289: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:54:03.289: INFO: kube-apiserver-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.289: INFO: kube-dns-v22-55c6fb7579-54jkj from kube-system started at 2019-02-14 05:19:03 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.289: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 19 12:54:03.289: INFO: 	Container kubedns ready: true, restart count 0
Feb 19 12:54:03.289: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:54:03.289: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-jd6vk from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.289: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 12:54:03.289: INFO: kube-dns-autoscaler-v22-656c98d7b5-gfrdp from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.289: INFO: 	Container autoscaler ready: true, restart count 0
Feb 19 12:54:03.289: INFO: kube-proxy-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.289: INFO: canal-mfnnl from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.289: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:54:03.289: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:54:03.289: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:54:03.289: INFO: kube-scheduler-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.289: INFO: kube-controller-manager-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.289: INFO: apiserver-proxy-nginx-preset-5b4466959d-fxx54 from kube-system started at 2019-02-14 05:19:03 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.289: INFO: 	Container proxy ready: true, restart count 0
Feb 19 12:54:03.289: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:54:03.289: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-103 before test
Feb 19 12:54:03.303: INFO: kube-controller-manager-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.303: INFO: default-http-backend-65bd46965-cdcjr from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.303: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 19 12:54:03.303: INFO: apiserver-proxy-nginx-preset-5b4466959d-4pj2p from kube-system started at 2019-02-14 05:19:03 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.303: INFO: 	Container proxy ready: true, restart count 0
Feb 19 12:54:03.303: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:54:03.303: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pz27f from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.303: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:54:03.303: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:54:03.303: INFO: kube-proxy-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.303: INFO: kube-dns-v22-55c6fb7579-zrzjg from kube-system started at 2019-02-14 05:19:23 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.303: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 19 12:54:03.303: INFO: 	Container kubedns ready: true, restart count 0
Feb 19 12:54:03.303: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 12:54:03.303: INFO: kube-scheduler-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.303: INFO: canal-xffd7 from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.303: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:54:03.303: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:54:03.303: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:54:03.303: INFO: kube-apiserver-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 12:54:03.303: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-5l2kt from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.303: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 12:54:03.303: INFO: 
Logging pods the kubelet thinks is on node kube-node-20-104 before test
Feb 19 12:54:03.314: INFO: kube-proxy-4pr8w from kube-system started at 2019-02-14 05:20:10 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.314: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 12:54:03.314: INFO: heketi-7f9b67f7f-txk48 from default started at 2019-02-14 05:21:05 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.314: INFO: 	Container heketi ready: true, restart count 0
Feb 19 12:54:03.314: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-19 11:42:36 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.314: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 12:54:03.314: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-mkhbh from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.314: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:54:03.314: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 12:54:03.314: INFO: canal-8jqlz from kube-system started at 2019-02-14 05:20:10 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.314: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:54:03.314: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:54:03.314: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:54:03.314: INFO: 
Logging pods the kubelet thinks is on node kube-node-20-105 before test
Feb 19 12:54:03.324: INFO: kube-proxy-b2w22 from kube-system started at 2019-02-14 05:20:10 +0000 UTC (1 container statuses recorded)
Feb 19 12:54:03.324: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 12:54:03.324: INFO: canal-jv9n9 from kube-system started at 2019-02-14 05:20:10 +0000 UTC (3 container statuses recorded)
Feb 19 12:54:03.324: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 12:54:03.324: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 12:54:03.324: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 12:54:03.324: INFO: sonobuoy-e2e-job-21151d8fb97a4946 from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.324: INFO: 	Container e2e ready: true, restart count 0
Feb 19 12:54:03.324: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 12:54:03.324: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-zv89v from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 12:54:03.324: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 12:54:03.324: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1584c50fcc273765], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:54:04.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jdn5m" for this suite.
Feb 19 12:54:10.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:54:10.504: INFO: namespace: e2e-tests-sched-pred-jdn5m, resource: bindings, ignored listing per whitelist
Feb 19 12:54:10.548: INFO: namespace e2e-tests-sched-pred-jdn5m deletion completed in 6.174334652s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.548 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:54:10.549: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9sct4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-738ea451-3445-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:54:10.779: INFO: Waiting up to 5m0s for pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-9sct4" to be "success or failure"
Feb 19 12:54:10.784: INFO: Pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.819554ms
Feb 19 12:54:12.791: INFO: Pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011770157s
Feb 19 12:54:14.798: INFO: Pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019080523s
Feb 19 12:54:16.805: INFO: Pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148": Phase="Running", Reason="", readiness=true. Elapsed: 6.025134015s
Feb 19 12:54:18.811: INFO: Pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.031518974s
STEP: Saw pod success
Feb 19 12:54:18.811: INFO: Pod "pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:54:18.815: INFO: Trying to get logs from node kube-node-20-105 pod pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:54:18.852: INFO: Waiting for pod pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148 to disappear
Feb 19 12:54:18.857: INFO: Pod pod-configmaps-738f6f5b-3445-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:54:18.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9sct4" for this suite.
Feb 19 12:54:24.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:54:24.948: INFO: namespace: e2e-tests-configmap-9sct4, resource: bindings, ignored listing per whitelist
Feb 19 12:54:25.056: INFO: namespace e2e-tests-configmap-9sct4 deletion completed in 6.191499241s

• [SLOW TEST:14.507 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:54:25.057: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-smrs8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7c3725b6-3445-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:54:25.588: INFO: Waiting up to 5m0s for pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-smrs8" to be "success or failure"
Feb 19 12:54:25.594: INFO: Pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.57555ms
Feb 19 12:54:27.600: INFO: Pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011928671s
Feb 19 12:54:29.606: INFO: Pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018456343s
Feb 19 12:54:31.612: INFO: Pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024092758s
Feb 19 12:54:33.618: INFO: Pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030429479s
STEP: Saw pod success
Feb 19 12:54:33.618: INFO: Pod "pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:54:33.622: INFO: Trying to get logs from node kube-node-20-104 pod pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:54:33.654: INFO: Waiting for pod pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148 to disappear
Feb 19 12:54:33.657: INFO: Pod pod-secrets-7c4e2151-3445-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:54:33.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-smrs8" for this suite.
Feb 19 12:54:39.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:54:39.705: INFO: namespace: e2e-tests-secrets-smrs8, resource: bindings, ignored listing per whitelist
Feb 19 12:54:39.827: INFO: namespace e2e-tests-secrets-smrs8 deletion completed in 6.164234895s

• [SLOW TEST:14.771 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:54:39.828: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5jb6c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5jb6c
Feb 19 12:56:14.074: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5jb6c
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 12:56:14.079: INFO: Initial restart count of pod liveness-exec is 0
Feb 19 12:57:52.409: INFO: Restart count of pod e2e-tests-container-probe-5jb6c/liveness-exec is now 1 (1m38.329893114s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:57:52.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5jb6c" for this suite.
Feb 19 12:57:58.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:57:58.567: INFO: namespace: e2e-tests-container-probe-5jb6c, resource: bindings, ignored listing per whitelist
Feb 19 12:57:58.609: INFO: namespace e2e-tests-container-probe-5jb6c deletion completed in 6.172516174s

• [SLOW TEST:198.781 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:57:58.609: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gttbh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 12:57:58.840: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-gttbh" to be "success or failure"
Feb 19 12:57:58.848: INFO: Pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 7.75831ms
Feb 19 12:58:00.855: INFO: Pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014221741s
Feb 19 12:58:02.861: INFO: Pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020398415s
Feb 19 12:58:04.868: INFO: Pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027384216s
Feb 19 12:58:06.874: INFO: Pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.033675622s
STEP: Saw pod success
Feb 19 12:58:06.874: INFO: Pod "downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:58:06.879: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 12:58:06.912: INFO: Waiting for pod downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148 to disappear
Feb 19 12:58:06.916: INFO: Pod downwardapi-volume-fb7eb0f4-3445-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:58:06.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gttbh" for this suite.
Feb 19 12:58:12.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:58:13.063: INFO: namespace: e2e-tests-downward-api-gttbh, resource: bindings, ignored listing per whitelist
Feb 19 12:58:13.093: INFO: namespace e2e-tests-downward-api-gttbh deletion completed in 6.171144388s

• [SLOW TEST:14.484 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:58:13.094: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bg9sh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-0422f88f-3446-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 12:58:13.347: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-bg9sh" to be "success or failure"
Feb 19 12:58:13.354: INFO: Pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.785055ms
Feb 19 12:58:15.360: INFO: Pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012933641s
Feb 19 12:58:17.366: INFO: Pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019453779s
Feb 19 12:58:19.373: INFO: Pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025835158s
Feb 19 12:58:21.381: INFO: Pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.034695754s
STEP: Saw pod success
Feb 19 12:58:21.382: INFO: Pod "pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:58:21.392: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 12:58:21.433: INFO: Waiting for pod pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148 to disappear
Feb 19 12:58:21.440: INFO: Pod pod-projected-secrets-042418bc-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:58:21.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bg9sh" for this suite.
Feb 19 12:58:27.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:58:27.556: INFO: namespace: e2e-tests-projected-bg9sh, resource: bindings, ignored listing per whitelist
Feb 19 12:58:27.617: INFO: namespace e2e-tests-projected-bg9sh deletion completed in 6.16914327s

• [SLOW TEST:14.523 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:58:27.617: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-ggzqf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-ggzqf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ggzqf to expose endpoints map[]
Feb 19 12:58:27.868: INFO: Get endpoints failed (8.60198ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 19 12:58:28.874: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ggzqf exposes endpoints map[] (1.014829864s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ggzqf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ggzqf to expose endpoints map[pod1:[100]]
Feb 19 12:58:32.937: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.050175105s elapsed, will retry)
Feb 19 12:58:33.949: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ggzqf exposes endpoints map[pod1:[100]] (5.062095213s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ggzqf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ggzqf to expose endpoints map[pod1:[100] pod2:[101]]
Feb 19 12:58:38.042: INFO: Unexpected endpoints: found map[0d6872db-3446-11e9-b551-525400c68782:[100]], expected map[pod1:[100] pod2:[101]] (4.084611054s elapsed, will retry)
Feb 19 12:58:42.109: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ggzqf exposes endpoints map[pod1:[100] pod2:[101]] (8.151770889s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ggzqf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ggzqf to expose endpoints map[pod2:[101]]
Feb 19 12:58:43.139: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ggzqf exposes endpoints map[pod2:[101]] (1.019536506s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ggzqf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ggzqf to expose endpoints map[]
Feb 19 12:58:43.156: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ggzqf exposes endpoints map[] (8.103091ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:58:43.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ggzqf" for this suite.
Feb 19 12:59:05.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:59:05.261: INFO: namespace: e2e-tests-services-ggzqf, resource: bindings, ignored listing per whitelist
Feb 19 12:59:05.388: INFO: namespace e2e-tests-services-ggzqf deletion completed in 22.18852107s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:37.772 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:59:05.389: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-nn6rz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-42nv9
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 19 12:59:13.808: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-v4cdq
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:59:38.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-nn6rz" for this suite.
Feb 19 12:59:44.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:59:44.090: INFO: namespace: e2e-tests-namespaces-nn6rz, resource: bindings, ignored listing per whitelist
Feb 19 12:59:44.200: INFO: namespace e2e-tests-namespaces-nn6rz deletion completed in 6.187514417s
STEP: Destroying namespace "e2e-tests-nsdeletetest-42nv9" for this suite.
Feb 19 12:59:44.204: INFO: Namespace e2e-tests-nsdeletetest-42nv9 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-v4cdq" for this suite.
Feb 19 12:59:50.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 12:59:50.288: INFO: namespace: e2e-tests-nsdeletetest-v4cdq, resource: bindings, ignored listing per whitelist
Feb 19 12:59:50.373: INFO: namespace e2e-tests-nsdeletetest-v4cdq deletion completed in 6.169046937s

• [SLOW TEST:44.985 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 12:59:50.374: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-76765
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-3e1def7d-3446-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 12:59:50.624: INFO: Waiting up to 5m0s for pod "pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-76765" to be "success or failure"
Feb 19 12:59:50.631: INFO: Pod "pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 7.213509ms
Feb 19 12:59:52.638: INFO: Pod "pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01421759s
Feb 19 12:59:54.644: INFO: Pod "pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019874057s
Feb 19 12:59:56.650: INFO: Pod "pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025973478s
STEP: Saw pod success
Feb 19 12:59:56.650: INFO: Pod "pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 12:59:56.655: INFO: Trying to get logs from node kube-node-20-104 pod pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 12:59:56.688: INFO: Waiting for pod pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148 to disappear
Feb 19 12:59:56.693: INFO: Pod pod-configmaps-3e1ed7a2-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 12:59:56.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-76765" for this suite.
Feb 19 13:00:02.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:00:02.759: INFO: namespace: e2e-tests-configmap-76765, resource: bindings, ignored listing per whitelist
Feb 19 13:00:02.888: INFO: namespace e2e-tests-configmap-76765 deletion completed in 6.189801633s

• [SLOW TEST:12.514 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:00:02.889: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-xjwwt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 19 13:00:03.651: INFO: Waiting up to 5m0s for pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc" in namespace "e2e-tests-svcaccounts-xjwwt" to be "success or failure"
Feb 19 13:00:03.660: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.365656ms
Feb 19 13:00:05.667: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014997637s
Feb 19 13:00:07.674: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022313606s
Feb 19 13:00:09.681: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029180406s
Feb 19 13:00:11.689: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037114252s
Feb 19 13:00:13.695: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.043283428s
Feb 19 13:00:15.704: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.052663038s
Feb 19 13:00:17.711: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.059913915s
Feb 19 13:00:19.717: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.065761526s
STEP: Saw pod success
Feb 19 13:00:19.717: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc" satisfied condition "success or failure"
Feb 19 13:00:19.722: INFO: Trying to get logs from node kube-node-20-105 pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc container token-test: <nil>
STEP: delete the pod
Feb 19 13:00:19.752: INFO: Waiting for pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc to disappear
Feb 19 13:00:19.758: INFO: Pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-m24pc no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 19 13:00:19.767: INFO: Waiting up to 5m0s for pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5" in namespace "e2e-tests-svcaccounts-xjwwt" to be "success or failure"
Feb 19 13:00:19.778: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.105943ms
Feb 19 13:00:21.783: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016344218s
Feb 19 13:00:23.789: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022259211s
Feb 19 13:00:25.795: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028127237s
Feb 19 13:00:27.805: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.038261375s
Feb 19 13:00:29.811: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044457673s
Feb 19 13:00:31.817: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.050722624s
Feb 19 13:00:33.824: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.056987887s
Feb 19 13:00:35.831: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.064073807s
STEP: Saw pod success
Feb 19 13:00:35.831: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5" satisfied condition "success or failure"
Feb 19 13:00:35.836: INFO: Trying to get logs from node kube-node-20-104 pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5 container root-ca-test: <nil>
STEP: delete the pod
Feb 19 13:00:35.870: INFO: Waiting for pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5 to disappear
Feb 19 13:00:35.879: INFO: Pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-9zhf5 no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 19 13:00:35.900: INFO: Waiting up to 5m0s for pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l" in namespace "e2e-tests-svcaccounts-xjwwt" to be "success or failure"
Feb 19 13:00:35.906: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 5.452935ms
Feb 19 13:00:37.912: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011335082s
Feb 19 13:00:39.918: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017928284s
Feb 19 13:00:41.925: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02510775s
Feb 19 13:00:43.931: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030627479s
Feb 19 13:00:45.937: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037008131s
Feb 19 13:00:47.945: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Pending", Reason="", readiness=false. Elapsed: 12.044440772s
Feb 19 13:00:49.950: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.049802844s
STEP: Saw pod success
Feb 19 13:00:49.950: INFO: Pod "pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l" satisfied condition "success or failure"
Feb 19 13:00:49.954: INFO: Trying to get logs from node kube-node-20-105 pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l container namespace-test: <nil>
STEP: delete the pod
Feb 19 13:00:49.986: INFO: Waiting for pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l to disappear
Feb 19 13:00:49.993: INFO: Pod pod-service-account-45e31ffb-3446-11e9-af36-92091ca56148-vwj9l no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:00:49.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-xjwwt" for this suite.
Feb 19 13:00:56.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:00:56.153: INFO: namespace: e2e-tests-svcaccounts-xjwwt, resource: bindings, ignored listing per whitelist
Feb 19 13:00:56.166: INFO: namespace e2e-tests-svcaccounts-xjwwt deletion completed in 6.16642322s

• [SLOW TEST:53.278 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:00:56.167: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-hkrgn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-hkrgn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hkrgn to expose endpoints map[]
Feb 19 13:00:56.409: INFO: Get endpoints failed (12.653694ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 19 13:00:57.415: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hkrgn exposes endpoints map[] (1.018721006s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-hkrgn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hkrgn to expose endpoints map[pod1:[80]]
Feb 19 13:01:01.476: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.048474497s elapsed, will retry)
Feb 19 13:01:04.508: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hkrgn exposes endpoints map[pod1:[80]] (7.080372373s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-hkrgn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hkrgn to expose endpoints map[pod1:[80] pod2:[80]]
Feb 19 13:01:08.588: INFO: Unexpected endpoints: found map[65f1e97a-3446-11e9-b551-525400c68782:[80]], expected map[pod1:[80] pod2:[80]] (4.070742786s elapsed, will retry)
Feb 19 13:01:09.603: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hkrgn exposes endpoints map[pod1:[80] pod2:[80]] (5.085647061s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-hkrgn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hkrgn to expose endpoints map[pod2:[80]]
Feb 19 13:01:09.633: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hkrgn exposes endpoints map[pod2:[80]] (18.564557ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-hkrgn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hkrgn to expose endpoints map[]
Feb 19 13:01:10.657: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hkrgn exposes endpoints map[] (1.013780958s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:01:10.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hkrgn" for this suite.
Feb 19 13:01:32.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:01:32.916: INFO: namespace: e2e-tests-services-hkrgn, resource: bindings, ignored listing per whitelist
Feb 19 13:01:32.946: INFO: namespace e2e-tests-services-hkrgn deletion completed in 22.246433031s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:36.780 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:01:32.947: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fq4gq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7b40d769-3446-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 13:01:33.189: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-fq4gq" to be "success or failure"
Feb 19 13:01:33.195: INFO: Pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.507667ms
Feb 19 13:01:35.201: INFO: Pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011420705s
Feb 19 13:01:37.209: INFO: Pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019189286s
Feb 19 13:01:39.214: INFO: Pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024416559s
Feb 19 13:01:41.220: INFO: Pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.031053193s
STEP: Saw pod success
Feb 19 13:01:41.220: INFO: Pod "pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:01:41.224: INFO: Trying to get logs from node kube-node-20-104 pod pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 13:01:41.260: INFO: Waiting for pod pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148 to disappear
Feb 19 13:01:41.264: INFO: Pod pod-projected-secrets-7b41ba93-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:01:41.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fq4gq" for this suite.
Feb 19 13:01:47.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:01:47.330: INFO: namespace: e2e-tests-projected-fq4gq, resource: bindings, ignored listing per whitelist
Feb 19 13:01:47.454: INFO: namespace e2e-tests-projected-fq4gq deletion completed in 6.181940703s

• [SLOW TEST:14.506 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:01:47.454: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gr9wz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 19 13:01:47.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-gr9wz'
Feb 19 13:01:48.218: INFO: stderr: ""
Feb 19 13:01:48.218: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 19 13:01:49.225: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:49.225: INFO: Found 0 / 1
Feb 19 13:01:50.225: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:50.225: INFO: Found 0 / 1
Feb 19 13:01:51.224: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:51.224: INFO: Found 0 / 1
Feb 19 13:01:52.224: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:52.225: INFO: Found 0 / 1
Feb 19 13:01:53.226: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:53.226: INFO: Found 0 / 1
Feb 19 13:01:54.225: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:54.225: INFO: Found 1 / 1
Feb 19 13:01:54.225: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 19 13:01:54.230: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:54.230: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 19 13:01:54.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 patch pod redis-master-nf87d --namespace=e2e-tests-kubectl-gr9wz -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 19 13:01:54.373: INFO: stderr: ""
Feb 19 13:01:54.373: INFO: stdout: "pod/redis-master-nf87d patched\n"
STEP: checking annotations
Feb 19 13:01:54.380: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:01:54.380: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:01:54.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gr9wz" for this suite.
Feb 19 13:02:16.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:02:16.534: INFO: namespace: e2e-tests-kubectl-gr9wz, resource: bindings, ignored listing per whitelist
Feb 19 13:02:16.560: INFO: namespace e2e-tests-kubectl-gr9wz deletion completed in 22.172439557s

• [SLOW TEST:29.106 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:02:16.560: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-xvtrw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148
Feb 19 13:02:16.800: INFO: Pod name my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148: Found 0 pods out of 1
Feb 19 13:02:21.807: INFO: Pod name my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148: Found 1 pods out of 1
Feb 19 13:02:21.807: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148" are running
Feb 19 13:02:23.817: INFO: Pod "my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148-2lrkb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 13:02:16 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 13:02:16 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 13:02:16 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-19 13:02:16 +0000 UTC Reason: Message:}])
Feb 19 13:02:23.818: INFO: Trying to dial the pod
Feb 19 13:02:28.836: INFO: Controller my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148: Got expected result from replica 1 [my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148-2lrkb]: "my-hostname-basic-9540371e-3446-11e9-af36-92091ca56148-2lrkb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:02:28.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xvtrw" for this suite.
Feb 19 13:02:34.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:02:34.992: INFO: namespace: e2e-tests-replication-controller-xvtrw, resource: bindings, ignored listing per whitelist
Feb 19 13:02:35.011: INFO: namespace e2e-tests-replication-controller-xvtrw deletion completed in 6.167669776s

• [SLOW TEST:18.451 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:02:35.011: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-n4lq6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-n4lq6/configmap-test-a03e58f2-3446-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 13:02:35.254: INFO: Waiting up to 5m0s for pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-n4lq6" to be "success or failure"
Feb 19 13:02:35.259: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.883069ms
Feb 19 13:02:37.265: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011256569s
Feb 19 13:02:39.272: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017859345s
Feb 19 13:02:41.278: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023949069s
Feb 19 13:02:43.284: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030468023s
Feb 19 13:02:45.291: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037258006s
Feb 19 13:02:47.296: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.042239917s
Feb 19 13:02:49.303: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.049181996s
Feb 19 13:02:51.310: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056169918s
Feb 19 13:02:53.316: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.062391625s
Feb 19 13:02:55.323: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.069123621s
Feb 19 13:02:57.330: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.075968875s
Feb 19 13:02:59.336: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.082082396s
Feb 19 13:03:01.343: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.089035513s
Feb 19 13:03:03.349: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 28.095365676s
Feb 19 13:03:05.356: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 30.101946232s
Feb 19 13:03:07.363: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 32.10860655s
Feb 19 13:03:09.371: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 34.117073962s
Feb 19 13:03:11.376: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 36.122491264s
Feb 19 13:03:13.383: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 38.129002869s
Feb 19 13:03:15.390: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 40.135953628s
Feb 19 13:03:17.396: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 42.141775463s
Feb 19 13:03:19.401: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 44.147437072s
Feb 19 13:03:21.408: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 46.153797937s
Feb 19 13:03:23.414: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 48.15963806s
Feb 19 13:03:25.420: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 50.166362685s
STEP: Saw pod success
Feb 19 13:03:25.420: INFO: Pod "pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:03:25.425: INFO: Trying to get logs from node kube-node-20-105 pod pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148 container env-test: <nil>
STEP: delete the pod
Feb 19 13:03:25.455: INFO: Waiting for pod pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148 to disappear
Feb 19 13:03:25.461: INFO: Pod pod-configmaps-a03f747d-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:03:25.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n4lq6" for this suite.
Feb 19 13:03:31.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:03:31.619: INFO: namespace: e2e-tests-configmap-n4lq6, resource: bindings, ignored listing per whitelist
Feb 19 13:03:31.658: INFO: namespace e2e-tests-configmap-n4lq6 deletion completed in 6.189142178s

• [SLOW TEST:56.647 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:03:31.658: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5cbk7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb 19 13:03:31.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-5cbk7'
Feb 19 13:03:32.194: INFO: stderr: ""
Feb 19 13:03:32.194: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 19 13:03:33.203: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:33.203: INFO: Found 0 / 1
Feb 19 13:03:34.203: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:34.203: INFO: Found 0 / 1
Feb 19 13:03:35.202: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:35.202: INFO: Found 0 / 1
Feb 19 13:03:36.200: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:36.200: INFO: Found 0 / 1
Feb 19 13:03:37.202: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:37.202: INFO: Found 0 / 1
Feb 19 13:03:38.201: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:38.201: INFO: Found 1 / 1
Feb 19 13:03:38.201: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 19 13:03:38.206: INFO: Selector matched 1 pods for map[app:redis]
Feb 19 13:03:38.206: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 19 13:03:38.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 logs redis-master-r5zk6 redis-master --namespace=e2e-tests-kubectl-5cbk7'
Feb 19 13:03:38.419: INFO: stderr: ""
Feb 19 13:03:38.419: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 13:03:37.198 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 13:03:37.198 # Server started, Redis version 3.2.12\n1:M 19 Feb 13:03:37.198 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 13:03:37.198 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 19 13:03:38.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 log redis-master-r5zk6 redis-master --namespace=e2e-tests-kubectl-5cbk7 --tail=1'
Feb 19 13:03:38.619: INFO: stderr: ""
Feb 19 13:03:38.619: INFO: stdout: "1:M 19 Feb 13:03:37.198 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 19 13:03:38.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 log redis-master-r5zk6 redis-master --namespace=e2e-tests-kubectl-5cbk7 --limit-bytes=1'
Feb 19 13:03:38.752: INFO: stderr: ""
Feb 19 13:03:38.752: INFO: stdout: " "
STEP: exposing timestamps
Feb 19 13:03:38.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 log redis-master-r5zk6 redis-master --namespace=e2e-tests-kubectl-5cbk7 --tail=1 --timestamps'
Feb 19 13:03:38.888: INFO: stderr: ""
Feb 19 13:03:38.888: INFO: stdout: "2019-02-19T13:03:37.199054682Z 1:M 19 Feb 13:03:37.198 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 19 13:03:41.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 log redis-master-r5zk6 redis-master --namespace=e2e-tests-kubectl-5cbk7 --since=1s'
Feb 19 13:03:41.541: INFO: stderr: ""
Feb 19 13:03:41.541: INFO: stdout: ""
Feb 19 13:03:41.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 log redis-master-r5zk6 redis-master --namespace=e2e-tests-kubectl-5cbk7 --since=24h'
Feb 19 13:03:41.692: INFO: stderr: ""
Feb 19 13:03:41.692: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 19 Feb 13:03:37.198 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 19 Feb 13:03:37.198 # Server started, Redis version 3.2.12\n1:M 19 Feb 13:03:37.198 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 19 Feb 13:03:37.198 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb 19 13:03:41.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5cbk7'
Feb 19 13:03:41.822: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:03:41.822: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 19 13:03:41.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-5cbk7'
Feb 19 13:03:41.949: INFO: stderr: "No resources found.\n"
Feb 19 13:03:41.949: INFO: stdout: ""
Feb 19 13:03:41.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -l name=nginx --namespace=e2e-tests-kubectl-5cbk7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 13:03:42.075: INFO: stderr: ""
Feb 19 13:03:42.075: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:03:42.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5cbk7" for this suite.
Feb 19 13:04:04.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:04:04.165: INFO: namespace: e2e-tests-kubectl-5cbk7, resource: bindings, ignored listing per whitelist
Feb 19 13:04:04.250: INFO: namespace e2e-tests-kubectl-5cbk7 deletion completed in 22.16893711s

• [SLOW TEST:32.592 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:04:04.251: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t5z4t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 13:04:04.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-t5z4t" to be "success or failure"
Feb 19 13:04:04.493: INFO: Pod "downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.729793ms
Feb 19 13:04:06.499: INFO: Pod "downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011067566s
Feb 19 13:04:08.505: INFO: Pod "downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016954479s
Feb 19 13:04:10.512: INFO: Pod "downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02320074s
STEP: Saw pod success
Feb 19 13:04:10.512: INFO: Pod "downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:04:10.517: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 13:04:10.553: INFO: Waiting for pod downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148 to disappear
Feb 19 13:04:10.559: INFO: Pod downwardapi-volume-d56ffc84-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:04:10.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t5z4t" for this suite.
Feb 19 13:04:16.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:04:16.626: INFO: namespace: e2e-tests-downward-api-t5z4t, resource: bindings, ignored listing per whitelist
Feb 19 13:04:16.741: INFO: namespace e2e-tests-downward-api-t5z4t deletion completed in 6.175430462s

• [SLOW TEST:12.490 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:04:16.741: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8mwl2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 19 13:04:16.969: INFO: Waiting up to 5m0s for pod "pod-dcdfee89-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-8mwl2" to be "success or failure"
Feb 19 13:04:16.976: INFO: Pod "pod-dcdfee89-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 7.005188ms
Feb 19 13:04:18.982: INFO: Pod "pod-dcdfee89-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012708807s
Feb 19 13:04:20.989: INFO: Pod "pod-dcdfee89-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019718806s
Feb 19 13:04:22.995: INFO: Pod "pod-dcdfee89-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025979575s
STEP: Saw pod success
Feb 19 13:04:22.995: INFO: Pod "pod-dcdfee89-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:04:23.000: INFO: Trying to get logs from node kube-node-20-104 pod pod-dcdfee89-3446-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:04:23.035: INFO: Waiting for pod pod-dcdfee89-3446-11e9-af36-92091ca56148 to disappear
Feb 19 13:04:23.038: INFO: Pod pod-dcdfee89-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:04:23.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8mwl2" for this suite.
Feb 19 13:04:31.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:04:31.192: INFO: namespace: e2e-tests-emptydir-8mwl2, resource: bindings, ignored listing per whitelist
Feb 19 13:04:31.205: INFO: namespace e2e-tests-emptydir-8mwl2 deletion completed in 8.16150803s

• [SLOW TEST:14.465 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:04:31.206: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-knnjz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e5813129-3446-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 13:04:31.452: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-knnjz" to be "success or failure"
Feb 19 13:04:31.457: INFO: Pod "pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.814381ms
Feb 19 13:04:33.463: INFO: Pod "pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010408011s
Feb 19 13:04:35.470: INFO: Pod "pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017401587s
Feb 19 13:04:37.477: INFO: Pod "pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024582346s
STEP: Saw pod success
Feb 19 13:04:37.477: INFO: Pod "pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:04:37.482: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 13:04:37.513: INFO: Waiting for pod pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148 to disappear
Feb 19 13:04:37.517: INFO: Pod pod-projected-configmaps-e5825aa0-3446-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:04:37.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knnjz" for this suite.
Feb 19 13:04:43.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:04:43.666: INFO: namespace: e2e-tests-projected-knnjz, resource: bindings, ignored listing per whitelist
Feb 19 13:04:43.683: INFO: namespace e2e-tests-projected-knnjz deletion completed in 6.159295668s

• [SLOW TEST:12.477 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:04:43.683: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-2kkw7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2kkw7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 13:04:43.903: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 13:05:14.081: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.67.39:8080/dial?request=hostName&protocol=udp&host=192.168.68.228&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2kkw7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:05:14.081: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:05:14.247: INFO: Waiting for endpoints: map[]
Feb 19 13:05:14.252: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.67.39:8080/dial?request=hostName&protocol=udp&host=192.168.67.38&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2kkw7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:05:14.252: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:05:14.391: INFO: Waiting for endpoints: map[]
Feb 19 13:05:14.396: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.67.39:8080/dial?request=hostName&protocol=udp&host=192.168.64.32&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2kkw7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:05:14.396: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:05:14.543: INFO: Waiting for endpoints: map[]
Feb 19 13:05:14.548: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.67.39:8080/dial?request=hostName&protocol=udp&host=192.168.65.174&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2kkw7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:05:14.548: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:05:14.674: INFO: Waiting for endpoints: map[]
Feb 19 13:05:14.683: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.67.39:8080/dial?request=hostName&protocol=udp&host=192.168.66.168&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-2kkw7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:05:14.683: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:05:14.807: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:05:14.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2kkw7" for this suite.
Feb 19 13:05:38.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:05:38.987: INFO: namespace: e2e-tests-pod-network-test-2kkw7, resource: bindings, ignored listing per whitelist
Feb 19 13:05:39.001: INFO: namespace e2e-tests-pod-network-test-2kkw7 deletion completed in 24.183264923s

• [SLOW TEST:55.318 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:05:39.002: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gqkpj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-0deccc58-3447-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-0deccc58-3447-11e9-af36-92091ca56148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:05:47.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gqkpj" for this suite.
Feb 19 13:06:09.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:06:09.481: INFO: namespace: e2e-tests-projected-gqkpj, resource: bindings, ignored listing per whitelist
Feb 19 13:06:09.523: INFO: namespace e2e-tests-projected-gqkpj deletion completed in 22.178500301s

• [SLOW TEST:30.522 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:06:09.524: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-grqn2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-grqn2
Feb 19 13:08:05.779: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-grqn2
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 13:08:05.784: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:12:06.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-grqn2" for this suite.
Feb 19 13:12:12.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:12:12.750: INFO: namespace: e2e-tests-container-probe-grqn2, resource: bindings, ignored listing per whitelist
Feb 19 13:12:12.770: INFO: namespace e2e-tests-container-probe-grqn2 deletion completed in 6.171471799s

• [SLOW TEST:363.247 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:12:12.771: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-8jll4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8jll4
I0219 13:12:13.008928      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8jll4, replica count: 1
I0219 13:12:14.059620      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 13:12:15.059935      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 13:12:16.060189      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 13:12:17.060484      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 13:12:18.060793      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 13:12:19.060976      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 19 13:12:19.175: INFO: Created: latency-svc-6gfx9
Feb 19 13:12:19.193: INFO: Got endpoints: latency-svc-6gfx9 [32.653049ms]
Feb 19 13:12:19.210: INFO: Created: latency-svc-6t9cf
Feb 19 13:12:19.216: INFO: Got endpoints: latency-svc-6t9cf [22.297502ms]
Feb 19 13:12:19.224: INFO: Created: latency-svc-56q4b
Feb 19 13:12:19.230: INFO: Got endpoints: latency-svc-56q4b [35.441875ms]
Feb 19 13:12:19.231: INFO: Created: latency-svc-rwvdw
Feb 19 13:12:19.242: INFO: Got endpoints: latency-svc-rwvdw [46.269613ms]
Feb 19 13:12:19.246: INFO: Created: latency-svc-q56z8
Feb 19 13:12:19.255: INFO: Got endpoints: latency-svc-q56z8 [60.609519ms]
Feb 19 13:12:19.260: INFO: Created: latency-svc-f8ftd
Feb 19 13:12:19.267: INFO: Got endpoints: latency-svc-f8ftd [71.678846ms]
Feb 19 13:12:19.268: INFO: Created: latency-svc-zxwx4
Feb 19 13:12:19.277: INFO: Got endpoints: latency-svc-zxwx4 [80.362285ms]
Feb 19 13:12:19.278: INFO: Created: latency-svc-lmnrz
Feb 19 13:12:19.289: INFO: Created: latency-svc-gzmw5
Feb 19 13:12:19.289: INFO: Got endpoints: latency-svc-lmnrz [91.988839ms]
Feb 19 13:12:19.300: INFO: Got endpoints: latency-svc-gzmw5 [104.479644ms]
Feb 19 13:12:19.301: INFO: Created: latency-svc-xtc56
Feb 19 13:12:19.313: INFO: Got endpoints: latency-svc-xtc56 [116.499875ms]
Feb 19 13:12:19.328: INFO: Created: latency-svc-q5zbq
Feb 19 13:12:19.332: INFO: Got endpoints: latency-svc-q5zbq [134.968165ms]
Feb 19 13:12:19.333: INFO: Created: latency-svc-spxrs
Feb 19 13:12:19.351: INFO: Got endpoints: latency-svc-spxrs [155.299759ms]
Feb 19 13:12:19.360: INFO: Created: latency-svc-j9jmr
Feb 19 13:12:19.373: INFO: Got endpoints: latency-svc-j9jmr [177.808051ms]
Feb 19 13:12:19.376: INFO: Created: latency-svc-4n2lh
Feb 19 13:12:19.385: INFO: Got endpoints: latency-svc-4n2lh [33.872414ms]
Feb 19 13:12:19.395: INFO: Created: latency-svc-mtvj8
Feb 19 13:12:19.404: INFO: Created: latency-svc-9kthg
Feb 19 13:12:19.410: INFO: Got endpoints: latency-svc-mtvj8 [213.513237ms]
Feb 19 13:12:19.413: INFO: Got endpoints: latency-svc-9kthg [215.957739ms]
Feb 19 13:12:19.426: INFO: Created: latency-svc-fkfbs
Feb 19 13:12:19.434: INFO: Created: latency-svc-qnz6s
Feb 19 13:12:19.445: INFO: Created: latency-svc-qtmts
Feb 19 13:12:19.450: INFO: Got endpoints: latency-svc-qnz6s [233.419255ms]
Feb 19 13:12:19.450: INFO: Got endpoints: latency-svc-fkfbs [253.765536ms]
Feb 19 13:12:19.457: INFO: Got endpoints: latency-svc-qtmts [226.766399ms]
Feb 19 13:12:19.461: INFO: Created: latency-svc-sn7xk
Feb 19 13:12:19.468: INFO: Created: latency-svc-vgrph
Feb 19 13:12:19.471: INFO: Got endpoints: latency-svc-sn7xk [229.095926ms]
Feb 19 13:12:19.474: INFO: Got endpoints: latency-svc-vgrph [218.415749ms]
Feb 19 13:12:19.478: INFO: Created: latency-svc-nlcqw
Feb 19 13:12:19.486: INFO: Got endpoints: latency-svc-nlcqw [219.157613ms]
Feb 19 13:12:19.492: INFO: Created: latency-svc-cdqtc
Feb 19 13:12:19.501: INFO: Got endpoints: latency-svc-cdqtc [223.843517ms]
Feb 19 13:12:19.509: INFO: Created: latency-svc-hd4h6
Feb 19 13:12:19.515: INFO: Got endpoints: latency-svc-hd4h6 [225.507552ms]
Feb 19 13:12:19.520: INFO: Created: latency-svc-64v92
Feb 19 13:12:19.532: INFO: Got endpoints: latency-svc-64v92 [231.987362ms]
Feb 19 13:12:19.535: INFO: Created: latency-svc-xv6gw
Feb 19 13:12:19.543: INFO: Got endpoints: latency-svc-xv6gw [230.44562ms]
Feb 19 13:12:19.545: INFO: Created: latency-svc-crw9t
Feb 19 13:12:19.556: INFO: Got endpoints: latency-svc-crw9t [224.244447ms]
Feb 19 13:12:19.561: INFO: Created: latency-svc-qmz59
Feb 19 13:12:19.567: INFO: Got endpoints: latency-svc-qmz59 [194.522131ms]
Feb 19 13:12:19.571: INFO: Created: latency-svc-gnkmh
Feb 19 13:12:19.579: INFO: Got endpoints: latency-svc-gnkmh [194.830696ms]
Feb 19 13:12:19.583: INFO: Created: latency-svc-4zj28
Feb 19 13:12:19.594: INFO: Created: latency-svc-kzn62
Feb 19 13:12:19.596: INFO: Got endpoints: latency-svc-4zj28 [185.958053ms]
Feb 19 13:12:19.603: INFO: Got endpoints: latency-svc-kzn62 [190.216208ms]
Feb 19 13:12:19.609: INFO: Created: latency-svc-vn76v
Feb 19 13:12:19.618: INFO: Got endpoints: latency-svc-vn76v [168.169672ms]
Feb 19 13:12:19.622: INFO: Created: latency-svc-7r628
Feb 19 13:12:19.627: INFO: Got endpoints: latency-svc-7r628 [177.283681ms]
Feb 19 13:12:19.646: INFO: Created: latency-svc-jwmsv
Feb 19 13:12:19.656: INFO: Got endpoints: latency-svc-jwmsv [199.314944ms]
Feb 19 13:12:19.662: INFO: Created: latency-svc-pbrsd
Feb 19 13:12:19.668: INFO: Created: latency-svc-dzk6w
Feb 19 13:12:19.669: INFO: Got endpoints: latency-svc-pbrsd [197.640127ms]
Feb 19 13:12:19.679: INFO: Created: latency-svc-8khf4
Feb 19 13:12:19.685: INFO: Got endpoints: latency-svc-dzk6w [211.075686ms]
Feb 19 13:12:19.689: INFO: Got endpoints: latency-svc-8khf4 [202.834026ms]
Feb 19 13:12:19.692: INFO: Created: latency-svc-wm7qg
Feb 19 13:12:19.703: INFO: Got endpoints: latency-svc-wm7qg [201.716129ms]
Feb 19 13:12:19.703: INFO: Created: latency-svc-j4rqx
Feb 19 13:12:19.714: INFO: Created: latency-svc-kgr25
Feb 19 13:12:19.715: INFO: Got endpoints: latency-svc-j4rqx [199.963404ms]
Feb 19 13:12:19.730: INFO: Got endpoints: latency-svc-kgr25 [197.474052ms]
Feb 19 13:12:19.734: INFO: Created: latency-svc-zpxzd
Feb 19 13:12:19.739: INFO: Got endpoints: latency-svc-zpxzd [195.898853ms]
Feb 19 13:12:19.743: INFO: Created: latency-svc-9b22r
Feb 19 13:12:19.755: INFO: Created: latency-svc-t7ckz
Feb 19 13:12:19.764: INFO: Created: latency-svc-kpqfm
Feb 19 13:12:19.776: INFO: Created: latency-svc-f7ckj
Feb 19 13:12:19.785: INFO: Got endpoints: latency-svc-9b22r [228.453961ms]
Feb 19 13:12:19.788: INFO: Created: latency-svc-9mg9q
Feb 19 13:12:19.795: INFO: Created: latency-svc-txnvw
Feb 19 13:12:19.803: INFO: Created: latency-svc-sljvq
Feb 19 13:12:19.812: INFO: Created: latency-svc-7skfm
Feb 19 13:12:19.820: INFO: Created: latency-svc-z5k4n
Feb 19 13:12:19.831: INFO: Created: latency-svc-s2hf4
Feb 19 13:12:19.837: INFO: Created: latency-svc-bqqjv
Feb 19 13:12:19.840: INFO: Got endpoints: latency-svc-t7ckz [272.217159ms]
Feb 19 13:12:19.845: INFO: Created: latency-svc-2dgcq
Feb 19 13:12:19.863: INFO: Created: latency-svc-4g8kz
Feb 19 13:12:19.878: INFO: Created: latency-svc-mkqhn
Feb 19 13:12:19.888: INFO: Got endpoints: latency-svc-kpqfm [308.152628ms]
Feb 19 13:12:19.888: INFO: Created: latency-svc-zv6rr
Feb 19 13:12:19.894: INFO: Created: latency-svc-8dkql
Feb 19 13:12:19.902: INFO: Created: latency-svc-zv6b9
Feb 19 13:12:19.910: INFO: Created: latency-svc-kj9bl
Feb 19 13:12:19.935: INFO: Got endpoints: latency-svc-f7ckj [339.516605ms]
Feb 19 13:12:19.947: INFO: Created: latency-svc-rbbjj
Feb 19 13:12:19.984: INFO: Got endpoints: latency-svc-9mg9q [380.877152ms]
Feb 19 13:12:19.997: INFO: Created: latency-svc-wmbmh
Feb 19 13:12:20.037: INFO: Got endpoints: latency-svc-txnvw [419.369383ms]
Feb 19 13:12:20.050: INFO: Created: latency-svc-p4lkg
Feb 19 13:12:20.085: INFO: Got endpoints: latency-svc-sljvq [457.637133ms]
Feb 19 13:12:20.098: INFO: Created: latency-svc-4btvh
Feb 19 13:12:20.142: INFO: Got endpoints: latency-svc-7skfm [486.206017ms]
Feb 19 13:12:20.157: INFO: Created: latency-svc-9fkkp
Feb 19 13:12:20.185: INFO: Got endpoints: latency-svc-z5k4n [516.794718ms]
Feb 19 13:12:20.202: INFO: Created: latency-svc-wk6rp
Feb 19 13:12:20.235: INFO: Got endpoints: latency-svc-s2hf4 [549.92599ms]
Feb 19 13:12:20.248: INFO: Created: latency-svc-vd86f
Feb 19 13:12:20.285: INFO: Got endpoints: latency-svc-bqqjv [596.394727ms]
Feb 19 13:12:20.299: INFO: Created: latency-svc-pwth4
Feb 19 13:12:20.338: INFO: Got endpoints: latency-svc-2dgcq [635.396818ms]
Feb 19 13:12:20.354: INFO: Created: latency-svc-qh9nt
Feb 19 13:12:20.385: INFO: Got endpoints: latency-svc-4g8kz [670.39083ms]
Feb 19 13:12:20.398: INFO: Created: latency-svc-z2ds4
Feb 19 13:12:20.437: INFO: Got endpoints: latency-svc-mkqhn [706.640179ms]
Feb 19 13:12:20.462: INFO: Created: latency-svc-vh4xx
Feb 19 13:12:20.486: INFO: Got endpoints: latency-svc-zv6rr [747.031873ms]
Feb 19 13:12:20.500: INFO: Created: latency-svc-5bqvr
Feb 19 13:12:20.538: INFO: Got endpoints: latency-svc-8dkql [753.164674ms]
Feb 19 13:12:20.553: INFO: Created: latency-svc-rt97z
Feb 19 13:12:20.584: INFO: Got endpoints: latency-svc-zv6b9 [744.550679ms]
Feb 19 13:12:20.597: INFO: Created: latency-svc-n6r8w
Feb 19 13:12:20.635: INFO: Got endpoints: latency-svc-kj9bl [747.035054ms]
Feb 19 13:12:20.653: INFO: Created: latency-svc-4bc4t
Feb 19 13:12:20.685: INFO: Got endpoints: latency-svc-rbbjj [749.986778ms]
Feb 19 13:12:20.701: INFO: Created: latency-svc-zsfln
Feb 19 13:12:20.736: INFO: Got endpoints: latency-svc-wmbmh [751.565664ms]
Feb 19 13:12:20.753: INFO: Created: latency-svc-fxjtz
Feb 19 13:12:20.783: INFO: Got endpoints: latency-svc-p4lkg [745.942143ms]
Feb 19 13:12:20.801: INFO: Created: latency-svc-lhrzc
Feb 19 13:12:20.834: INFO: Got endpoints: latency-svc-4btvh [749.544553ms]
Feb 19 13:12:20.848: INFO: Created: latency-svc-rln4j
Feb 19 13:12:20.887: INFO: Got endpoints: latency-svc-9fkkp [744.671936ms]
Feb 19 13:12:20.908: INFO: Created: latency-svc-zxdnq
Feb 19 13:12:20.939: INFO: Got endpoints: latency-svc-wk6rp [753.050853ms]
Feb 19 13:12:20.952: INFO: Created: latency-svc-fc4lt
Feb 19 13:12:20.990: INFO: Got endpoints: latency-svc-vd86f [754.597507ms]
Feb 19 13:12:21.017: INFO: Created: latency-svc-nph8s
Feb 19 13:12:21.038: INFO: Got endpoints: latency-svc-pwth4 [752.923659ms]
Feb 19 13:12:21.058: INFO: Created: latency-svc-v8ffz
Feb 19 13:12:21.085: INFO: Got endpoints: latency-svc-qh9nt [746.525219ms]
Feb 19 13:12:21.109: INFO: Created: latency-svc-pv5s2
Feb 19 13:12:21.135: INFO: Got endpoints: latency-svc-z2ds4 [749.833491ms]
Feb 19 13:12:21.164: INFO: Created: latency-svc-jrbz6
Feb 19 13:12:21.187: INFO: Got endpoints: latency-svc-vh4xx [750.777747ms]
Feb 19 13:12:21.203: INFO: Created: latency-svc-86d5m
Feb 19 13:12:21.238: INFO: Got endpoints: latency-svc-5bqvr [750.904231ms]
Feb 19 13:12:21.257: INFO: Created: latency-svc-sktkn
Feb 19 13:12:21.293: INFO: Got endpoints: latency-svc-rt97z [754.592269ms]
Feb 19 13:12:21.316: INFO: Created: latency-svc-ltzrb
Feb 19 13:12:21.343: INFO: Got endpoints: latency-svc-n6r8w [758.624921ms]
Feb 19 13:12:21.362: INFO: Created: latency-svc-z7php
Feb 19 13:12:21.389: INFO: Got endpoints: latency-svc-4bc4t [754.283828ms]
Feb 19 13:12:21.410: INFO: Created: latency-svc-swqtb
Feb 19 13:12:21.436: INFO: Got endpoints: latency-svc-zsfln [750.079152ms]
Feb 19 13:12:21.452: INFO: Created: latency-svc-8cdpk
Feb 19 13:12:21.485: INFO: Got endpoints: latency-svc-fxjtz [749.426822ms]
Feb 19 13:12:21.498: INFO: Created: latency-svc-rdm25
Feb 19 13:12:21.539: INFO: Got endpoints: latency-svc-lhrzc [755.851902ms]
Feb 19 13:12:21.557: INFO: Created: latency-svc-vn8p5
Feb 19 13:12:21.585: INFO: Got endpoints: latency-svc-rln4j [750.809406ms]
Feb 19 13:12:21.603: INFO: Created: latency-svc-5748n
Feb 19 13:12:21.636: INFO: Got endpoints: latency-svc-zxdnq [748.565708ms]
Feb 19 13:12:21.649: INFO: Created: latency-svc-pqrjg
Feb 19 13:12:21.686: INFO: Got endpoints: latency-svc-fc4lt [747.13696ms]
Feb 19 13:12:21.713: INFO: Created: latency-svc-2q7jf
Feb 19 13:12:21.741: INFO: Got endpoints: latency-svc-nph8s [751.457422ms]
Feb 19 13:12:21.768: INFO: Created: latency-svc-65w8f
Feb 19 13:12:21.787: INFO: Got endpoints: latency-svc-v8ffz [748.390835ms]
Feb 19 13:12:21.842: INFO: Got endpoints: latency-svc-pv5s2 [757.115707ms]
Feb 19 13:12:21.842: INFO: Created: latency-svc-6s7z6
Feb 19 13:12:21.863: INFO: Created: latency-svc-mbk82
Feb 19 13:12:21.885: INFO: Got endpoints: latency-svc-jrbz6 [750.383136ms]
Feb 19 13:12:21.908: INFO: Created: latency-svc-4kbb7
Feb 19 13:12:21.935: INFO: Got endpoints: latency-svc-86d5m [747.586647ms]
Feb 19 13:12:21.954: INFO: Created: latency-svc-h5fwq
Feb 19 13:12:21.988: INFO: Got endpoints: latency-svc-sktkn [750.624111ms]
Feb 19 13:12:22.003: INFO: Created: latency-svc-qjzlr
Feb 19 13:12:22.037: INFO: Got endpoints: latency-svc-ltzrb [743.703539ms]
Feb 19 13:12:22.054: INFO: Created: latency-svc-ng65m
Feb 19 13:12:22.084: INFO: Got endpoints: latency-svc-z7php [740.669792ms]
Feb 19 13:12:22.102: INFO: Created: latency-svc-xh576
Feb 19 13:12:22.142: INFO: Got endpoints: latency-svc-swqtb [752.659685ms]
Feb 19 13:12:22.157: INFO: Created: latency-svc-ktt5f
Feb 19 13:12:22.187: INFO: Got endpoints: latency-svc-8cdpk [751.737799ms]
Feb 19 13:12:22.201: INFO: Created: latency-svc-cmzr7
Feb 19 13:12:22.243: INFO: Got endpoints: latency-svc-rdm25 [757.685119ms]
Feb 19 13:12:22.259: INFO: Created: latency-svc-7422f
Feb 19 13:12:22.285: INFO: Got endpoints: latency-svc-vn8p5 [745.98425ms]
Feb 19 13:12:22.298: INFO: Created: latency-svc-rhr2n
Feb 19 13:12:22.340: INFO: Got endpoints: latency-svc-5748n [754.495147ms]
Feb 19 13:12:22.364: INFO: Created: latency-svc-8ttzn
Feb 19 13:12:22.384: INFO: Got endpoints: latency-svc-pqrjg [748.352822ms]
Feb 19 13:12:22.395: INFO: Created: latency-svc-xt6zh
Feb 19 13:12:22.436: INFO: Got endpoints: latency-svc-2q7jf [750.125329ms]
Feb 19 13:12:22.449: INFO: Created: latency-svc-g5gl4
Feb 19 13:12:22.484: INFO: Got endpoints: latency-svc-65w8f [742.800592ms]
Feb 19 13:12:22.498: INFO: Created: latency-svc-44n7k
Feb 19 13:12:22.536: INFO: Got endpoints: latency-svc-6s7z6 [749.193317ms]
Feb 19 13:12:22.553: INFO: Created: latency-svc-jv75h
Feb 19 13:12:22.587: INFO: Got endpoints: latency-svc-mbk82 [745.278049ms]
Feb 19 13:12:22.605: INFO: Created: latency-svc-v8b5m
Feb 19 13:12:22.636: INFO: Got endpoints: latency-svc-4kbb7 [750.538882ms]
Feb 19 13:12:22.648: INFO: Created: latency-svc-htw76
Feb 19 13:12:22.691: INFO: Got endpoints: latency-svc-h5fwq [755.531242ms]
Feb 19 13:12:22.704: INFO: Created: latency-svc-6qlc4
Feb 19 13:12:22.735: INFO: Got endpoints: latency-svc-qjzlr [746.668506ms]
Feb 19 13:12:22.749: INFO: Created: latency-svc-l9c67
Feb 19 13:12:22.785: INFO: Got endpoints: latency-svc-ng65m [748.351683ms]
Feb 19 13:12:22.799: INFO: Created: latency-svc-6nz29
Feb 19 13:12:22.834: INFO: Got endpoints: latency-svc-xh576 [750.282492ms]
Feb 19 13:12:22.847: INFO: Created: latency-svc-gth7c
Feb 19 13:12:22.883: INFO: Got endpoints: latency-svc-ktt5f [741.102888ms]
Feb 19 13:12:22.895: INFO: Created: latency-svc-dqj9t
Feb 19 13:12:22.938: INFO: Got endpoints: latency-svc-cmzr7 [750.216788ms]
Feb 19 13:12:22.953: INFO: Created: latency-svc-6fd2w
Feb 19 13:12:22.987: INFO: Got endpoints: latency-svc-7422f [743.86999ms]
Feb 19 13:12:23.000: INFO: Created: latency-svc-h8s65
Feb 19 13:12:23.037: INFO: Got endpoints: latency-svc-rhr2n [751.300423ms]
Feb 19 13:12:23.056: INFO: Created: latency-svc-lnsqr
Feb 19 13:12:23.091: INFO: Got endpoints: latency-svc-8ttzn [751.077483ms]
Feb 19 13:12:23.109: INFO: Created: latency-svc-4lzq9
Feb 19 13:12:23.136: INFO: Got endpoints: latency-svc-xt6zh [751.546744ms]
Feb 19 13:12:23.147: INFO: Created: latency-svc-kl2v4
Feb 19 13:12:23.190: INFO: Got endpoints: latency-svc-g5gl4 [753.593944ms]
Feb 19 13:12:23.202: INFO: Created: latency-svc-5fjs4
Feb 19 13:12:23.235: INFO: Got endpoints: latency-svc-44n7k [750.89289ms]
Feb 19 13:12:23.251: INFO: Created: latency-svc-rqvxh
Feb 19 13:12:23.283: INFO: Got endpoints: latency-svc-jv75h [747.350504ms]
Feb 19 13:12:23.298: INFO: Created: latency-svc-9zqdk
Feb 19 13:12:23.339: INFO: Got endpoints: latency-svc-v8b5m [751.970993ms]
Feb 19 13:12:23.353: INFO: Created: latency-svc-m44ck
Feb 19 13:12:23.386: INFO: Got endpoints: latency-svc-htw76 [749.651829ms]
Feb 19 13:12:23.397: INFO: Created: latency-svc-br6d6
Feb 19 13:12:23.436: INFO: Got endpoints: latency-svc-6qlc4 [745.399694ms]
Feb 19 13:12:23.450: INFO: Created: latency-svc-ttdfq
Feb 19 13:12:23.486: INFO: Got endpoints: latency-svc-l9c67 [750.513346ms]
Feb 19 13:12:23.501: INFO: Created: latency-svc-5tz7c
Feb 19 13:12:23.535: INFO: Got endpoints: latency-svc-6nz29 [750.024588ms]
Feb 19 13:12:23.550: INFO: Created: latency-svc-gzxgt
Feb 19 13:12:23.585: INFO: Got endpoints: latency-svc-gth7c [751.083352ms]
Feb 19 13:12:23.607: INFO: Created: latency-svc-w2w44
Feb 19 13:12:23.634: INFO: Got endpoints: latency-svc-dqj9t [750.808455ms]
Feb 19 13:12:23.649: INFO: Created: latency-svc-9vwz9
Feb 19 13:12:23.684: INFO: Got endpoints: latency-svc-6fd2w [746.207482ms]
Feb 19 13:12:23.699: INFO: Created: latency-svc-4knkh
Feb 19 13:12:23.738: INFO: Got endpoints: latency-svc-h8s65 [750.576608ms]
Feb 19 13:12:23.751: INFO: Created: latency-svc-5t6cr
Feb 19 13:12:23.784: INFO: Got endpoints: latency-svc-lnsqr [747.089825ms]
Feb 19 13:12:23.798: INFO: Created: latency-svc-nphn5
Feb 19 13:12:23.835: INFO: Got endpoints: latency-svc-4lzq9 [744.004317ms]
Feb 19 13:12:23.850: INFO: Created: latency-svc-55rs6
Feb 19 13:12:23.883: INFO: Got endpoints: latency-svc-kl2v4 [747.301637ms]
Feb 19 13:12:23.894: INFO: Created: latency-svc-2fd79
Feb 19 13:12:23.935: INFO: Got endpoints: latency-svc-5fjs4 [745.578177ms]
Feb 19 13:12:23.955: INFO: Created: latency-svc-2j2tv
Feb 19 13:12:23.985: INFO: Got endpoints: latency-svc-rqvxh [750.513672ms]
Feb 19 13:12:24.009: INFO: Created: latency-svc-hbr9b
Feb 19 13:12:24.035: INFO: Got endpoints: latency-svc-9zqdk [751.607515ms]
Feb 19 13:12:24.061: INFO: Created: latency-svc-6vl7m
Feb 19 13:12:24.092: INFO: Got endpoints: latency-svc-m44ck [752.40487ms]
Feb 19 13:12:24.105: INFO: Created: latency-svc-5pkdj
Feb 19 13:12:24.134: INFO: Got endpoints: latency-svc-br6d6 [748.620319ms]
Feb 19 13:12:24.149: INFO: Created: latency-svc-pckp5
Feb 19 13:12:24.185: INFO: Got endpoints: latency-svc-ttdfq [749.22326ms]
Feb 19 13:12:24.203: INFO: Created: latency-svc-fpblh
Feb 19 13:12:24.238: INFO: Got endpoints: latency-svc-5tz7c [752.067421ms]
Feb 19 13:12:24.250: INFO: Created: latency-svc-gtdl2
Feb 19 13:12:24.284: INFO: Got endpoints: latency-svc-gzxgt [748.417271ms]
Feb 19 13:12:24.300: INFO: Created: latency-svc-kjzz6
Feb 19 13:12:24.334: INFO: Got endpoints: latency-svc-w2w44 [749.221167ms]
Feb 19 13:12:24.349: INFO: Created: latency-svc-tlr6c
Feb 19 13:12:24.384: INFO: Got endpoints: latency-svc-9vwz9 [749.779032ms]
Feb 19 13:12:24.400: INFO: Created: latency-svc-zmmtd
Feb 19 13:12:24.433: INFO: Got endpoints: latency-svc-4knkh [748.916736ms]
Feb 19 13:12:24.447: INFO: Created: latency-svc-7rdsf
Feb 19 13:12:24.484: INFO: Got endpoints: latency-svc-5t6cr [745.947033ms]
Feb 19 13:12:24.500: INFO: Created: latency-svc-78t82
Feb 19 13:12:24.543: INFO: Got endpoints: latency-svc-nphn5 [758.875668ms]
Feb 19 13:12:24.556: INFO: Created: latency-svc-66v68
Feb 19 13:12:24.584: INFO: Got endpoints: latency-svc-55rs6 [749.169988ms]
Feb 19 13:12:24.596: INFO: Created: latency-svc-knqd2
Feb 19 13:12:24.634: INFO: Got endpoints: latency-svc-2fd79 [751.176319ms]
Feb 19 13:12:24.647: INFO: Created: latency-svc-4f8c7
Feb 19 13:12:24.692: INFO: Got endpoints: latency-svc-2j2tv [756.568871ms]
Feb 19 13:12:24.709: INFO: Created: latency-svc-qqnhm
Feb 19 13:12:24.735: INFO: Got endpoints: latency-svc-hbr9b [749.444205ms]
Feb 19 13:12:24.749: INFO: Created: latency-svc-stbbx
Feb 19 13:12:24.789: INFO: Got endpoints: latency-svc-6vl7m [753.75742ms]
Feb 19 13:12:24.801: INFO: Created: latency-svc-bdstm
Feb 19 13:12:24.834: INFO: Got endpoints: latency-svc-5pkdj [742.50551ms]
Feb 19 13:12:24.849: INFO: Created: latency-svc-gfbhv
Feb 19 13:12:24.885: INFO: Got endpoints: latency-svc-pckp5 [750.349953ms]
Feb 19 13:12:24.904: INFO: Created: latency-svc-94b82
Feb 19 13:12:24.938: INFO: Got endpoints: latency-svc-fpblh [752.980362ms]
Feb 19 13:12:24.953: INFO: Created: latency-svc-zvz8s
Feb 19 13:12:24.985: INFO: Got endpoints: latency-svc-gtdl2 [747.483467ms]
Feb 19 13:12:25.004: INFO: Created: latency-svc-6hgvm
Feb 19 13:12:25.034: INFO: Got endpoints: latency-svc-kjzz6 [750.751795ms]
Feb 19 13:12:25.047: INFO: Created: latency-svc-bnd8j
Feb 19 13:12:25.088: INFO: Got endpoints: latency-svc-tlr6c [753.385352ms]
Feb 19 13:12:25.104: INFO: Created: latency-svc-pbcm2
Feb 19 13:12:25.136: INFO: Got endpoints: latency-svc-zmmtd [751.821812ms]
Feb 19 13:12:25.151: INFO: Created: latency-svc-h88fd
Feb 19 13:12:25.184: INFO: Got endpoints: latency-svc-7rdsf [751.137794ms]
Feb 19 13:12:25.197: INFO: Created: latency-svc-vxqkr
Feb 19 13:12:25.234: INFO: Got endpoints: latency-svc-78t82 [750.647493ms]
Feb 19 13:12:25.247: INFO: Created: latency-svc-n2grc
Feb 19 13:12:25.283: INFO: Got endpoints: latency-svc-66v68 [740.109581ms]
Feb 19 13:12:25.298: INFO: Created: latency-svc-x8tgk
Feb 19 13:12:25.338: INFO: Got endpoints: latency-svc-knqd2 [753.071898ms]
Feb 19 13:12:25.350: INFO: Created: latency-svc-h2tnp
Feb 19 13:12:25.385: INFO: Got endpoints: latency-svc-4f8c7 [750.40733ms]
Feb 19 13:12:25.395: INFO: Created: latency-svc-hbnrc
Feb 19 13:12:25.435: INFO: Got endpoints: latency-svc-qqnhm [742.660452ms]
Feb 19 13:12:25.447: INFO: Created: latency-svc-4mtgq
Feb 19 13:12:25.485: INFO: Got endpoints: latency-svc-stbbx [749.623761ms]
Feb 19 13:12:25.497: INFO: Created: latency-svc-5bp52
Feb 19 13:12:25.537: INFO: Got endpoints: latency-svc-bdstm [748.635288ms]
Feb 19 13:12:25.550: INFO: Created: latency-svc-l2zf8
Feb 19 13:12:25.587: INFO: Got endpoints: latency-svc-gfbhv [752.790959ms]
Feb 19 13:12:25.601: INFO: Created: latency-svc-nbxcj
Feb 19 13:12:25.634: INFO: Got endpoints: latency-svc-94b82 [748.721392ms]
Feb 19 13:12:25.647: INFO: Created: latency-svc-vbvkc
Feb 19 13:12:25.684: INFO: Got endpoints: latency-svc-zvz8s [745.441501ms]
Feb 19 13:12:25.697: INFO: Created: latency-svc-5f75b
Feb 19 13:12:25.736: INFO: Got endpoints: latency-svc-6hgvm [750.401077ms]
Feb 19 13:12:25.746: INFO: Created: latency-svc-882jz
Feb 19 13:12:25.783: INFO: Got endpoints: latency-svc-bnd8j [748.91356ms]
Feb 19 13:12:25.798: INFO: Created: latency-svc-5vjgs
Feb 19 13:12:25.835: INFO: Got endpoints: latency-svc-pbcm2 [747.062767ms]
Feb 19 13:12:25.847: INFO: Created: latency-svc-vhxln
Feb 19 13:12:25.889: INFO: Got endpoints: latency-svc-h88fd [752.984812ms]
Feb 19 13:12:25.901: INFO: Created: latency-svc-d7ss5
Feb 19 13:12:25.943: INFO: Got endpoints: latency-svc-vxqkr [759.199102ms]
Feb 19 13:12:25.959: INFO: Created: latency-svc-j72jf
Feb 19 13:12:25.984: INFO: Got endpoints: latency-svc-n2grc [749.89255ms]
Feb 19 13:12:25.996: INFO: Created: latency-svc-5z72b
Feb 19 13:12:26.034: INFO: Got endpoints: latency-svc-x8tgk [750.434379ms]
Feb 19 13:12:26.048: INFO: Created: latency-svc-x2jws
Feb 19 13:12:26.084: INFO: Got endpoints: latency-svc-h2tnp [746.786414ms]
Feb 19 13:12:26.099: INFO: Created: latency-svc-qtqzb
Feb 19 13:12:26.134: INFO: Got endpoints: latency-svc-hbnrc [749.513937ms]
Feb 19 13:12:26.148: INFO: Created: latency-svc-mkrjf
Feb 19 13:12:26.187: INFO: Got endpoints: latency-svc-4mtgq [752.060702ms]
Feb 19 13:12:26.203: INFO: Created: latency-svc-hlhqk
Feb 19 13:12:26.237: INFO: Got endpoints: latency-svc-5bp52 [752.572177ms]
Feb 19 13:12:26.252: INFO: Created: latency-svc-mb5l7
Feb 19 13:12:26.288: INFO: Got endpoints: latency-svc-l2zf8 [750.145468ms]
Feb 19 13:12:26.302: INFO: Created: latency-svc-dj4g4
Feb 19 13:12:26.337: INFO: Got endpoints: latency-svc-nbxcj [750.010641ms]
Feb 19 13:12:26.349: INFO: Created: latency-svc-p8vfl
Feb 19 13:12:26.385: INFO: Got endpoints: latency-svc-vbvkc [751.015699ms]
Feb 19 13:12:26.396: INFO: Created: latency-svc-5mpzr
Feb 19 13:12:26.439: INFO: Got endpoints: latency-svc-5f75b [755.338414ms]
Feb 19 13:12:26.456: INFO: Created: latency-svc-kh656
Feb 19 13:12:26.487: INFO: Got endpoints: latency-svc-882jz [751.370807ms]
Feb 19 13:12:26.506: INFO: Created: latency-svc-6l8mf
Feb 19 13:12:26.539: INFO: Got endpoints: latency-svc-5vjgs [755.267375ms]
Feb 19 13:12:26.550: INFO: Created: latency-svc-gmtnx
Feb 19 13:12:26.590: INFO: Got endpoints: latency-svc-vhxln [754.593406ms]
Feb 19 13:12:26.604: INFO: Created: latency-svc-vngkq
Feb 19 13:12:26.635: INFO: Got endpoints: latency-svc-d7ss5 [745.9749ms]
Feb 19 13:12:26.649: INFO: Created: latency-svc-zhhhp
Feb 19 13:12:26.686: INFO: Got endpoints: latency-svc-j72jf [742.227806ms]
Feb 19 13:12:26.702: INFO: Created: latency-svc-48zpg
Feb 19 13:12:26.737: INFO: Got endpoints: latency-svc-5z72b [753.043111ms]
Feb 19 13:12:26.753: INFO: Created: latency-svc-2tw99
Feb 19 13:12:26.786: INFO: Got endpoints: latency-svc-x2jws [752.223843ms]
Feb 19 13:12:26.802: INFO: Created: latency-svc-fqc8l
Feb 19 13:12:26.834: INFO: Got endpoints: latency-svc-qtqzb [749.911567ms]
Feb 19 13:12:26.850: INFO: Created: latency-svc-btsrd
Feb 19 13:12:26.891: INFO: Got endpoints: latency-svc-mkrjf [756.685472ms]
Feb 19 13:12:26.909: INFO: Created: latency-svc-wps2w
Feb 19 13:12:26.936: INFO: Got endpoints: latency-svc-hlhqk [749.363719ms]
Feb 19 13:12:26.953: INFO: Created: latency-svc-vhncg
Feb 19 13:12:26.985: INFO: Got endpoints: latency-svc-mb5l7 [747.998248ms]
Feb 19 13:12:26.999: INFO: Created: latency-svc-rrhtr
Feb 19 13:12:27.033: INFO: Got endpoints: latency-svc-dj4g4 [745.724395ms]
Feb 19 13:12:27.088: INFO: Got endpoints: latency-svc-p8vfl [751.101326ms]
Feb 19 13:12:27.139: INFO: Got endpoints: latency-svc-5mpzr [754.805774ms]
Feb 19 13:12:27.185: INFO: Got endpoints: latency-svc-kh656 [746.032737ms]
Feb 19 13:12:27.236: INFO: Got endpoints: latency-svc-6l8mf [748.554829ms]
Feb 19 13:12:27.285: INFO: Got endpoints: latency-svc-gmtnx [746.536392ms]
Feb 19 13:12:27.335: INFO: Got endpoints: latency-svc-vngkq [744.956933ms]
Feb 19 13:12:27.384: INFO: Got endpoints: latency-svc-zhhhp [749.247353ms]
Feb 19 13:12:27.437: INFO: Got endpoints: latency-svc-48zpg [751.050246ms]
Feb 19 13:12:27.485: INFO: Got endpoints: latency-svc-2tw99 [747.188683ms]
Feb 19 13:12:27.537: INFO: Got endpoints: latency-svc-fqc8l [750.847485ms]
Feb 19 13:12:27.591: INFO: Got endpoints: latency-svc-btsrd [756.163677ms]
Feb 19 13:12:27.634: INFO: Got endpoints: latency-svc-wps2w [742.91872ms]
Feb 19 13:12:27.687: INFO: Got endpoints: latency-svc-vhncg [750.523772ms]
Feb 19 13:12:27.738: INFO: Got endpoints: latency-svc-rrhtr [752.583025ms]
Feb 19 13:12:27.738: INFO: Latencies: [22.297502ms 33.872414ms 35.441875ms 46.269613ms 60.609519ms 71.678846ms 80.362285ms 91.988839ms 104.479644ms 116.499875ms 134.968165ms 155.299759ms 168.169672ms 177.283681ms 177.808051ms 185.958053ms 190.216208ms 194.522131ms 194.830696ms 195.898853ms 197.474052ms 197.640127ms 199.314944ms 199.963404ms 201.716129ms 202.834026ms 211.075686ms 213.513237ms 215.957739ms 218.415749ms 219.157613ms 223.843517ms 224.244447ms 225.507552ms 226.766399ms 228.453961ms 229.095926ms 230.44562ms 231.987362ms 233.419255ms 253.765536ms 272.217159ms 308.152628ms 339.516605ms 380.877152ms 419.369383ms 457.637133ms 486.206017ms 516.794718ms 549.92599ms 596.394727ms 635.396818ms 670.39083ms 706.640179ms 740.109581ms 740.669792ms 741.102888ms 742.227806ms 742.50551ms 742.660452ms 742.800592ms 742.91872ms 743.703539ms 743.86999ms 744.004317ms 744.550679ms 744.671936ms 744.956933ms 745.278049ms 745.399694ms 745.441501ms 745.578177ms 745.724395ms 745.942143ms 745.947033ms 745.9749ms 745.98425ms 746.032737ms 746.207482ms 746.525219ms 746.536392ms 746.668506ms 746.786414ms 747.031873ms 747.035054ms 747.062767ms 747.089825ms 747.13696ms 747.188683ms 747.301637ms 747.350504ms 747.483467ms 747.586647ms 747.998248ms 748.351683ms 748.352822ms 748.390835ms 748.417271ms 748.554829ms 748.565708ms 748.620319ms 748.635288ms 748.721392ms 748.91356ms 748.916736ms 749.169988ms 749.193317ms 749.221167ms 749.22326ms 749.247353ms 749.363719ms 749.426822ms 749.444205ms 749.513937ms 749.544553ms 749.623761ms 749.651829ms 749.779032ms 749.833491ms 749.89255ms 749.911567ms 749.986778ms 750.010641ms 750.024588ms 750.079152ms 750.125329ms 750.145468ms 750.216788ms 750.282492ms 750.349953ms 750.383136ms 750.401077ms 750.40733ms 750.434379ms 750.513346ms 750.513672ms 750.523772ms 750.538882ms 750.576608ms 750.624111ms 750.647493ms 750.751795ms 750.777747ms 750.808455ms 750.809406ms 750.847485ms 750.89289ms 750.904231ms 751.015699ms 751.050246ms 751.077483ms 751.083352ms 751.101326ms 751.137794ms 751.176319ms 751.300423ms 751.370807ms 751.457422ms 751.546744ms 751.565664ms 751.607515ms 751.737799ms 751.821812ms 751.970993ms 752.060702ms 752.067421ms 752.223843ms 752.40487ms 752.572177ms 752.583025ms 752.659685ms 752.790959ms 752.923659ms 752.980362ms 752.984812ms 753.043111ms 753.050853ms 753.071898ms 753.164674ms 753.385352ms 753.593944ms 753.75742ms 754.283828ms 754.495147ms 754.592269ms 754.593406ms 754.597507ms 754.805774ms 755.267375ms 755.338414ms 755.531242ms 755.851902ms 756.163677ms 756.568871ms 756.685472ms 757.115707ms 757.685119ms 758.624921ms 758.875668ms 759.199102ms]
Feb 19 13:12:27.738: INFO: 50 %ile: 748.620319ms
Feb 19 13:12:27.738: INFO: 90 %ile: 753.593944ms
Feb 19 13:12:27.738: INFO: 99 %ile: 758.875668ms
Feb 19 13:12:27.738: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:12:27.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8jll4" for this suite.
Feb 19 13:12:53.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:12:53.859: INFO: namespace: e2e-tests-svc-latency-8jll4, resource: bindings, ignored listing per whitelist
Feb 19 13:12:53.931: INFO: namespace e2e-tests-svc-latency-8jll4 deletion completed in 26.183802457s

• [SLOW TEST:41.160 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:12:53.931: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2wm92
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-582s
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 13:12:54.178: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-582s" in namespace "e2e-tests-subpath-2wm92" to be "success or failure"
Feb 19 13:12:54.184: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.138192ms
Feb 19 13:12:56.191: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012350767s
Feb 19 13:12:58.197: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01863213s
Feb 19 13:13:00.202: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024091582s
Feb 19 13:13:02.209: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030424586s
Feb 19 13:13:04.215: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036990983s
Feb 19 13:13:06.222: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 12.043756856s
Feb 19 13:13:08.228: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 14.049832538s
Feb 19 13:13:10.235: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056632464s
Feb 19 13:13:12.241: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 18.062759958s
Feb 19 13:13:14.247: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 20.06867005s
Feb 19 13:13:16.254: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 22.075504415s
Feb 19 13:13:18.261: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 24.082204668s
Feb 19 13:13:20.267: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 26.088674534s
Feb 19 13:13:22.274: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 28.095587574s
Feb 19 13:13:24.281: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 30.102426772s
Feb 19 13:13:26.287: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 32.108726156s
Feb 19 13:13:28.293: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 34.114915392s
Feb 19 13:13:30.299: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 36.121034875s
Feb 19 13:13:32.306: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 38.127554769s
Feb 19 13:13:34.312: INFO: Pod "pod-subpath-test-secret-582s": Phase="Pending", Reason="", readiness=false. Elapsed: 40.133809828s
Feb 19 13:13:36.319: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 42.14030663s
Feb 19 13:13:38.325: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 44.146747485s
Feb 19 13:13:40.332: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 46.153509154s
Feb 19 13:13:42.338: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 48.159529259s
Feb 19 13:13:44.349: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 50.170414979s
Feb 19 13:13:46.355: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 52.176619046s
Feb 19 13:13:48.361: INFO: Pod "pod-subpath-test-secret-582s": Phase="Running", Reason="", readiness=false. Elapsed: 54.182300173s
Feb 19 13:13:50.367: INFO: Pod "pod-subpath-test-secret-582s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 56.188242929s
STEP: Saw pod success
Feb 19 13:13:50.367: INFO: Pod "pod-subpath-test-secret-582s" satisfied condition "success or failure"
Feb 19 13:13:50.373: INFO: Trying to get logs from node kube-node-20-104 pod pod-subpath-test-secret-582s container test-container-subpath-secret-582s: <nil>
STEP: delete the pod
Feb 19 13:13:50.409: INFO: Waiting for pod pod-subpath-test-secret-582s to disappear
Feb 19 13:13:50.414: INFO: Pod pod-subpath-test-secret-582s no longer exists
STEP: Deleting pod pod-subpath-test-secret-582s
Feb 19 13:13:50.414: INFO: Deleting pod "pod-subpath-test-secret-582s" in namespace "e2e-tests-subpath-2wm92"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:13:50.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2wm92" for this suite.
Feb 19 13:13:56.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:13:56.485: INFO: namespace: e2e-tests-subpath-2wm92, resource: bindings, ignored listing per whitelist
Feb 19 13:13:56.606: INFO: namespace e2e-tests-subpath-2wm92 deletion completed in 6.179365638s

• [SLOW TEST:62.675 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:13:56.606: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5v5zj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-36847c72-3448-11e9-af36-92091ca56148
STEP: Creating secret with name s-test-opt-upd-36847e56-3448-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-36847c72-3448-11e9-af36-92091ca56148
STEP: Updating secret s-test-opt-upd-36847e56-3448-11e9-af36-92091ca56148
STEP: Creating secret with name s-test-opt-create-36847e79-3448-11e9-af36-92091ca56148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:14:15.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5v5zj" for this suite.
Feb 19 13:14:39.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:14:39.183: INFO: namespace: e2e-tests-projected-5v5zj, resource: bindings, ignored listing per whitelist
Feb 19 13:14:39.230: INFO: namespace e2e-tests-projected-5v5zj deletion completed in 24.192796943s

• [SLOW TEST:42.624 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:14:39.230: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rdghf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 19 13:14:39.474: INFO: Waiting up to 5m0s for pod "pod-4feae0dc-3448-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-rdghf" to be "success or failure"
Feb 19 13:14:39.483: INFO: Pod "pod-4feae0dc-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 9.048293ms
Feb 19 13:14:41.490: INFO: Pod "pod-4feae0dc-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015652213s
Feb 19 13:14:43.499: INFO: Pod "pod-4feae0dc-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024934586s
Feb 19 13:14:45.504: INFO: Pod "pod-4feae0dc-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029912644s
Feb 19 13:14:47.510: INFO: Pod "pod-4feae0dc-3448-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.035707938s
STEP: Saw pod success
Feb 19 13:14:47.510: INFO: Pod "pod-4feae0dc-3448-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:14:47.514: INFO: Trying to get logs from node kube-node-20-105 pod pod-4feae0dc-3448-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:14:47.550: INFO: Waiting for pod pod-4feae0dc-3448-11e9-af36-92091ca56148 to disappear
Feb 19 13:14:47.555: INFO: Pod pod-4feae0dc-3448-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:14:47.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rdghf" for this suite.
Feb 19 13:14:53.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:14:53.693: INFO: namespace: e2e-tests-emptydir-rdghf, resource: bindings, ignored listing per whitelist
Feb 19 13:14:53.732: INFO: namespace e2e-tests-emptydir-rdghf deletion completed in 6.17067531s

• [SLOW TEST:14.502 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:14:53.733: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-89qpf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 19 13:14:53.969: INFO: Waiting up to 5m0s for pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148" in namespace "e2e-tests-var-expansion-89qpf" to be "success or failure"
Feb 19 13:14:53.979: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 9.984779ms
Feb 19 13:14:55.986: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016979763s
Feb 19 13:14:57.993: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023725038s
Feb 19 13:15:00.000: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03064107s
Feb 19 13:15:02.006: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037158922s
Feb 19 13:15:04.013: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.043621647s
Feb 19 13:15:06.019: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.050005135s
Feb 19 13:15:08.026: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.057004665s
Feb 19 13:15:10.033: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.06365861s
Feb 19 13:15:12.040: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.070452087s
Feb 19 13:15:14.045: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.076270862s
STEP: Saw pod success
Feb 19 13:15:14.045: INFO: Pod "var-expansion-588f14e0-3448-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:15:14.050: INFO: Trying to get logs from node kube-node-20-104 pod var-expansion-588f14e0-3448-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 13:15:14.079: INFO: Waiting for pod var-expansion-588f14e0-3448-11e9-af36-92091ca56148 to disappear
Feb 19 13:15:14.084: INFO: Pod var-expansion-588f14e0-3448-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:15:14.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-89qpf" for this suite.
Feb 19 13:15:20.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:15:20.136: INFO: namespace: e2e-tests-var-expansion-89qpf, resource: bindings, ignored listing per whitelist
Feb 19 13:15:20.267: INFO: namespace e2e-tests-var-expansion-89qpf deletion completed in 6.177660713s

• [SLOW TEST:26.535 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:15:20.268: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-dkqmm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 19 13:15:20.523: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dkqmm,SelfLink:/api/v1/namespaces/e2e-tests-watch-dkqmm/configmaps/e2e-watch-test-label-changed,UID:6860a0f3-3448-11e9-b551-525400c68782,ResourceVersion:953374,Generation:0,CreationTimestamp:2019-02-19 13:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 13:15:20.523: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dkqmm,SelfLink:/api/v1/namespaces/e2e-tests-watch-dkqmm/configmaps/e2e-watch-test-label-changed,UID:6860a0f3-3448-11e9-b551-525400c68782,ResourceVersion:953375,Generation:0,CreationTimestamp:2019-02-19 13:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 19 13:15:20.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dkqmm,SelfLink:/api/v1/namespaces/e2e-tests-watch-dkqmm/configmaps/e2e-watch-test-label-changed,UID:6860a0f3-3448-11e9-b551-525400c68782,ResourceVersion:953376,Generation:0,CreationTimestamp:2019-02-19 13:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 19 13:15:30.562: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dkqmm,SelfLink:/api/v1/namespaces/e2e-tests-watch-dkqmm/configmaps/e2e-watch-test-label-changed,UID:6860a0f3-3448-11e9-b551-525400c68782,ResourceVersion:953397,Generation:0,CreationTimestamp:2019-02-19 13:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 13:15:30.562: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dkqmm,SelfLink:/api/v1/namespaces/e2e-tests-watch-dkqmm/configmaps/e2e-watch-test-label-changed,UID:6860a0f3-3448-11e9-b551-525400c68782,ResourceVersion:953398,Generation:0,CreationTimestamp:2019-02-19 13:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 19 13:15:30.562: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dkqmm,SelfLink:/api/v1/namespaces/e2e-tests-watch-dkqmm/configmaps/e2e-watch-test-label-changed,UID:6860a0f3-3448-11e9-b551-525400c68782,ResourceVersion:953399,Generation:0,CreationTimestamp:2019-02-19 13:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:15:30.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dkqmm" for this suite.
Feb 19 13:15:36.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:15:36.730: INFO: namespace: e2e-tests-watch-dkqmm, resource: bindings, ignored listing per whitelist
Feb 19 13:15:36.730: INFO: namespace e2e-tests-watch-dkqmm deletion completed in 6.162241905s

• [SLOW TEST:16.463 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:15:36.731: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-m86hx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 19 13:15:36.951: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-879726862 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:15:37.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m86hx" for this suite.
Feb 19 13:15:43.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:15:43.278: INFO: namespace: e2e-tests-kubectl-m86hx, resource: bindings, ignored listing per whitelist
Feb 19 13:15:43.288: INFO: namespace e2e-tests-kubectl-m86hx deletion completed in 6.187701384s

• [SLOW TEST:6.557 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:15:43.288: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-x69rn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-7qd6
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 13:15:43.553: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-7qd6" in namespace "e2e-tests-subpath-x69rn" to be "success or failure"
Feb 19 13:15:43.561: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.907663ms
Feb 19 13:15:45.568: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015734715s
Feb 19 13:15:47.574: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021797359s
Feb 19 13:15:49.580: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02785895s
Feb 19 13:15:51.587: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.034618989s
Feb 19 13:15:53.594: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041591155s
Feb 19 13:15:55.600: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.047765238s
Feb 19 13:15:57.608: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.055417271s
Feb 19 13:15:59.614: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.061411118s
Feb 19 13:16:01.620: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.067638895s
Feb 19 13:16:03.628: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.07509833s
Feb 19 13:16:05.634: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.081220072s
Feb 19 13:16:07.640: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.087442687s
Feb 19 13:16:09.646: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 26.093869895s
Feb 19 13:16:11.658: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 28.105444263s
Feb 19 13:16:13.665: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 30.112490864s
Feb 19 13:16:15.672: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 32.119585655s
Feb 19 13:16:17.680: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 34.127159166s
Feb 19 13:16:19.687: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 36.134116803s
Feb 19 13:16:21.694: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 38.141081362s
Feb 19 13:16:23.700: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Running", Reason="", readiness=false. Elapsed: 40.147362953s
Feb 19 13:16:25.706: INFO: Pod "pod-subpath-test-downwardapi-7qd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 42.153384932s
STEP: Saw pod success
Feb 19 13:16:25.706: INFO: Pod "pod-subpath-test-downwardapi-7qd6" satisfied condition "success or failure"
Feb 19 13:16:25.711: INFO: Trying to get logs from node kube-node-20-105 pod pod-subpath-test-downwardapi-7qd6 container test-container-subpath-downwardapi-7qd6: <nil>
STEP: delete the pod
Feb 19 13:16:25.740: INFO: Waiting for pod pod-subpath-test-downwardapi-7qd6 to disappear
Feb 19 13:16:25.745: INFO: Pod pod-subpath-test-downwardapi-7qd6 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-7qd6
Feb 19 13:16:25.745: INFO: Deleting pod "pod-subpath-test-downwardapi-7qd6" in namespace "e2e-tests-subpath-x69rn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:16:25.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x69rn" for this suite.
Feb 19 13:16:31.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:16:31.917: INFO: namespace: e2e-tests-subpath-x69rn, resource: bindings, ignored listing per whitelist
Feb 19 13:16:31.935: INFO: namespace e2e-tests-subpath-x69rn deletion completed in 6.178262362s

• [SLOW TEST:48.647 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:16:31.936: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-75lkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-75lkh.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-75lkh.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-75lkh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-75lkh.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-75lkh.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-75lkh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 19 13:17:00.309: INFO: DNS probes using e2e-tests-dns-75lkh/dns-test-9319ce58-3448-11e9-af36-92091ca56148 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:17:00.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-75lkh" for this suite.
Feb 19 13:17:06.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:17:06.477: INFO: namespace: e2e-tests-dns-75lkh, resource: bindings, ignored listing per whitelist
Feb 19 13:17:06.523: INFO: namespace e2e-tests-dns-75lkh deletion completed in 6.186217196s

• [SLOW TEST:34.588 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:17:06.524: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-9tx7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 19 13:17:22.847: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:22.853: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:24.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:24.860: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:26.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:26.858: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:28.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:28.859: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:30.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:30.860: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:32.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:32.859: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:34.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:34.859: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:36.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:36.860: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:38.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:38.858: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:40.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:40.859: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:42.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:42.860: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:44.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:44.860: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:46.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:46.859: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:48.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:48.860: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 19 13:17:50.853: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 19 13:17:50.859: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:17:50.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9tx7s" for this suite.
Feb 19 13:18:12.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:18:13.055: INFO: namespace: e2e-tests-container-lifecycle-hook-9tx7s, resource: bindings, ignored listing per whitelist
Feb 19 13:18:13.055: INFO: namespace e2e-tests-container-lifecycle-hook-9tx7s deletion completed in 22.188054313s

• [SLOW TEST:66.531 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:18:13.055: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8dkrl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 19 13:18:13.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:13.782: INFO: stderr: ""
Feb 19 13:18:13.782: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 13:18:13.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:13.920: INFO: stderr: ""
Feb 19 13:18:13.920: INFO: stdout: "update-demo-nautilus-nc7k4 update-demo-nautilus-t84ml "
Feb 19 13:18:13.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-nc7k4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:14.040: INFO: stderr: ""
Feb 19 13:18:14.040: INFO: stdout: ""
Feb 19 13:18:14.040: INFO: update-demo-nautilus-nc7k4 is created but not running
Feb 19 13:18:19.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:19.181: INFO: stderr: ""
Feb 19 13:18:19.181: INFO: stdout: "update-demo-nautilus-nc7k4 update-demo-nautilus-t84ml "
Feb 19 13:18:19.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-nc7k4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:19.310: INFO: stderr: ""
Feb 19 13:18:19.310: INFO: stdout: ""
Feb 19 13:18:19.310: INFO: update-demo-nautilus-nc7k4 is created but not running
Feb 19 13:18:24.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:24.452: INFO: stderr: ""
Feb 19 13:18:24.452: INFO: stdout: "update-demo-nautilus-nc7k4 update-demo-nautilus-t84ml "
Feb 19 13:18:24.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-nc7k4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:24.584: INFO: stderr: ""
Feb 19 13:18:24.584: INFO: stdout: "true"
Feb 19 13:18:24.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-nc7k4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:24.708: INFO: stderr: ""
Feb 19 13:18:24.708: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 13:18:24.708: INFO: validating pod update-demo-nautilus-nc7k4
Feb 19 13:18:24.717: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 13:18:24.717: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 13:18:24.717: INFO: update-demo-nautilus-nc7k4 is verified up and running
Feb 19 13:18:24.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-t84ml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:24.837: INFO: stderr: ""
Feb 19 13:18:24.837: INFO: stdout: "true"
Feb 19 13:18:24.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-t84ml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:24.960: INFO: stderr: ""
Feb 19 13:18:24.961: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 13:18:24.961: INFO: validating pod update-demo-nautilus-t84ml
Feb 19 13:18:24.969: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 13:18:24.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 13:18:24.969: INFO: update-demo-nautilus-t84ml is verified up and running
STEP: scaling down the replication controller
Feb 19 13:18:24.972: INFO: scanned /root for discovery docs: <nil>
Feb 19 13:18:24.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:26.166: INFO: stderr: ""
Feb 19 13:18:26.166: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 13:18:26.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:26.303: INFO: stderr: ""
Feb 19 13:18:26.303: INFO: stdout: "update-demo-nautilus-nc7k4 update-demo-nautilus-t84ml "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 19 13:18:31.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:31.446: INFO: stderr: ""
Feb 19 13:18:31.446: INFO: stdout: "update-demo-nautilus-t84ml "
Feb 19 13:18:31.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-t84ml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:31.579: INFO: stderr: ""
Feb 19 13:18:31.579: INFO: stdout: "true"
Feb 19 13:18:31.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-t84ml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:31.698: INFO: stderr: ""
Feb 19 13:18:31.698: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 13:18:31.698: INFO: validating pod update-demo-nautilus-t84ml
Feb 19 13:18:31.705: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 13:18:31.705: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 13:18:31.705: INFO: update-demo-nautilus-t84ml is verified up and running
STEP: scaling up the replication controller
Feb 19 13:18:31.707: INFO: scanned /root for discovery docs: <nil>
Feb 19 13:18:31.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:32.883: INFO: stderr: ""
Feb 19 13:18:32.883: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 19 13:18:32.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:33.022: INFO: stderr: ""
Feb 19 13:18:33.022: INFO: stdout: "update-demo-nautilus-44m4b update-demo-nautilus-t84ml "
Feb 19 13:18:33.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-44m4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:33.156: INFO: stderr: ""
Feb 19 13:18:33.156: INFO: stdout: ""
Feb 19 13:18:33.156: INFO: update-demo-nautilus-44m4b is created but not running
Feb 19 13:18:38.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:38.290: INFO: stderr: ""
Feb 19 13:18:38.290: INFO: stdout: "update-demo-nautilus-44m4b update-demo-nautilus-t84ml "
Feb 19 13:18:38.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-44m4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:38.425: INFO: stderr: ""
Feb 19 13:18:38.425: INFO: stdout: "true"
Feb 19 13:18:38.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-44m4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:38.553: INFO: stderr: ""
Feb 19 13:18:38.553: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 13:18:38.553: INFO: validating pod update-demo-nautilus-44m4b
Feb 19 13:18:38.561: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 13:18:38.561: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 13:18:38.561: INFO: update-demo-nautilus-44m4b is verified up and running
Feb 19 13:18:38.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-t84ml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:38.696: INFO: stderr: ""
Feb 19 13:18:38.696: INFO: stdout: "true"
Feb 19 13:18:38.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods update-demo-nautilus-t84ml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:38.814: INFO: stderr: ""
Feb 19 13:18:38.814: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 19 13:18:38.814: INFO: validating pod update-demo-nautilus-t84ml
Feb 19 13:18:38.821: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 19 13:18:38.821: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 19 13:18:38.821: INFO: update-demo-nautilus-t84ml is verified up and running
STEP: using delete to clean up resources
Feb 19 13:18:38.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:38.953: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:18:38.953: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 19 13:18:38.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-8dkrl'
Feb 19 13:18:39.118: INFO: stderr: "No resources found.\n"
Feb 19 13:18:39.118: INFO: stdout: ""
Feb 19 13:18:39.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -l name=update-demo --namespace=e2e-tests-kubectl-8dkrl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 13:18:39.271: INFO: stderr: ""
Feb 19 13:18:39.271: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:18:39.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8dkrl" for this suite.
Feb 19 13:19:01.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:19:01.444: INFO: namespace: e2e-tests-kubectl-8dkrl, resource: bindings, ignored listing per whitelist
Feb 19 13:19:01.455: INFO: namespace e2e-tests-kubectl-8dkrl deletion completed in 22.176263658s

• [SLOW TEST:48.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:19:01.455: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-8wrhh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 19 13:19:01.680: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 19 13:19:01.693: INFO: Waiting for terminating namespaces to be deleted...
Feb 19 13:19:01.697: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-101 before test
Feb 19 13:19:01.710: INFO: kube-scheduler-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.710: INFO: canal-qdkqk from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.710: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 13:19:01.710: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 13:19:01.710: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 13:19:01.710: INFO: apiserver-proxy-nginx-preset-5b4466959d-8ms5x from kube-system started at 2019-02-18 07:35:39 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.710: INFO: 	Container proxy ready: true, restart count 0
Feb 19 13:19:01.710: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 13:19:01.710: INFO: kube-controller-manager-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.710: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-xq62r from kube-system started at 2019-02-18 07:35:13 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.710: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 13:19:01.710: INFO: kube-proxy-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.710: INFO: kube-apiserver-kube-master-20-101 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.710: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-5tddr from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.710: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 13:19:01.710: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 13:19:01.710: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-102 before test
Feb 19 13:19:01.721: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pkrq6 from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.721: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 13:19:01.721: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 13:19:01.721: INFO: kube-apiserver-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.721: INFO: kube-proxy-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.721: INFO: canal-mfnnl from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.721: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 13:19:01.721: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 13:19:01.721: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 13:19:01.721: INFO: kube-dns-v22-55c6fb7579-54jkj from kube-system started at 2019-02-14 05:19:03 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.721: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 19 13:19:01.721: INFO: 	Container kubedns ready: true, restart count 0
Feb 19 13:19:01.721: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 13:19:01.721: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-jd6vk from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.721: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 13:19:01.721: INFO: kube-dns-autoscaler-v22-656c98d7b5-gfrdp from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.721: INFO: 	Container autoscaler ready: true, restart count 0
Feb 19 13:19:01.721: INFO: kube-scheduler-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.721: INFO: kube-controller-manager-kube-master-20-102 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.721: INFO: apiserver-proxy-nginx-preset-5b4466959d-fxx54 from kube-system started at 2019-02-14 05:19:03 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.722: INFO: 	Container proxy ready: true, restart count 0
Feb 19 13:19:01.722: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 13:19:01.722: INFO: 
Logging pods the kubelet thinks is on node kube-master-20-103 before test
Feb 19 13:19:01.734: INFO: apiserver-provider-ipvsdr-preset-59cdc6b987-5l2kt from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.734: INFO: 	Container ipvsdr ready: true, restart count 0
Feb 19 13:19:01.734: INFO: kube-apiserver-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.734: INFO: default-http-backend-65bd46965-cdcjr from kube-system started at 2019-02-14 05:19:03 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.734: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 19 13:19:01.734: INFO: apiserver-proxy-nginx-preset-5b4466959d-4pj2p from kube-system started at 2019-02-14 05:19:03 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.734: INFO: 	Container proxy ready: true, restart count 0
Feb 19 13:19:01.734: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 13:19:01.734: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-pz27f from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.734: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 13:19:01.734: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 13:19:01.734: INFO: kube-controller-manager-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.734: INFO: kube-dns-v22-55c6fb7579-zrzjg from kube-system started at 2019-02-14 05:19:23 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.734: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 19 13:19:01.734: INFO: 	Container kubedns ready: true, restart count 0
Feb 19 13:19:01.734: INFO: 	Container sidecar ready: true, restart count 0
Feb 19 13:19:01.734: INFO: kube-proxy-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.734: INFO: canal-xffd7 from kube-system started at 2019-02-14 05:18:38 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.734: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 13:19:01.734: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 13:19:01.734: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 13:19:01.734: INFO: kube-scheduler-kube-master-20-103 from kube-system started at <nil> (0 container statuses recorded)
Feb 19 13:19:01.734: INFO: 
Logging pods the kubelet thinks is on node kube-node-20-104 before test
Feb 19 13:19:01.746: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-mkhbh from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.746: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 13:19:01.746: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 19 13:19:01.746: INFO: canal-8jqlz from kube-system started at 2019-02-14 05:20:10 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.746: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 13:19:01.746: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 13:19:01.746: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 13:19:01.746: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-19 11:42:36 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.746: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 19 13:19:01.746: INFO: kube-proxy-4pr8w from kube-system started at 2019-02-14 05:20:10 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.746: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 13:19:01.746: INFO: heketi-7f9b67f7f-txk48 from default started at 2019-02-14 05:21:05 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.746: INFO: 	Container heketi ready: true, restart count 0
Feb 19 13:19:01.746: INFO: 
Logging pods the kubelet thinks is on node kube-node-20-105 before test
Feb 19 13:19:01.754: INFO: kube-proxy-b2w22 from kube-system started at 2019-02-14 05:20:10 +0000 UTC (1 container statuses recorded)
Feb 19 13:19:01.754: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 19 13:19:01.754: INFO: canal-jv9n9 from kube-system started at 2019-02-14 05:20:10 +0000 UTC (3 container statuses recorded)
Feb 19 13:19:01.754: INFO: 	Container calico-node ready: true, restart count 0
Feb 19 13:19:01.754: INFO: 	Container install-cni ready: true, restart count 0
Feb 19 13:19:01.754: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 19 13:19:01.754: INFO: sonobuoy-e2e-job-21151d8fb97a4946 from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.754: INFO: 	Container e2e ready: true, restart count 0
Feb 19 13:19:01.754: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 19 13:19:01.754: INFO: sonobuoy-systemd-logs-daemon-set-2d8f614abb9d4259-zv89v from heptio-sonobuoy started at 2019-02-19 11:42:41 +0000 UTC (2 container statuses recorded)
Feb 19 13:19:01.754: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 19 13:19:01.754: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-efdc09fc-3448-11e9-af36-92091ca56148 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-efdc09fc-3448-11e9-af36-92091ca56148 off the node kube-node-20-104
STEP: verifying the node doesn't have the label kubernetes.io/e2e-efdc09fc-3448-11e9-af36-92091ca56148
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:19:15.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8wrhh" for this suite.
Feb 19 13:19:23.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:19:23.972: INFO: namespace: e2e-tests-sched-pred-8wrhh, resource: bindings, ignored listing per whitelist
Feb 19 13:19:24.055: INFO: namespace e2e-tests-sched-pred-8wrhh deletion completed in 8.180097863s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:22.600 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:19:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-ms5zx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 13:19:24.277: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:20:09.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ms5zx" for this suite.
Feb 19 13:20:15.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:20:15.486: INFO: namespace: e2e-tests-init-container-ms5zx, resource: bindings, ignored listing per whitelist
Feb 19 13:20:15.532: INFO: namespace e2e-tests-init-container-ms5zx deletion completed in 6.176038466s

• [SLOW TEST:51.477 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:20:15.532: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-lvjqp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 13:20:15.820: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1861f51c-3449-11e9-b551-525400c68782", Controller:(*bool)(0xc4229c7746), BlockOwnerDeletion:(*bool)(0xc4229c7747)}}
Feb 19 13:20:15.837: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"185f63c2-3449-11e9-b551-525400c68782", Controller:(*bool)(0xc4229c7912), BlockOwnerDeletion:(*bool)(0xc4229c7913)}}
Feb 19 13:20:15.846: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"186075b9-3449-11e9-b551-525400c68782", Controller:(*bool)(0xc42238cea6), BlockOwnerDeletion:(*bool)(0xc42238cea7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:20:20.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lvjqp" for this suite.
Feb 19 13:20:26.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:20:26.923: INFO: namespace: e2e-tests-gc-lvjqp, resource: bindings, ignored listing per whitelist
Feb 19 13:20:27.062: INFO: namespace e2e-tests-gc-lvjqp deletion completed in 6.19297863s

• [SLOW TEST:11.530 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:20:27.063: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-nkqm6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 19 13:20:27.287: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:21:19.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-nkqm6" for this suite.
Feb 19 13:21:42.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:21:42.049: INFO: namespace: e2e-tests-init-container-nkqm6, resource: bindings, ignored listing per whitelist
Feb 19 13:21:42.156: INFO: namespace e2e-tests-init-container-nkqm6 deletion completed in 22.172039929s

• [SLOW TEST:75.094 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:21:42.157: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-hdvl7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hdvl7
Feb 19 13:21:48.406: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hdvl7
STEP: checking the pod's current state and verifying that restartCount is present
Feb 19 13:21:48.411: INFO: Initial restart count of pod liveness-http is 0
Feb 19 13:22:14.494: INFO: Restart count of pod e2e-tests-container-probe-hdvl7/liveness-http is now 1 (26.083602788s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:22:14.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hdvl7" for this suite.
Feb 19 13:22:20.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:22:20.687: INFO: namespace: e2e-tests-container-probe-hdvl7, resource: bindings, ignored listing per whitelist
Feb 19 13:22:20.695: INFO: namespace e2e-tests-container-probe-hdvl7 deletion completed in 6.175181414s

• [SLOW TEST:38.538 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:22:20.695: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-zsfz9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 19 13:22:20.940: INFO: Waiting up to 5m0s for pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148" in namespace "e2e-tests-containers-zsfz9" to be "success or failure"
Feb 19 13:22:20.945: INFO: Pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.830937ms
Feb 19 13:22:22.950: INFO: Pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010272278s
Feb 19 13:22:24.956: INFO: Pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016633739s
Feb 19 13:22:26.963: INFO: Pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023487327s
Feb 19 13:22:28.970: INFO: Pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030267994s
STEP: Saw pod success
Feb 19 13:22:28.970: INFO: Pod "client-containers-62f92e99-3449-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:22:28.975: INFO: Trying to get logs from node kube-node-20-105 pod client-containers-62f92e99-3449-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:22:29.004: INFO: Waiting for pod client-containers-62f92e99-3449-11e9-af36-92091ca56148 to disappear
Feb 19 13:22:29.009: INFO: Pod client-containers-62f92e99-3449-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:22:29.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zsfz9" for this suite.
Feb 19 13:22:35.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:22:35.146: INFO: namespace: e2e-tests-containers-zsfz9, resource: bindings, ignored listing per whitelist
Feb 19 13:22:35.205: INFO: namespace e2e-tests-containers-zsfz9 deletion completed in 6.189461575s

• [SLOW TEST:14.510 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:22:35.205: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-ncp6w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 19 13:23:03.481: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:03.481: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:03.611: INFO: Exec stderr: ""
Feb 19 13:23:03.611: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:03.611: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:03.742: INFO: Exec stderr: ""
Feb 19 13:23:03.742: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:03.742: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:03.871: INFO: Exec stderr: ""
Feb 19 13:23:03.871: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:03.871: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.019: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 19 13:23:04.019: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:04.019: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.145: INFO: Exec stderr: ""
Feb 19 13:23:04.145: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:04.145: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.265: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 19 13:23:04.265: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:04.265: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.396: INFO: Exec stderr: ""
Feb 19 13:23:04.397: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:04.397: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.521: INFO: Exec stderr: ""
Feb 19 13:23:04.521: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:04.521: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.640: INFO: Exec stderr: ""
Feb 19 13:23:04.640: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ncp6w PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:23:04.640: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:23:04.800: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:23:04.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-ncp6w" for this suite.
Feb 19 13:23:52.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:23:52.920: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-ncp6w, resource: bindings, ignored listing per whitelist
Feb 19 13:23:53.000: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-ncp6w deletion completed in 48.19228265s

• [SLOW TEST:77.794 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:23:53.000: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q8d66
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 19 13:23:53.249: INFO: Waiting up to 5m0s for pod "pod-99fef319-3449-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-q8d66" to be "success or failure"
Feb 19 13:23:53.256: INFO: Pod "pod-99fef319-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.349676ms
Feb 19 13:23:55.262: INFO: Pod "pod-99fef319-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012107366s
Feb 19 13:23:57.269: INFO: Pod "pod-99fef319-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019088179s
Feb 19 13:23:59.275: INFO: Pod "pod-99fef319-3449-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025108765s
STEP: Saw pod success
Feb 19 13:23:59.275: INFO: Pod "pod-99fef319-3449-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:23:59.279: INFO: Trying to get logs from node kube-node-20-104 pod pod-99fef319-3449-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:23:59.309: INFO: Waiting for pod pod-99fef319-3449-11e9-af36-92091ca56148 to disappear
Feb 19 13:23:59.313: INFO: Pod pod-99fef319-3449-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:23:59.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q8d66" for this suite.
Feb 19 13:24:05.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:24:05.396: INFO: namespace: e2e-tests-emptydir-q8d66, resource: bindings, ignored listing per whitelist
Feb 19 13:24:05.494: INFO: namespace e2e-tests-emptydir-q8d66 deletion completed in 6.175170918s

• [SLOW TEST:12.494 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:24:05.494: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b6b9q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 13:24:05.746: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-b6b9q" to be "success or failure"
Feb 19 13:24:05.752: INFO: Pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.627383ms
Feb 19 13:24:07.757: INFO: Pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0109085s
Feb 19 13:24:09.763: INFO: Pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017290662s
Feb 19 13:24:11.769: INFO: Pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023299515s
Feb 19 13:24:13.776: INFO: Pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029860983s
STEP: Saw pod success
Feb 19 13:24:13.776: INFO: Pod "downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:24:13.780: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 13:24:13.818: INFO: Waiting for pod downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148 to disappear
Feb 19 13:24:13.823: INFO: Pod downwardapi-volume-a1712272-3449-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:24:13.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b6b9q" for this suite.
Feb 19 13:24:19.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:24:19.870: INFO: namespace: e2e-tests-downward-api-b6b9q, resource: bindings, ignored listing per whitelist
Feb 19 13:24:20.003: INFO: namespace e2e-tests-downward-api-b6b9q deletion completed in 6.17225743s

• [SLOW TEST:14.510 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:24:20.004: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-kzhfd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 19 13:24:20.252: INFO: Waiting up to 5m0s for pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148" in namespace "e2e-tests-containers-kzhfd" to be "success or failure"
Feb 19 13:24:20.256: INFO: Pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.563414ms
Feb 19 13:24:22.262: INFO: Pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010383144s
Feb 19 13:24:24.268: INFO: Pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016255447s
Feb 19 13:24:26.274: INFO: Pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022598748s
Feb 19 13:24:28.280: INFO: Pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028819834s
STEP: Saw pod success
Feb 19 13:24:28.280: INFO: Pod "client-containers-aa16b5ba-3449-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:24:28.285: INFO: Trying to get logs from node kube-node-20-104 pod client-containers-aa16b5ba-3449-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:24:28.319: INFO: Waiting for pod client-containers-aa16b5ba-3449-11e9-af36-92091ca56148 to disappear
Feb 19 13:24:28.323: INFO: Pod client-containers-aa16b5ba-3449-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:24:28.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kzhfd" for this suite.
Feb 19 13:24:34.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:24:34.427: INFO: namespace: e2e-tests-containers-kzhfd, resource: bindings, ignored listing per whitelist
Feb 19 13:24:34.497: INFO: namespace e2e-tests-containers-kzhfd deletion completed in 6.16724725s

• [SLOW TEST:14.493 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:24:34.498: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wqdxn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 19 13:24:34.744: INFO: Waiting up to 5m0s for pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-wqdxn" to be "success or failure"
Feb 19 13:24:34.750: INFO: Pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.632173ms
Feb 19 13:24:36.756: INFO: Pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012566205s
Feb 19 13:24:38.763: INFO: Pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019005915s
Feb 19 13:24:40.768: INFO: Pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024793667s
Feb 19 13:24:42.774: INFO: Pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030281493s
STEP: Saw pod success
Feb 19 13:24:42.774: INFO: Pod "pod-b2ba2cf6-3449-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:24:42.778: INFO: Trying to get logs from node kube-node-20-105 pod pod-b2ba2cf6-3449-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:24:42.810: INFO: Waiting for pod pod-b2ba2cf6-3449-11e9-af36-92091ca56148 to disappear
Feb 19 13:24:42.819: INFO: Pod pod-b2ba2cf6-3449-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:24:42.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wqdxn" for this suite.
Feb 19 13:24:48.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:24:48.957: INFO: namespace: e2e-tests-emptydir-wqdxn, resource: bindings, ignored listing per whitelist
Feb 19 13:24:49.001: INFO: namespace e2e-tests-emptydir-wqdxn deletion completed in 6.177201315s

• [SLOW TEST:14.504 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:24:49.002: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gxvn2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb 19 13:24:49.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:49.528: INFO: stderr: ""
Feb 19 13:24:49.528: INFO: stdout: "pod/pause created\n"
Feb 19 13:24:49.528: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 19 13:24:49.528: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-gxvn2" to be "running and ready"
Feb 19 13:24:49.533: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.735833ms
Feb 19 13:24:51.539: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011347566s
Feb 19 13:24:53.545: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017317018s
Feb 19 13:24:55.552: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 6.024130124s
Feb 19 13:24:55.552: INFO: Pod "pause" satisfied condition "running and ready"
Feb 19 13:24:55.552: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 19 13:24:55.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:55.712: INFO: stderr: ""
Feb 19 13:24:55.712: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 19 13:24:55.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pod pause -L testing-label --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:55.832: INFO: stderr: ""
Feb 19 13:24:55.832: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          6s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 19 13:24:55.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 label pods pause testing-label- --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:55.961: INFO: stderr: ""
Feb 19 13:24:55.961: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 19 13:24:55.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pod pause -L testing-label --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:56.078: INFO: stderr: ""
Feb 19 13:24:56.078: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          7s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb 19 13:24:56.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:56.217: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:24:56.217: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 19 13:24:56.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-gxvn2'
Feb 19 13:24:56.351: INFO: stderr: "No resources found.\n"
Feb 19 13:24:56.351: INFO: stdout: ""
Feb 19 13:24:56.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 get pods -l name=pause --namespace=e2e-tests-kubectl-gxvn2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 19 13:24:56.467: INFO: stderr: ""
Feb 19 13:24:56.467: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:24:56.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gxvn2" for this suite.
Feb 19 13:25:02.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:25:02.598: INFO: namespace: e2e-tests-kubectl-gxvn2, resource: bindings, ignored listing per whitelist
Feb 19 13:25:02.661: INFO: namespace e2e-tests-kubectl-gxvn2 deletion completed in 6.186386463s

• [SLOW TEST:13.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:25:02.662: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-55f4h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 13:25:02.896: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-55f4h" to be "success or failure"
Feb 19 13:25:02.902: INFO: Pod "downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.792274ms
Feb 19 13:25:04.908: INFO: Pod "downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012918827s
Feb 19 13:25:06.916: INFO: Pod "downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020222543s
Feb 19 13:25:08.922: INFO: Pod "downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026566583s
STEP: Saw pod success
Feb 19 13:25:08.922: INFO: Pod "downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:25:08.927: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 13:25:08.955: INFO: Waiting for pod downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148 to disappear
Feb 19 13:25:08.960: INFO: Pod downwardapi-volume-c38142fd-3449-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:25:08.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-55f4h" for this suite.
Feb 19 13:25:14.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:25:15.129: INFO: namespace: e2e-tests-projected-55f4h, resource: bindings, ignored listing per whitelist
Feb 19 13:25:15.143: INFO: namespace e2e-tests-projected-55f4h deletion completed in 6.174340775s

• [SLOW TEST:12.482 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:25:15.144: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gfhtc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 13:25:15.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-gfhtc'
Feb 19 13:25:15.531: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 13:25:15.531: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb 19 13:25:17.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-gfhtc'
Feb 19 13:25:17.693: INFO: stderr: ""
Feb 19 13:25:17.694: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:25:17.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gfhtc" for this suite.
Feb 19 13:25:23.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:25:23.737: INFO: namespace: e2e-tests-kubectl-gfhtc, resource: bindings, ignored listing per whitelist
Feb 19 13:25:23.883: INFO: namespace e2e-tests-kubectl-gfhtc deletion completed in 6.183002579s

• [SLOW TEST:8.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:25:23.883: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pqg59
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 13:25:32.664: INFO: Successfully updated pod "labelsupdated0284099-3449-11e9-af36-92091ca56148"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:25:34.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pqg59" for this suite.
Feb 19 13:25:56.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:25:56.814: INFO: namespace: e2e-tests-projected-pqg59, resource: bindings, ignored listing per whitelist
Feb 19 13:25:56.864: INFO: namespace e2e-tests-projected-pqg59 deletion completed in 22.162754576s

• [SLOW TEST:32.980 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:25:56.864: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lf4jd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e3d0f015-3449-11e9-af36-92091ca56148
STEP: Creating configMap with name cm-test-opt-upd-e3d0f1f6-3449-11e9-af36-92091ca56148
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e3d0f015-3449-11e9-af36-92091ca56148
STEP: Updating configmap cm-test-opt-upd-e3d0f1f6-3449-11e9-af36-92091ca56148
STEP: Creating configMap with name cm-test-opt-create-e3d0f20e-3449-11e9-af36-92091ca56148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:27:35.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lf4jd" for this suite.
Feb 19 13:27:57.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:27:57.887: INFO: namespace: e2e-tests-projected-lf4jd, resource: bindings, ignored listing per whitelist
Feb 19 13:27:58.034: INFO: namespace e2e-tests-projected-lf4jd deletion completed in 22.18299629s

• [SLOW TEST:121.170 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:27:58.034: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-2z6zd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 19 13:27:58.276: INFO: Waiting up to 5m0s for pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148" in namespace "e2e-tests-var-expansion-2z6zd" to be "success or failure"
Feb 19 13:27:58.281: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129884ms
Feb 19 13:28:00.287: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010121748s
Feb 19 13:28:02.293: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016440525s
Feb 19 13:28:04.299: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022867393s
Feb 19 13:28:06.306: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029283296s
Feb 19 13:28:08.312: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036017061s
Feb 19 13:28:10.318: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.041887951s
Feb 19 13:28:12.325: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.04874968s
Feb 19 13:28:14.333: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056220695s
Feb 19 13:28:16.339: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.062700481s
STEP: Saw pod success
Feb 19 13:28:16.339: INFO: Pod "var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:28:16.345: INFO: Trying to get logs from node kube-node-20-105 pod var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148 container dapi-container: <nil>
STEP: delete the pod
Feb 19 13:28:16.381: INFO: Waiting for pod var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148 to disappear
Feb 19 13:28:16.385: INFO: Pod var-expansion-2c0af5e5-344a-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:28:16.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-2z6zd" for this suite.
Feb 19 13:28:22.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:28:22.453: INFO: namespace: e2e-tests-var-expansion-2z6zd, resource: bindings, ignored listing per whitelist
Feb 19 13:28:22.591: INFO: namespace e2e-tests-var-expansion-2z6zd deletion completed in 6.198501108s

• [SLOW TEST:24.556 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:28:22.591: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6p9rf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3aac2ca6-344a-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 13:28:22.827: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-6p9rf" to be "success or failure"
Feb 19 13:28:22.833: INFO: Pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.305072ms
Feb 19 13:28:24.839: INFO: Pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011893126s
Feb 19 13:28:26.846: INFO: Pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018515346s
Feb 19 13:28:28.851: INFO: Pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024190178s
Feb 19 13:28:30.858: INFO: Pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.030654622s
STEP: Saw pod success
Feb 19 13:28:30.858: INFO: Pod "pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:28:30.863: INFO: Trying to get logs from node kube-node-20-104 pod pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 13:28:30.892: INFO: Waiting for pod pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148 to disappear
Feb 19 13:28:30.896: INFO: Pod pod-projected-configmaps-3aad1274-344a-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:28:30.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6p9rf" for this suite.
Feb 19 13:28:36.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:28:37.061: INFO: namespace: e2e-tests-projected-6p9rf, resource: bindings, ignored listing per whitelist
Feb 19 13:28:37.071: INFO: namespace e2e-tests-projected-6p9rf deletion completed in 6.168743178s

• [SLOW TEST:14.480 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:28:37.071: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rhpx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-434e34ad-344a-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 13:28:37.310: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-rhpx4" to be "success or failure"
Feb 19 13:28:37.319: INFO: Pod "pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.744705ms
Feb 19 13:28:39.327: INFO: Pod "pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016773075s
Feb 19 13:28:41.333: INFO: Pod "pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02282875s
Feb 19 13:28:43.339: INFO: Pod "pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029036317s
STEP: Saw pod success
Feb 19 13:28:43.339: INFO: Pod "pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:28:43.344: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 13:28:43.372: INFO: Waiting for pod pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148 to disappear
Feb 19 13:28:43.378: INFO: Pod pod-projected-configmaps-434f14bb-344a-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:28:43.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rhpx4" for this suite.
Feb 19 13:28:49.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:28:49.440: INFO: namespace: e2e-tests-projected-rhpx4, resource: bindings, ignored listing per whitelist
Feb 19 13:28:49.555: INFO: namespace e2e-tests-projected-rhpx4 deletion completed in 6.171622399s

• [SLOW TEST:12.484 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:28:49.555: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7qd9w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4abf3e9c-344a-11e9-af36-92091ca56148
STEP: Creating secret with name secret-projected-all-test-volume-4abf3e7d-344a-11e9-af36-92091ca56148
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 19 13:28:49.803: INFO: Waiting up to 5m0s for pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-7qd9w" to be "success or failure"
Feb 19 13:28:49.807: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213803ms
Feb 19 13:28:51.814: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011017459s
Feb 19 13:28:53.821: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017363442s
Feb 19 13:28:55.827: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02333127s
Feb 19 13:28:57.833: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029652139s
Feb 19 13:28:59.841: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03815444s
Feb 19 13:29:01.848: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.044733585s
Feb 19 13:29:03.855: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.051827287s
Feb 19 13:29:05.862: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.059180364s
Feb 19 13:29:07.870: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.06631014s
Feb 19 13:29:09.876: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.072244971s
Feb 19 13:29:11.882: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.079051955s
Feb 19 13:29:13.889: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.086181786s
Feb 19 13:29:15.896: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.092399844s
Feb 19 13:29:17.902: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 28.098430223s
Feb 19 13:29:19.909: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 30.105245766s
Feb 19 13:29:21.914: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 32.11074418s
Feb 19 13:29:23.920: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.116542333s
STEP: Saw pod success
Feb 19 13:29:23.920: INFO: Pod "projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:29:23.925: INFO: Trying to get logs from node kube-node-20-104 pod projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 19 13:29:23.957: INFO: Waiting for pod projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148 to disappear
Feb 19 13:29:23.965: INFO: Pod projected-volume-4abf3e2d-344a-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:29:23.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7qd9w" for this suite.
Feb 19 13:29:29.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:29:30.025: INFO: namespace: e2e-tests-projected-7qd9w, resource: bindings, ignored listing per whitelist
Feb 19 13:29:30.172: INFO: namespace e2e-tests-projected-7qd9w deletion completed in 6.20006861s

• [SLOW TEST:40.617 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:29:30.172: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5dmhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-62f4a56c-344a-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 13:29:30.415: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-5dmhm" to be "success or failure"
Feb 19 13:29:30.422: INFO: Pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.979442ms
Feb 19 13:29:32.429: INFO: Pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013909086s
Feb 19 13:29:34.436: INFO: Pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020978656s
Feb 19 13:29:36.441: INFO: Pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026283462s
Feb 19 13:29:38.449: INFO: Pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.033611707s
STEP: Saw pod success
Feb 19 13:29:38.449: INFO: Pod "pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:29:38.453: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 13:29:38.488: INFO: Waiting for pod pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148 to disappear
Feb 19 13:29:38.492: INFO: Pod pod-projected-configmaps-62f5e7ba-344a-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:29:38.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5dmhm" for this suite.
Feb 19 13:29:44.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:29:44.548: INFO: namespace: e2e-tests-projected-5dmhm, resource: bindings, ignored listing per whitelist
Feb 19 13:29:44.667: INFO: namespace e2e-tests-projected-5dmhm deletion completed in 6.166913003s

• [SLOW TEST:14.495 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:29:44.668: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fxkqv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 13:29:44.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-fxkqv'
Feb 19 13:29:45.256: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 13:29:45.256: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb 19 13:29:49.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-fxkqv'
Feb 19 13:29:49.451: INFO: stderr: ""
Feb 19 13:29:49.451: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:29:49.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fxkqv" for this suite.
Feb 19 13:29:55.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:29:55.626: INFO: namespace: e2e-tests-kubectl-fxkqv, resource: bindings, ignored listing per whitelist
Feb 19 13:29:55.638: INFO: namespace e2e-tests-kubectl-fxkqv deletion completed in 6.179297263s

• [SLOW TEST:10.970 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:29:55.638: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wxn7m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wxn7m
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wxn7m
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wxn7m
Feb 19 13:29:55.886: INFO: Found 0 stateful pods, waiting for 1
Feb 19 13:30:05.894: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:30:15.895: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:30:25.894: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:30:35.892: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 19 13:30:35.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:30:36.190: INFO: stderr: ""
Feb 19 13:30:36.190: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:30:36.190: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:30:36.196: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 19 13:30:46.203: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:30:46.203: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:30:46.225: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 19 13:30:46.225: INFO: ss-0  kube-node-20-105  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:29:55 +0000 UTC  }]
Feb 19 13:30:46.225: INFO: 
Feb 19 13:30:46.225: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 19 13:30:47.233: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993191754s
Feb 19 13:30:48.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985259661s
Feb 19 13:30:49.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978593748s
Feb 19 13:30:50.256: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971303634s
Feb 19 13:30:51.263: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96207934s
Feb 19 13:30:52.270: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955540855s
Feb 19 13:30:53.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.948432084s
Feb 19 13:30:54.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941252011s
Feb 19 13:30:55.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.2734ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wxn7m
Feb 19 13:30:56.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:30:56.612: INFO: stderr: ""
Feb 19 13:30:56.612: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:30:56.612: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:30:56.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:30:56.830: INFO: rc: 1
Feb 19 13:30:56.831: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc422be77d0 exit status 1 <nil> <nil> true [0xc42090c0f8 0xc42090c1c0 0xc42090c208] [0xc42090c0f8 0xc42090c1c0 0xc42090c208] [0xc42090c1b0 0xc42090c1d0] [0x8fd520 0x8fd520] 0xc421eca600 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 19 13:31:06.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:31:07.058: INFO: rc: 1
Feb 19 13:31:07.058: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc422d2dcb0 exit status 1 <nil> <nil> true [0xc422862210 0xc422862228 0xc422862240] [0xc422862210 0xc422862228 0xc422862240] [0xc422862220 0xc422862238] [0x8fd520 0x8fd520] 0xc4226f5920 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 19 13:31:17.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:31:17.284: INFO: rc: 1
Feb 19 13:31:17.284: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42200e090 exit status 1 <nil> <nil> true [0xc422862248 0xc422862260 0xc422862278] [0xc422862248 0xc422862260 0xc422862278] [0xc422862258 0xc422862270] [0x8fd520 0x8fd520] 0xc4226f5bc0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 19 13:31:27.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:31:27.576: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 19 13:31:27.576: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:31:27.576: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:31:27.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:31:27.837: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 19 13:31:27.837: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:31:27.837: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:31:27.847: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:31:27.847: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:31:27.847: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 19 13:31:27.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:31:28.114: INFO: stderr: ""
Feb 19 13:31:28.114: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:31:28.114: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:31:28.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:31:28.387: INFO: stderr: ""
Feb 19 13:31:28.387: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:31:28.387: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:31:28.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:31:28.610: INFO: stderr: ""
Feb 19 13:31:28.610: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:31:28.610: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:31:28.610: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:31:28.616: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 19 13:31:38.628: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:31:38.628: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:31:38.628: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:31:38.646: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:38.646: INFO: ss-0  kube-node-20-105    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:29:55 +0000 UTC  }]
Feb 19 13:31:38.646: INFO: ss-1  kube-node-20-104    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:38.646: INFO: ss-2  kube-master-20-101  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:38.646: INFO: 
Feb 19 13:31:38.646: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 13:31:39.652: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:39.652: INFO: ss-0  kube-node-20-105    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:29:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:29:55 +0000 UTC  }]
Feb 19 13:31:39.652: INFO: ss-1  kube-node-20-104    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:39.652: INFO: ss-2  kube-master-20-101  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:39.652: INFO: 
Feb 19 13:31:39.652: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 19 13:31:40.659: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:40.659: INFO: ss-1  kube-node-20-104    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:40.659: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:40.659: INFO: 
Feb 19 13:31:40.659: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 19 13:31:41.665: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:41.665: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:41.665: INFO: 
Feb 19 13:31:41.665: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 13:31:42.672: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:42.672: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:42.672: INFO: 
Feb 19 13:31:42.672: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 13:31:43.678: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:43.678: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:43.678: INFO: 
Feb 19 13:31:43.678: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 13:31:44.685: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:44.685: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:44.685: INFO: 
Feb 19 13:31:44.685: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 13:31:45.692: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:45.692: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:45.692: INFO: 
Feb 19 13:31:45.692: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 13:31:46.699: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:46.699: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:46.699: INFO: 
Feb 19 13:31:46.699: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 19 13:31:47.706: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Feb 19 13:31:47.706: INFO: ss-2  kube-master-20-101  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:31:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-19 13:30:46 +0000 UTC  }]
Feb 19 13:31:47.706: INFO: 
Feb 19 13:31:47.706: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wxn7m
Feb 19 13:31:48.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:31:48.913: INFO: rc: 1
Feb 19 13:31:48.913: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42206fe60 exit status 1 <nil> <nil> true [0xc42090c538 0xc42090c568 0xc42090c590] [0xc42090c538 0xc42090c568 0xc42090c590] [0xc42090c558 0xc42090c588] [0x8fd520 0x8fd520] 0xc421ecb8c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 19 13:31:58.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:31:59.049: INFO: rc: 1
Feb 19 13:31:59.049: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422ca23f0 exit status 1 <nil> <nil> true [0xc42000e198 0xc42000e228 0xc42000e2a8] [0xc42000e198 0xc42000e228 0xc42000e2a8] [0xc42000e1b8 0xc42000e278] [0x8fd520 0x8fd520] 0xc4226f4180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:32:09.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:32:09.180: INFO: rc: 1
Feb 19 13:32:09.180: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2c3c0 exit status 1 <nil> <nil> true [0xc422862000 0xc422862030 0xc422862050] [0xc422862000 0xc422862030 0xc422862050] [0xc422862028 0xc422862040] [0x8fd520 0x8fd520] 0xc422ba8120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:32:19.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:32:19.304: INFO: rc: 1
Feb 19 13:32:19.304: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2c7b0 exit status 1 <nil> <nil> true [0xc422862060 0xc4228620a0 0xc4228620c0] [0xc422862060 0xc4228620a0 0xc4228620c0] [0xc422862088 0xc4228620b8] [0x8fd520 0x8fd520] 0xc422ba8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:32:29.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:32:29.427: INFO: rc: 1
Feb 19 13:32:29.427: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552390 exit status 1 <nil> <nil> true [0xc42090c028 0xc42090c0a8 0xc42090c140] [0xc42090c028 0xc42090c0a8 0xc42090c140] [0xc42090c098 0xc42090c0f8] [0x8fd520 0x8fd520] 0xc421eca060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:32:39.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:32:39.570: INFO: rc: 1
Feb 19 13:32:39.570: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4225527e0 exit status 1 <nil> <nil> true [0xc42090c1b0 0xc42090c1d0 0xc42090c218] [0xc42090c1b0 0xc42090c1d0 0xc42090c218] [0xc42090c1c8 0xc42090c210] [0x8fd520 0x8fd520] 0xc421eca180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:32:49.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:32:49.695: INFO: rc: 1
Feb 19 13:32:49.695: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422ca28a0 exit status 1 <nil> <nil> true [0xc42000e2c8 0xc42000fda0 0xc42000feb0] [0xc42000e2c8 0xc42000fda0 0xc42000feb0] [0xc42000fd60 0xc42000fe70] [0x8fd520 0x8fd520] 0xc4226f4360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:32:59.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:32:59.833: INFO: rc: 1
Feb 19 13:32:59.833: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2cc00 exit status 1 <nil> <nil> true [0xc4228620c8 0xc4228620e0 0xc4228620f8] [0xc4228620c8 0xc4228620e0 0xc4228620f8] [0xc4228620d8 0xc4228620f0] [0x8fd520 0x8fd520] 0xc422ba84e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:33:09.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:33:09.952: INFO: rc: 1
Feb 19 13:33:09.952: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2d1d0 exit status 1 <nil> <nil> true [0xc422862100 0xc422862118 0xc422862130] [0xc422862100 0xc422862118 0xc422862130] [0xc422862110 0xc422862128] [0x8fd520 0x8fd520] 0xc422ba8600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:33:19.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:33:20.088: INFO: rc: 1
Feb 19 13:33:20.089: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552bd0 exit status 1 <nil> <nil> true [0xc42090c220 0xc42090c238 0xc42090c250] [0xc42090c220 0xc42090c238 0xc42090c250] [0xc42090c230 0xc42090c248] [0x8fd520 0x8fd520] 0xc421eca2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:33:30.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:33:30.252: INFO: rc: 1
Feb 19 13:33:30.252: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552f60 exit status 1 <nil> <nil> true [0xc42090c270 0xc42090c298 0xc42090c2b0] [0xc42090c270 0xc42090c298 0xc42090c2b0] [0xc42090c290 0xc42090c2a8] [0x8fd520 0x8fd520] 0xc421eca420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:33:40.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:33:40.383: INFO: rc: 1
Feb 19 13:33:40.384: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422be6420 exit status 1 <nil> <nil> true [0xc4200ea000 0xc4200ea5e8 0xc4200eaae0] [0xc4200ea000 0xc4200ea5e8 0xc4200eaae0] [0xc4200ea220 0xc4200ea9f0] [0x8fd520 0x8fd520] 0xc421fd2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:33:50.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:33:50.519: INFO: rc: 1
Feb 19 13:33:50.520: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422553380 exit status 1 <nil> <nil> true [0xc42090c2b8 0xc42090c2d0 0xc42090c2f0] [0xc42090c2b8 0xc42090c2d0 0xc42090c2f0] [0xc42090c2c8 0xc42090c2e8] [0x8fd520 0x8fd520] 0xc421eca540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:34:00.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:34:00.659: INFO: rc: 1
Feb 19 13:34:00.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422ca2a20 exit status 1 <nil> <nil> true [0xc4200eab60 0xc4200eaff8 0xc4200eb120] [0xc4200eab60 0xc4200eaff8 0xc4200eb120] [0xc4200eaec0 0xc4200eb090] [0x8fd520 0x8fd520] 0xc4226f4480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:34:10.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:34:10.811: INFO: rc: 1
Feb 19 13:34:10.811: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422be6450 exit status 1 <nil> <nil> true [0xc4200ea000 0xc4200ea5e8 0xc4200eaae0] [0xc4200ea000 0xc4200ea5e8 0xc4200eaae0] [0xc4200ea220 0xc4200ea9f0] [0x8fd520 0x8fd520] 0xc421eca060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:34:20.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:34:20.968: INFO: rc: 1
Feb 19 13:34:20.968: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4225523c0 exit status 1 <nil> <nil> true [0xc42090c048 0xc42090c0e0 0xc42090c1b0] [0xc42090c048 0xc42090c0e0 0xc42090c1b0] [0xc42090c0a8 0xc42090c140] [0x8fd520 0x8fd520] 0xc421fd2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:34:30.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:34:31.075: INFO: rc: 1
Feb 19 13:34:31.076: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552870 exit status 1 <nil> <nil> true [0xc42090c1c0 0xc42090c208 0xc42090c220] [0xc42090c1c0 0xc42090c208 0xc42090c220] [0xc42090c1d0 0xc42090c218] [0x8fd520 0x8fd520] 0xc421fd2180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:34:41.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:34:41.225: INFO: rc: 1
Feb 19 13:34:41.226: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2c3f0 exit status 1 <nil> <nil> true [0xc422862000 0xc422862030 0xc422862050] [0xc422862000 0xc422862030 0xc422862050] [0xc422862028 0xc422862040] [0x8fd520 0x8fd520] 0xc422ba8120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:34:51.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:34:51.357: INFO: rc: 1
Feb 19 13:34:51.358: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422be6990 exit status 1 <nil> <nil> true [0xc4200eac88 0xc4200eb2a8 0xc4200eb410] [0xc4200eac88 0xc4200eb2a8 0xc4200eb410] [0xc4200eb198 0xc4200eb3b0] [0x8fd520 0x8fd520] 0xc421eca180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:35:01.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:35:01.496: INFO: rc: 1
Feb 19 13:35:01.496: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552cc0 exit status 1 <nil> <nil> true [0xc42090c228 0xc42090c240 0xc42090c270] [0xc42090c228 0xc42090c240 0xc42090c270] [0xc42090c238 0xc42090c250] [0x8fd520 0x8fd520] 0xc421fd22a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:35:11.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:35:11.638: INFO: rc: 1
Feb 19 13:35:11.638: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2c7e0 exit status 1 <nil> <nil> true [0xc422862060 0xc4228620a0 0xc4228620c0] [0xc422862060 0xc4228620a0 0xc4228620c0] [0xc422862088 0xc4228620b8] [0x8fd520 0x8fd520] 0xc422ba8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:35:21.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:35:21.756: INFO: rc: 1
Feb 19 13:35:21.756: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4225530b0 exit status 1 <nil> <nil> true [0xc42090c280 0xc42090c2a0 0xc42090c2b8] [0xc42090c280 0xc42090c2a0 0xc42090c2b8] [0xc42090c298 0xc42090c2b0] [0x8fd520 0x8fd520] 0xc421fd23c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:35:31.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:35:31.893: INFO: rc: 1
Feb 19 13:35:31.893: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2ccc0 exit status 1 <nil> <nil> true [0xc4228620c8 0xc4228620e0 0xc4228620f8] [0xc4228620c8 0xc4228620e0 0xc4228620f8] [0xc4228620d8 0xc4228620f0] [0x8fd520 0x8fd520] 0xc422ba84e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:35:41.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:35:42.029: INFO: rc: 1
Feb 19 13:35:42.030: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422553500 exit status 1 <nil> <nil> true [0xc42090c2c0 0xc42090c2d8 0xc42090c318] [0xc42090c2c0 0xc42090c2d8 0xc42090c318] [0xc42090c2d0 0xc42090c2f0] [0x8fd520 0x8fd520] 0xc421fd24e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:35:52.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:35:52.162: INFO: rc: 1
Feb 19 13:35:52.163: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422be6e10 exit status 1 <nil> <nil> true [0xc4200eb460 0xc4200eb4d8 0xc4200eb518] [0xc4200eb460 0xc4200eb4d8 0xc4200eb518] [0xc4200eb4d0 0xc4200eb500] [0x8fd520 0x8fd520] 0xc421eca2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:36:02.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:36:02.317: INFO: rc: 1
Feb 19 13:36:02.317: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422d2cd20 exit status 1 <nil> <nil> true [0xc42090c328 0xc42090c348 0xc42090c370] [0xc42090c328 0xc42090c348 0xc42090c370] [0xc42090c340 0xc42090c360] [0x8fd520 0x8fd520] 0xc422ba85a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:36:12.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:36:12.457: INFO: rc: 1
Feb 19 13:36:12.457: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422be6420 exit status 1 <nil> <nil> true [0xc4200ea1e8 0xc4200ea800 0xc4200eab60] [0xc4200ea1e8 0xc4200ea800 0xc4200eab60] [0xc4200ea5e8 0xc4200eaae0] [0x8fd520 0x8fd520] 0xc421eca060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:36:22.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:36:22.618: INFO: rc: 1
Feb 19 13:36:22.618: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422be67e0 exit status 1 <nil> <nil> true [0xc4200eac88 0xc4200eb028 0xc4200eb198] [0xc4200eac88 0xc4200eb028 0xc4200eb198] [0xc4200eaff8 0xc4200eb120] [0x8fd520 0x8fd520] 0xc421eca180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:36:32.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:36:32.755: INFO: rc: 1
Feb 19 13:36:32.755: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552390 exit status 1 <nil> <nil> true [0xc42090c028 0xc42090c0a8 0xc42090c140] [0xc42090c028 0xc42090c0a8 0xc42090c140] [0xc42090c098 0xc42090c0f8] [0x8fd520 0x8fd520] 0xc421fd2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:36:42.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:36:42.909: INFO: rc: 1
Feb 19 13:36:42.909: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422552840 exit status 1 <nil> <nil> true [0xc42090c1b0 0xc42090c1d0 0xc42090c218] [0xc42090c1b0 0xc42090c1d0 0xc42090c218] [0xc42090c1c8 0xc42090c210] [0x8fd520 0x8fd520] 0xc421fd2180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 19 13:36:52.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-wxn7m ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:36:53.038: INFO: rc: 1
Feb 19 13:36:53.039: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 19 13:36:53.039: INFO: Scaling statefulset ss to 0
Feb 19 13:36:53.055: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 13:36:53.060: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wxn7m
Feb 19 13:36:53.064: INFO: Scaling statefulset ss to 0
Feb 19 13:36:53.077: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:36:53.081: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:36:53.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wxn7m" for this suite.
Feb 19 13:36:59.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:36:59.243: INFO: namespace: e2e-tests-statefulset-wxn7m, resource: bindings, ignored listing per whitelist
Feb 19 13:36:59.299: INFO: namespace e2e-tests-statefulset-wxn7m deletion completed in 6.182778491s

• [SLOW TEST:423.661 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:36:59.300: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rb88m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 19 13:36:59.536: INFO: Waiting up to 5m0s for pod "pod-6ea82834-344b-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-rb88m" to be "success or failure"
Feb 19 13:36:59.540: INFO: Pod "pod-6ea82834-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194808ms
Feb 19 13:37:01.546: INFO: Pod "pod-6ea82834-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010366205s
Feb 19 13:37:03.552: INFO: Pod "pod-6ea82834-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016052361s
Feb 19 13:37:05.559: INFO: Pod "pod-6ea82834-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022929518s
Feb 19 13:37:07.565: INFO: Pod "pod-6ea82834-344b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.029687572s
STEP: Saw pod success
Feb 19 13:37:07.566: INFO: Pod "pod-6ea82834-344b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:37:07.570: INFO: Trying to get logs from node kube-node-20-104 pod pod-6ea82834-344b-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:37:07.604: INFO: Waiting for pod pod-6ea82834-344b-11e9-af36-92091ca56148 to disappear
Feb 19 13:37:07.608: INFO: Pod pod-6ea82834-344b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:37:07.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rb88m" for this suite.
Feb 19 13:37:13.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:37:13.764: INFO: namespace: e2e-tests-emptydir-rb88m, resource: bindings, ignored listing per whitelist
Feb 19 13:37:13.795: INFO: namespace e2e-tests-emptydir-rb88m deletion completed in 6.181316331s

• [SLOW TEST:14.496 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:37:13.796: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bv8hf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:38:14.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bv8hf" for this suite.
Feb 19 13:38:36.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:38:36.098: INFO: namespace: e2e-tests-container-probe-bv8hf, resource: bindings, ignored listing per whitelist
Feb 19 13:38:36.210: INFO: namespace e2e-tests-container-probe-bv8hf deletion completed in 22.161581165s

• [SLOW TEST:82.414 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:38:36.210: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8lqfh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a86b8137-344b-11e9-af36-92091ca56148
STEP: Creating a pod to test consume configMaps
Feb 19 13:38:36.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148" in namespace "e2e-tests-configmap-8lqfh" to be "success or failure"
Feb 19 13:38:36.455: INFO: Pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.755301ms
Feb 19 13:38:38.461: INFO: Pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011440506s
Feb 19 13:38:40.469: INFO: Pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018528342s
Feb 19 13:38:42.475: INFO: Pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024749704s
Feb 19 13:38:44.481: INFO: Pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.031132571s
STEP: Saw pod success
Feb 19 13:38:44.481: INFO: Pod "pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:38:44.486: INFO: Trying to get logs from node kube-node-20-104 pod pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 19 13:38:44.520: INFO: Waiting for pod pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148 to disappear
Feb 19 13:38:44.525: INFO: Pod pod-configmaps-a86c7a9c-344b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:38:44.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8lqfh" for this suite.
Feb 19 13:38:50.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:38:50.579: INFO: namespace: e2e-tests-configmap-8lqfh, resource: bindings, ignored listing per whitelist
Feb 19 13:38:50.724: INFO: namespace e2e-tests-configmap-8lqfh deletion completed in 6.192334232s

• [SLOW TEST:14.514 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:38:50.725: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kptx8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 13:38:50.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-kptx8" to be "success or failure"
Feb 19 13:38:50.973: INFO: Pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.875884ms
Feb 19 13:38:52.979: INFO: Pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014670046s
Feb 19 13:38:54.985: INFO: Pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020900222s
Feb 19 13:38:56.992: INFO: Pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027782348s
Feb 19 13:38:58.999: INFO: Pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.034836172s
STEP: Saw pod success
Feb 19 13:38:58.999: INFO: Pod "downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:38:59.004: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 13:38:59.038: INFO: Waiting for pod downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148 to disappear
Feb 19 13:38:59.046: INFO: Pod downwardapi-volume-b112e1a9-344b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:38:59.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kptx8" for this suite.
Feb 19 13:39:05.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:39:05.210: INFO: namespace: e2e-tests-projected-kptx8, resource: bindings, ignored listing per whitelist
Feb 19 13:39:05.254: INFO: namespace e2e-tests-projected-kptx8 deletion completed in 6.199961765s

• [SLOW TEST:14.530 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:39:05.255: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-sdhgb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 19 13:39:05.514: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-sdhgb,SelfLink:/api/v1/namespaces/e2e-tests-watch-sdhgb/configmaps/e2e-watch-test-resource-version,UID:b9bafbc1-344b-11e9-b551-525400c68782,ResourceVersion:956941,Generation:0,CreationTimestamp:2019-02-19 13:39:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 13:39:05.514: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-sdhgb,SelfLink:/api/v1/namespaces/e2e-tests-watch-sdhgb/configmaps/e2e-watch-test-resource-version,UID:b9bafbc1-344b-11e9-b551-525400c68782,ResourceVersion:956942,Generation:0,CreationTimestamp:2019-02-19 13:39:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:39:05.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-sdhgb" for this suite.
Feb 19 13:39:11.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:39:11.673: INFO: namespace: e2e-tests-watch-sdhgb, resource: bindings, ignored listing per whitelist
Feb 19 13:39:11.707: INFO: namespace e2e-tests-watch-sdhgb deletion completed in 6.186415336s

• [SLOW TEST:6.452 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:39:11.707: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-jh69c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 19 13:39:11.957: INFO: Waiting up to 5m0s for pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148" in namespace "e2e-tests-containers-jh69c" to be "success or failure"
Feb 19 13:39:11.963: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.413775ms
Feb 19 13:39:13.971: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014552765s
Feb 19 13:39:15.979: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021859265s
Feb 19 13:39:17.985: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02797295s
Feb 19 13:39:19.990: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.033808969s
Feb 19 13:39:21.997: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.040218683s
STEP: Saw pod success
Feb 19 13:39:21.997: INFO: Pod "client-containers-bd9570e6-344b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:39:22.001: INFO: Trying to get logs from node kube-node-20-104 pod client-containers-bd9570e6-344b-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:39:22.030: INFO: Waiting for pod client-containers-bd9570e6-344b-11e9-af36-92091ca56148 to disappear
Feb 19 13:39:22.034: INFO: Pod client-containers-bd9570e6-344b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:39:22.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jh69c" for this suite.
Feb 19 13:39:28.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:39:28.145: INFO: namespace: e2e-tests-containers-jh69c, resource: bindings, ignored listing per whitelist
Feb 19 13:39:28.209: INFO: namespace e2e-tests-containers-jh69c deletion completed in 6.168576887s

• [SLOW TEST:16.502 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:39:28.210: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x6qrc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c769e55f-344b-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 13:39:28.449: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-x6qrc" to be "success or failure"
Feb 19 13:39:28.454: INFO: Pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.822741ms
Feb 19 13:39:30.461: INFO: Pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011655543s
Feb 19 13:39:32.468: INFO: Pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01882747s
Feb 19 13:39:34.492: INFO: Pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042378282s
Feb 19 13:39:36.498: INFO: Pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.048774821s
STEP: Saw pod success
Feb 19 13:39:36.498: INFO: Pod "pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:39:36.503: INFO: Trying to get logs from node kube-node-20-105 pod pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 19 13:39:36.530: INFO: Waiting for pod pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148 to disappear
Feb 19 13:39:36.534: INFO: Pod pod-projected-secrets-c76af99d-344b-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:39:36.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x6qrc" for this suite.
Feb 19 13:39:42.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:39:42.573: INFO: namespace: e2e-tests-projected-x6qrc, resource: bindings, ignored listing per whitelist
Feb 19 13:39:42.725: INFO: namespace e2e-tests-projected-x6qrc deletion completed in 6.186081752s

• [SLOW TEST:14.515 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:39:42.726: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-78k2w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 13:39:42.986: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 19 13:39:43.001: INFO: Number of nodes with available pods: 0
Feb 19 13:39:43.001: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 19 13:39:43.041: INFO: Number of nodes with available pods: 0
Feb 19 13:39:43.041: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:44.048: INFO: Number of nodes with available pods: 0
Feb 19 13:39:44.048: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:45.048: INFO: Number of nodes with available pods: 0
Feb 19 13:39:45.049: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:46.051: INFO: Number of nodes with available pods: 0
Feb 19 13:39:46.051: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:47.048: INFO: Number of nodes with available pods: 0
Feb 19 13:39:47.048: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:48.047: INFO: Number of nodes with available pods: 0
Feb 19 13:39:48.047: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:49.046: INFO: Number of nodes with available pods: 0
Feb 19 13:39:49.046: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:50.047: INFO: Number of nodes with available pods: 1
Feb 19 13:39:50.047: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 19 13:39:50.070: INFO: Number of nodes with available pods: 1
Feb 19 13:39:50.070: INFO: Number of running nodes: 0, number of available pods: 1
Feb 19 13:39:51.077: INFO: Number of nodes with available pods: 0
Feb 19 13:39:51.077: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 19 13:39:51.098: INFO: Number of nodes with available pods: 0
Feb 19 13:39:51.098: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:52.105: INFO: Number of nodes with available pods: 0
Feb 19 13:39:52.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:53.105: INFO: Number of nodes with available pods: 0
Feb 19 13:39:53.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:54.105: INFO: Number of nodes with available pods: 0
Feb 19 13:39:54.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:55.106: INFO: Number of nodes with available pods: 0
Feb 19 13:39:55.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:56.105: INFO: Number of nodes with available pods: 0
Feb 19 13:39:56.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:57.105: INFO: Number of nodes with available pods: 0
Feb 19 13:39:57.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:58.105: INFO: Number of nodes with available pods: 0
Feb 19 13:39:58.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:39:59.104: INFO: Number of nodes with available pods: 0
Feb 19 13:39:59.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:00.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:00.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:01.111: INFO: Number of nodes with available pods: 0
Feb 19 13:40:01.111: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:02.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:02.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:03.104: INFO: Number of nodes with available pods: 0
Feb 19 13:40:03.104: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:04.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:04.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:05.110: INFO: Number of nodes with available pods: 0
Feb 19 13:40:05.110: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:06.104: INFO: Number of nodes with available pods: 0
Feb 19 13:40:06.104: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:07.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:07.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:08.103: INFO: Number of nodes with available pods: 0
Feb 19 13:40:08.103: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:09.108: INFO: Number of nodes with available pods: 0
Feb 19 13:40:09.108: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:10.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:10.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:11.107: INFO: Number of nodes with available pods: 0
Feb 19 13:40:11.107: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:12.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:12.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:13.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:13.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:14.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:14.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:15.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:15.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:16.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:16.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:17.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:17.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:18.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:18.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:19.104: INFO: Number of nodes with available pods: 0
Feb 19 13:40:19.104: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:20.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:20.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:21.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:21.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:22.104: INFO: Number of nodes with available pods: 0
Feb 19 13:40:22.104: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:23.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:23.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:24.107: INFO: Number of nodes with available pods: 0
Feb 19 13:40:24.107: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:25.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:25.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:26.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:26.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:27.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:27.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:28.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:28.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:29.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:29.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:30.104: INFO: Number of nodes with available pods: 0
Feb 19 13:40:30.104: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:31.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:31.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:32.106: INFO: Number of nodes with available pods: 0
Feb 19 13:40:32.106: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:33.105: INFO: Number of nodes with available pods: 0
Feb 19 13:40:33.105: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:34.104: INFO: Number of nodes with available pods: 0
Feb 19 13:40:34.104: INFO: Node kube-master-20-101 is running more than one daemon pod
Feb 19 13:40:35.106: INFO: Number of nodes with available pods: 1
Feb 19 13:40:35.106: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-78k2w, will wait for the garbage collector to delete the pods
Feb 19 13:40:35.186: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.515142ms
Feb 19 13:40:35.287: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.258789ms
Feb 19 13:41:19.194: INFO: Number of nodes with available pods: 0
Feb 19 13:41:19.194: INFO: Number of running nodes: 0, number of available pods: 0
Feb 19 13:41:19.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-78k2w/daemonsets","resourceVersion":"957282"},"items":null}

Feb 19 13:41:19.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-78k2w/pods","resourceVersion":"957282"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:41:19.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-78k2w" for this suite.
Feb 19 13:41:25.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:41:25.373: INFO: namespace: e2e-tests-daemonsets-78k2w, resource: bindings, ignored listing per whitelist
Feb 19 13:41:25.423: INFO: namespace e2e-tests-daemonsets-78k2w deletion completed in 6.174937357s

• [SLOW TEST:102.696 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:41:25.424: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-9qkmk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-hfhn
STEP: Creating a pod to test atomic-volume-subpath
Feb 19 13:41:25.679: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hfhn" in namespace "e2e-tests-subpath-9qkmk" to be "success or failure"
Feb 19 13:41:25.690: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.458234ms
Feb 19 13:41:27.698: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018454628s
Feb 19 13:41:29.705: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025344234s
Feb 19 13:41:31.711: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031777094s
Feb 19 13:41:33.718: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.038552039s
Feb 19 13:41:35.724: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044319967s
Feb 19 13:41:37.730: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.050040939s
Feb 19 13:41:39.736: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.056488322s
Feb 19 13:41:41.742: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 16.062993922s
Feb 19 13:41:43.753: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 18.073662462s
Feb 19 13:41:45.759: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 20.079491959s
Feb 19 13:41:47.766: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 22.086658733s
Feb 19 13:41:49.773: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 24.093061109s
Feb 19 13:41:51.780: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 26.100082227s
Feb 19 13:41:53.787: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 28.107530571s
Feb 19 13:41:55.792: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 30.112553681s
Feb 19 13:41:57.799: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 32.119361151s
Feb 19 13:41:59.808: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 34.128495346s
Feb 19 13:42:01.814: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 36.134516014s
Feb 19 13:42:03.821: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 38.141635422s
Feb 19 13:42:05.829: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 40.149777731s
Feb 19 13:42:07.836: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 42.156510636s
Feb 19 13:42:09.842: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 44.162646715s
Feb 19 13:42:11.851: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 46.171645592s
Feb 19 13:42:13.857: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Running", Reason="", readiness=false. Elapsed: 48.177975717s
Feb 19 13:42:15.864: INFO: Pod "pod-subpath-test-configmap-hfhn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 50.184665653s
STEP: Saw pod success
Feb 19 13:42:15.864: INFO: Pod "pod-subpath-test-configmap-hfhn" satisfied condition "success or failure"
Feb 19 13:42:15.874: INFO: Trying to get logs from node kube-node-20-104 pod pod-subpath-test-configmap-hfhn container test-container-subpath-configmap-hfhn: <nil>
STEP: delete the pod
Feb 19 13:42:15.909: INFO: Waiting for pod pod-subpath-test-configmap-hfhn to disappear
Feb 19 13:42:15.914: INFO: Pod pod-subpath-test-configmap-hfhn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hfhn
Feb 19 13:42:15.914: INFO: Deleting pod "pod-subpath-test-configmap-hfhn" in namespace "e2e-tests-subpath-9qkmk"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:42:15.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9qkmk" for this suite.
Feb 19 13:42:21.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:42:22.025: INFO: namespace: e2e-tests-subpath-9qkmk, resource: bindings, ignored listing per whitelist
Feb 19 13:42:22.100: INFO: namespace e2e-tests-subpath-9qkmk deletion completed in 6.17659249s

• [SLOW TEST:56.675 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:42:22.100: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-6swf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:42:22.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6swf7" for this suite.
Feb 19 13:42:44.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:42:44.459: INFO: namespace: e2e-tests-pods-6swf7, resource: bindings, ignored listing per whitelist
Feb 19 13:42:44.530: INFO: namespace e2e-tests-pods-6swf7 deletion completed in 22.178821857s

• [SLOW TEST:22.430 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:42:44.531: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fmj6g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 19 13:43:19.308: INFO: Successfully updated pod "pod-update-activedeadlineseconds-3c6e6bc9-344c-11e9-af36-92091ca56148"
Feb 19 13:43:19.308: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-3c6e6bc9-344c-11e9-af36-92091ca56148" in namespace "e2e-tests-pods-fmj6g" to be "terminated due to deadline exceeded"
Feb 19 13:43:19.313: INFO: Pod "pod-update-activedeadlineseconds-3c6e6bc9-344c-11e9-af36-92091ca56148": Phase="Running", Reason="", readiness=true. Elapsed: 4.94511ms
Feb 19 13:43:21.319: INFO: Pod "pod-update-activedeadlineseconds-3c6e6bc9-344c-11e9-af36-92091ca56148": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.010910683s
Feb 19 13:43:21.319: INFO: Pod "pod-update-activedeadlineseconds-3c6e6bc9-344c-11e9-af36-92091ca56148" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:43:21.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fmj6g" for this suite.
Feb 19 13:43:27.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:43:27.364: INFO: namespace: e2e-tests-pods-fmj6g, resource: bindings, ignored listing per whitelist
Feb 19 13:43:27.506: INFO: namespace e2e-tests-pods-fmj6g deletion completed in 6.180652506s

• [SLOW TEST:42.976 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:43:27.507: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gkwhp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 19 13:43:27.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 --namespace=e2e-tests-kubectl-gkwhp run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 19 13:43:44.736: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 19 13:43:44.736: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:43:46.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gkwhp" for this suite.
Feb 19 13:43:52.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:43:52.870: INFO: namespace: e2e-tests-kubectl-gkwhp, resource: bindings, ignored listing per whitelist
Feb 19 13:43:52.926: INFO: namespace e2e-tests-kubectl-gkwhp deletion completed in 6.172455851s

• [SLOW TEST:25.418 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:43:52.926: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lm8sd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 19 13:43:53.143: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 19 13:43:53.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:43:53.890: INFO: stderr: ""
Feb 19 13:43:53.890: INFO: stdout: "service/redis-slave created\n"
Feb 19 13:43:53.890: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 19 13:43:53.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:43:54.126: INFO: stderr: ""
Feb 19 13:43:54.126: INFO: stdout: "service/redis-master created\n"
Feb 19 13:43:54.126: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 19 13:43:54.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:43:54.388: INFO: stderr: ""
Feb 19 13:43:54.388: INFO: stdout: "service/frontend created\n"
Feb 19 13:43:54.389: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 19 13:43:54.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:43:54.639: INFO: stderr: ""
Feb 19 13:43:54.639: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 19 13:43:54.640: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 19 13:43:54.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:43:54.885: INFO: stderr: ""
Feb 19 13:43:54.885: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 19 13:43:54.885: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 19 13:43:54.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 create -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:43:55.133: INFO: stderr: ""
Feb 19 13:43:55.134: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 19 13:43:55.134: INFO: Waiting for all frontend pods to be Running.
Feb 19 13:44:05.185: INFO: Waiting for frontend to serve content.
Feb 19 13:44:05.219: INFO: Trying to add a new entry to the guestbook.
Feb 19 13:44:05.239: INFO: Verifying that added entry can be retrieved.
Feb 19 13:44:05.261: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 13:44:10.285: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 19 13:44:15.313: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 19 13:44:20.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:44:20.518: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:44:20.518: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 13:44:20.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:44:20.686: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:44:20.686: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 13:44:20.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:44:20.874: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:44:20.874: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 13:44:20.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:44:21.024: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:44:21.024: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 13:44:21.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:44:21.178: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:44:21.178: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 19 13:44:21.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lm8sd'
Feb 19 13:44:21.363: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 19 13:44:21.364: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:44:21.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lm8sd" for this suite.
Feb 19 13:45:01.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:45:01.554: INFO: namespace: e2e-tests-kubectl-lm8sd, resource: bindings, ignored listing per whitelist
Feb 19 13:45:01.575: INFO: namespace e2e-tests-kubectl-lm8sd deletion completed in 40.200002677s

• [SLOW TEST:68.650 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:45:01.576: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fqjx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 13:45:01.824: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148" in namespace "e2e-tests-downward-api-fqjx7" to be "success or failure"
Feb 19 13:45:01.832: INFO: Pod "downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 7.732585ms
Feb 19 13:45:03.838: INFO: Pod "downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014094879s
Feb 19 13:45:05.846: INFO: Pod "downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021588417s
Feb 19 13:45:07.855: INFO: Pod "downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031202259s
STEP: Saw pod success
Feb 19 13:45:07.856: INFO: Pod "downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:45:07.861: INFO: Trying to get logs from node kube-node-20-105 pod downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 13:45:07.894: INFO: Waiting for pod downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148 to disappear
Feb 19 13:45:07.901: INFO: Pod downwardapi-volume-8e1f8791-344c-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:45:07.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fqjx7" for this suite.
Feb 19 13:45:13.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:45:13.950: INFO: namespace: e2e-tests-downward-api-fqjx7, resource: bindings, ignored listing per whitelist
Feb 19 13:45:14.088: INFO: namespace e2e-tests-downward-api-fqjx7 deletion completed in 6.180109352s

• [SLOW TEST:12.512 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:45:14.088: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-s6b74
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 19 13:45:14.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 api-versions'
Feb 19 13:45:14.445: INFO: stderr: ""
Feb 19 13:45:14.445: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nloadbalance.caicloud.io/v1alpha2\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nresource.caicloud.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:45:14.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s6b74" for this suite.
Feb 19 13:45:20.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:45:20.633: INFO: namespace: e2e-tests-kubectl-s6b74, resource: bindings, ignored listing per whitelist
Feb 19 13:45:20.645: INFO: namespace e2e-tests-kubectl-s6b74 deletion completed in 6.193168711s

• [SLOW TEST:6.557 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:45:20.646: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p845x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 19 13:45:20.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148" in namespace "e2e-tests-projected-p845x" to be "success or failure"
Feb 19 13:45:20.882: INFO: Pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 3.94324ms
Feb 19 13:45:22.889: INFO: Pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010538835s
Feb 19 13:45:24.895: INFO: Pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017050896s
Feb 19 13:45:26.901: INFO: Pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022469521s
Feb 19 13:45:28.906: INFO: Pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.02806027s
STEP: Saw pod success
Feb 19 13:45:28.906: INFO: Pod "downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:45:28.910: INFO: Trying to get logs from node kube-node-20-104 pod downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148 container client-container: <nil>
STEP: delete the pod
Feb 19 13:45:28.942: INFO: Waiting for pod downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148 to disappear
Feb 19 13:45:28.947: INFO: Pod downwardapi-volume-997b4b3b-344c-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:45:28.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p845x" for this suite.
Feb 19 13:45:34.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:45:35.073: INFO: namespace: e2e-tests-projected-p845x, resource: bindings, ignored listing per whitelist
Feb 19 13:45:35.131: INFO: namespace e2e-tests-projected-p845x deletion completed in 6.178590993s

• [SLOW TEST:14.486 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:45:35.132: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7442f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 19 13:45:35.392: INFO: Waiting up to 5m0s for pod "pod-a221e6e5-344c-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-7442f" to be "success or failure"
Feb 19 13:45:35.398: INFO: Pod "pod-a221e6e5-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.734089ms
Feb 19 13:45:37.404: INFO: Pod "pod-a221e6e5-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012003595s
Feb 19 13:45:39.410: INFO: Pod "pod-a221e6e5-344c-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018548954s
Feb 19 13:45:41.417: INFO: Pod "pod-a221e6e5-344c-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024841069s
STEP: Saw pod success
Feb 19 13:45:41.417: INFO: Pod "pod-a221e6e5-344c-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:45:41.421: INFO: Trying to get logs from node kube-node-20-104 pod pod-a221e6e5-344c-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:45:41.453: INFO: Waiting for pod pod-a221e6e5-344c-11e9-af36-92091ca56148 to disappear
Feb 19 13:45:41.458: INFO: Pod pod-a221e6e5-344c-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:45:41.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7442f" for this suite.
Feb 19 13:45:47.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:45:47.607: INFO: namespace: e2e-tests-emptydir-7442f, resource: bindings, ignored listing per whitelist
Feb 19 13:45:47.625: INFO: namespace e2e-tests-emptydir-7442f deletion completed in 6.161962564s

• [SLOW TEST:12.493 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:45:47.625: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-w6mmj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0219 13:45:48.915631      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 13:45:48.915: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:45:48.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w6mmj" for this suite.
Feb 19 13:45:54.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:45:55.062: INFO: namespace: e2e-tests-gc-w6mmj, resource: bindings, ignored listing per whitelist
Feb 19 13:45:55.092: INFO: namespace e2e-tests-gc-w6mmj deletion completed in 6.168175102s

• [SLOW TEST:7.467 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:45:55.093: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-grmqk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-grmqk
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 19 13:45:55.327: INFO: Found 0 stateful pods, waiting for 3
Feb 19 13:46:05.334: INFO: Found 1 stateful pods, waiting for 3
Feb 19 13:46:15.335: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:46:25.334: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:46:35.334: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:46:35.335: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:46:35.335: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:46:45.334: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:46:45.334: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:46:45.334: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:46:55.335: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:46:55.335: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:46:55.335: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:47:05.335: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:47:05.335: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:47:05.335: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:47:05.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-grmqk ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:47:05.657: INFO: stderr: ""
Feb 19 13:47:05.657: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:47:05.657: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 19 13:47:15.702: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 19 13:47:25.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-grmqk ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:47:26.002: INFO: stderr: ""
Feb 19 13:47:26.002: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:47:26.002: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:47:36.037: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:47:36.037: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:47:36.037: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:47:36.037: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:47:46.065: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:47:46.066: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:47:46.066: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:47:56.049: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:47:56.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:47:56.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:06.049: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:48:06.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:06.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:16.049: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:48:16.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:16.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:26.056: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:48:26.056: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:26.056: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:36.049: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:48:36.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:46.049: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:48:46.049: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 13:48:56.048: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:49:06.050: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:49:16.050: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 19 13:49:26.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-grmqk ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:49:26.369: INFO: stderr: ""
Feb 19 13:49:26.369: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:49:26.369: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:49:36.412: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 19 13:49:46.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-grmqk ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:49:46.721: INFO: stderr: ""
Feb 19 13:49:46.721: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:49:46.721: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:49:56.755: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:49:56.755: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:49:56.755: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:06.766: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:50:06.766: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:06.766: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:16.766: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:50:16.767: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:16.767: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:26.767: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:50:26.767: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:36.768: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:50:36.768: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:46.767: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:50:46.768: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:50:56.766: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:50:56.766: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:51:06.766: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:51:06.766: INFO: Waiting for Pod e2e-tests-statefulset-grmqk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 19 13:51:16.768: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
Feb 19 13:51:26.767: INFO: Waiting for StatefulSet e2e-tests-statefulset-grmqk/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 13:51:36.766: INFO: Deleting all statefulset in ns e2e-tests-statefulset-grmqk
Feb 19 13:51:36.770: INFO: Scaling statefulset ss2 to 0
Feb 19 13:51:56.792: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:51:56.797: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:51:56.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-grmqk" for this suite.
Feb 19 13:52:02.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:52:02.884: INFO: namespace: e2e-tests-statefulset-grmqk, resource: bindings, ignored listing per whitelist
Feb 19 13:52:03.008: INFO: namespace e2e-tests-statefulset-grmqk deletion completed in 6.170568619s

• [SLOW TEST:367.916 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:52:03.009: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2cqbj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 13:52:03.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-2cqbj'
Feb 19 13:52:03.396: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 13:52:03.396: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 19 13:52:03.410: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-jnt4c]
Feb 19 13:52:03.410: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-jnt4c" in namespace "e2e-tests-kubectl-2cqbj" to be "running and ready"
Feb 19 13:52:03.422: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.728439ms
Feb 19 13:52:05.429: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0188955s
Feb 19 13:52:07.435: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024216953s
Feb 19 13:52:09.440: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029153238s
Feb 19 13:52:11.445: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.034272091s
Feb 19 13:52:13.452: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041674553s
Feb 19 13:52:15.458: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.047440943s
Feb 19 13:52:17.463: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052657258s
Feb 19 13:52:19.471: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.060175124s
Feb 19 13:52:21.477: INFO: Pod "e2e-test-nginx-rc-jnt4c": Phase="Running", Reason="", readiness=true. Elapsed: 18.066096449s
Feb 19 13:52:21.477: INFO: Pod "e2e-test-nginx-rc-jnt4c" satisfied condition "running and ready"
Feb 19 13:52:21.477: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-jnt4c]
Feb 19 13:52:21.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2cqbj'
Feb 19 13:52:21.656: INFO: stderr: ""
Feb 19 13:52:21.656: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb 19 13:52:21.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2cqbj'
Feb 19 13:52:21.808: INFO: stderr: ""
Feb 19 13:52:21.808: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:52:21.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2cqbj" for this suite.
Feb 19 13:52:27.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:52:27.943: INFO: namespace: e2e-tests-kubectl-2cqbj, resource: bindings, ignored listing per whitelist
Feb 19 13:52:27.987: INFO: namespace e2e-tests-kubectl-2cqbj deletion completed in 6.172026563s

• [SLOW TEST:24.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:52:27.987: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pbrpf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 19 13:52:28.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pbrpf'
Feb 19 13:52:28.358: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 19 13:52:28.358: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb 19 13:52:28.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-pbrpf'
Feb 19 13:52:28.534: INFO: stderr: ""
Feb 19 13:52:28.534: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:52:28.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pbrpf" for this suite.
Feb 19 13:52:34.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:52:34.657: INFO: namespace: e2e-tests-kubectl-pbrpf, resource: bindings, ignored listing per whitelist
Feb 19 13:52:34.723: INFO: namespace e2e-tests-kubectl-pbrpf deletion completed in 6.181932689s

• [SLOW TEST:6.736 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:52:34.724: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qh7xs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qh7xs
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qh7xs
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qh7xs
Feb 19 13:52:34.959: INFO: Found 0 stateful pods, waiting for 1
Feb 19 13:52:44.967: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:52:54.967: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 19 13:52:54.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:52:55.255: INFO: stderr: ""
Feb 19 13:52:55.255: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:52:55.255: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:52:55.261: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 19 13:53:05.267: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:53:05.268: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:53:05.290: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999629s
Feb 19 13:53:06.297: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99162828s
Feb 19 13:53:07.304: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984985373s
Feb 19 13:53:08.311: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.977727707s
Feb 19 13:53:09.317: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.970969468s
Feb 19 13:53:10.322: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.964753038s
Feb 19 13:53:11.331: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.959498406s
Feb 19 13:53:12.337: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.950863684s
Feb 19 13:53:13.344: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.944343987s
Feb 19 13:53:14.349: INFO: Verifying statefulset ss doesn't scale past 1 for another 938.205703ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qh7xs
Feb 19 13:53:15.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:53:15.638: INFO: stderr: ""
Feb 19 13:53:15.638: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:53:15.638: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:53:15.643: INFO: Found 1 stateful pods, waiting for 3
Feb 19 13:53:25.650: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:53:35.651: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:53:35.651: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:53:35.651: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:53:45.650: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:53:45.650: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:53:45.650: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:53:55.650: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:53:55.651: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:53:55.651: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 19 13:53:55.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:53:55.961: INFO: stderr: ""
Feb 19 13:53:55.961: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:53:55.961: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:53:55.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:53:56.251: INFO: stderr: ""
Feb 19 13:53:56.251: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:53:56.251: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:53:56.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 19 13:53:56.486: INFO: stderr: ""
Feb 19 13:53:56.486: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 19 13:53:56.486: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 19 13:53:56.486: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:53:56.491: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 19 13:54:06.504: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:54:06.504: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:54:06.504: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 19 13:54:06.521: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999299s
Feb 19 13:54:07.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994445063s
Feb 19 13:54:08.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98724697s
Feb 19 13:54:09.543: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.979699673s
Feb 19 13:54:10.550: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972416681s
Feb 19 13:54:11.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965557517s
Feb 19 13:54:12.571: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.95097674s
Feb 19 13:54:13.579: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.944679517s
Feb 19 13:54:14.586: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.936825062s
Feb 19 13:54:15.593: INFO: Verifying statefulset ss doesn't scale past 3 for another 929.589909ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qh7xs
Feb 19 13:54:16.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:54:16.902: INFO: stderr: ""
Feb 19 13:54:16.902: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:54:16.902: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:54:16.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:54:17.145: INFO: stderr: ""
Feb 19 13:54:17.145: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:54:17.145: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:54:17.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-879726862 exec --namespace=e2e-tests-statefulset-qh7xs ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 19 13:54:17.391: INFO: stderr: ""
Feb 19 13:54:17.391: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 19 13:54:17.391: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 19 13:54:17.391: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 13:54:47.418: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qh7xs
Feb 19 13:54:47.422: INFO: Scaling statefulset ss to 0
Feb 19 13:54:47.435: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 13:54:47.438: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:54:47.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qh7xs" for this suite.
Feb 19 13:54:53.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:54:53.552: INFO: namespace: e2e-tests-statefulset-qh7xs, resource: bindings, ignored listing per whitelist
Feb 19 13:54:53.655: INFO: namespace e2e-tests-statefulset-qh7xs deletion completed in 6.181203401s

• [SLOW TEST:138.931 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:54:53.655: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-drf7l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 13:54:53.903: INFO: (0) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 12.958747ms)
Feb 19 13:54:53.910: INFO: (1) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 6.983161ms)
Feb 19 13:54:53.916: INFO: (2) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.785704ms)
Feb 19 13:54:53.922: INFO: (3) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.848154ms)
Feb 19 13:54:53.929: INFO: (4) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 6.918171ms)
Feb 19 13:54:53.936: INFO: (5) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 6.821203ms)
Feb 19 13:54:53.943: INFO: (6) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 7.125456ms)
Feb 19 13:54:53.948: INFO: (7) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.452533ms)
Feb 19 13:54:53.955: INFO: (8) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 6.956791ms)
Feb 19 13:54:53.961: INFO: (9) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.864798ms)
Feb 19 13:54:53.967: INFO: (10) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.91032ms)
Feb 19 13:54:53.974: INFO: (11) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 6.602381ms)
Feb 19 13:54:53.979: INFO: (12) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.55861ms)
Feb 19 13:54:53.985: INFO: (13) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.415019ms)
Feb 19 13:54:53.991: INFO: (14) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.774173ms)
Feb 19 13:54:53.996: INFO: (15) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.748965ms)
Feb 19 13:54:54.002: INFO: (16) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.711169ms)
Feb 19 13:54:54.008: INFO: (17) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.96525ms)
Feb 19 13:54:54.014: INFO: (18) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 5.450301ms)
Feb 19 13:54:54.018: INFO: (19) /api/v1/nodes/kube-master-20-101/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="apiserver/">apiserver/</a>
<a href="audit/">audi... (200; 4.692514ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:54:54.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-drf7l" for this suite.
Feb 19 13:55:00.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:55:00.073: INFO: namespace: e2e-tests-proxy-drf7l, resource: bindings, ignored listing per whitelist
Feb 19 13:55:00.205: INFO: namespace e2e-tests-proxy-drf7l deletion completed in 6.18089785s

• [SLOW TEST:6.549 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:55:00.205: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-p9pz4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p9pz4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 19 13:55:00.433: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 19 13:55:34.638: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.64.41:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p9pz4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:55:34.639: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:55:34.783: INFO: Found all expected endpoints: [netserver-0]
Feb 19 13:55:34.788: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.68.7:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p9pz4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:55:34.788: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:55:34.937: INFO: Found all expected endpoints: [netserver-1]
Feb 19 13:55:34.943: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.65.175:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p9pz4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:55:34.943: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:55:35.089: INFO: Found all expected endpoints: [netserver-2]
Feb 19 13:55:35.096: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.67.75:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p9pz4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:55:35.096: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:55:35.237: INFO: Found all expected endpoints: [netserver-3]
Feb 19 13:55:35.242: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.66.169:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p9pz4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 19 13:55:35.242: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
Feb 19 13:55:35.366: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:55:35.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p9pz4" for this suite.
Feb 19 13:55:59.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:55:59.429: INFO: namespace: e2e-tests-pod-network-test-p9pz4, resource: bindings, ignored listing per whitelist
Feb 19 13:55:59.573: INFO: namespace e2e-tests-pod-network-test-p9pz4 deletion completed in 24.199565476s

• [SLOW TEST:59.368 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:55:59.574: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-jkxnj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0219 13:56:30.358136      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 19 13:56:30.358: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:56:30.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jkxnj" for this suite.
Feb 19 13:56:36.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:56:36.410: INFO: namespace: e2e-tests-gc-jkxnj, resource: bindings, ignored listing per whitelist
Feb 19 13:56:36.523: INFO: namespace e2e-tests-gc-jkxnj deletion completed in 6.158567461s

• [SLOW TEST:36.950 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:56:36.524: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-n4lkz
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 19 13:56:36.767: INFO: Waiting up to 5m0s for pod "pod-2c5708c7-344e-11e9-af36-92091ca56148" in namespace "e2e-tests-emptydir-n4lkz" to be "success or failure"
Feb 19 13:56:36.771: INFO: Pod "pod-2c5708c7-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.574132ms
Feb 19 13:56:38.777: INFO: Pod "pod-2c5708c7-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010421993s
Feb 19 13:56:40.783: INFO: Pod "pod-2c5708c7-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016183672s
Feb 19 13:56:42.788: INFO: Pod "pod-2c5708c7-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021624255s
Feb 19 13:56:44.795: INFO: Pod "pod-2c5708c7-344e-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027990761s
STEP: Saw pod success
Feb 19 13:56:44.795: INFO: Pod "pod-2c5708c7-344e-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:56:44.799: INFO: Trying to get logs from node kube-node-20-105 pod pod-2c5708c7-344e-11e9-af36-92091ca56148 container test-container: <nil>
STEP: delete the pod
Feb 19 13:56:44.834: INFO: Waiting for pod pod-2c5708c7-344e-11e9-af36-92091ca56148 to disappear
Feb 19 13:56:44.844: INFO: Pod pod-2c5708c7-344e-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:56:44.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n4lkz" for this suite.
Feb 19 13:56:50.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:56:50.911: INFO: namespace: e2e-tests-emptydir-n4lkz, resource: bindings, ignored listing per whitelist
Feb 19 13:56:51.027: INFO: namespace e2e-tests-emptydir-n4lkz deletion completed in 6.176942943s

• [SLOW TEST:14.504 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:56:51.027: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-dm769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 19 13:57:19.283: INFO: Container started at 2019-02-19 13:56:57 +0000 UTC, pod became ready at 2019-02-19 13:57:18 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:57:19.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dm769" for this suite.
Feb 19 13:57:41.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:57:41.346: INFO: namespace: e2e-tests-container-probe-dm769, resource: bindings, ignored listing per whitelist
Feb 19 13:57:41.471: INFO: namespace e2e-tests-container-probe-dm769 deletion completed in 22.182195711s

• [SLOW TEST:50.444 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:57:41.471: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bkcs5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-530fc111-344e-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 13:57:41.734: INFO: Waiting up to 5m0s for pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-bkcs5" to be "success or failure"
Feb 19 13:57:41.738: INFO: Pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.182353ms
Feb 19 13:57:43.744: INFO: Pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009938759s
Feb 19 13:57:45.750: INFO: Pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015899201s
Feb 19 13:57:47.757: INFO: Pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023545802s
Feb 19 13:57:49.770: INFO: Pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.036333316s
STEP: Saw pod success
Feb 19 13:57:49.770: INFO: Pod "pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:57:49.775: INFO: Trying to get logs from node kube-node-20-105 pod pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148 container secret-volume-test: <nil>
STEP: delete the pod
Feb 19 13:57:49.807: INFO: Waiting for pod pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148 to disappear
Feb 19 13:57:49.811: INFO: Pod pod-secrets-5310e7a6-344e-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:57:49.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bkcs5" for this suite.
Feb 19 13:57:55.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:57:55.890: INFO: namespace: e2e-tests-secrets-bkcs5, resource: bindings, ignored listing per whitelist
Feb 19 13:57:55.991: INFO: namespace e2e-tests-secrets-bkcs5 deletion completed in 6.172854669s

• [SLOW TEST:14.519 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:57:55.991: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-zjtg4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5bb4ed57-344e-11e9-af36-92091ca56148
STEP: Creating a pod to test consume secrets
Feb 19 13:57:56.237: INFO: Waiting up to 5m0s for pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148" in namespace "e2e-tests-secrets-zjtg4" to be "success or failure"
Feb 19 13:57:56.243: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 5.097935ms
Feb 19 13:57:58.248: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010892217s
Feb 19 13:58:00.253: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015537192s
Feb 19 13:58:02.259: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021713995s
Feb 19 13:58:04.265: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027507146s
Feb 19 13:58:06.273: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 10.035697437s
Feb 19 13:58:08.280: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Pending", Reason="", readiness=false. Elapsed: 12.042138983s
Feb 19 13:58:10.286: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.048117576s
STEP: Saw pod success
Feb 19 13:58:10.286: INFO: Pod "pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148" satisfied condition "success or failure"
Feb 19 13:58:10.290: INFO: Trying to get logs from node kube-node-20-104 pod pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148 container secret-env-test: <nil>
STEP: delete the pod
Feb 19 13:58:10.330: INFO: Waiting for pod pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148 to disappear
Feb 19 13:58:10.335: INFO: Pod pod-secrets-5bb5e11b-344e-11e9-af36-92091ca56148 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 13:58:10.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zjtg4" for this suite.
Feb 19 13:58:16.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 13:58:16.389: INFO: namespace: e2e-tests-secrets-zjtg4, resource: bindings, ignored listing per whitelist
Feb 19 13:58:16.525: INFO: namespace e2e-tests-secrets-zjtg4 deletion completed in 6.184202175s

• [SLOW TEST:20.534 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 13:58:16.525: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2p86g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2p86g
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 19 13:58:16.795: INFO: Found 0 stateful pods, waiting for 3
Feb 19 13:58:26.803: INFO: Found 1 stateful pods, waiting for 3
Feb 19 13:58:36.802: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:58:46.802: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:58:56.804: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:58:56.804: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:58:56.804: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:59:06.804: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:59:06.804: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:59:06.804: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 13:59:16.803: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:59:16.803: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:59:16.803: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 19 13:59:16.839: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 19 13:59:26.883: INFO: Updating stateful set ss2
Feb 19 13:59:26.893: INFO: Waiting for Pod e2e-tests-statefulset-2p86g/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 19 13:59:37.000: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:59:47.008: INFO: Found 2 stateful pods, waiting for 3
Feb 19 13:59:57.007: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:59:57.008: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 13:59:57.008: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 14:00:07.009: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 14:00:07.009: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 14:00:07.009: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 19 14:00:17.007: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 14:00:17.007: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 14:00:17.007: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Feb 19 14:00:27.006: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 14:00:27.006: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 19 14:00:27.006: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 19 14:00:27.039: INFO: Updating stateful set ss2
Feb 19 14:00:27.046: INFO: Waiting for Pod e2e-tests-statefulset-2p86g/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 14:00:37.080: INFO: Updating stateful set ss2
Feb 19 14:00:37.100: INFO: Waiting for StatefulSet e2e-tests-statefulset-2p86g/ss2 to complete update
Feb 19 14:00:37.100: INFO: Waiting for Pod e2e-tests-statefulset-2p86g/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 14:00:47.112: INFO: Waiting for StatefulSet e2e-tests-statefulset-2p86g/ss2 to complete update
Feb 19 14:00:47.112: INFO: Waiting for Pod e2e-tests-statefulset-2p86g/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 14:00:57.113: INFO: Waiting for StatefulSet e2e-tests-statefulset-2p86g/ss2 to complete update
Feb 19 14:00:57.113: INFO: Waiting for Pod e2e-tests-statefulset-2p86g/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 19 14:01:07.112: INFO: Waiting for StatefulSet e2e-tests-statefulset-2p86g/ss2 to complete update
Feb 19 14:01:17.115: INFO: Waiting for StatefulSet e2e-tests-statefulset-2p86g/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 19 14:01:27.115: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2p86g
Feb 19 14:01:27.119: INFO: Scaling statefulset ss2 to 0
Feb 19 14:01:57.147: INFO: Waiting for statefulset status.replicas updated to 0
Feb 19 14:01:57.153: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 14:01:57.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2p86g" for this suite.
Feb 19 14:02:03.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 14:02:03.279: INFO: namespace: e2e-tests-statefulset-2p86g, resource: bindings, ignored listing per whitelist
Feb 19 14:02:03.363: INFO: namespace e2e-tests-statefulset-2p86g deletion completed in 6.177692383s

• [SLOW TEST:226.838 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 14:02:03.363: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v5mbz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 19 14:02:12.155: INFO: Successfully updated pod "annotationupdateef268085-344e-11e9-af36-92091ca56148"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 14:02:14.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v5mbz" for this suite.
Feb 19 14:02:36.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 14:02:36.245: INFO: namespace: e2e-tests-downward-api-v5mbz, resource: bindings, ignored listing per whitelist
Feb 19 14:02:36.372: INFO: namespace e2e-tests-downward-api-v5mbz deletion completed in 22.185057484s

• [SLOW TEST:33.009 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 14:02:36.373: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-8n86m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vb46r in namespace e2e-tests-proxy-8n86m
I0219 14:02:36.625163      17 runners.go:180] Created replication controller with name: proxy-service-vb46r, namespace: e2e-tests-proxy-8n86m, replica count: 1
I0219 14:02:37.675821      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 14:02:38.676038      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 14:02:39.676381      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 14:02:40.676667      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 14:02:41.677020      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 14:02:42.677289      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0219 14:02:43.677559      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 14:02:44.677957      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 14:02:45.678216      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 14:02:46.678528      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 14:02:47.678788      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0219 14:02:48.679059      17 runners.go:180] proxy-service-vb46r Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 19 14:02:48.685: INFO: setup took 12.091470413s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 19 14:02:48.694: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 8.808679ms)
Feb 19 14:02:48.694: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.939328ms)
Feb 19 14:02:48.694: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 9.26576ms)
Feb 19 14:02:48.694: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 9.074165ms)
Feb 19 14:02:48.695: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 9.062451ms)
Feb 19 14:02:48.695: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 9.583666ms)
Feb 19 14:02:48.695: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.653865ms)
Feb 19 14:02:48.698: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.858177ms)
Feb 19 14:02:48.701: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 15.010139ms)
Feb 19 14:02:48.701: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 15.368485ms)
Feb 19 14:02:48.701: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 15.073054ms)
Feb 19 14:02:48.701: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 15.60147ms)
Feb 19 14:02:48.703: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 17.822137ms)
Feb 19 14:02:48.704: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 18.780283ms)
Feb 19 14:02:48.705: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 20.083302ms)
Feb 19 14:02:48.707: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 21.620856ms)
Feb 19 14:02:48.715: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.446102ms)
Feb 19 14:02:48.716: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 8.053561ms)
Feb 19 14:02:48.716: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 8.271339ms)
Feb 19 14:02:48.716: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 8.429715ms)
Feb 19 14:02:48.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 10.247598ms)
Feb 19 14:02:48.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 9.854243ms)
Feb 19 14:02:48.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 9.991778ms)
Feb 19 14:02:48.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 10.290919ms)
Feb 19 14:02:48.718: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 10.506027ms)
Feb 19 14:02:48.719: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 10.704815ms)
Feb 19 14:02:48.719: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 11.030942ms)
Feb 19 14:02:48.719: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 11.835253ms)
Feb 19 14:02:48.720: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 11.786618ms)
Feb 19 14:02:48.720: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.237992ms)
Feb 19 14:02:48.720: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.157195ms)
Feb 19 14:02:48.720: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.410442ms)
Feb 19 14:02:48.725: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 4.792352ms)
Feb 19 14:02:48.727: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 6.187025ms)
Feb 19 14:02:48.727: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 5.955619ms)
Feb 19 14:02:48.729: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.153863ms)
Feb 19 14:02:48.731: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 9.211889ms)
Feb 19 14:02:48.731: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.969924ms)
Feb 19 14:02:48.731: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 10.103971ms)
Feb 19 14:02:48.731: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 9.457158ms)
Feb 19 14:02:48.731: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 9.410491ms)
Feb 19 14:02:48.731: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 10.056937ms)
Feb 19 14:02:48.732: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 10.873079ms)
Feb 19 14:02:48.733: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 11.912779ms)
Feb 19 14:02:48.733: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 11.777329ms)
Feb 19 14:02:48.733: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.017666ms)
Feb 19 14:02:48.733: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 11.894858ms)
Feb 19 14:02:48.733: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 13.314277ms)
Feb 19 14:02:48.741: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.672547ms)
Feb 19 14:02:48.745: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 11.048166ms)
Feb 19 14:02:48.745: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 10.739247ms)
Feb 19 14:02:48.745: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 10.512578ms)
Feb 19 14:02:48.745: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 11.547369ms)
Feb 19 14:02:48.746: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 10.59352ms)
Feb 19 14:02:48.747: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 11.082134ms)
Feb 19 14:02:48.747: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 11.180593ms)
Feb 19 14:02:48.747: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 11.389076ms)
Feb 19 14:02:48.747: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 11.504272ms)
Feb 19 14:02:48.749: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 14.266496ms)
Feb 19 14:02:48.750: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 14.8662ms)
Feb 19 14:02:48.750: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 15.603129ms)
Feb 19 14:02:48.750: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 15.392834ms)
Feb 19 14:02:48.750: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 15.600169ms)
Feb 19 14:02:48.751: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 15.44486ms)
Feb 19 14:02:48.756: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 5.019254ms)
Feb 19 14:02:48.757: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 5.751141ms)
Feb 19 14:02:48.758: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 6.929248ms)
Feb 19 14:02:48.758: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 6.673137ms)
Feb 19 14:02:48.758: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 6.534212ms)
Feb 19 14:02:48.759: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 7.00316ms)
Feb 19 14:02:48.759: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 6.575555ms)
Feb 19 14:02:48.759: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 6.661904ms)
Feb 19 14:02:48.760: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.09372ms)
Feb 19 14:02:48.760: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 7.882365ms)
Feb 19 14:02:48.762: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 10.00239ms)
Feb 19 14:02:48.763: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 10.919718ms)
Feb 19 14:02:48.764: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 11.47312ms)
Feb 19 14:02:48.764: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.100194ms)
Feb 19 14:02:48.765: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 12.814114ms)
Feb 19 14:02:48.765: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 13.322099ms)
Feb 19 14:02:48.771: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 5.72903ms)
Feb 19 14:02:48.773: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 6.678054ms)
Feb 19 14:02:48.773: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.532467ms)
Feb 19 14:02:48.773: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 7.711687ms)
Feb 19 14:02:48.774: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.693171ms)
Feb 19 14:02:48.774: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 7.996051ms)
Feb 19 14:02:48.775: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.822458ms)
Feb 19 14:02:48.776: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.730288ms)
Feb 19 14:02:48.776: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 9.452458ms)
Feb 19 14:02:48.777: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 9.984271ms)
Feb 19 14:02:48.777: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 10.231216ms)
Feb 19 14:02:48.778: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 11.32742ms)
Feb 19 14:02:48.778: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 11.469098ms)
Feb 19 14:02:48.778: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 12.326399ms)
Feb 19 14:02:48.779: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 12.576751ms)
Feb 19 14:02:48.779: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 12.490581ms)
Feb 19 14:02:48.787: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.312206ms)
Feb 19 14:02:48.787: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 6.350776ms)
Feb 19 14:02:48.788: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.278132ms)
Feb 19 14:02:48.788: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.262482ms)
Feb 19 14:02:48.789: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.139295ms)
Feb 19 14:02:48.789: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 8.064304ms)
Feb 19 14:02:48.789: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 8.436278ms)
Feb 19 14:02:48.789: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 8.941872ms)
Feb 19 14:02:48.792: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.146524ms)
Feb 19 14:02:48.792: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 11.420865ms)
Feb 19 14:02:48.792: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 11.408599ms)
Feb 19 14:02:48.792: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 12.469086ms)
Feb 19 14:02:48.792: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 12.255395ms)
Feb 19 14:02:48.793: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.867035ms)
Feb 19 14:02:48.794: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 13.618926ms)
Feb 19 14:02:48.794: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 13.369098ms)
Feb 19 14:02:48.801: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 6.820014ms)
Feb 19 14:02:48.801: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 6.382299ms)
Feb 19 14:02:48.801: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 6.969539ms)
Feb 19 14:02:48.801: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 6.876769ms)
Feb 19 14:02:48.803: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.87213ms)
Feb 19 14:02:48.803: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 7.992155ms)
Feb 19 14:02:48.804: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 9.188708ms)
Feb 19 14:02:48.804: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 9.896903ms)
Feb 19 14:02:48.805: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 10.317818ms)
Feb 19 14:02:48.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 12.035459ms)
Feb 19 14:02:48.806: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 11.922428ms)
Feb 19 14:02:48.807: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 12.150928ms)
Feb 19 14:02:48.807: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 11.91652ms)
Feb 19 14:02:48.807: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.396557ms)
Feb 19 14:02:48.807: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.508373ms)
Feb 19 14:02:48.808: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 13.334986ms)
Feb 19 14:02:48.814: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 6.046316ms)
Feb 19 14:02:48.814: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 6.269781ms)
Feb 19 14:02:48.815: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.093826ms)
Feb 19 14:02:48.818: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 9.437444ms)
Feb 19 14:02:48.819: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 10.701057ms)
Feb 19 14:02:48.819: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 10.296702ms)
Feb 19 14:02:48.819: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 10.9962ms)
Feb 19 14:02:48.820: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.012571ms)
Feb 19 14:02:48.820: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 11.211317ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 11.938024ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.260226ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 12.65573ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 12.948142ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 12.503134ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.977963ms)
Feb 19 14:02:48.821: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 12.584843ms)
Feb 19 14:02:48.829: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.16638ms)
Feb 19 14:02:48.829: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.257576ms)
Feb 19 14:02:48.830: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 8.023724ms)
Feb 19 14:02:48.830: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 8.270654ms)
Feb 19 14:02:48.833: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 11.088884ms)
Feb 19 14:02:48.834: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 11.683256ms)
Feb 19 14:02:48.834: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 12.43093ms)
Feb 19 14:02:48.834: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 11.834836ms)
Feb 19 14:02:48.834: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.594274ms)
Feb 19 14:02:48.834: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.783156ms)
Feb 19 14:02:48.836: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 13.694578ms)
Feb 19 14:02:48.836: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 13.960781ms)
Feb 19 14:02:48.836: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 13.744476ms)
Feb 19 14:02:48.836: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 13.786467ms)
Feb 19 14:02:48.836: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 14.13148ms)
Feb 19 14:02:48.843: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 20.912447ms)
Feb 19 14:02:48.851: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 7.787954ms)
Feb 19 14:02:48.851: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 8.264824ms)
Feb 19 14:02:48.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 8.674519ms)
Feb 19 14:02:48.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 8.587806ms)
Feb 19 14:02:48.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.609216ms)
Feb 19 14:02:48.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.690946ms)
Feb 19 14:02:48.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 9.482571ms)
Feb 19 14:02:48.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 10.561584ms)
Feb 19 14:02:48.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 10.492044ms)
Feb 19 14:02:48.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 10.218245ms)
Feb 19 14:02:48.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 10.906166ms)
Feb 19 14:02:48.855: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 11.76457ms)
Feb 19 14:02:48.855: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 11.669337ms)
Feb 19 14:02:48.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 13.200045ms)
Feb 19 14:02:48.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 13.175488ms)
Feb 19 14:02:48.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 13.229263ms)
Feb 19 14:02:48.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 4.885687ms)
Feb 19 14:02:48.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 5.572723ms)
Feb 19 14:02:48.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 5.378038ms)
Feb 19 14:02:48.864: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.387363ms)
Feb 19 14:02:48.864: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.450003ms)
Feb 19 14:02:48.865: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.89695ms)
Feb 19 14:02:48.865: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 8.596593ms)
Feb 19 14:02:48.865: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 8.864583ms)
Feb 19 14:02:48.866: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 9.384326ms)
Feb 19 14:02:48.867: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.888212ms)
Feb 19 14:02:48.867: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 9.93636ms)
Feb 19 14:02:48.869: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.089173ms)
Feb 19 14:02:48.870: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 13.571491ms)
Feb 19 14:02:48.872: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 14.914752ms)
Feb 19 14:02:48.872: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 15.254442ms)
Feb 19 14:02:48.872: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 15.714542ms)
Feb 19 14:02:48.879: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 6.207819ms)
Feb 19 14:02:48.880: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 7.283801ms)
Feb 19 14:02:48.880: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.600866ms)
Feb 19 14:02:48.880: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.734155ms)
Feb 19 14:02:48.883: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 10.156437ms)
Feb 19 14:02:48.883: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 10.896147ms)
Feb 19 14:02:48.883: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 10.516171ms)
Feb 19 14:02:48.884: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 11.240858ms)
Feb 19 14:02:48.885: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 12.312789ms)
Feb 19 14:02:48.885: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 12.551538ms)
Feb 19 14:02:48.885: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.496512ms)
Feb 19 14:02:48.885: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.251992ms)
Feb 19 14:02:48.885: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 12.161271ms)
Feb 19 14:02:48.887: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 13.813285ms)
Feb 19 14:02:48.888: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 14.779829ms)
Feb 19 14:02:48.888: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 15.37352ms)
Feb 19 14:02:48.895: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 6.490514ms)
Feb 19 14:02:48.895: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.075675ms)
Feb 19 14:02:48.896: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.480373ms)
Feb 19 14:02:48.897: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 8.505331ms)
Feb 19 14:02:48.897: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.701004ms)
Feb 19 14:02:48.897: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 8.744637ms)
Feb 19 14:02:48.897: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 8.887805ms)
Feb 19 14:02:48.898: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 9.281225ms)
Feb 19 14:02:48.898: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.802796ms)
Feb 19 14:02:48.899: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 10.341394ms)
Feb 19 14:02:48.899: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 10.125181ms)
Feb 19 14:02:48.900: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 10.748311ms)
Feb 19 14:02:48.901: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 12.210054ms)
Feb 19 14:02:48.901: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 12.210572ms)
Feb 19 14:02:48.901: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.598545ms)
Feb 19 14:02:48.901: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.611698ms)
Feb 19 14:02:48.908: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 6.345665ms)
Feb 19 14:02:48.908: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 6.786328ms)
Feb 19 14:02:48.909: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 7.685275ms)
Feb 19 14:02:48.910: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 7.536639ms)
Feb 19 14:02:48.911: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.326625ms)
Feb 19 14:02:48.911: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.603215ms)
Feb 19 14:02:48.911: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 8.453716ms)
Feb 19 14:02:48.911: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.527983ms)
Feb 19 14:02:48.912: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 8.973488ms)
Feb 19 14:02:48.913: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 9.718382ms)
Feb 19 14:02:48.913: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 10.661739ms)
Feb 19 14:02:48.913: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 10.973116ms)
Feb 19 14:02:48.914: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 11.834504ms)
Feb 19 14:02:48.914: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 11.666443ms)
Feb 19 14:02:48.914: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 12.369805ms)
Feb 19 14:02:48.914: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.148201ms)
Feb 19 14:02:48.921: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 5.59128ms)
Feb 19 14:02:48.922: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 6.385455ms)
Feb 19 14:02:48.922: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 7.252059ms)
Feb 19 14:02:48.922: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.264921ms)
Feb 19 14:02:48.924: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 9.254194ms)
Feb 19 14:02:48.924: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 9.601545ms)
Feb 19 14:02:48.925: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.791282ms)
Feb 19 14:02:48.925: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 9.362331ms)
Feb 19 14:02:48.926: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 10.643431ms)
Feb 19 14:02:48.928: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 12.132059ms)
Feb 19 14:02:48.928: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 11.847661ms)
Feb 19 14:02:48.928: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 12.81065ms)
Feb 19 14:02:48.929: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 12.750844ms)
Feb 19 14:02:48.929: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 13.092728ms)
Feb 19 14:02:48.929: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 14.04734ms)
Feb 19 14:02:48.930: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 13.197862ms)
Feb 19 14:02:48.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 5.161363ms)
Feb 19 14:02:48.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 4.836728ms)
Feb 19 14:02:48.936: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 6.015956ms)
Feb 19 14:02:48.937: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 6.353326ms)
Feb 19 14:02:48.937: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 6.172708ms)
Feb 19 14:02:48.938: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.243994ms)
Feb 19 14:02:48.938: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 7.35907ms)
Feb 19 14:02:48.939: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.985244ms)
Feb 19 14:02:48.939: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 8.085769ms)
Feb 19 14:02:48.939: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 8.315039ms)
Feb 19 14:02:48.940: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 9.222713ms)
Feb 19 14:02:48.940: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 10.103155ms)
Feb 19 14:02:48.941: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 11.441166ms)
Feb 19 14:02:48.941: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 11.283ms)
Feb 19 14:02:48.941: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 11.649696ms)
Feb 19 14:02:48.942: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 11.81691ms)
Feb 19 14:02:48.948: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 6.094502ms)
Feb 19 14:02:48.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 8.214253ms)
Feb 19 14:02:48.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 8.786554ms)
Feb 19 14:02:48.952: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 8.942501ms)
Feb 19 14:02:48.955: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 10.99618ms)
Feb 19 14:02:48.955: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 11.777536ms)
Feb 19 14:02:48.955: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 11.844913ms)
Feb 19 14:02:48.955: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.135582ms)
Feb 19 14:02:48.956: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 13.13711ms)
Feb 19 14:02:48.956: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 14.272042ms)
Feb 19 14:02:48.957: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 12.809764ms)
Feb 19 14:02:48.957: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 14.490848ms)
Feb 19 14:02:48.957: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 14.696271ms)
Feb 19 14:02:48.957: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 13.165824ms)
Feb 19 14:02:48.957: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 14.900152ms)
Feb 19 14:02:48.957: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 14.08684ms)
Feb 19 14:02:48.968: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 10.46597ms)
Feb 19 14:02:48.968: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 9.901815ms)
Feb 19 14:02:48.968: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 10.794394ms)
Feb 19 14:02:48.968: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 9.881701ms)
Feb 19 14:02:48.970: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 12.170121ms)
Feb 19 14:02:48.970: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 11.860343ms)
Feb 19 14:02:48.971: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 13.891722ms)
Feb 19 14:02:48.971: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 13.480904ms)
Feb 19 14:02:48.971: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 13.223726ms)
Feb 19 14:02:48.971: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 13.1897ms)
Feb 19 14:02:48.971: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 13.434483ms)
Feb 19 14:02:48.971: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 13.042899ms)
Feb 19 14:02:48.973: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 14.446341ms)
Feb 19 14:02:48.975: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 16.716276ms)
Feb 19 14:02:48.975: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 16.912041ms)
Feb 19 14:02:48.975: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 17.03377ms)
Feb 19 14:02:48.981: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:443/proxy/... (200; 5.434221ms)
Feb 19 14:02:48.982: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv/proxy/rewriteme"... (200; 5.462213ms)
Feb 19 14:02:48.983: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 6.861588ms)
Feb 19 14:02:48.983: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:160/proxy/: foo (200; 7.006585ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname1/proxy/: foo (200; 15.376839ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname2/proxy/: tls qux (200; 17.251766ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:1080/proxy/rewri... (200; 16.344075ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:460/proxy/: tls baz (200; 16.806454ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname2/proxy/: bar (200; 15.401341ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 16.127334ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/http:proxy-service-vb46r:portname1/proxy/: foo (200; 15.533724ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8n86m/pods/http:proxy-service-vb46r-tdwwv:1080/proxy/... (200; 16.296396ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/proxy-service-vb46r:portname2/proxy/: bar (200; 17.150572ms)
Feb 19 14:02:48.992: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/https:proxy-service-vb46r-tdwwv:462/proxy/: tls qux (200; 16.066553ms)
Feb 19 14:02:48.993: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/pods/proxy-service-vb46r-tdwwv:162/proxy/: bar (200; 16.567256ms)
Feb 19 14:02:48.993: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8n86m/services/https:proxy-service-vb46r:tlsportname1/proxy/: tls baz (200; 15.397415ms)
STEP: deleting { ReplicationController} proxy-service-vb46r in namespace e2e-tests-proxy-8n86m, will wait for the garbage collector to delete the pods
Feb 19 14:02:49.059: INFO: Deleting { ReplicationController} proxy-service-vb46r took: 11.13334ms
Feb 19 14:02:49.159: INFO: Terminating { ReplicationController} proxy-service-vb46r pods took: 100.302923ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 14:02:50.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8n86m" for this suite.
Feb 19 14:02:56.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 14:02:56.905: INFO: namespace: e2e-tests-proxy-8n86m, resource: bindings, ignored listing per whitelist
Feb 19 14:02:57.037: INFO: namespace e2e-tests-proxy-8n86m deletion completed in 6.1706022s

• [SLOW TEST:20.664 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 19 14:02:57.037: INFO: >>> kubeConfig: /tmp/kubeconfig-879726862
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-nb2wv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 19 14:02:57.281: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nb2wv,SelfLink:/api/v1/namespaces/e2e-tests-watch-nb2wv/configmaps/e2e-watch-test-watch-closed,UID:0f2515f8-344f-11e9-b551-525400c68782,ResourceVersion:960898,Generation:0,CreationTimestamp:2019-02-19 14:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 19 14:02:57.281: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nb2wv,SelfLink:/api/v1/namespaces/e2e-tests-watch-nb2wv/configmaps/e2e-watch-test-watch-closed,UID:0f2515f8-344f-11e9-b551-525400c68782,ResourceVersion:960899,Generation:0,CreationTimestamp:2019-02-19 14:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 19 14:02:57.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nb2wv,SelfLink:/api/v1/namespaces/e2e-tests-watch-nb2wv/configmaps/e2e-watch-test-watch-closed,UID:0f2515f8-344f-11e9-b551-525400c68782,ResourceVersion:960900,Generation:0,CreationTimestamp:2019-02-19 14:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 19 14:02:57.301: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nb2wv,SelfLink:/api/v1/namespaces/e2e-tests-watch-nb2wv/configmaps/e2e-watch-test-watch-closed,UID:0f2515f8-344f-11e9-b551-525400c68782,ResourceVersion:960901,Generation:0,CreationTimestamp:2019-02-19 14:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 19 14:02:57.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nb2wv" for this suite.
Feb 19 14:03:03.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 19 14:03:03.446: INFO: namespace: e2e-tests-watch-nb2wv, resource: bindings, ignored listing per whitelist
Feb 19 14:03:03.482: INFO: namespace e2e-tests-watch-nb2wv deletion completed in 6.175335479s

• [SLOW TEST:6.446 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SFeb 19 14:03:03.482: INFO: Running AfterSuite actions on all node
Feb 19 14:03:03.483: INFO: Running AfterSuite actions on node 1
Feb 19 14:03:03.483: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 8414.719 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 2h20m15.847511853s
Test Suite Passed
